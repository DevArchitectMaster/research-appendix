@article{WANG2023119531,
title = {Digital twin-supported smart city: Status, challenges and future research directions},
journal = {Expert Systems with Applications},
volume = {217},
pages = {119531},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.119531},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423000325},
author = {Hao Wang and Xiaowei Chen and Fu Jia and Xiaojuan Cheng},
keywords = {Digital twin, Smart city, Information management, Data management, Literature review},
abstract = {A city can be considered a carrier of multiple sources of data and information that are updated in real time and experiences continuous operation and development. Therefore, a system that can obtain and manage data/information gathered from different physical objects in a city in real time is needed. Digital twin (DT) technology is a virtual representation of an object or system that spans its lifecycle; it is updated from real-time data and uses simulation, machine learning and reasoning to help with decision-making. However, how to apply these features of the DT to better manage smart cities (SCs) has not yet been systematically summarized and analysed. In this study, 202 papers on DT-supported SCs are reviewed, based on which the drivers and challenges of applying DT-supported SCs and the solutions for the challenges were identified. In addition, this study explored the possible outcomes of applying DT-supported technologies in SCs. This study also contributes to the DT-supported SCs for city management research and practice.}
}
@article{RIZWAN2023100698,
title = {Intelligent digital twin for federated learning in AIoT networks},
journal = {Internet of Things},
volume = {22},
pages = {100698},
year = {2023},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2023.100698},
url = {https://www.sciencedirect.com/science/article/pii/S2542660523000215},
author = {Atif Rizwan and Rashid Ahmad and Anam Nawaz Khan and Rongxu Xu and Do Hyeun Kim},
keywords = {Digital twin, Federated learning, AIoT networks, OCF IoTivity},
abstract = {Federated Learning (FL) promises to solve the data privacy problem by training the local model on each node and sharing the model parameters instead of the data itself. Next, the FL server applies model aggregation techniques to aggregate the received models and broadcast the resulting model to the connected clients. This study proposes a Digital Twin-based Federated Learning (DT-FL) framework to virtually monitor and controls the remotely deployed physical clients and their training process. The connection-oriented protocol, Open Connectivity Foundation (OCF) Iotivity, connects the FL clients with the FL server to ensure packet delivery. OCF Iotivity sends/receives the models’ weights to/from the server, and Hyper Text Transfer Protocol (HTTP) is used to monitor clients’ local training. After receiving partially trained models from clients, the server performs the optimal model selection using the normal distribution method by considering the performance of the model. Finally, the best-selected models are aggregated, and the final model is broadcasted to the clients. The framework utilizes Raspberrypi 4 devices as clients with limited computational capabilities, due to which the experiments are conducted with structured energy consumption data. The dataset comprises of 8 multistory residential buildings located in different geographical locations of the Republic of Korea. Each residential building is treated as an FL client and registered on DT using the IP address and port number. The DT-FL framework can be used with classification and regression datasets, and the model architecture for that data can be designed on the DT platform. The experiments are conducted with the partial and full participation of clients. The results show the minimum delay time in physical and virtual object synchronization and better performance and generalization of the global model for each client. The source code of the proposed DT-FL framework is available on GitHub.}
}
@article{FERNANDEZLEON2023105945,
title = {A deep encoder-decoder for surrogate modelling of liquid moulding of composites},
journal = {Engineering Applications of Artificial Intelligence},
volume = {120},
pages = {105945},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.105945},
url = {https://www.sciencedirect.com/science/article/pii/S095219762300129X},
author = {J. Fernández-León and K. Keramati and C. Miguel and C. González and L. Baumela},
keywords = {Composite materials, Liquid moulding, Surrogate models, Deep learning},
abstract = {The paper proposes a surrogate model for liquid moulding of structural composites. A methodology is presented to simulate the dual-phase Darcy’s flow in a heterogeneous porous medium. The approach is an encoder–decoder that receives as input a matrix of permeabilities and produces two scalar fields that represent the pressure and front flow. This model is trained with synthetic data generated with a computer fluid dynamics simulator. In this context, the lack of robustness of models trained with the popular L2 and L1 losses is highlighted and several enhancements to these baseline approaches are introduced. First, the study provides a piece-wise power-logarithmic loss that improves training in the presence of the bimodal distribution of error residuals produced by the dual-phase flow predictions. A non-uniform sampling strategy for the selection of time training snapshots is also included, which contributes to improve the prediction accuracy. The estimation of the front flow field is further refined with a multi-task training strategy. The introduction of these improvements in the baseline models reduce the relative error of the pressure and front flow fields by more than 50%, performing these simulations in a record time of 50 ms. The surrogate model is further evaluated as a digital twin to predict – in a real experiment – the location and spatial extent of race-tracking channels and regions with dissimilar degrees of permeability.}
}
@article{DESANTANA2023103029,
title = {Predicting the need for XAI from high-granularity interaction data},
journal = {International Journal of Human-Computer Studies},
volume = {175},
pages = {103029},
year = {2023},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2023.103029},
url = {https://www.sciencedirect.com/science/article/pii/S1071581923000356},
author = {Vagner Figueredo {de Santana} and Ana Fucs and Vinícius Segura and Daniel Brugnaro {de Moraes} and Renato Cerqueira},
keywords = {Explainability prediction, Fine-grained interaction, Micro behavior, User behavior analysis, Interaction log analysis, Interaction prediction, Node2vec},
abstract = {Recent advances in Artificial Intelligence (AI) and Machine Learning (ML) brought light on the need for explainability in multiple domains (e.g., healthcare, finance, justice, and recruiting). Explainability or Explainable AI (XAI) can be defined as everything that makes AI more understandable to human beings. However, XAI features may vary according to the AI algorithm used. Beyond XAI features, different AI algorithms vary in terms of speed, performance, and costs associated with training/running models. Knowing when to choose the right algorithm for the task at hand, therefore, is fundamental in multiple AI systems, for instance, AutoML and AutoAI. In this paper, we propose a method to analyze patterns of high-granularity user interface (UI) events (i.e., mouse, keyboard, and additional custom events triggered on the millisecond scale) to predict when users will interact with UI elements that provide explainability for the AI in place. In this context, this paper presents: (1) a user study involving 37 participants (7 in the pilot phase and 30 in the main experiment phase) in which people performed a task of reporting a bug using a text form associated with an AI data quality meter and its XAI UI element and (2) an approach to model micro behavior using node2vec to predict when the interaction with XAI UI element will occur. The proposed approach uses a rich dataset (approximately 129k events) and combines node2vec and a Logistic Regression classifier. Results obtained show we have obtained an event-by-event prediction of the interaction with XAI with an average F-score of 0.90 (σ=0.06). From the presented results, one expects to support researchers in the realm of UI personalization to consider high-granularity interaction data when predicting the need for XAI while users are interacting with AI model outputs.}
}
@article{MU2023174,
title = {Toward a smart wire arc additive manufacturing system: A review on current developments and a framework of digital twin},
journal = {Journal of Manufacturing Systems},
volume = {67},
pages = {174-189},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0278612523000237},
author = {Haochen Mu and Fengyang He and Lei Yuan and Philip Commins and Hongmin Wang and Zengxi Pan},
keywords = {WAAM, Additive manufacturing, Digital twin, Process planning, Monitoring, Control, Simulation},
abstract = {In recent years, Wire Arc Additive Manufacturing (WAAM) has attracted increasing scientific attention. With the rise of Industry 4.0 and smart manufacturing, Digital Twin (DT) has become an emerging technology that is finding increased acceptance in Additive Manufacturing (AM) processes. This paper aims to provide a systematic review of current developments of DT in AM processes and then derive a suitable DT for the WAAM system. Firstly, DT developments in AM processes are introduced from supervisory, control, and predictive aspects. This provides a reference and inspiration for designing process DTs by reviewing their structures, algorithms, and methodologies. Secondly, the current research on process planning, monitoring, modeling, online control, and simulation in WAAM is reviewed. Particular attention is given to intelligent algorithms, such as machine learning. Thirdly, the challenges to building a WAAM-DT are introduced step-by-step. Finally, the paper concludes by proposing a framework of WAAM-DT as a hybrid and intelligent solution for monitoring, modeling, control, and simulation.}
}
@article{DUMITRACHE2023955,
title = {Collaborative Decisions in Knowledge Management for Intelligent Cyber-Enterprises},
journal = {Procedia Computer Science},
volume = {221},
pages = {955-962},
year = {2023},
note = {Tenth International Conference on Information Technology and Quantitative Management (ITQM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.074},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923008323},
author = {Ioan Dumitrache and Larisa Stefania Predescu and Simona Iuliana Caramihai and Mihnea Alexandru Moisescu},
keywords = {multi-agent systems, knowledge management, cognitive systems, collaborative decision},
abstract = {The faster and faster IT integration of various categories of activities - from production to administration, passing through medicine, transport, education, government, etc. - led to important changes in terms of obtaining, storing and using data. On the other hand, the increasingly rapid accumulation of societal challenges has exerted immense pressure on the relatively nascent discipline of knowledge management, which is expected to help address increasingly complex issues, primarily related to decision-making aspects that necessitate the selection and transformation of data into information and knowledge. This article focuses on establishing a framework for developing a collaborative, dynamic, heterogeneous decision-making system that includes both human and cybernetic agents as well as digital twins. Such a system creates and sustains a knowledge management flow that is essential for making informed decisions, achieved by selectively collecting and appropriately transforming data into information.}
}
@article{HOSAMO2023112992,
title = {Improving building occupant comfort through a digital twin approach: A Bayesian network model and predictive maintenance method},
journal = {Energy and Buildings},
volume = {288},
pages = {112992},
year = {2023},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2023.112992},
url = {https://www.sciencedirect.com/science/article/pii/S0378778823002220},
author = {Haidar Hosamo Hosamo and Henrik Kofoed Nielsen and Dimitrios Kraniotis and Paul Ragnar Svennevig and Kjeld Svidt},
keywords = {Digital Twin, Building information modeling (BIM), Occupants comfort, Predictive maintenance, Facility management, Decision-making},
abstract = {This study introduces a Bayesian network model to evaluate the comfort levels of occupants of two non-residential Norwegian buildings based on data collected from satisfaction surveys and building performance parameters. A Digital Twin approach is proposed to integrate building information modeling (BIM) with real-time sensor data, occupant feedback, and a probabilistic model of occupant comfort to detect and predict HVAC issues that may impact comfort. The study also uses 200000 points as historical data of various sensors to understand the previous building systems’ behavior. The study also presents new methods for using BIM as a visualization platform and for predictive maintenance to identify and address problems in the HVAC system. For predictive maintenance, nine machine learning algorithms were evaluated using metrics such as ROC, accuracy, F1-score, precision, and recall, where Extreme Gradient Boosting (XGB) was the best algorithm for prediction. XGB is on average 2.5% more accurate than Multi-Layer Perceptron (MLP), and up to 5% more accurate than the other models. Random Forest is around 96% faster than XGBoost while being relatively easier to implement. The paper introduces a novel method that utilizes several standards to determine the remaining useful life of HVAC, leading to a potential increase in its lifetime by at least 10% and resulting in significant cost savings. The result shows that the most important factors that affect occupant comfort are poor air quality, lack of natural light, and uncomfortable temperature. To address the challenge of applying these methods to a wide range of buildings, the study proposes a framework using ontology graphs to integrate data from different systems, including FM, CMMS, BMS, and BIM. This study’s results provide insight into the factors that influence occupant comfort, help to expedite identifying equipment malfunctions and point towards potential solutions, leading to more sustainable and energy-efficient buildings.}
}
@article{BRAGUEZ2023504,
title = {The possibilities of changes in learning experiences with Metaverse},
journal = {Procedia Computer Science},
volume = {219},
pages = {504-511},
year = {2023},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN – International Conference on Project MANagement / HCist – International Conference on Health and Social Care Information Systems and Technologies 2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.318},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923003277},
author = {Joana Braguez and Marta Braguez and Sílvia Moreira and Carla Filipe},
keywords = {Metaverse, virtual reality, augmented reality, virtual worlds, learning experiences},
abstract = {This review aims to define the Metaverse, present the roles of AR, MR and VR, and also the concepts of digital twins and lifelogging. The evolution of applications for Metaverse in various sectors, especially gaming, has created the possibility of using Metaverse for education. We present the vast field of these applications and educational projects. The challenges that educators face are discussed and the potential and limitations of its educational applications are explained. It's suggested to embrace the Metaverse in classes but not in a full-time learning environment, instead, it should be used as a complement, when justified. Some of its limitations may be weaker social connections there are concerns for privacy and security. The big potential offered by Metaverse technologies is the immersive experience of content and social interactions.}
}
@article{SHI2023108172,
title = {Real-time plume tracking using transfer learning approach},
journal = {Computers & Chemical Engineering},
volume = {172},
pages = {108172},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108172},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423000418},
author = {Jihao Shi and Weikang Xie and Junjie Li and Xinqi Zhang and Xinyan Huang and Asif Sohail Usmani and Faisal Khan and Guoming Chen},
keywords = {Natural gas release, Flammable area prediction, Variable-fidelity modeling, Transfer learning, Deep learning, Digital twin for emergency management},
abstract = {Deep learning has been used to track the real-time flammable plume of natural gas. However, a large volume of high-fidelity data is required to train the deep learning model for sufficient accuracy in congested industrial environments, which can be computationally prohibitive. This study proposes a transfer learning-based variable-fidelity approach for real-time plume tracking. A Gaussian dispersion model was applied to efficiently generate a large volume of low-fidelity data, which is then used to pre-train the deep learning model. A limited number of high-fidelity simulations were conducted by solving the Navier-Stokes equation to fine-tune the pre-trained model. A case study demonstrated our proposed approach could reduce high-fidelity computations by 72% while ensuring prediction accuracy with R2=0.96 for released plume area estimation in congested chemical facilities. Optimal number of frozen layers, learning rate and the number of high-fidelity simulations required were determined to ensure adequate efficiency for this approach. This study provides an efficient alternative to improve the generalization of deep learning for real-time plume area estimation for large-scale congested chemical plants.}
}
@article{YUAN2023398,
title = {Digital Twin-Based economic assessment of solar energy in smart microgrids using reinforcement learning technique},
journal = {Solar Energy},
volume = {250},
pages = {398-408},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2022.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X22009021},
author = {Guanghui Yuan and Fei Xie},
keywords = {Smart microgrid, Reinforcement learning, Load scheduling, Demand response, Renewable energy},
abstract = {Utility companies recognize the importance and necessity of demand response (DR) programs for reducing the increased production costs associated with rising energy demand. The advent of smart information and communication systems has made DR programs on the basis of cost a viable option to control load in smart microgrids. Small domestic consumers are rapidly using stochastic renewable energy resources such as photovoltaic (PV). The study examines an integrated layout for residential load scheduling or load commitment problems (LCP) with renewable energy resources no matter what kind of tariff is applied. Uncertainty-based decision-making problems are effectively solved using reinforcement learning (RL). The paper proposes an RL-enabled solution to the LCP in smart microgrids. An innovative aspect of the study is the development of an integrated layout containing an implementable solution that takes into account user satisfaction, stochastic renewable power, and tariffs. In simulation tests, the suggested layout is tested for its effectiveness and flexibility. An analysis of the algorithm's efficiency using a household user with schedule-able and non-schedulable devices, together with a PV resource, has been presented.}
}
@article{SHI2023114244,
title = {Real-time natural gas explosion modeling of offshore platforms by using deep learning probability approach},
journal = {Ocean Engineering},
volume = {276},
pages = {114244},
year = {2023},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2023.114244},
url = {https://www.sciencedirect.com/science/article/pii/S0029801823006285},
author = {Jihao Shi and He Zhang and Junjie Li and Weikang Xie and Wenhua Zhao and Asif Sohail Usmani and Guoming Chen},
keywords = {Natural gas explosion, Offshore platform, Deep learning probability model, Accident reconstruction, Uncertainty estimation},
abstract = {Natural gas explosion of offshore platform is prone to cause accidental disaster such as platform collapse and casualties etc. Real-time natural gas explosion consequence reconstruction is essential to support a quick accidental emergency response planning to prevent the accidental escalation to disaster. The widely-used CFD is computationally intensive and thereby has a significant delay. Machine/deep learning-based models offer a potential real-time alternative, which however are not able to quantify the uncertainty of spatial overpressure prediction. This study aims to propose a hybrid deep learning probability model to real-time predict spatial explosion overpressure of offshore platform by using sparsely-observed overpressures. In this hybrid model, Variational Bayesian inference is incorporated into deep learning backbone. Both natural gas explosion experimental and numerical modeling of offshore platform are conducted to construct the benchmark dataset. By using this benchmark dataset, sensitivity analysis of Monte Carlo sampling number N, drop probability p on model's performance is also conducted. The results demonstrated our model exhibits high accuracy with R2 = 0.955 and real-time capability with inference time of 2.9s. Compared to the state-of-the-art model, the additional uncertainty estimation improves the accuracy and robustness of spatial overpressure prediction, which contributes to the reliable explosion accidental emergency decision-making. Overall, this study provides a reliable alternative for constructing digital twin emergency management system to effectively manage natural gas explosion risk of offshore platforms.}
}
@article{LIU2023104480,
title = {Towards Human-centric Digital Twins: Leveraging Computer Vision and Graph Models to Predict Outdoor Comfort},
journal = {Sustainable Cities and Society},
volume = {93},
pages = {104480},
year = {2023},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2023.104480},
url = {https://www.sciencedirect.com/science/article/pii/S2210670723000914},
author = {Pengyuan Liu and Tianhong Zhao and Junjie Luo and Binyu Lei and Mario Frei and Clayton Miller and Filip Biljecki},
keywords = {Spatial analysis, Walkability, Built environment, Graph neural network, Urban study},
abstract = {Conventional sidewalk studies focused on quantitative analysis of sidewalk walkability at a large scale which cannot capture the dynamic interactions between the environment and individual factors. Embracing the idea of Tech for Social Good, Urban Digital Twins seek AI-empowered approaches to bridge humans with digitally-mediated technologies to enhance their prediction ability. We employ GraphSAGE-LSTM, a geo-spatial artificial intelligence (GeoAI) framework on crowdsourced data and computer vision to predict human comfort on the sidewalks. Conceptualising the pedestrians and their interactions with surrounding built and unbuilt environments as human-centric dynamic graphs, our model captures such spatio-temporal variations given by the sequential movements of human walking, enabling the GraphSAGE-LSTM to be spatio-temporal-explicit. Our experiments suggest that the proposed model provides higher accuracy by more than 20% than a traditional machine learning model and two state-of-art deep learning frameworks, thus, enhancing the prediction power of Urban Digital Twin. The source code for the model is shared openly on GitHub.}
}
@article{LI2023127289,
title = {Uncertainty quantification and aerodynamic robust optimization of turbomachinery based on graph learning methods},
journal = {Energy},
volume = {273},
pages = {127289},
year = {2023},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2023.127289},
url = {https://www.sciencedirect.com/science/article/pii/S0360544223006837},
author = {Jinxing Li and Tianyuan Liu and Guangya Zhu and Yunzhu Li and Yonghui Xie},
keywords = {Uncertainty quantification, Aerodynamic robust optimization, Turbomachinery, Field prediction, Graph neural network},
abstract = {The actual operation of turbomachinery is inevitably affected by multi-source uncertainties. Such uncertainties are detrimental to the performance and reliability of energy systems. Based on graph learning methods, this work aims to provide a convenient and effective approach for aerodynamic robust optimization of turbomachinery. A radial inflow turbine is taken as the research target and Dual Graph Neural Network (DGNN) regression model is constructed for flow field prediction and performance discrimination. By comparing the accuracy and time consumption, the advantages of DGNN over classical surrogate models and computational fluid dynamics (CFD) are clarified. The proposed model is integrated into uncertainty quantification and aerodynamic robust optimization. The effect of multi-source uncertainties on performance is quantified. The stochastic response of flow fields is also obtained conveniently through DGNN. Robust optimization is performed for power and efficiency, respectively. The power robust optimization improves the power by 1.52% and reduces the standard deviation of power by 15.45%. The efficiency robust optimization achieves an efficiency improvement of 1.76% (increment) and an efficiency standard deviation reduction of 36.82%. The proposed approach is an efficient and competitive choice for uncertainty quantification and robust optimization. The present work contributes to constructing the digital twin of turbomachinery systems.}
}
@article{SULTANA202318586,
title = {Biohydrogen from food waste: Modeling and estimation by machine learning based super learner approach},
journal = {International Journal of Hydrogen Energy},
volume = {48},
number = {49},
pages = {18586-18600},
year = {2023},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2023.01.339},
url = {https://www.sciencedirect.com/science/article/pii/S0360319923006249},
author = {Nahid Sultana and S. M. Zakir Hossain and Sumayh S. Aljameel and M.E. Omran and S.A. Razzak and B. Haq and M.M. Hossain},
keywords = {Biohydrogen, Biomethane, Food waste, Bayesian algorithm, Support vector regression, Machine learning},
abstract = {This study demonstrated the application of a hybrid Bayesian algorithm (BA) and support vector regression (SVR) as a potential super-learner tool (BA-SVR) to predict biohydrogen production from food waste-originated feedstocks. The novelty of the present approach, as compared to the existing response surface methodology (RSM), includes (i) hybridization of BA with SVR for modeling of biohydrogen production and minimization of biomethane formation, (ii) performance evaluation and comparison of the developed BA-SVR models with the existing RSM models based on the several indicators such as coefficient of determination (R2), relative error (RE), mean absolute error (MAE), mean absolute percentage error (MAPE), and root mean square error (RMSE), (iii) analysis of the robustness of the model and (iv) testing generalization ability. The calculated values of these indicators suggested that the proposed super leaner models demonstrated better performance predicting the biohydrogen and biomethane (products) responses than those using the existing RSM models - as reported in Rafieenia et al. 2019 [45]. The estimated low errors for biohydrogen: MAE = 0.5919, RMSE = 0.592, MAPE = 11.1387; for biomethane: MAE = 0.2681, RMSE = 0.2688, MAPE = 0.3708, signifie the reliable model predictions. The BA-SVR model also provided high adj R2 (>0.99 for both biohydrogen and biomethane), indicating an excellent fitting of the model. Concerning the MAPE, the proposed BA-SVR models for both the biohydrogen and biomethane responses showed superior performances (as compared to the RSM models) with a performance enhancement of 64.16% and 98.81%, respectively.}
}
@article{SALVADOR2023107402,
title = {Fast and robust parameter estimation with uncertainty quantification for the cardiac function},
journal = {Computer Methods and Programs in Biomedicine},
volume = {231},
pages = {107402},
year = {2023},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2023.107402},
url = {https://www.sciencedirect.com/science/article/pii/S016926072300069X},
author = {Matteo Salvador and Francesco Regazzoni and Luca Dede’ and Alfio Quarteroni},
keywords = {Cardiac electromechanics, Machine Learning, Surrogate modeling, Parameter estimation, Uncertainty quantification},
abstract = {Background and objectives
Parameter estimation and uncertainty quantification are crucial in computational cardiology, as they enable the construction of digital twins that faithfully replicate the behavior of physical patients. Many model parameters regarding cardiac electromechanics and cardiovascular hemodynamics need to be robustly fitted by starting from a few, possibly non-invasive, noisy observations. Moreover, short execution times and a small amount of computational resources are required for the effective clinical translation.
Methods
In the framework of Bayesian statistics, we combine Maximum a Posteriori estimation and Hamiltonian Monte Carlo to find an approximation of model parameters and their posterior distributions. Fast simulations and minimal memory requirements are achieved by using an accurate and geometry-specific Artificial Neural Network surrogate model for the cardiac function, matrix–free methods, automatic differentiation and automatic vectorization. Furthermore, we account for the surrogate modeling error and measurement error.
Results
We perform three different in silico test cases, ranging from the ventricular function to the entire cardiocirculatory system, involving whole-heart mechanics, arterial and venous hemodynamics. By employing a single central processing unit on a standard laptop, we attain highly accurate estimations for all model parameters in short computational times. Furthermore, we obtain posterior distributions that contain the true values inside the 90% credibility regions.
Conclusions
Many model parameters regarding the entire cardiovascular system can be fastly and robustly identified with minimal hardware requirements. This can be achieved when a small amount of non-invasive data is available and when high levels of signal-to-noise ratio are present in the quantities of interest. With these features, our approach meets the requirements for clinical exploitation, while being compliant with Green Computing practices.}
}
@article{WANG202323,
title = {Digital-Twin-Enhanced Quality Prediction for the Composite Materials},
journal = {Engineering},
volume = {22},
pages = {23-33},
year = {2023},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2022.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S2095809923000036},
author = {Yucheng Wang and Fei Tao and Ying Zuo and Meng Zhang and Qinglin Qi},
keywords = {Digital twin, Quality prediction, Composites, Coupling models},
abstract = {Composite materials are widely used in many fields due to their excellent properties. Quality defects in composite materials can lead to lower quality components, creating potential risk of accidents. Experimental and simulation methods are commonly used to predict the quality of composite materials. However, it is difficult to predict the quality of composite materials accurately due to the uncertain curing environment and incomplete feature space. To address this problem, a digital twin (DT) visual model of a composite material is first constructed. Then, a static autoclave DT virtual model is coupled with a variable composite material DT virtual model to construct a model of the curing process. Features are added to the proposed model by generating simulated data to enhance the quality prediction. An extreme learning machine (ELM) for quality prediction is trained with the generated data. Finally, the effectiveness of the proposed method is verified through result analysis.}
}
@article{YANG2023102564,
title = {Automation of SME production with a Cobot system powered by learning-based vision},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {83},
pages = {102564},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102564},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000406},
author = {Xingyu Yang and Zhengxue Zhou and Jonas H. Sørensen and Christoffer B. Christensen and Mikail Ünalan and Xuping Zhang},
keywords = {Collaborative robot, SME production, Learning-based vision, Multi-functional gripper, Digital twin},
abstract = {The features of collaborative robots (cobots), like lightweight, easy programming, and flexibility, meet the production automation requirements in SMEs. However, SME productions are usually in semi-structured or cluttered environments, which raises major challenges in implementing cobot systems in SME production, for instance, increasing the visual perception of cobots, handling diverse tasks, and fast deploying cobot systems, etc. Therefore, we propose an automation framework for SME production by addressing these challenges with cobots to facilitate their production. First, the learning-based vision system is developed and implemented with the You Only Look Once (YOLOv5) for object detection, and with the Convolutional Neural Network cascaded with a Support Vector Machine (CNN-SVM) for quality control of products. Then, the multi-functional gripper system is designed and fabricated to be capable of performing multiple operations and tasks without tool changing, and be able to tolerate a certain level of changes in the environment. After that, a digital twin of the robotic system is developed, which enables the system developer to save time in troubleshooting and debugging, and the customers to have a customized model with all the elements and functions required before system deployment. Finally, the onsite testing of the integrated system is conducted in collaboration with our SME industrial partner, and the test results show that the cobot system can perform the automated production process well and accurately. It is feasible to extend the application of such a cobot system to other SME productions.}
}
@article{OEDA20231191,
title = {A student modeling method combining Deep Learning and forgetting models with Knowledge Tracing},
journal = {Procedia Computer Science},
volume = {225},
pages = {1191-1200},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.107},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923012656},
author = {Shinichi Oeda and Shunichi Hasegawa},
keywords = {Educational Data Mining, Deep Learning, Intelligent Tutoring System, Student Modeling, Knowledge Tracing, Item Response Theory},
abstract = {Educational Data Mining (EDM) aims to enhance education by analyzing learners’ skills and question difficulty levels using machine learning methods. Knowledge Tracing (KT), a subfield of EDM, utilizes Hidden Markov Models to estimate learners’ abilities and predict their performance on unseen questions. While deep learning methods, such as bi-directional RNNs, have improved KT's accuracy, they may lack interpretability from an educational psychology perspective. Item Response Theory (IRT), widely used in educational statistics, offers greater explanatory potential. This study proposes a model that integrates the concept of forgetting into IRT for improved accuracy and explainability in Knowledge Tracing using bi-directional RNNs. The forgetting concept is based on Ebbinghaus’ forgetting curve theory. Three experiments were conducted using synthetic data to compare a model from a previous study, a model based on the proposed method, and a model that combines the previous study's model with IRT but excludes the forgetting concept.}
}
@article{PESHKOVA2023100313,
title = {Digital twin concept: Healthcare, education, research},
journal = {Journal of Pathology Informatics},
volume = {14},
pages = {100313},
year = {2023},
issn = {2153-3539},
doi = {https://doi.org/10.1016/j.jpi.2023.100313},
url = {https://www.sciencedirect.com/science/article/pii/S215335392300127X},
author = {Maria Peshkova and Valentina Yumasheva and Ekaterina Rudenko and Natalia Kretova and Peter Timashev and Tatiana Demura},
keywords = {Digital twins, Databases, Digital pathology, Biobanking},
abstract = {Introducing the concept of digital twins in healthcare, medical education, and research is a complex multistage challenge requiring participation of multidisciplinary teams. In pursuing this goal, we have created a validated database of scans of colorectal tumor slides associated with relevant clinical and histological information. This database is also linked to the blood bank, which opens a wide range of opportunities for further research. Herein, we present our experience within the scope of the digital twins initiative.}
}
@article{SHEN2023377,
title = {Digital twin application for attach detection and mitigation of PV-based smart systems using fast and accurate hybrid machine learning algorithm},
journal = {Solar Energy},
volume = {250},
pages = {377-387},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23000075},
author = {Zhongjie Shen and Wenqing Xu and Weikai Li and Yaoyao Shi and Fan Gao},
keywords = {Cyber security, Hybrid microgrids, Sequential hypothesis testing},
abstract = {Microgrids (MG) is originally designed to make Smart Grids more energy-efficient and reliable. The MG represents a complex cyber-physical system whose functioning is driven by the interaction of physical actions and computational elements, making it vulnerable to many forms of malicious cyber-attack. This study considers the effect of data integrity attack (DIA) on the performance of hybrid MGs, an important cyber threat to microgrids (MGs). Further, this paper develops a new process using sequential hypothesis testing (SHT) for detecting DIA on renewable energy resources and improving the security of information in hybrid MGs. By using a binary sample generated from the suggested approach, an analysis statistic is computed and afterward compared to 2 thresholds for deciding between the 3 options. On the measured energy production of renewable energy sources such as wind turbines, DIAs of various severity levels have been conducted for assessing the impact of DIAs on hybrid MG security. A standard IEEE test system has been used to evaluate the efficiency of the suggested process.}
}
@article{MISHRA2023100724,
title = {Advanced contribution of IoT in agricultural production for the development of smart livestock environments},
journal = {Internet of Things},
volume = {22},
pages = {100724},
year = {2023},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2023.100724},
url = {https://www.sciencedirect.com/science/article/pii/S2542660523000471},
author = {Shailendra Mishra and Sunil Kumar Sharma},
keywords = {Digital twins in livestock farming (DTLF), Internet of Things (IoT), Livestock farming, Artificial intelligence (AI), Machine learning (ML), Global positioning satellite, Radio frequency identification},
abstract = {Many areas of contemporary life need the use of Artificial Intelligence (AI), Machine Learning (ML), and the Internet of Things (IoT) for analysis and comprehension. The application of AI and ML in livestock farming has led to an improved understanding of animal behavior and discomfort, the prevention and management of diseases, and the efficiency of the farmer's economic choices. Digital twin technology is a particularly promising field that builds on AI and is already being utilized to increase efficiency and decrease costs in cattle livestock agriculture. A Digital Twin (DT) is a constant-update numerical copy of smart livestock environments. The proposed research is IoT, and Digital Twins in Livestock Farming (DTLF) might expand extensive Precision Livestock Farming (PLF), technology and tools use, and farm animal health and well-being. Global Positioning Satellite (GPS), Radio Frequency IDentification (RFID), AI, and even ML are only some current technologies that may be used for automated tracking of individual animal whereabouts. There is promise in using these methods and innovations to monitor and evaluate animal welfare, but these techniques are difficult. Just like other revolutionary innovations, the utilization of the DT mechanism will improve disease analysis prediction for individual farms by a factor of 92%. The responsiveness of DTLF will be a 92% response rate in analyzing the Heartbeat, a 94% effectiveness rate in analyzing the Temperature Range, and a 94% overall effectiveness in evaluating the Humidity Range.}
}
@article{ARSIWALA2023112851,
title = {Digital twin with Machine learning for predictive monitoring of CO2 equivalent from existing buildings},
journal = {Energy and Buildings},
volume = {284},
pages = {112851},
year = {2023},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2023.112851},
url = {https://www.sciencedirect.com/science/article/pii/S0378778823000816},
author = {Arva Arsiwala and Faris Elghaish and Mohammed Zoher},
keywords = {Digital Twin, BIM, Internet of things (IoT), Artificial Intelligence (AI), Big Data (BD), Net zero, Sustainability, Carbon emission},
abstract = {The revolution of the industry 4.0 presents a new era of digital transformation for the construction industry, advancing towards the concept of digital twins, while on the other hand it faces the global challenge of reducing carbon emissions from operational assets. The current research gap in the application of digital twins for achieving net zero were reviewed in this study, highlighting its potentials for enhancement in the built environment, and emphasizing the need for demonstration of a use-case analysis for its adoption by the industry. This research presents a digital twin solution to automate the monitoring and controlling of equivalent carbon dioxide (eCO2) emissions from existing assets through the integration of IoT, BIM, and artificial intelligence across a comprehensive solution, further validating its workability through a real-life use case analysis. The study revealed the significance of BIM and IoT, as essential components of a digital twin to visualise critical spatial information for enhanced facility management specifically for monitoring of indoor air quality of spaces, while also coalescing an AI-supported system to predict carbon emissions from the collected data through integration of machine learning features across the digital twin. The output of the entire solution is displayed as an interactive dashboard for observing trends and patterns, enabling stakeholders to implement effective data-driven retrofitting strategies. This research is a fundamental initiation for implementing digital twins to monitor emissions from existing assets, a step towards achieving the net zero targets.}
}
@incollection{SU2023309,
title = {Chapter 16 - Outlook of future landscape of artificial intelligence in health care of liver disease and challenges},
editor = {Tung-Hung Su and Jia-Horng Kao},
booktitle = {Artificial Intelligence, Machine Learning, and Deep Learning in Precision Medicine in Liver Diseases},
publisher = {Academic Press},
pages = {309-322},
year = {2023},
isbn = {978-0-323-99136-0},
doi = {https://doi.org/10.1016/B978-0-323-99136-0.00008-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323991360000088},
author = {Tung-Hung Su and Jia-Horng Kao},
keywords = {Future medicine, Health care, Innovation, Precision medicine, Workflow},
abstract = {Artificial intelligence (AI) is growing in importance in hepatology. Various sources of data from electric health records, radiology, and pathology have been used to develop AI models for nonalcoholic fatty liver disease, viral hepatitis, cirrhosis, acute liver failure, liver transplantation, hepatocellular carcinoma, drug-induced liver injury, and precision medicine. AI will soon be integrated in the clinical workflow to manage liver disease, although several issues need to be considered. AI will facilitate interdisciplinary care and collaboration with physicians, but it will not replace them. Data are crucial in the development of AI algorithms, whereas the collection and standardization of medical data from various sources are important to develop AI models, so data disparity and security should be carefully managed. The deployment and efficacy of AI models should be evaluated in clinical scenarios. Several novel fields of AI research involve training models using multimodal data and multiomics data. Advances in natural language processing help to explore unstructured electric health records. Digital epidemiology, digital twins, and federated learning are other trends. Telemedicine and self-monitoring using multiple wearable devices facilitate a useful paradigm of health care. The era of AI will transform the health care of liver disease.}
}
@article{HUANG2023102545,
title = {Hybrid learning-based digital twin for manufacturing process: Modeling framework and implementation},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {82},
pages = {102545},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102545},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000212},
author = {Ziqi Huang and Marcel Fey and Chao Liu and Ege Beysel and Xun Xu and Christian Brecher},
keywords = {Digital twin, Digital shadow, Artificial intelligence, Machine tool, Smart manufacturing},
abstract = {Digital twin (DT) and artificial intelligence (AI) technologies are powerful enablers for Industry 4.0 toward sustainable resilient manufacturing. Digital twins of machine tools and machining processes combine advanced digital techniques and production domain knowledge, facilitate the enhancement of agility, traceability, and resilience of production systems, and help machine tool builders achieve a paradigm shift from one-time products provision to on-going service delivery. However, the adaptability and accuracy of digital twins at the shopfloor level are restricted by heterogeneous data sources, modeling precision as well as uncertainties from dynamical industrial environments. This article proposes a novel modeling framework to address these inadequacies by in-depth integrating AI techniques and machine tool expertise using aggregated data along the product development process. A data processing procedure is constructed to contextualize metadata sources from the design, planning, manufacturing, and quality stages and link them into a digital thread. On this consistent data basis, a modeling pipeline is presented to incorporate production and machine tool prior knowledge into AI development pipeline, while considering the multi-fidelity nature of data sources in dynamic industrial circumstances. In terms of implementation, we first introduce our existing work for building digital twins of machine tool and manufacturing process. Within this infrastructure, we developed a hybrid learning-based digital twin for manufacturing process following proposed modeling framework and tested it in an external industrial project exemplarily for real-time workpiece quality monitoring. The result indicates that the proposed hybrid learning-based digital twin enables learning uncertainties of the interaction of machine tools and machining processes in real industrial environments, thus allows estimating and enhancing the modeling reliability, depending on the data quality and accessibility. Prospectively, it also contributes to the reparametrization of model parameters and to the adaptive process control.}
}
@incollection{NALINI2023185,
title = {Chapter 10 - Impact of internet of things and digital twin on manufacturing era},
editor = {Rajesh Kumar Dhanaraj and Ali Kashif Bashir and Vani Rajasekar and Balamurugan Balusamy and Pooja Malik},
booktitle = {Digital Twin for Smart Manufacturing},
publisher = {Academic Press},
pages = {185-202},
year = {2023},
isbn = {978-0-323-99205-3},
doi = {https://doi.org/10.1016/B978-0-323-99205-3.00010-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323992053000109},
author = {M. Nalini and M.R. Bharathkumar and R. Keerthivasan and N. Nithyashree and V. Dhanashree},
keywords = {Automation, interlink, less human interaction, simulation, monitoring, analytics},
abstract = {Every piece of information gathered must be shared and used effectively without compromising security. The digital twin and the Internet of Things (IoT) are two sides of the same technological coin. Both aspects have a similar sounding name, however, they are not the same. The backbone of IoT is referred to as a digital twin. Before real data can perform, it must be simulated and processed, which is what the digital twin and IoT combine to provide. In almost every other company, these qualities have been instilled in numerous fields. The main difference between digital twin and the IoT is that the digital twin is a real-time virtual representation of any plan or object using technologies such as reasoning, simulation, complex decision-making, and machine learning, whereas IoT is a network connected to physical devices that run, process, and act on data. Clearly, the proliferation of IoT devices contributes to the possibility of digital twins. Furthermore, as IoT devices improve, digital twin might be incorporated in smaller and less sophisticated products, providing significant benefits to businesses.}
}
@article{SEMERARO2023127086,
title = {Digital twin in battery energy storage systems: Trends and gaps detection through association rule mining},
journal = {Energy},
volume = {273},
pages = {127086},
year = {2023},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2023.127086},
url = {https://www.sciencedirect.com/science/article/pii/S0360544223004802},
author = {Concetta Semeraro and Haya Aljaghoub and Mohammad Ali Abdelkareem and Abdul Hai Alami and A.G. Olabi},
keywords = {Digital twin, Battery energy storage system, Formal concept analysis, Association rule mining, Unsupervised machine learning},
abstract = {Energy sector is being revolutionized with the introduction of digitalization technologies. Digitalization technologies converted conventional energy grids into smart grids. Therefore, the virtual representation of battery energy storage systems, known as a digital twin, has become a highly valuable tool in the energy industry. This technology seamlessly integrates battery energy storage systems into smart grids and facilitates fault detection and prognosis, real-time monitoring, temperature control, optimization, and parameter estimations. In general, the use of digital twin technology improves the efficiency of the battery system after a thorough assessment of the battery performance. Hence, this paper aims to review the advancements of digital twin technology in battery energy storage systems. In particular, this paper focuses on the different functions and architectures of the digital twin for battery energy storage systems. Then, this paper further analyzes the digital twin characteristics using the Formal Concept Analysis (FCA) algorithm. The FCA is run to find trends and gaps between the digital twin functions and architectures in the battery system. Exploring the trends and gaps from previous research associated with the integration of digital twin with battery energy systems is essential to pave the way for further enhancements in this field.}
}
@article{PIRES2023103884,
title = {Reinforcement learning based trustworthy recommendation model for digital twin-driven decision-support in manufacturing systems},
journal = {Computers in Industry},
volume = {148},
pages = {103884},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.103884},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523000349},
author = {Flávia Pires and Paulo Leitão and António Paulo Moreira and Bilal Ahmad},
keywords = {Digital twin, Decision-support, Recommendation systems, Similarity measures, Trust-based model},
abstract = {Digital twin is one promising and key technology that emerged with Industry 4.0 to assist the decision-making process in multiple industries, enabling potential benefits such as reducing costs, and risk, improving efficiency, and supporting decision-making. Despite these, the decision–making approach of carrying out a what-if simulation study using digital twin models of each and every possible scenario independently is time-consuming and requires significant computational resources. The integration of recommendation systems within the digital twin-driven decision-support framework can support the decision-making process by providing targeted scenario recommendations, reducing the decision-making time and imposing decision- making efficiency. However, recommendation systems have inherent challenges, such as cold-start, data sparsity, and prediction accuracy. The integration of trust and similarity measures with recommendation systems alleviates the challenges mentioned earlier, and the integration of machine learning techniques enables better recommendations through their ability to simulate human learning. Having this in mind, this paper proposes a trust-based recommendation approach using a reinforcement learning technique combined with similarity measures, which can be integrated within a digital twin-based what-if simulation decision-support system. This approach was experimentally validated by performing accurate recommendations in an industrial case study of a battery pack assembly line. The results show improvements in the proposed model regarding the accuracy of the prediction about the user rating of the recommended scenarios over the state-of-the-art recommendation approaches, particularly in cold-start and data sparsity scenarios.}
}
@article{FANG2023109108,
title = {Self-supervised intermittent fault detection for analog circuits guided by prior knowledge},
journal = {Reliability Engineering & System Safety},
volume = {233},
pages = {109108},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109108},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023000236},
author = {Xiaoyu Fang and Jianfeng Qu and Yi Chai},
keywords = {Self-supervised learning, Prior knowledge, Teacher–student model, Intermittent fault detection, Analog circuits},
abstract = {Intermittent faults (IFs) are common in electronic systems, which are short-term, repeatable and cumulative. IF samples are difficult to collect, so detection is usually performed using one-class learning approaches, which require only fault-free samples to participate in the training. Teacher–student model typically uses the cognitive biases of teacher and student on fault signals to detect faults. Introducing prior knowledge of IFs in the teacher model may help to produce greater fault cognitive bias and thus improve detection. Inspired by this, this paper proposes a prior knowledge-guided teacher–student (PKGTS) model based on self-supervised learning. In analog circuits, IFs cause transient changes in the circuit signal in terms of amplitude, frequency, and waveform. Therefore, based on this prior knowledge, corresponding signal transformations are designed to simulate possible fault variations and introduce prior knowledge to the teacher through a pretext task. Finally, only the knowledge of the teacher’s fault-free state is imparted to the student. During the testing phase, IF detection is achieved through the cognitive biases of faults, as the student model does not have prior knowledge of faults. In two typical analog filtering circuit experiments, the effectiveness of the proposed method under different noise levels and fault intensities is verified.}
}
@article{ABDELRAHMAN2023110511,
title = {Learning data teaching strategies via knowledge tracing},
journal = {Knowledge-Based Systems},
volume = {269},
pages = {110511},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110511},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123002617},
author = {Ghodai Abdelrahman and Qing Wang},
keywords = {Knowledge tracing, Machine teaching, Reinforcement learning, Key-value memory network, Attention},
abstract = {Teaching plays a fundamental role in human learning. Typically, a human teaching strategy involves assessing a student’s knowledge progress for tailoring the teaching materials to enhance the learning progress. A human teacher can achieve this by tracing a student’s knowledge over essential learning concepts in a task. Albeit, such a teaching strategy is not well exploited yet in machine learning as current machine teaching methods tend to directly assess the progress of individual training samples without paying attention to the underlying learning concepts in a learning task. In this paper, we propose a novel method, called Knowledge Augmented Data Teaching (KADT), which can optimize a data teaching strategy for a student model by tracing its knowledge progress over multiple learning concepts in a learning task. Specifically, the KADT method incorporates a knowledge tracing model to dynamically capture the knowledge progress of a student model in terms of latent learning concepts. We further develop an attention-pooling mechanism to distill knowledge representations of a student model with respect to class labels, which enables to develop a data teaching strategy on critical training samples. We have evaluated the performance of the KADT method on four different machine learning tasks, including knowledge tracing, sentiment analysis, movie recommendation, and image classification. The KADT method consistently outperforms the state-of-the-art methods on all these tasks.}
}
@article{ZHOU202329,
title = {Digital twin application for reinforcement learning based optimal scheduling and reliability management enhancement of systems},
journal = {Solar Energy},
volume = {252},
pages = {29-38},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.01.042},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23000506},
author = {Jun Zhou and Mei Yang and Yong Zhan and Li Xu},
keywords = {Demand response, Photovoltaic, Energy storages, Smart home scheduling, Reinforcement learning, digital twin simulation},
abstract = {Increasing populations and economic expansion have substantially increased the energy requirements of residential consumers. Energy storage system (ESS) and distributed generation (DGs) are key tools for tackling this problem in smart homes. This study investigates the cost of electricity for residential consumers as a result of the combination of distributed photovoltaics (PVs) and ESSs for IoT-based smart home. Moreover, this paper examines energy management advantages due to bidirectional energy flow (H2G). In order to formulate the home energy management issue, PV and ESS end-user satisfaction limitations are taken into account. This study exploits a Q value-enabled reinforcement learning (RL) method to optimize home appliance scheduling (HAS) according to end-user priority. According to simulation outcomes, the suggested scheduling for household appliances performs well, and demand response (DR) measures have been implemented. It can be seen that the cost of electricity consumption as well as the uncertainty of the system have decreased in digital twin real-based application.}
}
@incollection{GU2023773,
title = {Chapter 23 - Summary and outlook of future directions and perspectives for additive manufacturing research and development},
editor = {Dongdong Gu},
booktitle = {Laser Additive Manufacturing of Metallic Materials and Components},
publisher = {Elsevier},
pages = {773-782},
year = {2023},
series = {Additive Manufacturing Materials and Technologies},
isbn = {978-0-12-823783-0},
doi = {https://doi.org/10.1016/B978-0-12-823783-0.00012-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128237830000127},
author = {Dongdong Gu},
keywords = {Digital twins, Digitized material, Hybrid manufacturing, Intelligent manufacturing, Machine learning, Materials genome initiative},
abstract = {The material-structure-performance-integrated additive manufacturing (MSPI-AM), as a concept embodied throughout this book, continues to develop into a practical methodology that contributes to the high performance and multifunctionality goals of AM. Many opportunities exist to enhance MSPI-AM. MSPI-AM relies on a more digitized material and structure development and printing, which could be accomplished by considering different paradigms for AM materials discovery with the Materials Genome Initiative, standardization of formats for digitizing materials and structures to accelerate data aggregation, and a systematic printability database to enhance autonomous decision-making of printers. MSPI-oriented AM becomes more intelligent in processes and production, with the integration of intelligent detection, sensing, and monitoring; big-data statistics and analytics; machine learning; and digital twins. MSPI-AM further calls for more hybrid approaches to yield the final high-performance/multifunctional achievements, with more versatile materials selection and more comprehensive integration of virtual manufacturing and real production to navigate more complex printing. We hope that MSPI-AM can become a key strategy for the sustainable development of AM technologies.}
}
@article{YU2023104627,
title = {Conditional generative data-free knowledge distillation},
journal = {Image and Vision Computing},
volume = {131},
pages = {104627},
year = {2023},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2023.104627},
url = {https://www.sciencedirect.com/science/article/pii/S026288562300001X},
author = {Xinyi Yu and Ling Yan and Yang Yang and Libo Zhou and Linlin Ou},
keywords = {Data-free knowledge distillation, Generative adversarial networks, Model compression, Convolutional neural networks},
abstract = {Knowledge distillation has made remarkable achievements in model compression. However, most existing methods require the original training data, which is usually unavailable due to privacy and security issues. This paper proposes a conditional generative data-free knowledge distillation (CGDD) framework for training lightweight networks without real data. This framework realizes efficient knowledge distillation based on conditional image generation. Specifically, we treat the preset labels as ground truth to train a semi-supervised conditional generator. The trained generator can produce specified classes of training images. During training, we force the student model to extract the hidden knowledge in teacher feature maps, which provide crucial cues to the learning process. Meanwhile, we construct an adversarial training framework to promote distillation performance. The framework will help the student model to explore larger data space. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on different datasets. Compared with other data-free works, our method obtains state-of-the-art results on CIFAR100, Caltech101, and different versions of ImageNet datasets. The codes will be released.}
}
@incollection{SINGH2023221,
title = {Chapter 12 - Potential applications of digital twin technology in virtual factory},
editor = {Rajesh Kumar Dhanaraj and Ali Kashif Bashir and Vani Rajasekar and Balamurugan Balusamy and Pooja Malik},
booktitle = {Digital Twin for Smart Manufacturing},
publisher = {Academic Press},
pages = {221-241},
year = {2023},
isbn = {978-0-323-99205-3},
doi = {https://doi.org/10.1016/B978-0-323-99205-3.00011-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780323992053000110},
author = {Anamika Singh and Md. Akkas Ali and Balamurugan Balusamy and Vandana Sharma},
keywords = {Digital twin, model of digital twin, simulation, product lifecycle, virtual reality},
abstract = {In the recent years, the digital twin technology has become an emerging approach, especially for the manufacturing sectors, and also is considered the center of attention for the industries and, currently to the academic sector as well. It can be understood as the virtual model drawn to show the replica of the physical model. The technology has expanded its importance to various sectors ranging from businesses to aircraft manufacturing, from academics to healthcare, and more. This approach integrates big data, artificial intelligence (AI), Internet of Things (IoT), and machine learning (ML), which are the core concepts of Industry 4.0. The IoT is a widespread concept in todays industries, which has rendered the twin technology more cost-effective and user friendly for the industrial as well as the business world. Digital twin technology represents the blueprint of the product or service being manufactured and works throughout the lifecycle of the system. Digital twin results as the emerging concept to the fourth revolution of the industries with immense opportunities. With further advancements in ML and AI, it is expected to lead the machines to the next level. It is a key concept for cyber-physical system. This chapter mainly explains: 1.Introduction and history of digital twin technology2.Types of digital twin technology and its conceptual model3.Working of digital twin technology4.Potential applications of digital twin in virtual factory.5.How it differs from simulation.}
}
@article{DUPUIS2023354,
title = {Forecasting Future Product Sequences To Be Processed In Tire Production Using Deep Learning Technique},
journal = {Procedia Computer Science},
volume = {219},
pages = {354-361},
year = {2023},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN – International Conference on Project MANagement / HCist – International Conference on Health and Social Care Information Systems and Technologies 2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.300},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923003095},
author = {Ambre Dupuis and Camélia Dadouchi and Bruno Agard and Robert Pellerin},
keywords = {Industry 4.0, Production sequencing, Sequence analysis, RNN, Seq2Seq},
abstract = {Production sequencing methodology using DeepLearning Seq2Seq-LSTM is applied to a tire production case study in Quebec, Canada. Production and demand data are used to predict the most likely product sequences to operate. The comparison of 4 forecasting models, differing in consideration of demand and a statistical component, leads to nearly 70% of good prediction when all machines are studied and 10 production scenarios are considered. This performance reaches 92% for a specific class of machines. The analysis of the forecasts by class of machine allows highlighting 2 factors influencing the performance of the models, namely the ratio of product/machine by class and the total number of available records. The forecasts of possible production scenarios can then be used in a digital twin to evaluate a reasonable number of options and develop a decision support system for production sequencing.}
}
@incollection{ICHIMURA2023129,
title = {Chapter 5 - A Teacher–Student-based adaptive structural deep learning model and its estimating uncertainty of image data},
editor = {Steven G. Krantz and Arni S.R. {Srinivasa Rao} and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {49},
pages = {129-149},
year = {2023},
booktitle = {Artificial Intelligence},
issn = {0169-7161},
doi = {https://doi.org/10.1016/bs.host.2023.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169716123000226},
author = {Takumi Ichimura and Shin Kamada and Toshihide Harada and Ken Inoue},
keywords = {Adaptive structural learning, Ensemble deep learning, Teacher–Student model, Deep belief network, Restricted Boltzmann machine, Alzheimer's disease},
abstract = {Deep learning has been successfully used as a model that can effectively represent multiple features of the input space and significantly improve image recognition performance on deep architectures. Adaptive structural learning methods of restricted Boltzmann machines (Adaptive RBM) and deep belief networks (Adaptive DBN) have been developed as self-organizing deep learning models. The model uses a neuron generation–annihilation algorithm to find the optimal number of hidden neurons in the RBM for a given input data and then layers a new RBM as a hidden layer on top of the trained RBM to obtain the appropriate DBN structure. The proposed learning model was applied to PET and MRI image data sets in ADNI digital archive for the early detection of MCI (Mild Cognitive Impairment) and AD (Alzheimer's Disease). Two deep learning models were constructed to classify the PET and MRI images, respectively. For the training set, our model showed 99.7% and 99.2% classification accuracy for PET and MRI images, and for the test set, the model showed 98.8% and 96.7% accuracy for them. The Adaptive DBN model achieved the highest classification accuracy among the other CNN models. Moreover, the Teacher–Student-based Adaptive DBN was developed as an ensemble learning to improve the classification power for the test data set of MRI images and the accuracy increased to 98.3%. The accuracy of AD vs CN, MCI vs CN, and MCI vs AD for the MRI images by Teacher–Student-based Adaptive DBN are 98.4%, 98.8%, and 97.8%, respectively. Moreover, the difference between the diagnostic results by the proposed deep learning model and Medical Questionnaire was discussed.}
}
@article{ZHONG2023104791,
title = {Blockchain-driven integration technology for the AEC industry},
journal = {Automation in Construction},
volume = {150},
pages = {104791},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104791},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523000511},
author = {Botao Zhong and Xing Pan and Lieyun Ding and Qiang Chen and Xiaowei Hu},
keywords = {Architecture, engineering, and construction (AEC), Blockchain-driven integration technology (BDIT), Critical review, Technological developments, Technological applications, Further evolutions},
abstract = {In the architecture, engineering, and construction (AEC) industry, blockchain-driven integration technology (BDIT) has witnessed rapid development. A critical literature review of BDIT can contribute toward innovation for the AEC industry. In this study, a quantitative mapping of 247 BDIT literatures from 2017 to 2022 was conducted. Following the clue of quantitative work, two critical levels of technological development and application for BDIT were analyzed. The findings suggest: (1) the technological developments of BDIT may involve technological integration (i.e., integration of blockchain and internet of thing/building information modeling/edge computing) and knowledge framework; and (2) the technological applications of BDIT may involve information automation management and building information management. To further explore the trends of BDIT, some future evolutions (i.e., integration of blockchain and federated learning/digital twin/cloud-edge-end), application scenarios and challenges of BDIT were discussed. This study provides valuable theoretical and practical references for future research on BDIT in the AEC industry.}
}
@article{WU2023100443,
title = {Internet of Everything and Digital Twin enabled Service Platform for Cold Chain Logistics},
journal = {Journal of Industrial Information Integration},
volume = {33},
pages = {100443},
year = {2023},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2023.100443},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X2300016X},
author = {Wei Wu and Leidi Shen and Zhiheng Zhao and Arjun Rachana Harish and Ray Y. Zhong and George Q. Huang},
keywords = {Service platform, Internet of everything, Digital twin, Cold chain logistics, Abnormal stationary detection, Indoor positioning},
abstract = {The proliferation of the e-commerce market has posed challenges to staff safety, product quality, and operational efficiency, especially for cold chain logistics (CCL). Recently, the logistics of vaccine supply under the worldwide COVID-19 pandemic rearouses public attention and calls for innovative solutions to tackle the challenges remaining in CCL. Accordingly, this study proposes a cyber-physical platform framework applying the Internet of Everything (IoE) and Digital Twin (DT) technologies to promote information integration and provide smart services for different stakeholders in the CCL. In the platform, reams of data are generated, gathered, and leveraged to interconnect and digitalize physical things, people, and processes in cyberspace, paving the way for digital servitization. Deep learning techniques are used for accident identification and indoor localization based on Bluetooth Low Energy (BLE) to actualize real-time staff safety supervision in the cold warehouse. Both algorithms are designed to take advantage of the IoE infrastructure to achieve online self-adapting in response to surrounding evolutions. Besides, with the help of mobile and desktop applications, paperless operation for shipment, remote temperature and humidity (T&H) monitoring, anomaly detection and warning, and customer interaction are enabled. Thus, information traceability and visibility are highly fortified in this way. Finally, a real-life case study is conducted in a pharmaceutical distribution center to demonstrate the feasibility and practicality of the proposed platform and methods. The dedicated hardware and software are developed and deployed on site. As a result, the effectiveness of staff safety management, operational informatization, product quality assurance, and stakeholder loyalty maintenance shows a noticeable improvement. The insights and lessons harvested in this study may spark new ideas for researchers and inspire practitioners to meet similar needs in the industry.}
}
@article{PAN2023355,
title = {Real-time digital twin machine learning-based cost minimization model for renewable-based microgrids considering uncertainty},
journal = {Solar Energy},
volume = {250},
pages = {355-367},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23000063},
author = {Mingyu Pan and Qijing Xing and Zhichao Chai and He Zhao and Qinfei Sun and Dapeng Duan},
keywords = {Reinforcement learning, Energy management, Markov chain scheme, Renewable-based microgrid, Digital twin},
abstract = {This research study aims to investigate the microgrid operation for distributing energy including of a local user, a wind turbine, 5 photovoltaics (PV), and a battery, which is linked by a transformer to the external network. This paper examines a reinforcement learning (RL) method that uses 2steps-ahead to schedule the batteries, which is essential for achieving the objective of the users. There is an essential architecture to make multi-criteria decisions via an individual user to increase the battery's usage at peak times and increase the wind turbine's usage for local consumption. RL algorithms select the optimum battery planning measures based on forecasts of wind power and photovoltaic availability. Through the suggested learning, the user can better understand the optimum battery planning measures for various time-varying environment factors. By using the proposed architecture, smart users are capable of learning the uncertain environment and selecting optimum energy management measures based on their experiences.}
}
@article{BUHALIS2023104724,
title = {Metaverse as a disruptive technology revolutionising tourism management and marketing},
journal = {Tourism Management},
volume = {97},
pages = {104724},
year = {2023},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2023.104724},
url = {https://www.sciencedirect.com/science/article/pii/S0261517723000067},
author = {Dimitrios Buhalis and Daniel Leung and Michael Lin},
keywords = {Metaverse, Immersive experience, Virtual experience, Information communication technologies},
abstract = {Metaverse is the next disruptive technology that will impact society in the coming decades, by enabling immersive experiences in both virtual and physical environments. Although still conceptual, Metaverse converges the physical and digital universe, allowing users to seamlessly traverse between them. Digital immersion offers opportunities for people to travel in time, supporting users to experience virtually ancient encounters, space explorations or dangerous natural phenomena, such as volcano eruptions. Users can explore immersive environments for working, learning, transacting, exploring interests and socialising with others. This is already evident in gaming ecosystems, where gamers effectively interact in the metaverse. Although still experimental, Metaverse is expected to revolutionize travel and tourism management and marketing. It empowers destination awareness, positioning and branding, as well as coordination and management, through digital twins. Metaverse provides opportunities to support trip planning, interaction and engagement, effectively transforming consumer behaviour. Visiting and engaging with destinations virtually is expected to motivate real travel, rather than replace it. This paper provides a vision of how Metaverse can revolutionize tourism experiences and transform tourism management and marketing. Drawing on a systematic review of scholarly works, articles from media and industry reports, this study defines and conceptualizes the Metaverse ecosystem for tourism and travel. It explores the foundations of the disruptions that Metaverse brings to tourism destinations and organisations and identifies the building blocks of Metaverse tourism. The study outlines research directions so that the tourism industry can take full advantage of the Metaverse capabilities and opportunities emerging as well as identify challenges for the future.}
}
@article{TRIPURA2023107008,
title = {Probabilistic machine learning based predictive and interpretable digital twin for dynamical systems},
journal = {Computers & Structures},
volume = {281},
pages = {107008},
year = {2023},
issn = {0045-7949},
doi = {https://doi.org/10.1016/j.compstruc.2023.107008},
url = {https://www.sciencedirect.com/science/article/pii/S004579492300038X},
author = {Tapas Tripura and Aarya Sheetal Desai and Sondipon Adhikari and Souvik Chakraborty},
keywords = {Predictive digital twin, Model update, Probabilistic machine learning, Stochastic differential equation},
abstract = {A framework for creating and updating digital twins for dynamical systems from a library of physics-based functions is proposed. The sparse Bayesian machine learning is used to update and derive an interpretable expression for the digital twin. Two approaches for updating the digital twin are proposed. The first approach makes use of both the input and output information from a dynamical system, whereas the second approach utilizes output-only observations to update the digital twin. Both methods use a library of candidate functions representing certain physics to infer new perturbation terms in the existing digital twin model. In both cases, the resulting expressions of updated digital twins are identical, and in addition, the epistemic uncertainties are quantified. In the first approach, the regression problem is derived from a state-space model, whereas in the latter case, the output-only information is treated as a stochastic process. The concepts of Itô calculus and Kramers-Moyal expansion are being utilized to derive the regression equation. The performance of the proposed approaches is demonstrated using highly nonlinear dynamical systems such as the crack-degradation problem. Numerical results demonstrated in this paper almost exactly identify the correct perturbation terms along with their associated parameters in the dynamical system. The probabilistic nature of the proposed approach also helps in quantifying the uncertainties associated with updated models. The proposed approaches provide an exact and explainable description of the perturbations in digital twin models, which can be directly used for better cyber-physical integration, long-term future predictions, degradation monitoring, and model-agnostic control.}
}
@article{SAITO20232892,
title = {Proposal of Cyber Range for Control System based on Virtual Commissioning Technology},
journal = {Procedia Computer Science},
volume = {225},
pages = {2892-2901},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.282},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923014400},
author = {Taishin Saito and Sou Takahashi and Jun Sato and Miki Matsunoki and Toshiyuki Kanmachi and Satoru Yamada and Kuniaki Yajima},
keywords = {Cyber Security, Security Education, Operational Technology, Industrial Control System, Cyber Range},
abstract = {Manufacturing companies are rapidly moving toward Digitalization. As a result, today's industrial systems integrate information systems and manufacturing systems. In this context, damage caused by cyber-attacks has become apparent, and cyber-attacks on factories are increasing both in Japan and overseas. Therefore, there is an increasing need to implement cyber security measures and education in manufacturing and factories from the BCP (Business Continuity Plan) perspective, which considers safety measures for individual processes and the supply chain. The industrial automation industry is beginning to develop designs through virtual commissioning based on VR product (digital twin) models, and all of this development work is increasingly taking place in virtual space. However, no security educational materials utilize CPS (Cyber-Physical Space), which is free from time and space, based on these technologies. This research aims to develop human resources who can respond to the paradigm shift and realize a suitable environment for cyber security education by constructing a remote training environment using VR product technology that can actually be used in student experiments and practical training.}
}
@article{ZHANG2023129094,
title = {Multi-step ahead probabilistic forecasting of multiple hydrological variables for multiple stations},
journal = {Journal of Hydrology},
volume = {617},
pages = {129094},
year = {2023},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2023.129094},
url = {https://www.sciencedirect.com/science/article/pii/S0022169423000367},
author = {Zhendong Zhang and Haihua Tang and Hui Qin and Bin Luo and Chao Zhou and Huayan Zhou},
keywords = {River Basin Digital Twin, Hydrological forecasting, Probabilistic forecasting, Deep learning},
abstract = {The demand for more accurate simulation of physical river basin puts forward higher requirements on the number of hydrological forecast stations, types of hydrological variables, forecast accuracy, forecast period and quantitative uncertainty. Therefore, how to simultaneously obtain multi-step ahead probabilistic forecasting of multiple hydrological variables for multiple stations is a key issue to be solved in this study. Firstly, the background of River Basin Digital Twin is introduced and the new problems faced by hydrological forecasting in this background are analyzed. Then, the input and output of hydrological forecasting are reconstructed into 4-D tensors. Next, a new hybrid deep learning model (B-CM-C3D) based on 3-D Convolutional Neural Network, Convolutional Minimum Gate Memory Neural Network and Variational Bayesian Neural Network is proposed to obtain multi-step ahead probabilistic forecasting of multiple hydrological variables for multiple stations. Finally, in order to verify the performance of this model, it was compared with four state-of-the-art models in the Yangtze River Basin. The experimental results show that: (1) the deterministic prediction accuracy and probabilistic forecasting comprehensive performance of B-CM-C3D are better than other comparison models in 80% of the results. (2) B-CM-C3D shortens the training time of B-CL-C3D by 43% and improves the prediction accuracy.}
}
@article{SOO2023529,
title = {MachIne learning for nutrient recovery in the smart city circular economy – A review},
journal = {Process Safety and Environmental Protection},
volume = {173},
pages = {529-557},
year = {2023},
issn = {0957-5820},
doi = {https://doi.org/10.1016/j.psep.2023.02.065},
url = {https://www.sciencedirect.com/science/article/pii/S0957582023001672},
author = {Allan Soo and Li Wang and Chen Wang and Ho Kyong Shon},
keywords = {Nutrient, Circular economy, Smart city, Machine learning, Internet of things, Sustainability},
abstract = {Urbanisation is leading to a concentration of growing city populations that contribute significantly to economic growth, while becoming epicentres of waste generation, greenhouse gas emissions, and food consumption. Nutrient smart city circular economy is currently an understudied intersection of growing city populations of food consumers, nutrient recovery technologies, Internet of Things (IoT), and agriculture. Meanwhile, machine learning has exploded with popularity over the years, with many circular economy literatures examining its usefulness in its predictive qualities to support management, optimisation, and recovery of useful resources from organic waste. This review paper examines advancements in machine learning for macronutrient recovery in city organic waste systems for a circular economy. The use of ML will greatly improve the scalability, transparency, productivity and accuracy of nutrient: recovery technologies, logistics, dissemination, and reuse. ML can also be combined with hardware to automate tedious waste separation, recovery and agricultural tasks using drones, hydroponics and satellites. Meanwhile, crop yields, nutrient demand-supply efficiencies, food security, environmental soil monitoring, and prosumer involvement could all increase. However, ML applications for urine, anaerobic digestion and prosumer economics are lacking.}
}
@article{YOU2023388,
title = {Digital Twin simulation for deep learning framework for predicting solar energy market load in Trade-By-Trade data},
journal = {Solar Energy},
volume = {250},
pages = {388-397},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X2300004X},
author = {Lili You and Mingli Zhu},
keywords = {Deep learning, Short-term market load forecast, Smart grid, Modified teaching–learning algorithm},
abstract = {Because users behave randomly and in a nonlinear way, predicting electrical loads proves to be a difficult procedure. Due to the development of the smart grid (SG) and advanced metering infrastructure (AMI), humans will be capable of recording, monitoring, and analyzing these non-linear behaviors. The use of electric load projection layouts is a necessity in order to make decisions, plan, and evaluate contracts in electrical systems. Consequently, there have been several load prediction methods in the research that demonstrate trade-offs among prediction precision and runtime (convergence rate). The current paper presents a method for short-term load prediction of market in trade-by-trade data that would be quick and precise. Modified mutual information (MMI) is used to extract abstractive characteristics from historic information. Learning empowers the factored conditional restricted Boltzmann machine (FCRBM) for predicting the electrical loads. Ultimately, the efficiency has been optimized using the suggested modified teaching–learning algorithm (MTLA). The suggested architecture has the advantage of improving prediction precision and convergence rate. The MMI method and FCRBM layout improve prediction precision. In addition, MTLA has been used to enhance the convergence rates. Based on simulation outcomes, the suggested quick and precise layout performs better than conventional layouts when it comes to forecasting precision and convergence rates, including Bi-level, MI-artificial neural network (MI-ANN), and accurate fast converging short-term load forecast (AFC-STLF).}
}
@article{NATGUNANATHAN2023100370,
title = {Deakin microgrid digital twin and analysis of AI models for power generation prediction},
journal = {Energy Conversion and Management: X},
volume = {18},
pages = {100370},
year = {2023},
issn = {2590-1745},
doi = {https://doi.org/10.1016/j.ecmx.2023.100370},
url = {https://www.sciencedirect.com/science/article/pii/S2590174523000260},
author = {Iynkaran Natgunanathan and Vicky Mak-Hau and Sutharshan Rajasegarar and Adnan Anwar},
keywords = {Solar energy, Microgrid, Power prediction, Machine learning, Deep learning},
abstract = {To achieve carbon neutral by 2025, Deakin University launched a AUD 23 million Renewable Energy Microgrid in 2020 with a 7-megawatt solar farm, the largest at an Australian University. A web-based digital twin (DT) is developed to provide operators with intelligence and insights through several AI-driven capabilities. Accurate and computationally efficient power generation prediction is one of the critical elements in this DT. To this end, we researched the literature and identified the commonly used Machine Learning-based prediction models and compared them computationally using power generation and weather sensor data obtained from the solar farm. From the computational experiments, we find that, overall, Artificial Neural Network (ANN) has achieved the highest R2-score (0.944) and the lowest RMSE (14.848). To obtain further insights, we compared the methods using our two novel metrics, the x-percentile Closeness scores and the x-percentile Absolute error scores. The new metrics provide us with a spectrum to measure the consistency and robustness of the prediction methods instead of just a single value. Further, power generation can fluctuate substantially, and a prediction model should be accurate regardless of the magnitude of the output, hence measuring the relative error has its merits. By our two new metrics, using the data from our Deakin Microgrid, Random Forrest (RF) outperformed the other methods tested, with the smallest absolute relative error across the whole spectrum (from 0.011 to 0.457). RF is also the fastest in model training time at 4.894 s and XGBoost came second at 5.115 s–a big contrast to ANN at 144.102 s. All prediction times are under 1 s. RF is therefore used as a power prediction algorithm in our Deakin Microgrid Digital Twin.}
}
@article{TENG2023110160,
title = {Structural damage detection based on transfer learning strategy using digital twins of bridges},
journal = {Mechanical Systems and Signal Processing},
volume = {191},
pages = {110160},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2023.110160},
url = {https://www.sciencedirect.com/science/article/pii/S0888327023000675},
author = {Shuai Teng and Xuedi Chen and Gongfa Chen and Li Cheng},
keywords = {Structural damage detection, Convolutional neural network, Digital twin, Transfer learning, Real bridge case},
abstract = {In this paper, a novel structural damage detection (SDD) method based on the digital twin (DT) and transfer learning (TL) was proposed. The SDD methods based on the convolutional neural network (CNN) have proved their effectiveness in the many civil structures (models). However, their application to damage detection of real structures still faces some unprecedented challenges. It was widely known that a CNN needs a large number of training samples. It was difficult or/and impossible to obtain the sufficient samples covering various damage scenarios for in-service structures, which will limit the application of the CNN in real structures. Therefore, in this paper, a large number of damage samples of the numerical models were obtained by using the DT technology, and used to train a CNN as a pre-trained network. Then, the pre-trained CNN was transferred to the experimentally tested structure and real bridge structure by using the TL technology. The results confirm that the CNN trained by a large number of DT models has strong compatibility, and the detection accuracy of numerical models was more than 90%; the combination with TL technology significantly improves the performance of the CNN for experimental structures (the convergence speed was increased by 40–70%, and the detection accuracy was also improved by 5–17%). Meanwhile, the accuracy of damage detection for the real bridge structure reached 97.3% (76.6% higher than that of existing methods (non-digital twin)) by TL technology. It is demonstrated that the proposed method facilitates the application of the CNN in real structures.}
}
@article{LIEBENBERG2023102182,
title = {Information systems engineering with Digital Shadows: Concept and use cases in the Internet of Production},
journal = {Information Systems},
volume = {114},
pages = {102182},
year = {2023},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2023.102182},
url = {https://www.sciencedirect.com/science/article/pii/S0306437923000182},
author = {Martin Liebenberg and Matthias Jarke},
keywords = {Digital Shadow, Internet of Production (IoP), Database views, World Wide Lab (WWL), Cooperative information systems, Digital twin, Informed machine learning, Knowledge pipeline},
abstract = {Entering the second decade of the Industrie 4.0 vision, the production sector is facing challenges in taking full advantage of global digitalization. Production research has focused on sophisticated mathematical models ranging from molecular materials modeling to production control to supply chain logistics. These models help simulate and control the related physical system but the variety of individual situations and behaviors is captured only as statistical uncertainty. The emergence of data-driven methods adds statistical or AI models learned from real-time production data to Digital Twins, and ideally allows for continuous synchronization (twinning) between physical and virtual system. However, the complexity of today’s production systems precludes Digital Twins covering more than just a few system perspectives, especially if realtime performance is required. To achieve better performance and more precise context adaptation, the interdisciplinary research cluster “Internet of Production” at RWTH Aachen University is exploring the concept of Digital Shadows. We conceptualize Digital Shadows as a generalization of compact views on dynamic processes, whose defining “query” combines condensed measurement data with efficient simplified mathematical models. Their small size makes Digital Shadows amenable to dynamic function allocation in hybrid cloud–edge settings. In addition to showing the similarities and differences to the traditional view concept, we also present a conceptual embedding of Digital Shadows in the context of large distributed system architectures, and sovereign data exchange in international Data Space communities. Two production use case experiences demonstrate that Digital Shadows can be valuable carriers of deep and reusable engineering knowledge for technical and ecological progress.}
}
@article{XU2023100455,
title = {Ensuring construction material provenance using Internet of Things and blockchain: Learning from the food industry},
journal = {Journal of Industrial Information Integration},
volume = {33},
pages = {100455},
year = {2023},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2023.100455},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X23000286},
author = {Jinying Xu and Jinfeng Lou and Weisheng Lu and Liupengfei Wu and Chen Chen},
keywords = {Material provenance, Construction logistics and supply chain, Food industry, Blockchain, Internet of Things, Framework},
abstract = {Ensuring material provenance is widely considered a promising solution to the persistent issues related to material fraudulence in the construction industry. However, current strategies of managing construction logistics and supply chain perplex provenance tracing and tracking by adding too many intermediaries and using low technologies. By learning from the food industry which shares similar complexity, prolonged supply chain, and numerous stakeholders, this research aims to develop a framework deployable for material provenance tracing and tracking in the construction industry. It does so by mixing the uses of (a) cross-sectoral learning; (b) design science research; and (c) internet of things (IoT) and blockchain technology. The developed framework has four interconnected layers, namely the business layer with different stakeholders and activities, the IoT layer to collect the provenance footprints, the blockchain layer with a mainchain to store open provenance data and sidechains to store organizational private data, and the application layer to facilitate the management of quality, safety, payment, logistic and supply chain, and sustainability. The underpinning philosophy of the framework is to capture the IoT-driven provenance footprints and put them in custody in blockchain. The framework is further illustrated and refined by using a pilot construction project in Hong Kong, which was endeavored to track steel provenance from its adjacent Pearl River Delta, the so-called “World's Factory”. The framework shows enormous prospects, e.g., adopting digital twins, lifecycle traceability, improved efficiency, and transparent operations, meanwhile facing challenges, e.g., under-developed regulations, scalability issues, and information leakage risks, which all call for future research.}
}
@article{CHO2023109541,
title = {Ambiguity-aware robust teacher (ART): Enhanced self-knowledge distillation framework with pruned teacher network},
journal = {Pattern Recognition},
volume = {140},
pages = {109541},
year = {2023},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2023.109541},
url = {https://www.sciencedirect.com/science/article/pii/S0031320323002418},
author = {Yucheol Cho and Gyeongdo Ham and Jae-Hyeok Lee and Daeshik Kim},
keywords = {Knowledge distillation, Self-knowledge distillation, Network pruning, Teacher-student model, Long-tail samples, Ambiguous samples, Sample ambiguity, Data augmentation},
abstract = {Self-knowledge distillation (self-KD) methods, which use a student model itself as the teacher model instead of a large and complex teacher model, are currently a subject of active study. Since most previous self-KD approaches relied on the knowledge of a single teacher model, if the teacher model incorrectly predicted confusing samples, poor-quality knowledge was transferred to the student model. Unfortunately, natural images are often ambiguous for teacher models due to multiple objects, mislabeling, or low quality. In this paper, we propose a novel knowledge distillation framework named ambiguity-aware robust teacher knowledge distillation (ART-KD) that provides refined knowledge, that reflects the ambiguity of the samples with network pruning. Since the pruned teacher model is simply obtained by copying and pruning the teacher model, re-training process is unnecessary in ART-KD. The key insight of ART-KD lies in the predictions of a teacher model and pruned teacher model for ambiguous samples providing different distributions with low similarity. From these two distributions, we obtain a joint distribution considering the ambiguity of the samples as teacher’s knowledge for distillation. We comprehensively evaluate our method on public classification benchmarks, as well as more challenging benchmarks for fine-grained visual recognition (FGVR), achieving much superior performance to state-of-the-art counterparts.}
}
@article{HONG20231963,
title = {Diagnosis of PV faults using digital twin and convolutional mixer with LoRa notification system},
journal = {Energy Reports},
volume = {9},
pages = {1963-1976},
year = {2023},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2023.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S2352484723000124},
author = {Ying-Yi Hong and Rolando A. Pula},
keywords = {Convolutional neural network, Diagnosis, Digital twin, Markov transition field, Photovoltaics},
abstract = {The amount of energy that is generated using photovoltaic (PV) arrays has been increasing rapidly over recent years. To avoid energy and financial losses due to PV faults, numerous methods for diagnosing PV faults have been proposed. Both digital twin (DT) and deep learning (DL) have been proven to be effective in solving detection/classification problems in various fields. This work develops a method of PV fault diagnosis that has the following three stages: (1) Detection of faults in a PV array using DT, (2) classification of the detected faults using ConvMixer, and (3) notification of detected and classified faults using a LoRa (long-range) system. DT is a virtual/digital model that is designed to reflect accurately the behavior and characteristics of a physical object. This work implements the model-based DC power generation of PV arrays using DT. In this study, a new DL method, called the convolutional mixer (ConvMixer) based on patch embedding and combining depthwise and pointwise convolutions to classify PV faults, is presented. The inputs of ConvMixer are 2D images generated from data on PV DC array power using a Markov transition field (MTF) transform. A LoRa notification system is very suitable for use in low-power wide-area networks (LPWANs), such as those needed in large PV farms. Simulation results demonstrate that the proposed ConvMixer outperforms other classical machine learning (ML) methods, such as decision tree, k-nearest neighbor, random forest, and support vector machine methods, as well as other classical CNN-based methods, such as AlexNet, ResNet50, VGG16, and VGG19. A real-time digital simulator (Opal-RT eMegasim) is used to verify the real-time applicability of the integration of DT, ConvMixer, and the LoRa notification system.}
}
@article{FAROOQ2023102173,
title = {Residual attention based uncertainty-guided mean teacher model for semi-supervised breast masses segmentation in 2D ultrasonography},
journal = {Computerized Medical Imaging and Graphics},
volume = {104},
pages = {102173},
year = {2023},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2022.102173},
url = {https://www.sciencedirect.com/science/article/pii/S0895611122001434},
author = {Muhammad Umar Farooq and Zahid Ullah and Jeonghwan Gwak},
keywords = {Breast tumor segmentation, Mean teacher–student, Self-ensembling, semi-supervised learning, uncertainty estimation},
abstract = {Breast tumor is the second deadliest disease among women around the world. Earlier tumor diagnosis is extremely important for improving the survival rate. Recent deep-learning techniques proved helpful in the timely diagnosis of various tumors. However, in the case of breast tumors, the characteristics of the tumors, i.e., low visual contrast, unclear boundary, and diversity in shape and size of breast lesions, make it more challenging to design a highly efficient detection system. Additionally, the scarcity of publicly available labeled data is also a major hurdle in the development of highly accurate and robust deep-learning models for breast tumor detection. To overcome these issues, we propose residual-attention-based uncertainty-guided mean teacher framework which incorporates the residual and attention blocks. The residual for optimizing the deep network by enabling the flow of high-level features and attention modules improves the focus of the model by optimizing its weights during the learning process. We further explore the potential of utilizing unlabeled data during the training process by employing the semi-supervised learning (SSL) method. Particularly, the uncertainty-guided mean-teacher student architecture is exploited to demonstrate the potential of incorporating the unlabeled samples during the training of residual attention U-Net model. The proposed SSL framework has been rigorously evaluated on two publicly available labeled datasets, i.e., BUSI and UDIAT datasets. The quantitative as well as qualitative results demonstrate that the proposed framework achieved competitive performance with respect to the previous state-of-the-art techniques and outperform the existing breast ultrasound masses segmentation techniques. Most importantly, the study demonstrates the potential of incorporating the additional unlabeled data for improving the performance of breast tumor segmentation.}
}
@article{EDWARDS2023104774,
title = {Digital twin development through auto-linking to manage legacy assets in nuclear power plants},
journal = {Automation in Construction},
volume = {148},
pages = {104774},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104774},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523000341},
author = {Chloe Edwards and Daniel López Morales and Carl Haas and Sriram Narasimhan and Giovanni Cascante},
keywords = {Digital twins, Deep learning, Computer vision, 3D point cloud processing, Asset management, 3D scanning, Nuclear power plants, Semantic enrichment of 3D point clouds},
abstract = {Digitalization of Nuclear Power Plants (NPPs) is critical for their safe and effective operation and maintenance. Development of Digital Twins (DTs) of NPP legacy assets and subsystems is key to achieving this goal. Doing this effectively requires a framework for intelligent allocation of limited resources. This framework is developed here by synthesizing emerging best practices with NPP operators' needs for legacy assets management. Within the framework, a pipeline employs deep-learning object detection to read and locate equipment tags in images. It computes their locations in the corresponding 3D point clouds and then relates that data to an asset management system. The pipeline is premised on preservation and augmentation of existing NPP asset management processes that preclude options such as RFID tags or barcodes. It is a significant step toward more efficient development of DTs of legacy assets. The contributions are framed in the context of a typical Canadian legacy NPP.}
}
@incollection{WANG202397,
title = {Chapter 5 - Intelligent digital twin reference architecture models for medical and healthcare industry},
editor = {Abdulmotaleb {El Saddik}},
booktitle = {Digital Twin for Healthcare},
publisher = {Academic Press},
pages = {97-119},
year = {2023},
isbn = {978-0-323-99163-6},
doi = {https://doi.org/10.1016/B978-0-32-399163-6.00010-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032399163600010X},
author = {Zhi Wang and Abdulmotaleb {El Saddik}},
keywords = {digital twin, healthcare, medical, AI, machine learning, architecture, multimedia, IoT, IoT edge, cloud, digital patient, federated machine learning, robot, remote surgery, PaaS},
abstract = {The recent redefinition of Digital Twin (DT) significantly has been expanding DT's potential and increasing momentum in both industries and academic research. DTs have not only widely adopted in manufacture industry but also become a new trend in medical and healthcare industry. However, traditional architectures do not provide satisfactory solutions for protecting privacy, breaking data silos, handling big data, and quickly integrating heterogeneous DTs. In this chapter, we introduced Intelligent DT architecture reference model for medical and health industry. It not only addresses the above challenges but also analytically defines the location of DT services deployed, the detail logic capabilities DT system provides and interfaces among them. We analytically molded DT's architecture models, analyzed their suitable application scenarios, and recommend using loosely coupled DT architecture model that combine data-centric, event-centric and application centric methodologies for complex cases in medical and healthcare industry. The architecture is helpful in identifying various levels of business and technical requirements and designing DT system. Additionally, we present the use case of digital patient and automatic remote surgery to give a detail explanation and demonstrate the efficacy of the architecture reference model: distributed DTs can analyze the current and historical medical data to plan, practice, and perform remote surgery. From feedback loop and machine learning module, DTs can gradually learn how to perform operations and make the operation automatic. This architecture reference model can works as a high level template to facilitate designing and integrating DTs across different systems, platforms, and domains.}
}
@article{AKINRINTOYO2023103243,
title = {(INVITED)Reconfigurable topology testbeds: A new approach to optical system experiments},
journal = {Optical Fiber Technology},
volume = {76},
pages = {103243},
year = {2023},
issn = {1068-5200},
doi = {https://doi.org/10.1016/j.yofte.2023.103243},
url = {https://www.sciencedirect.com/science/article/pii/S1068520023000226},
author = {Emmanuel Akinrintoyo and Zehao Wang and Bob Lantz and Tingjun Chen and Dan Kilper},
keywords = {Networking testbeds, Digital twin, Machine learning (ML), Stimulated Raman scattering (SRS), Software-defined networking (SDN), Optical physical layer control},
abstract = {Optical transmission systems provide high capacity, low latency and jitter, and high reliability for city-scale networks. Recirculating loop experiments have facilitated the study of signal propagation in long-haul optical transmission systems. However, they are unsuited for developing control and management software for city-scale optical networks with dozens or hundreds of reconfigurable optical add drop multiplexer (ROADM) units, diverse interconnection topologies, and dynamic traffic patterns. Large-scale testbeds can help, but may be inflexible and time- or cost-prohibitive. Reconfigurable testbeds such as COSMOS enable piece-wise emulation of a city-scale network by applying space and wavelength switching, dual-use software-defined networking (SDN) controllers, and comb sources, while digital twin models enable software emulation. Results from the development of a digital twin for COSMOS are presented for optical amplifiers and stimulated Raman scattering (SRS) including both analytical and machine learning (ML) models.}
}
@article{FU2023110,
title = {Forgery face detection via adaptive learning from multiple experts},
journal = {Neurocomputing},
volume = {527},
pages = {110-118},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223000279},
author = {Xinghe Fu and Shengming Li and Yike Yuan and Bin Li and Xi Li},
keywords = {Face forgery detection, Knowledge distillation, Adaptive learning, Multi-expert learning},
abstract = {As an important and challenging problem, Face Forgery Detection has gained considerable attention. Usually, it suffers from the diversity of forgery patterns in forgery images, which requires a detection model to have capability of capturing various patterns in the challenging scenarios. To address this problem, we present a divide-and-aggregate learning framework to build multi-expert models and integrate them into a unified model. Firstly, the built multi-expert models are pre-trained to capture and preserve the specific forgery pattern produced by each manipulation method separately. Secondly, to transfer diverse knowledge of experts, we propose an integrating approach based on knowledge distillation. However, the difference of manipulation-aware knowledge among these experts concerns the way of distillation when the knowledge is combined in the only student model. Thus, to determine the importance of each expert, we propose a sample-aware Adaptive Learning from Experts strategy (ALFE) to assign adaptive expert distillation weights for each fake sample based on the predictions of each expert. Experiments show that our method achieves SOTA performances on ACC/AUC in the benchmark of FaceForensics++, demonstrating the effectiveness of our proposed method.}
}
@article{HU2023937,
title = {Investigation on Smart Campus Management Platform Based on Digital Twin},
journal = {Procedia Computer Science},
volume = {228},
pages = {937-945},
year = {2023},
note = {3rd International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.11.123},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923019543},
author = {Pan Hu},
keywords = {Digital Twin, Smart Campus, Big Data, Campus Management, Modernization of Education},
abstract = {With the improvement of digitalization and the development of information technology, intelligent campus management has become an important research direction in the current education field. Based on digital twin technology, this article proposed a design scheme for a smart campus management platform to address the current problems in campus management. This could manage and serve students, teachers, parents, and other aspects, and achieve the mining and analysis of school big data. Through the implementation and application of the platform, the efficiency and accuracy of campus management could be improved, and the modernization of education could be further promoted. The smart campus management platform of digital twin utilized digital twin technology to digitize the campus environment, equipment, students, teaching resources, and other information of the school, thus achieving three-dimensional visualization, intelligent analysis, and feedback. The experimental results showed that the security of the smart campus management platform designed in this article exceeded 90% and performed well in system testing.}
}
@article{WANG2023109142,
title = {Online bearing fault diagnosis using numerical simulation models and machine learning classifications},
journal = {Reliability Engineering & System Safety},
volume = {234},
pages = {109142},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109142},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023000571},
author = {Hui Wang and Junkang Zheng and Jiawei Xiang},
keywords = {Digital twin, Simulation numerical model, Machine learning model, Bearing fault diagnosis},
abstract = {Digital twin (DT) is the embodiment of the most advanced achievements of the current simulation technology theory development and the direction of intelligent development in the future. However, it is a great challenge to really integrate it into practical project application. Motivated by DT, an application method combining numerical simulation model and machine learning classification is proposed to show the advantages of digital twin. To ensure the reliability of the twin model, it is necessary to build a simulation model using a mature dynamic model, and modify it through the Pearson correlation coefficient (PCC) which is a kind of model online learning. Then, the required fault type is introduced by modifying the relevant fault influence factors, which is synchronously inserted into the normal operation model to obtain the normal, fault and other simulation numerical data. Finally, the machine learning model is used to predict the probability of each fault and feedback the impact value to the actual operation to guide the adjustment of actual parameters and the determination of maintenance plans. The experimental results show that this method can effectively predict the possibility of bearing failure synchronously and guide the adjustment and maintenance of actual bearing operating parameters.}
}
@article{ZHANG202336,
title = {Balanced knowledge distillation for long-tailed learning},
journal = {Neurocomputing},
volume = {527},
pages = {36-46},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.01.063},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223000711},
author = {Shaoyu Zhang and Chen Chen and Xiyuan Hu and Silong Peng},
keywords = {Long-tailed learning, Knowledge distillation, Vision and text classification},
abstract = {Deep models trained on long-tailed datasets exhibit unsatisfactory performance on tail classes. Existing methods usually modify the classification loss to increase the learning focus on tail classes, which unexpectedly sacrifice the performance on head classes. In fact, this scheme leads to a contradiction between the two goals of long-tailed learning, i.e., learning generalizable representations and facilitating learning for tail classes. In this work, we explore knowledge distillation in long-tailed scenarios and propose a novel distillation framework, named Balanced Knowledge Distillation (BKD), to disentangle the contradiction between the two goals and achieve both simultaneously. Specifically, given a teacher model, we train the student model by minimizing the combination of an instance-balanced classification loss and a class-balanced distillation loss. The former benefits from the sample diversity and learns generalizable representation, while the latter considers the class priors and facilitates learning for tail classes. We conduct extensive experiments on several long-tailed benchmark datasets and demonstrate that the proposed BKD is an effective knowledge distillation framework in long-tailed scenarios, as well as a competitive method for long-tailed learning. Our source code is available: https://github.com/EricZsy/BalancedKnowledgeDistillation.}
}
@incollection{HICKERSON2023267,
title = {Chapter 14 - Applying AI to advanced biomanufacturing},
editor = {Chandra P. Sharma and Thomas Chandy and Vinoy Thomas},
booktitle = {Artificial Intelligence in Tissue and Organ Regeneration},
publisher = {Academic Press},
pages = {267-288},
year = {2023},
isbn = {978-0-443-18498-7},
doi = {https://doi.org/10.1016/B978-0-443-18498-7.00002-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184987000028},
author = {Darren H.M. Hickerson and Joshua Hunsberger},
keywords = {Advanced biomanufacturing, Artificial intelligence, Digital twin, Limited memory, Limited memory artificial intelligence, Machine learning, Organ regeneration, Predictive analytics, Quality assurance, Quality control, Reactive machine, Regulatory requirements, Somatic cells, Stem cells, Tissue engineered bladder, Tissue engineering},
abstract = {This chapter explores applying artificial intelligence and machine learning to advanced biomanufacturing. We start with current and potential applications of AI to different subcomponents of advanced biomanufacturing using the tissue-engineered bladder as a model use case. This includes logistics and materials planning and preparation; integration of clinical and manufacturing site systems for custom organ design and production; biopsy processing for key cell types; automation of cell expansion; final construct maturation and release testing; and workflow considerations and advantages of using AI systems. These topics address the application of digital twin technology and a discussion of regulatory constraints for GMP manufacturing using AI. Next we consider applying AI to small-scale operations and early-phase clinical trials using a novel shared-resource testbed platform.}
}
@article{ADEPU2023106571,
title = {Melanoma classification from dermatoscopy images using knowledge distillation for highly imbalanced data},
journal = {Computers in Biology and Medicine},
volume = {154},
pages = {106571},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.106571},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523000367},
author = {Anil Kumar Adepu and Subin Sahayam and Umarani Jayaraman and Rashmika Arramraju},
keywords = {Cost-Sensitive Learning, Deep Learning, EfficientNet, Stratified K-fold Cross Validation, In-painting, ISIC-2020 dataset, Teacher Student Model},
abstract = {Melanoma is a deadly malignant skin cancer that generally grows and spreads rapidly. Early detection of melanoma can improve the prognosis of a patient. However, large-scale screening for melanoma is arduous due to human error and the unavailability of trained experts. Accurate automatic melanoma classification from dermoscopy images can help mitigate such issues. However, the classification task is challenging due to class-imbalance, high inter-class, and low intra-class similarity problems. It results in poor sensitivity scores when it comes to the disease classification task. The work proposes a novel knowledge-distilled lightweight Deep-CNN-based framework for melanoma classification to tackle the high inter-class and low intra-class similarity problems. To handle the high class-imbalance problem, the work proposes using Cost-Sensitive Learning with Focal Loss, to achieve better sensitivity scores. As a pre-processing step, an in-painting algorithm is used to remove artifacts from dermoscopy images. New CutOut variants, namely, Sprinkled and microscopic Cutout augmentations, have been employed as regularizers to avoid over-fitting. The robustness of the model has been studied through stratified K-fold cross-validation. Ablation studies with test time augmentation (TTA) and the addition of various noises like salt & pepper, pepper-only, and Gaussian noises have been studied. All the models trained in the work have been evaluated on the SIIM-ISIC Melanoma Classification Challenge - ISIC-2020 dataset. With our EfficientNet-B5 (FL) teacher model, the EfficientNet-B2 student model achieved an Area under the Curve (AUC) of 0.9295, and a sensitivity of 0.8087 on the ISIC-2020 test data. The sensitivity value of 0.8087 for melanoma classification is the current state-of-the-art result in the literature for the ISIC-2020 dataset which is a significant 49.48% increase from the best non-distilled standalone model, EfficientNet B5 (FL) teacher with 0.5410.}
}
@article{CHIURCO20231908,
title = {Data Modeling and ML Practice for Enabling Intelligent Digital Twins in Adaptive Production Planning and Control},
journal = {Procedia Computer Science},
volume = {217},
pages = {1908-1917},
year = {2023},
note = {4th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.391},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922024760},
author = {Alessandro Chiurco and Mohaiad Elbasheer and Francesco Longo and Letizia Nicoletti and Vittorio Solina},
keywords = {Digital Twin, Machine Learning, Adaptive Production Planning, Framework, Industrial case study, HeuristicLab},
abstract = {Technological advancements in AI, IoT, and Simulation push the frontier of the industry 4.0 to realize intelligent Digital twins (DT) of the industrial systems. This growing interest in manufacturing DTs inspires solutions for the flexibility, reliability, and resilience of production plans. However, the effort in building a clear guideline for dealing with data and algorithms is still its infancy. This paper combines multidisciplinary knowledge in Machine Learning (ML), and Production Planning & Control (PPC) to facilitate the integration of the ML algorithms into Production systems’ DTs. The paper proposes an architecture-based workflow to introduce ML and data practitioners into the creation of intelligent DTs for adaptive PPC. The framework in this study is explained with a simplified industrial case study that uses Neural Networks, k-Nearest Neighbor, and the Symbolic regression algorithms to justify the utility of the proposed framework.}
}
@incollection{ALOQAILY202339,
title = {Chapter 3 - Digital twin for healthcare immersive services: fundamentals, architectures, and open issues},
editor = {Abdulmotaleb {El Saddik}},
booktitle = {Digital Twin for Healthcare},
publisher = {Academic Press},
pages = {39-71},
year = {2023},
isbn = {978-0-323-99163-6},
doi = {https://doi.org/10.1016/B978-0-32-399163-6.00008-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323991636000081},
author = {Moayad Aloqaily and Ouns Bouachir and Fakhri Karray},
keywords = {digital twin, immersive technology, healthcare, AI, XR},
abstract = {Digital Twin (DT) and Immersive Services (XR) technologies are revolutionizing the medical sector through designing applications that support virtual representation and interactive reality. Both technologies leverage one another to advance healthcare services and provide professionals a virtual environment where they can interact with the digital information of their patients more conveniently. The integration of DT and XR technologies enables the creation of advanced 3D models of patients (e.g., organs or body) based on their accurate real data gathered and processed by the DT improving traditional healthcare treatments such as telemedicine, training, and consultation. This chapter introduces the DT technology in immersive healthcare services and presents its benefits to the medical sector. It discusses the various requirements and protocols to build immersive models of the DT using advanced Artificial Intelligence (AI) and Machine Learning (ML)-based mechanisms. The chapter also proposes various paradigms that can be used to enable rapid deployment of these models, meeting the strict demands of the medical sector in terms of efficiency, accuracy, and precision.}
}
@incollection{VEERAMAKALI202321,
title = {Chapter 2 - Knowledge-Driven Digital Twin Manufacturing},
editor = {Rajesh Kumar Dhanaraj and Ali Kashif Bashir and Vani Rajasekar and Balamurugan Balusamy and Pooja Malik},
booktitle = {Digital Twin for Smart Manufacturing},
publisher = {Academic Press},
pages = {21-34},
year = {2023},
isbn = {978-0-323-99205-3},
doi = {https://doi.org/10.1016/B978-0-323-99205-3.00005-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323992053000055},
author = {T. Veeramakali and A. Shobanadevi and S. Prabu},
keywords = {Industry 4.0, human-centric industrial internet, smart factory, ubiquitous knowledge, service-oriented digital twin, knowledge-based intelligent skills},
abstract = {The current era is witnessing big data-driven product design, leading to the advent of new generation information technologies in industry and product design. Consequently, big data-driven product design focuses mostly on physical data analysis instead of virtual models; in other words, there is no frequent convergence between a product’s virtual and physical space. Recently, the interest in developing a digital twin, which interconnects the real and virtual world, has grown rapidly throughout the world. As Industry 4.0 hypes the power of artificial intelligence embedded into “things,” it neglects the role of the human component, which is still essential in many manufacturing activities, such as machine setup or maintenance. A digital twin of service-oriented manufacturing knowledge was developed, which leverages a flexible ontology-based knowledge structure combined with an augmented reality input system for intuitive, hands-on knowledge retrieval. The autonomous and self-optimizing characteristics of intelligent manufacturing suggest new demands, including learning and cognitive capabilities. Intelligent manufacturing offers enhanced quality, high productivity, low costs, and great flexibility for manufacturers. Intelligent manufacturing utilizes digital twins to monitor the status of their systems in real time and predict failures before they happen. In this chapter, the main focus is on reviewing and discussing the existing literature to convey the concept, operation, and application of digital twin manufacturing.}
}
@article{PANTOJAROSERO2023104842,
title = {Damage-augmented digital twins towards the automated inspection of buildings},
journal = {Automation in Construction},
volume = {150},
pages = {104842},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104842},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523001024},
author = {B.G. Pantoja-Rosero and R. Achanta and K. Beyer},
keywords = {Post-earthquake damage assessment, Digital twins, 3D building models, Structure from motion, Deep learning, Masonry buildings},
abstract = {Current procedures for the rapid inspection of buildings and infrastructure are subjective, time-consuming, and cumbersome to document, necessitating new technologies to automate the process and eliminate these shortcomings. Fortunately, recent developments in imaging devices and artificial intelligence, such as computer vision, provide the necessary tools for this, though they are not yet integrated into infrastructure applications. In this paper, we propose an end-to-end pipeline that generates damage-augmented digital twins for buildings at LOD3, including geometrical information as well as data pertaining to damage condition and its characterization. Our framework incorporates multiple-view images to (1) create a level of detail model, (2) segment damage information, and (3) characterize damage. The core of the method is the structure from motion, which is used to reconstruct the building scene, and machine-learning models that segment and characterize damage. In contrast to current practices, our method does not require manual intervention, generates lightweight models, and can be applied to a wide range of assets. The results generated with our pipeline represent a significant step towards an automated infrastructure damage assessment. We intend to expand our work in the future to include real-time applications and applications to other types of infrastructure. Codes and data sets are publicly available (https://github.com/eesd-epfl/DADT_buildings and https://doi.org/10.5281/zenodo.7767478).}
}
@article{CHENG2023241,
title = {Machine learning enabled learning based optimization algorithm in digital twin simulator for management of smart islanded solar-based microgrids},
journal = {Solar Energy},
volume = {250},
pages = {241-247},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2022.12.040},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X22009203},
author = {Tan Cheng and Xiangqian Zhu and Fan Yang and Wenfeng Wang},
keywords = {Support vector machine, Elephant herd optimizer, Energy storage, Photovoltaic production, Demand-side management},
abstract = {The key element of tomorrow's smart islanded microgrids (SMG) is Demand Side Management (DSM). Global energy awareness has led to an increase in SMGs' performance and peak balancing capabilities. DSMs are the control layout in these grids, and they aim at optimizing loads in various ways. The SMG includes batteries and distributed photovoltaics. This paper combines an Elephant Herding optimization algorithm (EHOA) and support sector machine (SVM) to the decision-making method in batteries for reducing the electric bill. EHOA could be an effective method for finding a nearly optimum solution to the load scheduling issue in order to reduce the consumers' expenses. Particularly, energy costs could be decreased if the consumer responds to prices that vary with the time of day. Therefore, The EHOA has been applied to assign the battery's optimum energy storage range. The SVM has been trained as a powerful machine learning method using optimal information from the EHOA. It has been employed to determine the amount of energy that has been transmitted into and out of batteries in order to take the lowest possible electric bills. In comparison to the current approach of 2.3 at the consumption of 8.2 kWh/day, the cost of the suggested method of mean generation oscillation (Gosc) has been equated to 2.27 dollars for the residential load. EHOA-SVM decreases 11.2% of energy costs, thereby assisting the decision-maker to balance the stability of demand-side measures.}
}
@article{GAO2023104835,
title = {AIoT-informed digital twin communication for bridge maintenance},
journal = {Automation in Construction},
volume = {150},
pages = {104835},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104835},
url = {https://www.sciencedirect.com/science/article/pii/S092658052300095X},
author = {Yan Gao and Haijiang Li and Guanyu Xiong and Honghong Song},
keywords = {Digital twin, Bridge maintenance, Communication complexity, Time delay, Resilience, Edge computing, LPWAN},
abstract = {Digital twin (DT) has been moving progressively from concept to practice for bridge operation and maintenance (O&M), but its issues of data synchronization and fault tolerance remain problematic. This paper investigates the time delay of bridge DT services according to communication and computation complexity, revealing the distinct impact of their sequence, and proposes an AIoT-informed DT communication framework to solve the above issues. The information hierarchy and two-way communication can be leveraged to minimize communication complexity in the framework. Meanwhile, the data flow and resilience of the proposed framework are demonstrated using a Petri net. Moreover, the framework is developed into a prototypical DT through cross-platform integration and validated with different cases. The results demonstrate that compared with other existing bridge DTs, the proposed framework has high efficiency, low-latency, and excellent fault tolerance, which can contribute to the efficiency and safety of bridge O&M, especially under communication-constraint circumstances. The framework is also promising for federated learning to protect the AI-model privacy of different stakeholders and has the potential to support agent-based intelligent bridge management in the future with little human intervention.}
}
@article{LI2023127067,
title = {Data-driven enabling technologies in soft sensors of modern internal combustion engines: Perspectives},
journal = {Energy},
volume = {272},
pages = {127067},
year = {2023},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2023.127067},
url = {https://www.sciencedirect.com/science/article/pii/S0360544223004619},
author = {Ji Li and Quan Zhou and Xu He and Wan Chen and Hongming Xu},
keywords = {Data driven, Enabling technology, Soft sensors, Internal combustion engines, Digital twin},
abstract = {Under the dual thrust of decarbonisation and digitalisation, data-driven enabling technologies become the most promising solutions to reducing the time, cost, and effort required in the development of modern internal combustion engines (ICEs) in which it is hard to handle high-data-cost, high-dimensional, complex nonlinear modelling problems. This paper proposes a view of data-driven enabling technologies used in ICE soft sensors with a focus on the reduction of experimental effort and model complexity to accelerate the development of ICE decarbonisation. The current progress in data-driven modelling of ICEs is briefly outlined from four aspects: data acquisition methods, data processing methods, machine learning methods and model validation methods. Moreover, the challenges of establishing ICE models with high accuracy, fast response, and strong robustness for real-time control are structured and analysed. Based on the challenges, perspectives on three aspects of versatility, practicality, and autonomy are presented. Finally, physics/data-enhanced machine learning and digital twin technology are suggested to empower soft sensors used for modern ICEs.}
}
@article{DANESHFAR2023108,
title = {An octonion-based nonlinear echo state network for speech emotion recognition in Metaverse},
journal = {Neural Networks},
volume = {163},
pages = {108-121},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001600},
author = {Fatemeh Daneshfar and Mohammad (Behdad) Jamshidi},
keywords = {Speech emotion recognition, Digital twins, Metaverse, Octonion algebra, Echo state network, Machine learning},
abstract = {While the Metaverse is becoming a popular trend and drawing much attention from academia, society, and businesses, processing cores used in its infrastructures need to be improved, particularly in terms of signal processing and pattern recognition. Accordingly, the speech emotion recognition (SER) method plays a crucial role in creating the Metaverse platforms more usable​ and enjoyable for its users. However, existing SER methods continue to be plagued by two significant problems in the online environment. The shortage of adequate engagement and customization between avatars and users is recognized as the first issue and the second problem is related to the complexity of SER problems in the Metaverse as we face people and their digital twins or avatars. This is why developing efficient machine learning (ML) techniques specified for hypercomplex signal processing is essential to enhance the impressiveness and tangibility of the Metaverse platforms. As a solution, echo state networks (ESNs), which are an ML powerful tool for SER, can be an appropriate technique to enhance the Metaverse’s foundations in this area. Nevertheless, ESNs have some technical issues restricting them from a precise and reliable analysis, especially in the aspect of high-dimensional data. The most significant limitation of these networks is the high memory consumption caused by their reservoir structure in face of high-dimensional signals. To solve all problems associated with ESNs and their application in the Metaverse, we have come up with a novel structure for ESNs empowered by octonion algebra called NO2GESNet. Octonion numbers have eight dimensions, compactly display high-dimensional data, and improve the network precision and performance in comparison to conventional ESNs. The proposed network also solves the weaknesses of the ESNs in the presentation of the higher-order statistics to the output layer by equipping it with a multidimensional bilinear filter. Three comprehensive scenarios to use the proposed network in the Metaverse have been designed and analyzed, not only do they show the accuracy and performance of the proposed approach, but also the ways how SER can be employed in the Metaverse platforms.}
}
@article{HARRIES2023306,
title = {Digital Twins for Predictive Maintenance},
journal = {Procedia CIRP},
volume = {118},
pages = {306-311},
year = {2023},
note = {16th CIRP Conference on Intelligent Computation in Manufacturing Engineering},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.06.053},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123002779},
author = {Tobias Harries and Matthew Hartnoll and Mohammadmilad Hafezianrazavi and Harry Meek and Aydin Nassehi},
keywords = {Predictive maintenance, Digital twin},
abstract = {Modern maintenance strategies tend to be a mixture of different approaches, dependent on the type of machine and the component failure mode. For some machines, time-based maintenance is appropriate, however not all failure is fully age-related and other situations may require risk-based or condition-based maintenance. Predictive maintenance is a method originating from condition-based maintenance and is primarily used to predict the remaining useful life of a machine. Predictive models can be data driven, experimental, physics based or a hybrid thereof. In this paper, a virtual factory is used together with a data/experimental driven hybrid approach through the use of statistical models encompassed in a digital twin to calculate the remaining useful life of machines in the factory. An augmented statistical model is chosen for this purpose as it relies on data being fed from the factory during operation, therefore suiting the twin's functionality. Sensor data from previous machines or failure profiles is pre-processed and machine learning is used to extract condition indicators. These indicators are used to identify different types of fault and predict degradation paths. Such a method requires no mechanistic understanding of the process and is thus generalizable. Furthermore, with the possibility of using synthetic data, the method requires limited historic data compared to other methods, therefore suiting the scale of small to medium factories where predictive maintenance approaches are most challenging to implement.}
}
@article{XIA2023109256,
title = {A digital twin-enhanced semi-supervised framework for motor fault diagnosis based on phase-contrastive current dot pattern},
journal = {Reliability Engineering & System Safety},
volume = {235},
pages = {109256},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109256},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023001710},
author = {Pengcheng Xia and Yixiang Huang and Zhiyu Tao and Chengliang Liu and Jie Liu},
keywords = {Digital twin, Fault diagnosis, Motor, Semi-supervised learning, Transfer learning},
abstract = {Motor plays a core role in most industrial equipment. Accurate fault diagnosis of motor is a critical task and intelligent data-driven methods have gained significant advances. However, to obtain sufficient labeled data to train the models is expensive and laborious in industrial applications, and how to utilize three-phase current signals efficiently is a challenging task. To deal with these problems, a digital twin-enhanced semi-supervised framework is proposed for label-scarce motor fault diagnosis. First, a precise motor digital twin model is established based on multi-physics simulation and knowledge transfer is performed from the virtual space to the physical space. Second, a novel phase-contrastive current dot pattern (PCCDP) representation is proposed to transform three-phase motor stator current to a gray-scale image with an ordered arrangement and then characteristics of three phases can be contrasted in tight regions for efficient processing. Third, inter-space sample generation is proposed for continuous feature manifold learning to tackle discrepancy between spaces. Finally, intra-space sample generation and a clustering-based metric learning are also introduced to improve semi-supervised fault diagnosis performance. An induction motor fault experiment is conducted and a digital twin model is built correspondingly. Experiments verify the effectiveness and superiority of the proposed framework.}
}
@article{SALA2023640,
title = {On the development of the Digital Shadow of the Fischertechnik Training Factory Industry 4.0: an educational perspective},
journal = {Procedia Computer Science},
volume = {217},
pages = {640-649},
year = {2023},
note = {4th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.260},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922023389},
author = {Roberto Sala and Fabiana Pirola and Giuditta Pezzotta},
keywords = {Digital Twin, Digital Shadow, Learning Factory, Industry 4.0, Bloom's Taxonomy},
abstract = {The fourth industrial revolution is characterized by the increasing availability of data, which can be collected from machines to create digital counterparts of them (e.g., Digital Shadow, Digital Twin), understand their status, and drive strategic and operational decisions. To effectively create and use such digital counterparts, it is necessary to hire skilled people or train them to achieve the necessary competencies, for instance using learning factories, which are nowadays becoming more and more common. From an educational standpoint, it is interesting to observe how such competencies could be developed starting from a personal background. The paper describes the development process of the Digital Shadow of the Fischertechnik Training Factory Industry 4.0 in the context of a university course. The aim was to understand if the competencies acquired during the Computer Science bachelor's degree were enough to allow for the development of a functioning Digital Shadow of the learning factory.}
}
@article{ZHENG20231,
title = {A collaborative intelligence-based approach for handling human-robot collaboration uncertainties},
journal = {CIRP Annals},
volume = {72},
number = {1},
pages = {1-4},
year = {2023},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2023.04.057},
url = {https://www.sciencedirect.com/science/article/pii/S0007850623000951},
author = {Pai Zheng and Shufei Li and Junming Fan and Chengxi Li and Lihui Wang},
keywords = {Human-robot collaboration, Manufacturing system, Collaborative intelligence},
abstract = {Human-Robot Collaboration (HRC) has played a pivotal role in today's human-centric smart manufacturing scenarios. Nevertheless, limited concerns have been given to HRC uncertainties. By integrating both human and artificial intelligence, this paper proposes a Collaborative Intelligence (CI)-based approach for handling three major types of HRC uncertainties (i.e., human, robot and task uncertainties). A fine-grained human digital twin modelling method is introduced to address human uncertainties with better robotic assistance. Meanwhile, a learning from demonstration approach is offered to handle robotic task uncertainties with human intelligence. Lastly, the feasibility of the proposed CI has been demonstrated in an illustrative HRC assembly task.}
}
@article{ASSADZADEH2023101875,
title = {Excavator 3D pose estimation using deep learning and hybrid datasets},
journal = {Advanced Engineering Informatics},
volume = {55},
pages = {101875},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.101875},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623000034},
author = {Amin Assadzadeh and Mehrdad Arashpour and Heng Li and Reza Hosseini and Faris Elghaish and Shanaka Baduge},
keywords = {Computer vision, Construction machinery, Deep convilutional neural networks, Machine learning, Pose estimation, Safety and productivity analysis},
abstract = {Earthwork operations are crucial parts of most construction projects. Heavy construction equipment and workers are often required to work in limited workspaces simultaneously. Struck-by accidents resulting from poor worker and equipment interactions account for a large proportion of accidents and fatalities on construction sites. The emerging technologies based on computer vision and artificial intelligence offer an opportunity to enhance construction safety through advanced monitoring utilizing site cameras. A crucial pre-requisite to the development of safety monitoring applications is the ability to identify accurately and localize the position of the equipment and its critical components in 3D space. This study proposes a workflow for excavator 3D pose estimation based on deep learning using RGB images. In the proposed workflow, an articulated 3D digital twin of an excavator is used to generate the necessary data for training a 3D pose estimation model. In addition, a method for generating hybrid datasets (simulation and laboratory) for adapting the 3D pose estimation model for various scenarios with different camera parameters is proposed. Evaluations prove the capability of the workflow in estimating the 3D pose of excavators. The study concludes by discussing the limitations and future research opportunities.}
}
@article{CHABEAUTI202377,
title = {Digital twin of forged part to reduce distortion in machining},
journal = {CIRP Annals},
volume = {72},
number = {1},
pages = {77-80},
year = {2023},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2023.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0007850623000677},
author = {Hugo Chabeauti and Mathieu Ritou and Bruno Lavisse and Guenael Germain and Virginie Charbonnier},
keywords = {Digital twin, Residual stress, Deformation},
abstract = {When long parts are machined in forged blanks, the variability of bulk residual stress (RS) fields leads to uncontrolled deformation after machining, requiring manual reshaping. An original hybrid digital twin of forged part is thus proposed to manage the bulk RS variability and reduce part distortion in machining. The behavior model of parts relies both on reduced models of thermomechanical simulations of the forging process variability, on-line measurements and machine learning from the previous parts deformations. Adaptive machining solutions can then be simulated for a rapid decision-making. The approach was validated on a series of aeronautic forged parts.}
}
@article{JIA2023101915,
title = {From simple digital twin to complex digital twin part II: Multi-scenario applications of digital twin shop floor},
journal = {Advanced Engineering Informatics},
volume = {56},
pages = {101915},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.101915},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623000435},
author = {Wenjie Jia and Wei Wang and Zhenzu Zhang},
keywords = {Digital twin, Shop floor, Intelligent manufacturing, Deep learning},
abstract = {The shop floor has always been an important application object for the digital twin. It is well known that production, process, and product are the core business of the shop floor. Therefore, the digital twin shop floor covers multi-dimensional information and multi-scale application scenarios. In this paper, the digital twin shop floor is constructed according to the modeling method of the complex digital twin proposed in Part I. The digital twin shop floor is firstly divided into several simple digital twins that focus on scenarios of different scales. Two simple application scenarios are constructed, including tool wear prediction and spindle temperature prediction. Main functions in different application scenarios, such as data acquisition, data processing, and data visualization, are implemented and encapsulated as components to construct simple digital twins. Secondly, ontology models, knowledge graphs, and message queues are used to assemble these simple digital twins into the complex digital twin shop floor. And two complex application scenarios are constructed, including machining geometry simulation considering spindle temperature and production scheduling considering tool wear. The implementation of the complex digital twin shop floor demonstrates the feasibility of the proposed modeling method.}
}
@article{CAO202377,
title = {Real-Time Machine Learning-based fault Detection, Classification, and locating in large scale solar Energy-Based Systems: Digital twin simulation},
journal = {Solar Energy},
volume = {251},
pages = {77-85},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2022.12.042},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X22009215},
author = {Hanhua Cao and Dongming Zhang and Shujuan Yi},
keywords = {Energy management, Machine learning, Bat optimization algorithm, Microgrid, Cyber security},
abstract = {The current study considers numerous renewable energy resources, distributed power generation units, energy storage, and plug-in hybrid electric vehicles (PHEV) in order to propose a reliable large-scale energy management framework that can be applied to islanded and grid-connected operations of renewable hybrid AC-DC microgrids (MGs). The framework uses a bat optimization algorithm (BOA) for minimizing the operating costs of the network and in addition introduces an intrusion detection system (IDS) according to the sequential hypothesis testing (SHT) method for detecting identity-enabled cyber-attacks (i.e classification of Sybil attacks, masquerading attacks) on the wireless-enabled advanced metering infrastructures (AMI). The suggested IDS uses the received signal strength (RSS) amount for distinguishing various signal resources and detecting cyberattacks. An IEEE 33-bus testing system has been used to construct a real-time hybrid MG in order to determine the reliability and efficiency of the suggested framework.}
}
@article{HERRMANN20231188,
title = {A Petri Net Architecture for Real-Time Human Activity Recognition in Work Systems},
journal = {Procedia Computer Science},
volume = {217},
pages = {1188-1199},
year = {2023},
note = {4th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.317},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922024024},
author = {Jan-Phillip Herrmann and Alexander Atanasyan and Felix Casser and Sven Tackenberg},
keywords = {Colored Petri net, Human-centered Assistance, Experimentable Digital Twins},
abstract = {Real-time human-centered assistance in industrial processes depends on the individual history of the work person's activities in the work system and requires adequate methods for tracking the person's actions. Most research in human activity recognition is based on recognizing actions from video data using computer vision methods. Digital equipment, standardized machine data interfaces, and smart wearable devices extend the possibilities to describe the current state of the work system. Petri nets have already been applied to human activity recognition, however, without the requirement of detecting actions in real-time. This paper proposes a Petri net architecture that enables hierarchical description-based human activity recognition in industrial work processes. We present an extension, a Partitioned Colored Petri Net, based on the colored Petri net formalism that infers activities from state transitions of the work system in real-time. In a case study, we demonstrate the Petri net's application for an error-based learning system that visualizes error consequences in augmented reality using experimentable digital twins.}
}
@article{DIJKSTRA2023107754,
title = {Clustering children's learning behaviour to identify self-regulated learning support needs},
journal = {Computers in Human Behavior},
volume = {145},
pages = {107754},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107754},
url = {https://www.sciencedirect.com/science/article/pii/S074756322300105X},
author = {S.H.E. Dijkstra and M. Hinne and E. Segers and I. Molenaar},
keywords = {Self-regulated learning, Learning behaviour, Bayesian nonparametric clustering},
abstract = {When children are learning using adaptive learning technologies (ALTs), the technology builds a learner model, which creates temporal trajectories providing insight into how children's knowledge develops. Based on this learner model, ALTs adjust the difficulty of problems for each child, yet children still need to regulate their practice behaviour and uphold effort and accuracy. The temporal trajectories are consequently likely to, besides showing children's knowledge development, be indicative of children's regulation. Therefore, we explore clusters of these trajectories to further identify failure in children's self-regulated learning (SRL) and potential support needs. We propose a data-driven approach to cluster 354 trajectories of 134 5th graders learning three skills with different complexity. The resulting 9 clusters were interpreted using practice accuracy and effort as indicators of regulation of practice behaviour and prior and post-knowledge and learning gain as indicators of knowledge development. The differences between clusters regarding these indicators signal there are different levels of SRL failure and, consequently, different SRL support needs: high accuracy and knowledge development indicate minimal support needs, whereas clusters with low accuracy, showing no knowledge development, indicate extensive SRL support needs. In conclusion: clusters of temporal patterns in children's learning data can identify SRL support is needed.}
}
@article{XIE2023102428,
title = {Compressing convolutional neural networks with cheap convolutions and online distillation},
journal = {Displays},
volume = {78},
pages = {102428},
year = {2023},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2023.102428},
url = {https://www.sciencedirect.com/science/article/pii/S0141938223000616},
author = {Jiao Xie and Shaohui Lin and Yichen Zhang and Linkai Luo},
keywords = {Cheap convolution, Knowledge distillation, Online distillation, CNN compression and acceleration},
abstract = {Visual impairment assistance systems play a vital role in improving the standard of living for visually impaired people (VIP). With the development of deep learning technologies and assistive devices, many assistive technologies for VIP have achieved remarkable success in environmental perception and navigation. In particular, convolutional neural network (CNN)-based models have surpassed the level of human recognition and achieved a strong generalization ability. However, the large memory and computation consumption in CNNs have been one of the main barriers to deploying them into resource-limited systems for visual impairment assistance applications. To this end, most cheap convolutions (e.g., group convolution, depth-wise convolution, and shift convolution) have recently been used for memory and computation reduction but with a specific architecture design. Furthermore, it results in a low discriminability of the compressed networks by directly replacing the standard convolution with these cheap ones. In this paper, we propose to use knowledge distillation to improve the performance of compact student networks with cheap convolutions. In our case, the teacher is a network with the standard convolution, while the student is a simple transformation of the teacher architecture without complicated redesigning. In particular, we introduce a novel online distillation method, which online constructs the teacher network without pre-training and conducts mutual learning between the teacher and student network, to improve the performance of the student model. Extensive experiments demonstrate that the proposed approach achieves superior performance to simultaneously reduce memory and computation overhead of cutting-edge CNNs on different datasets, including CIFAR-10/100 and ImageNet ILSVRC 2012, compared to the previous CNN compression and acceleration methods. The codes are publicly available at https://github.com/EthanZhangYC/OD-cheap-convolution.}
}
@article{CHUNG2023138313,
title = {Ensemble machine learning approach for examining critical process parameters and scale-up opportunities of microbial electrochemical systems for hydrogen peroxide production},
journal = {Chemosphere},
volume = {324},
pages = {138313},
year = {2023},
issn = {0045-6535},
doi = {https://doi.org/10.1016/j.chemosphere.2023.138313},
url = {https://www.sciencedirect.com/science/article/pii/S0045653523005805},
author = {Tae Hyun Chung and Manjila Shahidi and Symon Mezbahuddin and Bipro Ranjan Dhar},
keywords = {Machine learning, Meta-learning, Microbial electrochemical system, Microbial electrochemical technology, Hydrogen peroxide},
abstract = {Hydrogen peroxide (H2O2) production in microbial electrochemical systems (MESs) is an attractive option for enabling a circular economy in the water/wastewater sector. Here, a machine learning algorithm was developed, using a meta-learning approach, to predict the H2O2 production rates in MES based on the seven input variables, including various design and operating parameters. The developed models were trained and cross-validated using the experimental data collected from 25 published reports. The final ensemble meta-learner model (combining 60 models) demonstrated a high prediction accuracy with very high R2 (0.983) and low root-mean-square error (RMSE) (0.647 kg H2O2 m−3 d−1) values. The model identified the carbon felt anode, GDE cathode, and cathode-to-anode volume ratio as the top three most important input features. Further scale-up analysis for small-scale wastewater treatment plants indicated that proper design and operating conditions could increase the H2O2 production rate to as high as 9 kg m−3 d−1.}
}
@incollection{BROSINSKY202379,
title = {4 - Machine learning and digital twins: monitoring and control for dynamic security in power systems},
editor = {Emilio {Barocio Espejo} and Felix Rafael {Segundo Sevilla} and Petr Korba},
booktitle = {Monitoring and Control of Electrical Power Systems Using Machine Learning Techniques},
publisher = {Elsevier},
pages = {79-106},
year = {2023},
isbn = {978-0-323-99904-5},
doi = {https://doi.org/10.1016/B978-0-32-399904-5.00010-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323999045000107},
author = {Christoph Brosinsky and Mert Karaçelebi and Jochen L. Cremer},
keywords = {surrogate models, digital twin, machine learning, dynamic security assessment, moving horizon estimation},
abstract = {The reader of the chapter will be able to connect techniques from machine learning (ML) and digital twins (DTs) to gain insights for monitoring and control of (dynamic) security for electrical power systems. DTs are validated and verified high-fidelity (hf) models providing high simulation accuracy. DTs can be used for simulation of the supervised process of system operation and are therefore able to provide synthetic studied data, where measurement data are scarce. However, for some real-time applications in monitoring and control, such high-fidelity simulation models are not appropriate due to the corresponding computational barrier. There, ML aims to create an application-specific, low-fidelity (lf) approximation of the digital twin. Such trained lf models are used in real-time applications where computational time is scarce and lf information is sufficient. The conceptual intersection of hf and lf models has been little explored and becomes increasingly complex. This chapter aims to provide a conceptual overview of how such hf and lf models can be combined. This chapter is split into two parts where the first part is to introduce ML, lf models, and digital twins, hf models, for power systems analysis, and the second chapter is to use these two types of models to form purpose-driven surrogate lf models, illustrated on the example of dynamic security assessment (DSA). In the first part, the concepts for using DTs as hf models for online power system studies and their corresponding tuning of model parameters are introduced. Subsequently, ML i.e., lf models, are introduced and their corresponding training frameworks.}
}
@article{LIPPI2023103892,
title = {Enabling causality learning in smart factories with hierarchical digital twins},
journal = {Computers in Industry},
volume = {148},
pages = {103892},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.103892},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523000428},
author = {Marco Lippi and Matteo Martinelli and Marco Picone and Franco Zambonelli},
keywords = {Smart factories, Causal models, Digital twins},
abstract = {Smart factories are complex systems where many different components need to interact and cooperate in order to achieve common goals. In particular, devices must be endowed with the skill of learning how to react in front of evolving situations and unexpected scenarios. In order to develop these capabilities, we argue that systems will need to build an internal, and possibly shared, representation of their operational world that represents causal relations between actions and observed variables. Within this context, digital twins will play a crucial role, by providing the ideal infrastructure for the standardisation and digitisation of the whole industrial process, laying the groundwork for the high-level learning and inference processes. In this paper, we introduce a novel hierarchical architecture enabled by digital twins, that can be exploited to build logical abstractions of the overall system, and to learn causal models of the environment directly from data. We implement our vision through a case study of a simulated production process. Our results in that scenario show that Bayesian networks and intervention via do-calculus can be effectively exploited within the proposed architecture to learn interpretable models of the environment. Moreover, we evaluate how the use of digital twins has a strong impact on the reduction of the physical complexity perceived by external applications.}
}
@article{KINACI2023114128,
title = {Ship digital twin architecture for optimizing sailing automation},
journal = {Ocean Engineering},
volume = {275},
pages = {114128},
year = {2023},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2023.114128},
url = {https://www.sciencedirect.com/science/article/pii/S0029801823005127},
author = {Omer Kemal Kinaci},
keywords = {Maritime digital twin, Autonomous ship, Level 2 autonomy, Maritime autonomous surface ships},
abstract = {A fully autonomous ship should be monitored in a digital environment to track its real-time response to the changes in its surroundings. It is commanded by a controller algorithm whose optimum parameters is subject to change with respect to the changes in the environment. The ship's response with respect to these variations in the controller parameters need to be tracked to develop a full understanding of the ship's autonomy. As such, it is believed that the digital twin of a ship is an essential component of the path to fully autonomous ships. Despite maritime institutions not giving the credit to it yet, the ship digital twin concept is expected to be one of the leading topics in marine engineering soon. In this study, we try to establish the ship digital twin concept in terms of navigation autonomy. The paper starts by introducing the path to full autonomy in seas and the need for the digital twin by defining this concept for ships. A maneuvering mathematical model is used to represent the physical ship. The details of the model and the controller algorithms are given next. The propeller and rudder models are first validated by free-running self-propulsion and turning circle tests. The ship considered in this study has a twisted rudder and does not possess course-keeping ability; therefore, it requires autopilot to move straight ahead. Three types of simulation cases are identified with one being the autopilot mode. In the other two cases, the ship is forced to conduct two hard maneuvers while accelerating/decelerating. Investigation of the generated results reveals the effectiveness of the digital twin architecture used in this study. It has also allowed us to conduct a controller stability analysis, which has shown the behavior of the controller gains to detect the most optimum values for the considered model ship.}
}
@article{LUFTENSTEINER2023938,
title = {Improving Virtual Sensor Models by Censored Online Data},
journal = {Procedia Computer Science},
volume = {217},
pages = {938-947},
year = {2023},
note = {4th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.291},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922023699},
author = {Sabrina Luftensteiner and Michael Zwick},
keywords = {Online Learning, Censored Data, Virtual Sensor},
abstract = {Digital twins are able to bridge the physical and the virtual world, which is especially useful in industrial environments. One small, but rather essential, kind of digital twin is the so called virtual sensor model. This type of model is used to enhance or replace a physical sensor in industrial settings to reduce costs or enable information retrieval from inaccessible locations within a machine or process. The virtual sensor model is usually trained once, whereat only a predefined amount of information without any adaptation possibilities on the clients side is provided. As manufacturers want to provide the possibility of custom adaptations for their clients, the virtual sensor models require to incorporate adaptive features, which also have to handle incomplete data recordings, e.g. uncensored data. Traditional offline machine learning approaches are often insufficient for such adaptive requirements, therefore the usage of online learning approaches is gaining increased attention, to avoid high computational, storage and temporal costs. This paper covers the continued training of such adaptive virtual sensor models, focusing on the handling and integration of censored online data. Different approaches to tackle the problems of catastrophic forgetting in online learning and correction of censored data are presented as well as the handling of censored data in online learning environments. The experiments sections compares various scenarios with and without censored data using an industrial dataset and demonstrates the positive influence of different online learning approaches.}
}
@article{WANG2023109152,
title = {Digital twin aided adversarial transfer learning method for domain adaptation fault diagnosis},
journal = {Reliability Engineering & System Safety},
volume = {234},
pages = {109152},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109152},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023000674},
author = {Jinrui Wang and Zongzhen Zhang and Zhiliang Liu and Baokun Han and Huaiqian Bao and Shanshan Ji},
keywords = {Fault diagnosis, Digital twin, Simscape, Transfer learning, Triplex pump},
abstract = {Machine health management has become the focus of equipment monitoring upgrading with the advance of digital twin (DT). The DT model is able to generate system performance data that is close to reality, which opens a new way for the cyber-physical integration of equipment monitoring. Furthermore, it also provides a significant opportunity for mechanical fault diagnosis when the collected fault signals are insufficient. In this paper, a DT aided intelligent fault diagnosis model is proposed for triplex pump. Specifically, the simulation model of the triplex pump is built by Simscape in MATLAB, and the measured simulation data is continuously updated to construct the DT model. Then a novel transfer learning model based on domain-adversarial strategy and Wasserstein distance is present and trained by the source domain data which generated from the DT model. Next, the opening pressure of the triplex pump is controlled to simulate different working conditions, so as to achieve feature transfer and fault diagnosis for the DT model. The experimental results show that the proposed method is effective and superior to other advanced transfer learning methods.}
}
@article{LIU2023112629,
title = {Automatic interpretation of strain distributions measured from distributed fiber optic sensors for crack monitoring},
journal = {Measurement},
volume = {211},
pages = {112629},
year = {2023},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2023.112629},
url = {https://www.sciencedirect.com/science/article/pii/S0263224123001938},
author = {Yiming Liu and Yi Bao},
keywords = {Crack monitoring, Digital twin, Distributed fiber optic sensor, Machine learning, Structural health monitoring},
abstract = {Distributed fiber optic sensors have exhibited superior capabilities in monitoring cracks in engineering structures through measuring detailed strain distributions. However, manually interpreting the measurements from long distributed sensors deployed in large-scale structures is time-consuming, labor-intensive, and subject to human errors. This paper proposes to automate the identification, localization, quantification, and visualization of cracks through intelligent interpretation of strain distributions measured from distributed fiber optic sensors based on machine learning. Based on these intelligent capabilities, a live digital twin model based on building information modeling is developed to visualize cracks. The digital twin model is updatable with real-time measurements from strain distributions from distributed fiber optic sensors. The proposed approach is evaluated via laboratory testing of a concrete beam. The results show that the proposed approach achieves high accuracy in interpretation of sensor data for crack monitoring. This research advances the capabilities of structural health monitoring using distributed fiber optic sensors.}
}
@article{HE2023173,
title = {Management and real-time monitoring of interconnected energy hubs using digital twin: Machine learning based approach},
journal = {Solar Energy},
volume = {250},
pages = {173-181},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2022.12.041},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X22009227},
author = {Qingsu He and Muqing Wu and Chun Liu and Dan Jin and Min Zhao},
keywords = {Smart Grids, Smart Energy Hub, Energy Management System, Reinforcement Learning, Financial analysis},
abstract = {Getting equipped by highly new smart technologies, Energy Hubs (EHs) and Smart Grids (SGs) are gaining interest these days. Energy management will advance over time as a result of the interaction impact among power and natural gas grids, and the use of smart technology for communications. The present study proposes a novel approach entitled Smart EH (SEH) for modeling multi-carrier energy systems in SG environments. Furthermore, this paper determines the optimum management and sizing of combined heat and power, auxiliary boiler, absorption chiller, as well as transformer unit as the essential components of an SEH. It is difficult to address the requirements of SGs with most conventional load scheduling algorithms because they lack robustness and performance in complex environments. An evaluation of the benefits and costs of optimizing such parameters was carried out in this paper and the Reinforcement Learning (RL) algorithm is applied to solve the optimization problem. An individual user in a dynamic electrical market was examined as an SEH in support of the suggested approach. According to simulation outcomes, the suggested method is effective regarding time efficiencies and load variations.}
}
@article{WANG2023134,
title = {Multi-objective optimal scheduling of laminar cooling water supply system for hot rolling mills driven by digital twin for energy-saving},
journal = {Journal of Process Control},
volume = {122},
pages = {134-146},
year = {2023},
issn = {0959-1524},
doi = {https://doi.org/10.1016/j.jprocont.2023.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0959152423000045},
author = {Fenjia Wang and Yong Song and Chao Liu and Anrui He and Yi Qiang},
keywords = {Laminar cooling, Digital twin, Optimal scheduling, Online Sequential Extreme Learning Machine, Improved Sparrow Search Algorithm, Energy saving},
abstract = {As a result of the complex structure of laminar cooling water supply systems, both facets of strict process requirements and various intermittent running conditions could cause challenges of energy-saving and equipment upkeep. Given the energy wastage issue of the laminar cooling system of hot rolling, this paper develops an optimal scheduling system according to digital twin using Online Sequential Extreme Learning Machine (OS-ELM) and multi-objective evolutionary optimization using Improved Sparrow Search Algorithm (ISSA). The optimal scheduling system according to digital twins can accurately predict the water consumption trend of the water supply system and optimize the scheduling instructions and operation scheme through dynamic information interaction and mapping of process constraints, intermittent operating conditions, rolling rhythm, measured data, etc. between physical space and virtual space. Experimental results reveal that the proposed method can lessen power usage by 13.60% and water consumption by 10.54% regarding the premise of ensuring what is needed of cooling procedures. In addition, the water pump can maintain high effectiveness during operation to guarantee the security and stability of laminar cooling water supply systems.}
}
@article{WU2023104446,
title = {High Fidelity Digital Twin-Based Anomaly Detection and Localization for Smart Water Grid Operation Management},
journal = {Sustainable Cities and Society},
volume = {91},
pages = {104446},
year = {2023},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2023.104446},
url = {https://www.sciencedirect.com/science/article/pii/S2210670723000574},
author = {Zheng Yi Wu and Alvin Chew and Xue Meng and Jianping Cai and Jocelyn Pok and Rony Kalfarisi and Kah Cheong Lai and Sock Fang Hew and Jia Jie Wong},
keywords = {Digital twin, Machine learning, Data analytics, Smart water grid, Anomaly detection, Anomaly localization},
abstract = {Smart Water Grid (SWG) plays a critical role in sustaining cities economic and social development, but challenges remain in fully realizing the benefits of SWG. While Digital twin (DT) has been discussed in some literature for possible SWG applications, there has been limited, or no technical framework developed to facilitate SWG operation and management. In this paper, a generic framework is developed for constructing SWG high fidelity Digital Twin (DT) by integrating digital thread with various digital models for visualization, data-driven analysis, physics-based simulations, and decision-making support. Both the physics-based models and data-driven models are trained/retrained and calibrated/re-calibrated respectively by using the data collected with the sensors installed throughout a SWG. The information derived from the SWG DT can be diagnostic, predictive, and prescriptive to significantly augment users’ intelligence for improving SWG operation and management. One important application of digital twin augmented intelligence is illustrated to timely detect and localize anomaly events, which may include, but not be limited to, pipe bursts and unauthorized water usages. The solution is tested on the selected areas in Singapore to construct the ever-green DT by calibrating and recalibrating the models for near real-time SWG operation management. The case study was conducted for three supply zones with the total pipeline length of more than 1000 km and 40 weeks of monitoring data, collected by 89 pressure monitoring stations and 8 flow meters at inlets and boundary. More than 3300 data-driven models are trained for optimizing the model performance to achieve accuracy of greater than 80% F1 score for detecting anomaly events, which are subsequently localized within 400 m with 2–3 days lead time.}
}
@article{LI2023106688,
title = {Machine learning assisted advanced battery thermal management system: A state-of-the-art review},
journal = {Journal of Energy Storage},
volume = {60},
pages = {106688},
year = {2023},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2023.106688},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X23000853},
author = {Ao Li and Jingwen Weng and Anthony Chun Yin Yuen and Wei Wang and Hengrui Liu and Eric Wai Ming Lee and Jian Wang and Sanghoon Kook and Guan Heng Yeoh},
keywords = {Battery thermal management, Thermal runaway, Mitigation, Artificial neural networks, Machine learning},
abstract = {With an increasingly wider application of the lithium-ion battery (LIB), specifically the drastic increase of electric vehicles in cosmopolitan cities, improving the thermal and fire resilience of LIB systems is inevitable. Thus, in-depth analysis and performance-based study on battery thermal management system (BTMs) design have arisen as a popular research topic in energy storage systems. Among the LIB system parameters, such as battery temperature distribution, battery heat generation rate, cooling medium properties, electrical properties, physical dimension design, etc., multi-factor design optimisation is one of the most difficult experimental tasks. Computational simulations deliver a holistic solution to the BTMs design, yet it demands an immense amount of computational power and time, which is often not practical for the design optimisation process. Therefore, machine learning (ML) models play a non-substitute role in the safety management of battery systems. ML models aid in temperature prediction and safety diagnosis, thereby assisting in the early warning of battery fire and its mitigation. In this review article, we summarise extensive lists of literature on BTMs employing ML models and identify the current state-of-the-art research, which is expected to serve as a much-needed guideline and reference for future design optimisation. Following that, the application of various ML models in battery fire diagnosis and early warning is illustrated. Finally, the authors propose improved approaches to advanced battery safety management with ML. This review paper aims to bring new insights into the application of ML in the LIB thermal safety issue and BTMs design and anticipate boosting further advanced battery system design not limited to the thermal management system, as well as proposing potential digital twin modelling for BTMs.}
}
@article{TIAN2023105328,
title = {Data-driven and physics-informed Bayesian learning of spatiotemporally varying consolidation settlement from sparse site investigation and settlement monitoring data},
journal = {Computers and Geotechnics},
volume = {157},
pages = {105328},
year = {2023},
issn = {0266-352X},
doi = {https://doi.org/10.1016/j.compgeo.2023.105328},
url = {https://www.sciencedirect.com/science/article/pii/S0266352X2300085X},
author = {Huaming Tian and Yu Wang},
keywords = {Machine learning, Digital twin, Bayesian method, Dictionary learning, Compressive sampling/sensing},
abstract = {A digital twin of a geotechnical project (e.g., a reclamation or ground improvement project) is a virtual model that aims to continuously learn from actual observations (e.g., site investigation and monitoring data) and improve model prediction (e.g., spatiotemporally varying consolidation settlement). However, real geotechnical observation data obtained from a site are often spatially sparse (e.g., site investigation data) and spatiotemporally varying (e.g., settlement monitoring data). The sparse and spatiotemporally varying data pose great challenges for continuous learning of data and improvement in model prediction. To address these challenges, this study proposes a novel data-driven and physics-informed Bayesian learning framework that automatically develops ground models from spatially sparse site investigation data, performs geotechnical analysis, and integrates geotechnical analysis results with limited, but spatiotemporally varying, settlement monitoring data to improve model prediction in a systematic and quantitative manner. The proposed method contains three key components, (1) data-driven ground modeling by Bayesian compressive sampling (BCS) using sparse site investigation data as input, (2) finite element modeling (FEM) of consolidation settlement that incorporates domain knowledge, and (3) Bayesian sparse dictionary learning of settlement monitoring data together with FEM results. The proposed method is illustrated using a real ground improvement project, and the results show that the proposed approach performs well.}
}
@article{XU2023101950,
title = {A mini imitation game: How individuals model social robots via behavioral outcomes and social roles},
journal = {Telematics and Informatics},
volume = {78},
pages = {101950},
year = {2023},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.101950},
url = {https://www.sciencedirect.com/science/article/pii/S073658532300014X},
author = {Kun Xu},
keywords = {Human-robot interaction, Media Equation, The Computers are Social Actors paradigm, Social presence, Social cognitive theory, Modeling effects},
abstract = {In past works, social robots have been designed to mimic human appearances and behavior. However, little is known about how human beings may imitate social robots. Drawing on social cognitive theory and the Media Equation, this study focuses on the modeling effects of social robots in an environment protection context. A lab experiment (N = 128) with a between-subjects factorial design was conducted to examine how social robots’ behavioral outcomes and social roles affected individuals’ modeling behavior. This study suggested that social robots’ positive behavioral outcomes were effective in evoking users’ modeling tendencies serially through social presence and identification or only through identification. Robots’ mere presentation of behavior with no outcomes exerted effects serially through social presence and identification. Additionally, assigning social robots an instructor role led to users’ modeling behavior serially through users’ perception of robots’ expertise and credibility. The study analyzed the psychological mechanisms behind users’ modeling behavior.}
}
@article{MACHADO202336,
title = {Digital twin of an absorption chiller for solar cooling},
journal = {Renewable Energy},
volume = {208},
pages = {36-51},
year = {2023},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2023.03.048},
url = {https://www.sciencedirect.com/science/article/pii/S0960148123003403},
author = {Diogo Ortiz Machado and William D. Chicaiza and Juan M. Escaño and Antonio J. Gallego and Gustavo A. {de Andrade} and Julio E. Normey-Rico and Carlos Bordons and Eduardo F. Camacho},
keywords = {Dynamic modeling, Fuzzy, Principal Component Analysis, Heat Ventilation and Air Conditioning, Fresnel Solar Collector},
abstract = {The aim of this study is to create a digital twin of a commercial absorption chiller for control and optimization purposes. The chiller is a complex system that is affected by solar intermittency and non-linearities. The authors use Adaptive Neuro-fuzzy Inference System (ANFIS) to model the chiller’s behavior during transients and part-load events. The chiller is divided into four sub-models, each modeled by ANFIS, and trained and validated using data from 15 days of operation. The ANFIS models are precise, accurate, and fast, with a worst-case Mean Absolute Percentage Error (MAPE) of 3.30% and reduced error dispersion (σE=0.88) and Standard Error (SE=0.01). The models outperformed literature models in terms of MAPE, with MAPEs of 1.12%, 2.21%, and 3.24% for the High Temperature Generator (HTG), absorber + condenser, and evaporator outlet temperatures, respectively. The computational execution time of the model is also a valuable asset, with an average simulation step taking less than 0.20 ms and a total simulation time of 8.9 s for three days of operation. The resulting digital twin is suitable for Model Predictive Control applications and fast what-if analysis and optimization due to its gray-box representation and computational speed.}
}
@incollection{JIANG2023297,
title = {Polymer Grade Transition Control via Reinforcement Learning Trained with a Physically Consistent Memory Sequence-to-Sequence Digital Twin},
editor = {Antonios C. Kokossis and Michael C. Georgiadis and Efstratios Pistikopoulos},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {52},
pages = {297-303},
year = {2023},
booktitle = {33rd European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-15274-0.50048-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443152740500482},
author = {Zhen-Feng Jiang and David Shan-Hill Wong and Jia-Lin Kang and Yuan Yao and Yao-Chen Chuang},
keywords = {Reinforcement learning, Sequence-to-Sequence with Memory Layer, Model Predictive Control, Grade transition},
abstract = {In this work, a memory layer sequence-to-sequence digital twin (ML-StSDT) of a high-density polyethylene (HDPE) reactor simulated by ASPEN DynamicsTM was constructed using simulated grade transition and steady-state operating data. A reinforcement learning control (RLC) algorithm was developed by training with the ML-StSDT. The RLC was able to control both grade transition and steady-state operation of the simulated plant. The RLC performs better or equally well when compared with the direct application of ML-StSDT in nonlinear model predictive control (NLMPC) but substantially reduces the computation load. Our results demonstrate the feasibility of deep learning models serving as a digital twin for RLC training in nonlinear process control applications.}
}
@article{HUANG20238,
title = {Machine learning-based demand response in PV-based smart home considering energy management in digital twin},
journal = {Solar Energy},
volume = {252},
pages = {8-19},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.01.044},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X2300052X},
author = {Jueru Huang and Dmitry D. Koroteev and Marina Rynkovskaya},
keywords = {Energy management, Demand response, Smart home, Machine learning, Electricity cost},
abstract = {Energy management (EM) systems need to have the flexibility to take the optimum real-time decision in the face of constantly varying market factors. Demand response (DR) has become the newest method of improving the performance and reliability of the electrical system. Here, an hour-ahead DR algorithm is proposed for EM at home. This paper presents an artificial neural network approach that uses stable cost predictions as a method for dealing with upcoming price uncertainties. For making optimum and decentralized decisions for various household devices, multi-agent reinforcement learning has been used along with predicted upcoming costs. This paper conducts the simulation with shiftable, non-shiftable, and controllable loads to determine the effectiveness of this suggested EM strategy. Based on the outcomes of the experiments, this suggested DR algorithm has capable of handling EM for a number of devices, minimizing consumer electricity expenses and discomfort prices, and helping the consumer considerably reduce its energy expenses in comparison to a benchmark using no DR.}
}
@article{KAKIZAKI20232808,
title = {Student modeling considering learning behavior history with deep factorization machines},
journal = {Procedia Computer Science},
volume = {225},
pages = {2808-2815},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.273},
url = {https://www.sciencedirect.com/science/article/pii/S187705092301431X},
author = {Toma Kakizaki and Shinichi Oeda},
keywords = {Intelligent tutoring system, Educational data mining, Student modeling, Knowledge tracing, Factorization machines, DeepLearning},
abstract = {To use an intelligent tutoring system (ITS) in an educational setting effectively, it is necessary to understand the skill status of students and recommend appropriate questions. Existing studies focused on improving the performance of ITS using student modeling to estimate the skill status of students. Knowledge tracing (KT) is the mainstream student modeling method, and deep learning approaches such as deep knowledge tracing and self-attentive knowledge tracing have been studied extensively in recent years. These models take only the questions solved by the student and the correct or incorrect answers to those questions as input; they do not assume the use of other features. In this study, we perform student modeling using DeepFM and FiBiNET that combines factorization machines and deep learning. Our results indicate that these models are more accurate than KT because of their ability to cope with sparse data and consider pairwise feature interactions, and more suited for real-world applications than KT.}
}
@incollection{SALINI202335,
title = {Chapter 3 - Digital twin and artificial intelligence in industries},
editor = {Rajesh Kumar Dhanaraj and Ali Kashif Bashir and Vani Rajasekar and Balamurugan Balusamy and Pooja Malik},
booktitle = {Digital Twin for Smart Manufacturing},
publisher = {Academic Press},
pages = {35-58},
year = {2023},
isbn = {978-0-323-99205-3},
doi = {https://doi.org/10.1016/B978-0-323-99205-3.00014-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323992053000146},
author = {S. Salini and B. Persis Urbana Ivy},
keywords = {Digital twins, cyber twins, DTS, artificial intelligence, taxonomy, meta-dimension},
abstract = {Applications of digital twin (DT) contribute to smart manufacturing via the integration of the cyber domain and the real world. Artificial Intelligence (AI) that is based on machine learning (ML) is generally recognized as being among the most promising technological developments in the manufacturing industry. Despite this, machine learning techniques call for enormous quantities of high-quality training datasets, and in the case of supervised ML, human labeling of such datasets is often necessary. Collecting and analyzing historical performance data to uncover operational insights has been a long-standing driver of efficiency and innovation for a wide variety of businesses, across all industrial sectors and even farther afield. However, the possible advantages of this method have not yet been leveraged to their maximum. There is a tendency for vast volumes of data, spanning anything from the current state of subsurface assets to the attitude that customers express on social media postings, to go mostly unrecorded and unanalyzed. This may be a problem for businesses. However, due to the limitations of existing IoT platforms in representing complex industrial machines, supporting production line-based application testing, and the lack of cost models for application cost/benefit analysis, the development of such Industry 4.0 applications is currently quite costly. Cyber Twins (CTs) are an extension of DTs that we propose using to facilitate the rapid and low-cost creation of Industry 4.0 applications. CTs may incorporate machine simulators and provide semantic descriptions of the machines they model, which makes it possible to test applications without putting the production line at risk or incurring additional costs. The applications for Industry 4.0 are based on CT and the accompanying cost models are the primary topics of this research. Second, the paper provides empirical results that connect existing academic literature to the interdependencies between edge components and internal and external services and systems in the Industry 4.0 paradigm. The novel aspect of this research is a new method for creating a DT, or a virtual representation that acts as the real-time digital counterpart of a physical object or process as defined by a conceptual model. This is the chapter’s primary contribution. The approach that was used to conduct the research for this article was conceptually similar to an investigation of complex, linked, and coupled systems using the grounded theory. This research provides an outline of how to increase AI development in IoT networks via integrating human-computer interactions across different knowledge management systems. These interactions take place in different information management systems. In addition, the previously used real-time controllable method has been improved, as well as optimized. Additionally, it performs simulation testing on the method in both a serial and a parallel fashion. The relevant mining time of the improved algorithm is shown to be substantially less than the time required by the conventional data mining method when applied to the same dataset, as shown by the test results when the ideal scenario of the parallel algorithm has been achieved. The amount of time required for conventional mining is around three and a half times as long as the amount of time required for data mining in this study, and the amount of power that the optimization method requires to operate has been decreased to 20W. With the help of AI, the manufacturing model (DT) and the decision support system are able to include all of the information generated by these subsystems. DT data technology facilitates the identification of pertinent information that can be processed and used to inform managerial decision-making. Applications of AI may open a wide variety of doors in the manufacturing industry, leading to the creation of new business models and the improvement of existing procedures. A formal model was used to define the landscape to guarantee the feasibility of conducting an in-depth analysis of the status and progression of the landscape, while taking into account DT and other technologies. The adoption of DT and Industrial Internet of Things for modeling of a real enterprise’s production process was taken into consideration. However, Digital Twin Store (DTS) has stricter standards, particularly in regard to the real-time engagement that is expected. A new technique that satisfies the aforementioned characteristics may be found in the use of AI, which is an efficient way of boosting the intelligence of the physical shop floor. In this piece of research, a conceptual framework for AI-enhanced DTS in interaction is presented. The real-time engagement is significantly increased by AI-enhanced DTS, thanks to its predictive control. The AI-enhanced interaction implementation technique in DTS is also discussed in length in this presentation. Finally, the DTS has implemented the necessary technology to support interaction.}
}
@article{IRINO2023345,
title = {Digital twin based accuracy compensation},
journal = {CIRP Annals},
volume = {72},
number = {1},
pages = {345-348},
year = {2023},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2023.04.088},
url = {https://www.sciencedirect.com/science/article/pii/S0007850623001269},
author = {Naruhiro Irino and Akihito Kobayashi and Yuta Shinba and Kengo Kawai and Daniel Spescha and Konrad Wegener},
keywords = {Digital twin, Dynamics, Thermal error compensation},
abstract = {A new method for predicting thermal displacements and dynamic characteristics of a machine tool using a digital twin to compensate for accuracy has been developed. The compensation method is based on an accuracy prediction method using model order reduction to reproduce the behavior of machine tools digitally according to their physical characteristics. Additionally, by coupling with the digital twin of dynamics, a comprehensive digital machine tool is generated. Using this model, the compensation of machining accuracy for ambient temperature conditions was validated on the actual machine. As a result, the error in the machining space was successfully compensated. Additionally, the dynamic cutting force was accurately estimated. A new method of compensation for thermal displacement and volumetric accuracy was established, which can visualize the actual machine phenomena in more detail than the conventional compensation of mathematical models by regression, machine learning, and neural networks.}
}
@article{ZHANG2023101485,
title = {Hybrid deep learning model for accurate classification of solid waste in the society},
journal = {Urban Climate},
volume = {49},
pages = {101485},
year = {2023},
issn = {2212-0955},
doi = {https://doi.org/10.1016/j.uclim.2023.101485},
url = {https://www.sciencedirect.com/science/article/pii/S2212095523000792},
author = {Huanping Zhang and Hanhua Cao and Yuhuai Zhou and Changle Gu and Danyu Li},
keywords = {Solid waste management, Classification, Deep learning, Convolution neural network (CNN), Deep belief network (DBN), Optuna, Alexnet, Urban city},
abstract = {Due to the increasing initiatives for urbanization and the development of smart cities, waste generation, segregation, and its management have become fundamental tasks. To provide efficient planning for waste management and its processes, such as collection, sorting, recycling, and disposal, recently, machine learning (ML) approaches have been utilized to assist the authorities. However, the identification of the best ML approach for the prediction of waste is a challenging effort. Finding adequate waste litter measurement is necessary for the ecological characteristics to improve over time. The waste from the trash may divide into organic and recycling types. In this paper, the optimized hybrid deep learning model has been developed for waste classification. This proposed work takes advantage of (i) data collection and preprocessing (ii) feature extraction using CNN (AlexNet) (iii) waste prediction from the urban cities' wastes using DBN, and (iv) hyperparameter optimization using Optuna. This model obtained an R2 score of 0.94, MPE 0.02 than other state-of-the-art approaches. Compared to the individual learners model, this proposed optimized hybrid deep learning model boosts the performance to predict waste generation and classify it with increased accuracy.}
}
@article{GU2023286,
title = {Accurate and fast machine learning algorithm for systems outage prediction},
journal = {Solar Energy},
volume = {251},
pages = {286-294},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23000130},
author = {Chan Gu and Chen Chen and Wei Tang},
keywords = {Digital Twin, Solar-based System Outages, Cyber-vulnerabilities, Cyber Threats, Machine Learning, Resiliency},
abstract = {Cyber-attacks (CAs) on electrical networks in presents of renewable energies, particularly solar energy, have become more complex and sophisticated over the past few years by making severe system outages. In light of increased automation in solar-based energy industries, a holistic cyber-physical infrastructure must be considered to predict the effect of CAs on electrical networks and the ways to enhance its resilience. The present study examines the resilience characteristics at the equipment area of the diverse control methods and their effect on the outage severity of the smart grid using digital twins (DT) simulation technology. The paper presents a machine learning based metric for measuring the resilience of cyber-physical features that considers device-level characteristics, vulnerabilities, and system models. Resiliency refers to a system's capability of providing energy even during severe contingencies and relates to the ability to resist, forecast, and recover. An example based on the newest CA against Ukraine has been provided and simulated on DT environment. A case study is proposed to illustrate how cyber-physical resilience metrics can be applied to improve operators' situational awareness and provide more proactive or corrective control measures for improving resilience.}
}