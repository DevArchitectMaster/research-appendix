@article{SUN2023110969,
title = {A Metaverse text recognition model based on character-level contrastive learning},
journal = {Applied Soft Computing},
volume = {149},
pages = {110969},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110969},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623009870},
author = {Le Sun and Huiyun Li and Ghulam Muhammad},
keywords = {Metaverse, Lightweight model, Scene text recognition, Noise robustness, Time efficiency},
abstract = {Accurate and efficient text recognition can enhance the accuracy and time efficiency of human–computer interaction and information exchange in noise Metaverse scenarios. For example, it can improve the safety of digital twin-based intelligent transportation and the intelligence of Non-Player Characters. Robust features play a vital role in the performance of scene text recognition models in noise Metaverse situations. To extract robust features, and improve the accuracy and time efficiency of scene text recognition, we propose a Character level text recognition model in Metaverse applications, called MetaChara. It contains two main components: a lightweight text feature extraction module (LightFeature), and a robust character recognition module (RobChara). LightFeature leverages the advantage of global feature aggregation in the primitive representation learning network to handle irregular text images.RobChara incorporates the capability of contrastive learning from the momentum contrast method, improving the robustness of feature extraction in MetaChara. It structures a feature queue for organized storage. By optimizing the similarity of intra-character features and maximizing inter-character differences, it makes the model better adapted to scene text recognition tasks in Metaverse. Experiment results demonstrate that MetaChara is light with 29.14 million parameters and time efficient with an average recognition speed of 1.73 s. It also achieves excellent performance in terms of FLoating-point Operations (FLOPs), registering only 59.60 billion times for each operation. MetaChara achieves an average accuracy of 0.969 for character recognition. We present a case study where MetaChara quickly and accurately recognizes scene texts within the context of autonomous driving in the Metaverse. This demonstrates how MetaChara enhances safety and improves time efficiency for intelligent transportation systems.}
}
@article{HADDELER2023104512,
title = {Real-time terrain anomaly perception for safe robot locomotion using a digital double framework},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104512},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104512},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001513},
author = {Garen Haddeler and Hari P. Palanivelu and Fabien Colonnier and Yung Chuen Ng and Albertus H. Adiwahono and Zhibin Li and Chee-Meng Chew and Meng Yee Michael Chuah},
keywords = {Robot sensing, Legged robot locomotion, Digital twins, Field robotics},
abstract = {Digital twinning systems are effective tools to test and develop new robotic capabilities before applying them in the real world. This work presents a real-time digital double framework that improves and facilitates robot perception of the environment. Soft or non-rigid terrains can cause locomotion failures, while visual perception alone is often insufficient to assess the physical properties of such surfaces. To tackle this problem we employ the proposed framework to estimate ground collapsibility through physical interactions while the robot is dynamically walking on challenging terrains. We extract discrepancy information between the two systems, a simulated digital double that is synchronized with a real robot, both using exactly the same physical model and locomotion controller. The discrepancy in sensor measurements between the real robot and its digital double serves as a critical indicator of anomalies between expected and actual motion and is utilized as input to a learning-based model for terrain collapsibility analysis. The performance of the collapsibility estimation was evaluated in a variety of real-world scenarios involving flat, inclined, elevated, and outdoor terrains. Our results demonstrate the generality and efficacy of our real-time digital double architecture for estimating terrain collapsibility.}
}
@article{ABDEEN2023102032,
title = {Citizen-centric digital twin development with machine learning and interfaces for maintaining urban infrastructure},
journal = {Telematics and Informatics},
volume = {84},
pages = {102032},
year = {2023},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.102032},
url = {https://www.sciencedirect.com/science/article/pii/S0736585323000965},
author = {Fathima Nishara Abdeen and Sara Shirowzhan and Samad M.E. Sepasgozar},
keywords = {City digital twin, Macro digital twin, Infrastructure, Machine learning, Deep learning, Sensors, Application processing interfaces},
abstract = {Serious interoperability challenges prevent the stakeholders of infrastructure projects and citizens as the final users, from interacting with each other and helping maintain a project over its lifetime. This paper focuses on macro-scale digital twins collecting stakeholders’ feedback as the end users of the infrastructure and its service buildings. The aim is to examine various technologies for developing a CCDT and use the information processed to maintain and manage infrastructure services. This involves a systematic review, investigating technologies for data acquisition, data processing, and interface development to improve CCDT capabilities. Among the 89 selected articles, 16% of the sample dataset directly focused on users’ engagement. When considering data acquisition technologies, the open data platforms (37% of the sample dataset), remote sensors (37%), and IoT sensors (8%) ensure the dynamic capabilities of the digital twin. Volunteered geographic information (VGI) and social sensing are two prominent technologies that encourage citizen engagement. The number of articles considering the use of segmentation and classification and object detection and tracking algorithms at city-scale digital twins is significant, accounting for 25% and 24% of all articles discussing various algorithms. Further, the study carried out a comprehensive analysis of application programming interfaces (APIs) while presenting their specifications, features, and applications.}
}
@article{LAKHAN2023101747,
title = {Secure-fault-tolerant efficient industrial internet of healthcare things framework based on digital twin federated fog-cloud networks},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {35},
number = {9},
pages = {101747},
year = {2023},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101747},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823003014},
author = {Abdullah Lakhan and Ali Azawii {Abdul Lateef} and Mohd Khanapi {Abd Ghani} and Karrar Hameed Abdulkareem and Mazin Abed Mohammed and Jan Nedoma and Radek Martinek and Begoña Garcia-Zapirain},
keywords = {IoHT, Fault-tolerant, Digital twin, Industry 5.0, Blockchain, SFTS, Fog-cloud networks, CNN},
abstract = {The Industrial Internet of Healthcare Things (IIoHT) is the emerging paradigm in digital healthcare. Context-aware healthcare sensors, local intelligent watches, healthcare devices, wireless communication technologies, fog, and cloud computing are all parts of the IIoHT used in healthcare. The ubiquitous healthcare services it provides to its users in practice. However, the current IIoHT healthcare frameworks have security and failure issues in mobile fog and cloud networks where they are spread out. This paper presents the secure, fault-tolerant IIoHT Framework based on digital twin (DT) federated learning-enabled fog-cloud models. The DT is an effective technology that makes virtual copies of servers at different locations. DT integrated with federated learning inside the fog and cloud environments, where the failure of tasks and execution improved for healthcare sensor data. The study aims to reduce processing time and the risk of task failure. The study presents the Secure and Fault-Tolerant Strategies (SFTS)-enabled IIoHT framework that optimizes wearable sensor data and executes it with the minimum offloading and processing delays. Simulation results show that the proposed work minimized the security risk by 40%, failure risk of tasks risk by 50%, and the training and testing time by 39% for sensor data during the execution of mobile fog cloud networks.}
}
@article{SUN2023113991,
title = {On-line Milling Tool Wear Monitoring Under Practical Machining Conditions},
journal = {Measurement},
pages = {113991},
year = {2023},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2023.113991},
url = {https://www.sciencedirect.com/science/article/pii/S0263224123015555},
author = {Yi Sun and Jigang He and Hongli Gao and Hongliang Song and Liang Guo},
keywords = {tool-wear monitoring, anodic or cathodic samples, marginal distribution, conditional distribution},
abstract = {Tool-wear monitoring plays a crucial role in high-speed cutting machining as it ensures the accuracy of the machining surface, improves tool utilization, and extends the life of machine tools. However, effectively selecting and processing data from each stage of the feed-path and leveraging the vast amount of unlabeled data associated with different processing parameters present considerable challenges in practical scenarios. To deal with the above problems, this study proposes the tool-wear monitoring method using unreliable pseudo-labels (TWM-U2PL), comprising both a teacher model and a student model. Within TWM-U2PL, the teacher model encompasses two independent classifiers that facilitate the extraction and categorization of tool-wear features, additionally assigning labels to certain unlabeled data as either anodic or cathodic samples. The student model achieves accurate tool-wear monitoring by dynamically adjusting marginal and conditional distribution. The experiments on a tool-wear dataset confirmed the effectiveness of TWM-U2PL, which achieved an outstanding accuracy of 87.25%, surpassing the well-known models such as CNN, CHMM, and FE-PCA-SA.}
}
@article{ZHONG2023103350,
title = {Advances in intelligent detection, monitoring, and control for preserving the quality of fresh fruits and vegetables in the supply chain},
journal = {Food Bioscience},
volume = {56},
pages = {103350},
year = {2023},
issn = {2212-4292},
doi = {https://doi.org/10.1016/j.fbio.2023.103350},
url = {https://www.sciencedirect.com/science/article/pii/S2212429223010015},
author = {Xiaolong Zhong and Min Zhang and Tiantian Tang and Benu Adhikari and Yamei Ma},
keywords = {Sensors, Detection, Imaging, Machine learning, Algorithm},
abstract = {The raw materials and information sharing of global fresh produce supply chains is happening every day, with the same time, losses of spoiled fruits and vegetables also exist, too. Most of the existing strategies have been successfully used in stop-loss practices such as refrigeration, atmosphere control and coating. They have achieved significant benefits but lack initiative. In this review, we sorted out and compiled data-driven networks and technical equipment reports, like emerging sensors, smart indicators and computer vision, etc. In addition, we also give suggestions on the system improvements of fruit and vegetable supply chain, including better applying cloud processing platforms such as IoT and blockchain to the supply chain. Finally, among the recommendations given, we highlight the importance of fencing strategies and real-time data management.}
}
@article{YOCKEY2023104960,
title = {Cyber threat assessment of machine learning driven autonomous control systems of nuclear power plants},
journal = {Progress in Nuclear Energy},
volume = {166},
pages = {104960},
year = {2023},
issn = {0149-1970},
doi = {https://doi.org/10.1016/j.pnucene.2023.104960},
url = {https://www.sciencedirect.com/science/article/pii/S0149197023003955},
author = {Patience Yockey and Anna Erickson and Christopher Spirito},
keywords = {Machine learning, Autonomous control systems, Digital twins, Cybersecurity},
abstract = {Advanced cyber-attacks against critical infrastructure and the energy sector are becoming more common. With the invention of autonomous control systems (ACS) within advanced nuclear reactor designs, system designers, reactor operators, and regulators must consider cybersecurity during the design and operational phases. This article provides a cyber threat assessment of machine learning (ML)-based digital twinning (DT) technologies in the context of advanced reactor ACS. A cyber–physical testbed was created to emulate nuclear reactor digital instrumentation and controls (I&C) and act as a basis for the ACS. The ACS was designed as two plant-level DTs predicting reactor malfunctions and determining control actions and two component-level DTs responsible for classifying component states and forecasting component inputs and outputs (I/O). Two duplicate ACS designs– one using a traditional ML framework and one using an automated ML (AutoML) framework– were created and tested against cyber-attacks on training data, real-time process data, and ML model architectures to determine their respective qualitative cyber-risk in terms of likelihood and impact. Both frameworks showed similar cyber-resilience against training, real-time, and ML architecture attacks, proving that neither is inherently more secure. Recommended safeguard and security measures are posed to system designers, reactor operators, and regulators to maintain the cybersecurity of ML-based DT technologies such as ACS, prompting a holistic view of shared responsibility for maintaining cyber-secure ML-based systems.}
}
@article{KUMAR2023111921,
title = {Digital twin-driven SDN for smart grid: A deep learning integrated blockchain for cybersecurity},
journal = {Solar Energy},
volume = {263},
pages = {111921},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.111921},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23005546},
author = {Prabhat Kumar and Randhir Kumar and Ahamed Aljuhani and Danish Javeed and Alireza Jolfaei and A. K. M. Najmul Islam},
keywords = {Blockchain, Deep learning, Digital twin, Internet of things, Smart grid, Software-defined networking},
abstract = {Internet of Things (IoT)-enabled Smart Grid (SG) network is envisioned as the next-generation network for intelligent and efficient electric power transmission. In SG environment, the Smart Meters (SMs) mostly exchange services and data from Service Providers (SPs) via insecure public channel. This makes the entire SG ecosystem vulnerable to various security threats. Motivated from the aforementioned challenges, we incorporate Digital Twin (DT) technology, Software-Defined Networking (SDN), Deep Learning (DL) and blockchain into the design of a novel SG network. Specifically, a secure communication channel is first designed using an authentication method based on blockchain technology that has the ability to withstand a number of well-known assaults. Second, a new DL architecture that includes a self-attention mechanism, a Bidirectional-Gated Recurrent Unit (Bi-GRU) model, fully connected layers, and a softmax classifier is designed to enhance the attack detection process in SG environments. To deliver low latency and real-time services, the SDN is next employed as the network’s backbone to send requests from SMs to a global SDN controller. DT technology is finally integrated into the SDN control plane, which stores the operating states and behavior models of SMs and communicates with SMs. The efficiency of the proposed framework is demonstrated by the blockchain implementation used in the SG network to assess computing time for the various numbers of transactions per block. Finally, the numerical results based on the N-BaIoT dataset shows better intrusion detection.}
}
@article{MA2023110718,
title = {Digital twin model for chiller fault diagnosis based on SSAE and transfer learning},
journal = {Building and Environment},
volume = {243},
pages = {110718},
year = {2023},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2023.110718},
url = {https://www.sciencedirect.com/science/article/pii/S036013232300745X},
author = {Xin Ma and Fan Chen and Zhihan Wang and Ke Li and Changbin Tian},
keywords = {Chiller, Fault diagnosis, Stacked sparse auto-encoder, Transfer learning, Digital twin},
abstract = {The equipment of chiller systems is characterized by a complex mechanical structure and operating environments that vary widely, resulting in high failure rates, energy waste, and costly maintenance. Traditional fault diagnosis methods suffer from low levels of digitalization and intelligence. Therefore, timely and accurate detection and diagnosis of the operating status of chiller systems are critical. To address the above issues, this study proposes a digital twin (DT) model for chiller system fault diagnosis based on stacked sparse auto-encoder (SSAE) and transfer learning (TL). First, a chiller system digital twin mapping model is constructed utilizing digital twin technology. Then, the SSAE model is constructed to provide real-time defect diagnosis and fault result validation. Finally, to address the limited chiller system data in practical applications, the knowledge of fault diagnosis acquired in the source domain is transferred to the target domain via TL. Experimental results demonstrate that the SSAE model outperforms back propagation (BP), recurrent neural network (RNN) and long short-term memory (LSTM) model in term of accuracy. Furthermore, using TL achieves a diagnostic accuracy of over 90% for different degrees of fault severity, with a significant decrease in cross-entropy loss compared to no TL, confirming the effectiveness of the TL method.}
}
@article{CHEN2023103439,
title = {Semi-supervised knowledge distillation framework for global-scale urban man-made object remote sensing mapping},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {122},
pages = {103439},
year = {2023},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2023.103439},
url = {https://www.sciencedirect.com/science/article/pii/S1569843223002637},
author = {Dingyuan Chen and Ailong Ma and Yanfei Zhong},
keywords = {Remote sensing, Knowledge distillation, Urban man-made object, Label diversity},
abstract = {Accurate mapping of global urban man-made objects such as buildings and roads is critical for monitoring urbanization. Remote sensing imagery provides a cost-effective way of mapping these objects, but the challenge of “knowledge forgetting” arises due to urban diversity and the continuous growth of global samples. Although the existing knowledge distillation approaches can transfer knowledge from a larger teacher model to a smaller student model by distilling the knowledge learned from reliable labels, they fail to work for global-scale mapping, which lies in two aspects: low-quality labeling and fixed-size models. In this paper, we propose GUMONet, which is a semi-supervised knowledge distillation framework for global-scale urban man-made object mapping. For the first phase, a label diversity progressive learning module is introduced for generating high-quality labels in a semi-supervised manner. Label diversity is used to measure the diverse urban patterns based on spatial-semantic uncertainty, where the diversified labels clustered in object boundaries and heterogeneous areas are attributed to high spatial uncertainty and semantic uncertainty, respectively. Based on the label diversity, the model decision boundary is progressively determined from coarse to fine. Specifically, at the early stage, instances away from the decision boundary are selected to ensure the stability of the model training. As the iteration progresses, instances close to the decision boundary are associated with a higher probability of further enhancing the quality of the uncertain labels by hard sample mining. For the second phase, a size-variable knowledge distillation module is adopted to optimize the data-model matching process. This module consists of a noise teacher model that prevents overfitting by injecting noise perturbations to increase the data distribution complexity and a size-variable student model that avoids underfitting by dynamically adjusting its size with the growth of global samples. We applied GUMONet to six study areas across four continents, with data from different sensors, achieving an 18.97% improvement in intersection over union, compared with the previous methods. Our results also demonstrate a positive correlation between urban development and urban diversity, with a correlation coefficient of 0.749. As urban development progresses, urban diversity stabilizes and building transformation becomes the primary means of promoting further development.}
}
@article{WANG2023110625,
title = {Digital twin modeling for structural strength monitoring via transfer learning-based multi-source data fusion},
journal = {Mechanical Systems and Signal Processing},
volume = {200},
pages = {110625},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2023.110625},
url = {https://www.sciencedirect.com/science/article/pii/S0888327023005332},
author = {Bo Wang and Zengcong Li and Ziyu Xu and Zhiyong Sun and Kuo Tian},
keywords = {Digital twin modeling, Data fusion, Structural strength monitoring, Bagging, Transfer learning},
abstract = {Experimental measurement and numerical simulation are two typical methods to monitor the strength variation of structures. However, the former method is difficult to lay sufficient sensors on structures with large sizes or complex curved surfaces, and the latter one suffers from low prediction accuracy due to the simplification and idealization of the physical entity. How to efficiently utilize and combine these two kinds of methods remains a challenging problem. In this study, a novel digital twin modeling method via transfer learning-based multi-source data fusion (DTM-TL-MSDF) is proposed to make full use of the experiment data and the simulation data, aiming to establish an accurate digital twin model for structural strength monitoring in real-time. In the off-line stage, the clustering algorithm is used to pre-process the huge simulation data to relieve the computational burden, and the deep neural network (DNN) model is then pre-trained using the pre-processed simulation data. In the on-line stage, the pre-trained DNN model is fine-tuned using the experimental data to carry out transfer learning. Moreover, the bagging algorithm is employed in the fine-tuning process to improve the robustness and prediction accuracy due to its ability to address the dataset with only a small number of training points. To illustrate the effectiveness of the DTM-TL-MSDF method, a one-dimensional test function and an experimental study of a rectangular plate with hole under axial tension are studied. Results indicate that the DTM-TL-MSDF method can build an accurate digital twin model by integrating the simulation data and the experimental data with excellent global and local accuracy, providing a novel solution to monitor the variations of the structural full-field strength in real-time.}
}
@article{KILIC2023129118,
title = {Digital twin for Electronic Centralized Aircraft Monitoring by machine learning algorithms},
journal = {Energy},
volume = {283},
pages = {129118},
year = {2023},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2023.129118},
url = {https://www.sciencedirect.com/science/article/pii/S0360544223025124},
author = {Ugur Kilic and Gorkem Yalin and Omer Cam},
keywords = {Machine learning, Estimation, Turbofan, Primary engine parameters, Digital twin},
abstract = {Electronic Centralized Aircraft Monitoring (ECAM) parameters play a vital role in the operation of an aircraft to reduce the workload of the cockpit crew. A wide-body commercial aircraft with a triple-spool turbofan engine is examined within the scope of the study. This study is focused on the estimation of the ECAM primary engine parameters: Engine Pressure Ratio, Exhaust Gas Temperature, Fuel Flow, and Shaft Speeds without any additional measurement for data continuity. The recorded flight data obtained from a commercial aircraft is processed with machine learning methods, and the most suitable estimation method is tried to be determined. Correlation analysis is carried out for each data in the study to show strong predictor candidates. The modeling process is conducted by using MATLAB. Results indicate that the Fine Decision Tree is better at memorizing data, while the Wide Neural Network is better at generalizing data. Computational results show that the developed models are outstandingly precise and accurate to estimate aircraft's ECAM data to ensure flight safety for health and performance monitoring of an engine. Thus, when an unreliable situation occurs while performing the flight in practical conditions, the cockpit crew will be able to overcome this situation by Digital Twin.}
}
@article{BRAIK2023104020,
title = {A novel digital twin framework of electric power infrastructure systems subjected to hurricanes},
journal = {International Journal of Disaster Risk Reduction},
volume = {97},
pages = {104020},
year = {2023},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2023.104020},
url = {https://www.sciencedirect.com/science/article/pii/S2212420923005009},
author = {Abdullah M. Braik and Maria Koliou},
keywords = {Bayesian network, Community resilience, Digital twin, Electric power network, Hurricanes},
abstract = {The electric power network (EPN) is one of the most critical infrastructure systems as most lifeline, economic, and social systems depend heavily on it, and any disruption in the network may affect the well-being of modern societies. Being the most vulnerable to natural hazards, the resilience of the EPN has received plenty of attention in recent years, particularly considering the increasing frequency and severity of natural hazards associated with climate instabilities. The data revolution and the recent advances in the fields of artificial intelligence (AI), machine learning (ML), and the Internet of Things (IoT) have prompted researchers to take the next step and expand the available predictive models toward digital twins (DT). However, there is still a lack of an applicable framework for a DT of infrastructure systems in the face of disasters. In this paper, a novel DT framework of the EPN when subjected to hurricanes is proposed that combines physics-based and data-driven models while also employing a dynamic Bayesian network (DBN). The DBN can be updated in near real-time via data sensing to provide a DT that is simple, computationally feasible, scalable, and capable of modeling and estimating the failure and performance states of the various elements of the EPN. The proposed DT framework is applied to Galveston Island's EPN, and the results are validated using historical data, demonstrating that the DT can produce detailed and highly accurate estimations to be used in decision-making for community resilience planning.}
}
@article{BOUKREDERA2023107035,
title = {Enhancing the drilling efficiency through the application of machine learning and optimization algorithm},
journal = {Engineering Applications of Artificial Intelligence},
volume = {126},
pages = {107035},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107035},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623012198},
author = {Farouk Said Boukredera and Mohamed Riad Youcefi and Ahmed Hadjadj and Chinedu Pascal Ezenkwu and Vahid Vaziri and Sumeet S. Aphale},
keywords = {Drilling optimization, Drilling vibrations, Artificial neural network, Machine learning, Rate of penetration},
abstract = {This article presents a novel Artificial Intelligence (AI) workflow to enhance drilling performance by mitigating the adverse impact of drill-string vibrations on drilling efficiency. The study employs three supervised machine learning (ML) algorithms, namely the Multi-Layer Perceptron (MLP), Support Vector Regression (SVR), and Regression Decision Tree (DTR), to train models for bit rotation (Bit RPM), rate of penetration (ROP), and torque. These models combine to form a digital twin for a drilling system and are validated through extensive cross-validation procedures against actual drilling parameters using field data. The combined SVR - Bit RPM model is then used to categorize torsional vibrations and constrain optimized parameter selection using the Particle Swarm Optimization block (PSO). The SVR-ROP model is integrated with a PSO under two constraints: Stick Slip Index (SSI<0.05) and Depth of Cut (DOC<5 mm) to further improve torsional stability. Simulations predict a 43% increase in ROP and torsional stability on average when the optimized parameters WOB and RPM are applied. This would avoid the need to trip in/out to change the bit, and the drilling time can be reduced from 66 to 31 h. The findings of this study illustrate the system's competency in determining optimal drilling parameters and boosting drilling efficiency. Integrating AI techniques offers valuable insights and practical solutions for drilling optimization, particularly in terms of saving drilling time and improving the ROP, which increases potential savings.}
}
@article{ZHU2023780,
title = {A reduced order model based on adaptive proper orthogonal decomposition incorporated with modal coefficient learning for digital twin in process industry},
journal = {Journal of Manufacturing Processes},
volume = {102},
pages = {780-794},
year = {2023},
issn = {1526-6125},
doi = {https://doi.org/10.1016/j.jmapro.2023.07.061},
url = {https://www.sciencedirect.com/science/article/pii/S1526612523007454},
author = {Xiaoyang Zhu and Yangjian Ji},
keywords = {Reduced order model, Adaptive proper orthogonal decomposition, Modal coefficient learning, Digital twin, Process industry},
abstract = {The digital twin (DT) technology provides a viable and promising direction for improving the level of the production status monitoring and the overall product quality in various fields. However, the accuracy of working condition identification, the timeliness of process adjustment, and the stability of product quality are put forward higher requirements in the process industry, which is characterized by nonlinear, large-scale, and dynamic complex systems. Therefore, it still remains a tricky challenge to construct and maintain an effective and accurate DT model in the process industry. A reduced order model (ROM) with the adaptive updating ability is proposed. The adaptive proper orthogonal decomposition (APOD) is adopted to achieve the continuous iteration and the adaptive optimization of the reduced basis set. Correspondingly, an adaptive learning algorithm based on the least squares support vector regression (LS-SVR) is developed to quickly obtain the modal coefficients and effectively circumvent the prohibitively high computational cost. In this way, the physical field of interest is expressed in a low-dimensional approximation with a high accuracy. The effectiveness of the method is verified by a case study in the process industry. Results show that the proposed model displays a high-precision fitting and a significant time saving for the full order model (FOM).}
}
@article{EUGENE2023108430,
title = {Learning and optimization under epistemic uncertainty with Bayesian hybrid models},
journal = {Computers & Chemical Engineering},
volume = {179},
pages = {108430},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108430},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423003009},
author = {Elvis A. Eugene and Kyla D. Jones and Xian Gao and Jialu Wang and Alexander W. Dowling},
keywords = {Bayesian inference, Optimization under uncertainty, Grey-box modeling, Digital twins},
abstract = {Hybrid (i.e., grey-box) models are a powerful and flexible paradigm for predictive science and engineering. Grey-box models use data-driven constructs to incorporate unknown or computationally intractable phenomena into glass-box mechanistic models. The pioneering work of statisticians Kennedy and O’Hagan introduced a new paradigm to quantify epistemic (i.e., model-form) uncertainty. While popular in several engineering disciplines, prior work using Kennedy–O’Hagan hybrid models focuses on prediction with accurate uncertainty estimates. This work demonstrates computational strategies to deploy Bayesian hybrid models for optimization under uncertainty. Specifically, the posterior distributions of Bayesian hybrid models provide a principled uncertainty set for stochastic programming, chance-constrained optimization, or robust optimization. Through two illustrative case studies, we demonstrate the efficacy of hybrid models, composed of a structurally inadequate glass-box model and Gaussian process bias correction term, for decision-making using limited training data. From these case studies, we develop recommended best practices and explore the trade-offs between different hybrid model architectures.}
}
@article{SARKAR2023,
title = {Cyber-agricultural systems for crop breeding and sustainable production},
journal = {Trends in Plant Science},
year = {2023},
issn = {1360-1385},
doi = {https://doi.org/10.1016/j.tplants.2023.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1360138523002637},
author = {Soumik Sarkar and Baskar Ganapathysubramanian and Arti Singh and Fateme Fotouhi and Soumyashree Kar and Koushik Nagasubramanian and Girish Chowdhary and Sajal K. Das and George Kantor and Adarsh Krishnamurthy and Nirav Merchant and Asheesh K. Singh},
keywords = {cyber-agricultural systems, precision agriculture, smart farming, digital twins, ubiquitous sensing, cyberinfrastructure},
abstract = {The cyber-agricultural system (CAS) represents an overarching framework of agriculture that leverages recent advances in ubiquitous sensing, artificial intelligence, smart actuators, and scalable cyberinfrastructure (CI) in both breeding and production agriculture. We discuss the recent progress and perspective of the three fundamental components of CAS – sensing, modeling, and actuation – and the emerging concept of agricultural digital twins (DTs). We also discuss how scalable CI is becoming a key enabler of smart agriculture. In this review we shed light on the significance of CAS in revolutionizing crop breeding and production by enhancing efficiency, productivity, sustainability, and resilience to changing climate. Finally, we identify underexplored and promising future directions for CAS research and development.}
}
@article{MENG2023111870,
title = {Digital twin for intelligent probabilistic short term load forecasting in solar based smart grids using shark algorithm},
journal = {Solar Energy},
volume = {262},
pages = {111870},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.111870},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23005030},
author = {Fantuo Meng and Xianchang Wang},
keywords = {Probabilistic prediction model, Solar based smart grids, Real-time data prediction, Real-time digital twin simulation, Shark optimization},
abstract = {This article proposes a novel evolving based prediction model for the accurate short term load forecasting in solar based smart grids. The proposed method uses a probabilistic method for uncertainty quantization to make sure that the maximum modeling of the prediction interval would be achieved in a renewable based environment. In this regard, the innovative lower upper bound estimation method (LUBE) is trained using the real-time data of the smart grid gathered by the digital twin of the system. This would result in much higher results due to the avoidance of malfunction of the smart metering devices located within the smart grid. Digital twin can help predict the load demand in solar based smart grids by using machine learning algorithms to analyze the data from the smart grid. This data can be used to create a model of the system and predict how the load demand will change based on different factors such as weather, time of day, and season. By understanding the load demand, solar based smart grids can better manage their energy resources and optimize the performance of the system. In order to improve the model performance, white shark optimization algorithm (WSOA) is used as the trainer of the prediction model in a heuristic environment. The results advocate the high accuracy and reliability of the proposed method on practical dataset,}
}
@article{ZHAO2023100477,
title = {Statistical learning prediction of fatigue crack growth via path slicing and re-weighting},
journal = {Theoretical and Applied Mechanics Letters},
volume = {13},
number = {6},
pages = {100477},
year = {2023},
issn = {2095-0349},
doi = {https://doi.org/10.1016/j.taml.2023.100477},
url = {https://www.sciencedirect.com/science/article/pii/S209503492300048X},
author = {Yingjie Zhao and Yong Liu and Zhiping Xu},
keywords = {Fatigue crack growth, Structural health monitoring, Statistical noises, Rare events, Digital libraries},
abstract = {Predicting potential risks associated with the fatigue of key structural components is crucial in engineering design. However, fatigue often involves entangled complexities of material microstructures and service conditions, making diagnosis and prognosis of fatigue damage challenging. We report a statistical learning framework to predict the growth of fatigue cracks and the life-to-failure of the components under loading conditions with uncertainties. Digital libraries of fatigue crack patterns and the remaining life are constructed by high-fidelity physical simulations. Dimensionality reduction and neural network architectures are then used to learn the history dependence and nonlinearity of fatigue crack growth. Path-slicing and re-weighting techniques are introduced to handle the statistical noises and rare events. The predicted fatigue crack patterns are self-updated and self-corrected by the evolving crack patterns. The end-to-end approach is validated by representative examples with fatigue cracks in plates, which showcase the digital-twin scenario in real-time structural health monitoring and fatigue life prediction for maintenance management decision-making.}
}
@article{YU2023101599,
title = {Sensor-based indoor air temperature prediction using deep ensemble machine learning: An Australian urban environment case study},
journal = {Urban Climate},
volume = {51},
pages = {101599},
year = {2023},
issn = {2212-0955},
doi = {https://doi.org/10.1016/j.uclim.2023.101599},
url = {https://www.sciencedirect.com/science/article/pii/S2212095523001931},
author = {Wenhua Yu and Bahareh Nakisa and Emran Ali and Seng W. Loke and Svetlana Stevanovic and Yuming Guo},
keywords = {Deep ensemble machine learning, Indoor temperature, Low-cost air quality sensors, Urban environment, Australia},
abstract = {Accurate prediction of indoor temperature is critical for climate change adaptation and occupant health. The aim of this study is to investigate an improved deep ensemble machine learning framework (DEML), by adjusting the model architecture with several machine learning (ML) and deep learning (DL) approaches to forecast the sensor-based indoor temperature in the Australian urban environment. We collected ambient station-based temperatures, satellite-based outdoor climate characteristics, and low-cost sensor-based indoor environmental metrics from 96 devices from August 2019 to November 2022, and established DEML with a rolling windows approach to assess the prediction stability over time. The DEML model was compared with several benchmark models, including Random Forest (RF), Support Vector Machine (SVM), eXtreme Gradient Boosting (XGboost), Long-short term memory (LSTM), and Super Learner model (SL). A total of 13,715 days [median: 341 days; IQR (the interquartile range): 221–977 days] of low-cost sensor-based indoor temperature were included in 25 commercial and residential buildings across eight cities. The prediction performance of DEML was superior to the other five benchmark models in most of the sensors [coefficients of determination (R2) of 0.861–0.990 and root mean square error (RMSE) of 0.125–0.886 °C], followed by RF and SL algorithms. DEML consistently achieved high accuracy across different climate zones, seasons, and building types, which could be used as a crucial tool for optimizing energy use, maintaining occupant comfort and health, and adapting to the impacts of climate change.}
}
@article{WANG2023101689,
title = {Security in defect detection: A new one-pixel attack for fooling DNNs},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {35},
number = {8},
pages = {101689},
year = {2023},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101689},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823002434},
author = {Pengchuan Wang and Qianmu Li and Deqiang Li and Shunmei Meng and Muhammad Bilal and Amrit Mukherjee},
keywords = {Industry 5.0, Endogenous safety, Zero-defect production, Defect detection, Network equipment, Deep neural network, TLMFO, One-pixel attack},
abstract = {The Industrial 5.0 Model integrates enabling technologies such as deep learning, digital twins, and the meta-universe with new development concepts. However, model and data security may pose challenges for developing zero-defect production and other industrial manufacturing industries. To address this issue, we generate adversarial examples using a one-pixel attack in adversarial machine learning, which can fool the defect detection classification model. The traditional one-pixel attack based on the Differential Evolution (DE) algorithm has limited global search ability. Therefore, we use a novel algorithm called Teaching and Learning-based Moth-Flame Optimization (TLMFO), which enhances the global search performance and improves the attack effectiveness. We evaluate TLMFO on benchmark functions and attacks on Cifar10 and ImageNet datasets, and compare it with MFO and DE. The results show that TLMFO outperforms both MFO and DE in terms of accuracy and speed of convergence. Moreover, TLMFO achieves notably better attack effectiveness than DE under targeted and untargeted attacks on the Cifar10 dataset and under-targeted attacks on the ImageNet dataset. Our research confirms that safety prevention is a link worth considering in developing Industry 5.0.}
}
@article{YANG2023104502,
title = {Intelligent optimization strategy for electrochemical removal of ammonia nitrogen by neural network embedded in a non-dominated sorting genetic algorithm},
journal = {Journal of Water Process Engineering},
volume = {56},
pages = {104502},
year = {2023},
issn = {2214-7144},
doi = {https://doi.org/10.1016/j.jwpe.2023.104502},
url = {https://www.sciencedirect.com/science/article/pii/S221471442301022X},
author = {Zhengwu Yang and Peng Chen and Guangyuan Meng and Xinwan Zhang and Yaqi Shi and Wenzhao Fu and Huawei Hu and Lehua Zhang},
keywords = {Ammonia nitrogen, Electrochemistry, Backpropagation neural network, Non-dominated sorted genetic algorithm-II, Multi-objective optimization},
abstract = {Electrochemical is a promising approach for the removal of ammonia nitrogen, but the challenge is to achieve better performance under lower energy consumption. In this study, a new electrochemical system hybrid with intelligent optimization algorithms was developed for the efficient removal of ammonia nitrogen and energy saving. Ammonia removal performance and energy consumption were recorded when the traditional electrochemical system operated at various parameters. As the premise of model training, the data were processed through Scatter diagram matrix, Box plot, Principal Component Analysis, Spearman correlation and Shapley Additive Explanations to evaluate the redundancy and independence of parameters. Backpropagation neural network based on deep learning was used as surrogate model of non-dominated sorted genetic algorithm-II, meanwhile, the range of electrochemical parameters was used as the constraint for multi-objective optimization. The optimized result is the Pareto front and the optimal solution was obtained by combining the Technique for Order Preference by Similarity to an Ideal Solution. This new hybrid system achieved an increase of 11.75 % ~ 13.61 % in ammonia removal and a reduction of 21.31 % ~ 36.84 % in energy consumption. The optimal solution represents a better ammonia removal performance at low energy consumption, which is meaningful for the concept of a real-time controlled electrochemical system.}
}
@article{ZHU2023,
title = {Mastering air combat game with deep reinforcement learning},
journal = {Defence Technology},
year = {2023},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2023.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S2214914723002349},
author = {Jingyu Zhu and Minchi Kuang and Wenqing Zhou and Heng Shi and Jihong Zhu and Xu Han},
keywords = {Air combat, MCLDPPO, Interruption mechanism, Digital twin, Distributed system},
abstract = {Reinforcement learning has been applied to air combat problems in recent years, and the idea of curriculum learning is often used for reinforcement learning, but traditional curriculum learning suffers from the problem of plasticity loss in neural networks. Plasticity loss is the difficulty of learning new knowledge after the network has converged. To this end, we propose a motivational curriculum learning distributed proximal policy optimization (MCLDPPO) algorithm, through which trained agents can significantly outperform the predictive game tree and mainstream reinforcement learning methods. The motivational curriculum learning is designed to help the agent gradually improve its combat ability by observing the agent's unsatisfactory performance and providing appropriate rewards as a guide. Furthermore, a complete tactical maneuver is encapsulated based on the existing air combat knowledge, and through the flexible use of these maneuvers, some tactics beyond human knowledge can be realized. In addition, we designed an interruption mechanism for the agent to increase the frequency of decision-making when the agent faces an emergency. When the number of threats received by the agent changes, the current action is interrupted in order to reacquire observations and make decisions again. Using the interruption mechanism can significantly improve the performance of the agent. To simulate actual air combat better, we use digital twin technology to simulate real air battles and propose a parallel battlefield mechanism that can run multiple simulation environments simultaneously, effectively improving data throughput. The experimental results demonstrate that the agent can fully utilize the situational information to make reasonable decisions and provide tactical adaptation in the air combat, verifying the effectiveness of the algorithmic framework proposed in this paper.}
}
@article{CASTRO2023107009,
title = {Digital twin framework using agent-based metaheuristic optimization},
journal = {Engineering Applications of Artificial Intelligence},
volume = {126},
pages = {107009},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107009},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623011934},
author = {Brenno Moura Castro and Marcelo de Miranda Reis and Ronaldo Moreira Salles and Ulisses A. Monteiro and Ricardo H.R. Gutiérrez},
keywords = {Catamaran, FE model updating, Multi-agent models, Vibration, Modal parameters},
abstract = {Despite advances in instrumentation and measurement techniques, it is still necessary to update numerical models to simulate or predict some structural responses, for example. Thus, this work proposes a metaheuristic framework based on hybrid agents, an approach within the Artificial Intelligence (AI) topics for updating Finite Element (FE) numerical models. This framework aims to provide flexible non-deterministic strategies to guide the updating process, ranging from simple local search procedures to complex learning processes. Two case studies are presented: (i) a free–free aluminium beam tested under laboratory conditions and; (ii) a catamaran tested during a sea trial under real operating conditions. The updating process aimed to optimize the stiffness matrix while maintaining the mass matrix unchanged. The objective function seeks to minimize the differences between numerical and experimental modal parameters, namely, natural frequencies and vibration modes. Results from the digital twin framework showed that the difference in natural frequencies significantly decreased, for example, 9% to 1% for the free–free aluminium beam and 15% to 4% for the catamaran’s main deck, when comparing the experimental with the updated FE model. As for the updated FE vibration modes, the Modal Assurance Criteria (MAC) values decreased slightly in both cases but within the acceptable MAC values (above 0.9), thus showing good consistency with the experimental vibration modes. In the end, the proposed framework was able to update the FE model directly using its respective reduced model, circumventing the”black box” of commercial packages.}
}
@article{KHAN2023100890,
title = {A precision-centric approach to overcoming data imbalance and non-IIDness in federated learning},
journal = {Internet of Things},
volume = {23},
pages = {100890},
year = {2023},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2023.100890},
url = {https://www.sciencedirect.com/science/article/pii/S2542660523002135},
author = {Anam Nawaz Khan and Atif Rizwan and Rashid Ahmad and Qazi Waqas Khan and Sunhwan Lim and Do Hyeun Kim},
keywords = {Parameter aggregation, OOD data, Fair federated learning, Thermal comfort},
abstract = {Federated learning (FL) enables decentralized model training, but the distribution of data across devices presents significant challenges to global model convergence. Existing approaches risk losing the representativeness of local models after model aggregation, calling for a more efficient and robust solution. In this study, we address the model aggregation challenge within FL by focusing on elevating the performance of the global model amidst class imbalance and non-independent, non-identically distributed data. We aim to train a global model collaboratively that represents all participating nodes, promoting fairness and ensuring adequate representation of all classes in the model. We propose redistributing local model weights based on their precision-based contributions to each class to enhance the performance and communication efficiency of federated thermal comfort prediction. Our proposed method can assist in allocating more resources and attention to nodes with high precision for underrepresented classes, thereby improving the global model overall performance and fairness. Furthermore, our framework leverages the virtualization capability of digital-twin to enable the dynamic registration and participation of nodes in the federated learning process in real-time. The developed digital-twin framework allows for real-time monitoring and control of the decentralized training. Through our evaluation on a real dataset, we showcase noteworthy enhancements in accuracy and communication efficiency when compared to existing methods. Our evaluation shows that the proposed Class Precision-Weighted Aggregation technique (Fed-CPWA) outperforms Federated Averaging, with higher accuracy of 82.85% and lower communication costs by 25%. Our contribution represents a significant stride towards sustainable thermal comfort modeling, further advancing the development of equitable and resilient federated learning techniques.}
}
@article{LI2023109498,
title = {Dynamic scheduling of multi-memory process flexible job shop problem based on digital twin},
journal = {Computers & Industrial Engineering},
volume = {183},
pages = {109498},
year = {2023},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2023.109498},
url = {https://www.sciencedirect.com/science/article/pii/S0360835223005223},
author = {Zhi Li and Yingjian Chen},
keywords = {Digital twin workshop, Multi-memory process, Flexible manufacturing system, Dynamic scheduling},
abstract = {Digital twin is one of the newly-emerged enabling technologies for achieving intelligent manufacturing. Based on the physical–digital convergence, digital twin provides manufacturing systems with a new model of collaboration between the workforce and industrial processes. With the characteristics of real-time communication and data-driven enablers, the digital twin scheduling strategy requires close cooperation between workers, systems and processes. However, in the process of digitization and intelligentization, industry will need to face the challenge of supporting new technologies and worker skills development. To this end, the paper considers workers’ multi-memory process (learning and forgetting) in the flexible job shop scheduling problem (MPFJSP). Meanwhile, the dynamic scheduling strategy of the digital twin-driven MPFJSP is proposed under machine breakdowns aiming at simultaneously minimizing the makespan, total carbon emissions, total production cost and product quality stability. A virtual workshop is adopted to simulate and optimize the dynamic scheduling scheme to realize intelligent workshop scheduling. Finally, a computational experiment is carried out to verify the effectiveness and advantages of the proposed intelligent scheduling strategy.}
}
@article{YUAN20232481,
title = {In situ characterization techniques and methodologies for high-temperature electrochemistry},
journal = {Chem},
volume = {9},
number = {9},
pages = {2481-2508},
year = {2023},
issn = {2451-9294},
doi = {https://doi.org/10.1016/j.chempr.2023.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S2451929423003236},
author = {Rui Yuan and Handong Jiao and Hongmin Zhu and Daining Fang and Shuqiang Jiao},
keywords = {high-temperature electrochemistry,  study, methodology},
abstract = {Summary
High-temperature electrochemistry (HTE) plays an important role in basic industries, including metallurgy and energy and future frontier technologies such as deep space exploration and carbon neutralization. At present, traditional research methods based on ex situ, macroscale characterization, and theory analogy with room-temperature electrochemistry cannot meet the demands of researchers. In situ characterization techniques can monitor real-time information, which can establish a full spatiotemporal, multidimensional, cross-scale methodology with the support of theoretical calculations, numerical simulations, and so on. It is hence of urgency to summarize and outlook the in situ characterization techniques and analytical methods of HTE. This review focuses on the in situ characterization techniques in HTE and points to a future direction in order to construct a methodology for HTE research. We therefore call on more researchers to enter the field of HTE in order to drive HTE engineering to realize low-carbon, high efficiency, refinement, and intelligence.}
}
@article{JAMSHIDI2023110798,
title = {Metaverse and microorganism digital twins: A deep transfer learning approach},
journal = {Applied Soft Computing},
volume = {147},
pages = {110798},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110798},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623008165},
author = {Mohammad (Behdad) Jamshidi and Saleh Sargolzaei and Salimeh Foorginezhad and Omid Moztarzadeh},
keywords = {Artificial intelligence, Bacteria species, Convolutional neural network, Digital twin, Deep learning, Transfer learning, Image processing, Machine vision, Machine learning, Microorganism, Metaverse},
abstract = {Preparing the infrastructure for analyzing, recognizing, and characterizing microorganisms in the Metaverse can transform the fields of biology, medicine, and drug discovery. Accordingly, the realization of digital twins of microorganisms, such as viruses, fungi, algae, bacteria, protozoa, archaea, and multicellular animal parasites, can streamline the applicability of the Metaverse and similar emerging technologies like Cyber-Physical Healthcare Systems (CPHS). This is why a new approach to the digital twinning of bacteria has been presented in this research. This method of digital twinning can revolutionize the research and study of bacteria because it allows us to separate useful and harmful bacterial species, increasing the efficiency of treatment noticeably. This innovative method can easily be used by clinics, medical centers, or even by private users physically and virtually and can be adapted to every centralized or decentralized Metaverse Platform. To determine the proper treatment, biologists have always tried to identify the correct bacterial species that prompted a bacterial infection. They use various indicators, such as the bacterial cell’s shape and the size of the colony formed by the bacteria, to classify different types of bacteria with different biochemistries and shapes. However, it is challenging because of the extensive similarities between some species. For instance, such similarities exist between Staphylococcus aureus and Staphylococcus saprophyticus, which has caused numerous false diagnostic reports by operators. Wrong species reports bring about treatment failure and increase antibiotic resistance issues. Therefore, the digital twins of bacteria cover all of their identifiable characteristics and overcome many limitations to study them. In this approach, DTL techniques, including MobileNetV2, EfficientNetV2-S, and ResNet-50, have been employed to build digital twins of bacteria species. A hybrid dataset was used for training and evaluation. Among the models, EfficientNetV2-S exhibited the best performance, with a validation accuracy of 99.58% and a test accuracy of 99.33%. The results showed the ability of deep learning models to make bacteria digital twins based on image processing from different labs, thus assisting experts in speeding up the process and reducing diagnostic errors. In addition, in the mispredicted cases, the correct species was among the first three choices of the model. Therefore, not only can experts use DTL approaches to speed up the digital twin realization of microorganisms in the Metaverse, but they can also use these methods to reduce diagnostic errors.}
}
@article{HASSAN2023101728,
title = {SMFSOP: A semantic-based modelling framework for student outcome prediction},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {35},
number = {8},
pages = {101728},
year = {2023},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101728},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823002823},
author = {Yomna M.I. Hassan and Abeer Elkorany and Khaled Wassif},
keywords = {Semantic similarity, Semantic student modeling, Outcome prediction, Regression, Classification, Attribute reduction},
abstract = {Over the past two decades, studying the various factors affecting student performance became essential. Knowing these factors assist in enhancing student’s performance, teaching practices and policy decisions. This research proposes a framework named “Semantic-based Modeling Framework for Student Outcome Prediction” (SMFSOP), to automatically map students’ activities within their learning environment to a standardized behavioral model (Community of Inquiry model (CoI)). The generated student representation is utilized to cluster students and predict an outcome based on their cluster. The framework is divided into three phases: Data gathering and pre-processing, automated mapping, clustering and prediction. The automatic mapping uses semantic similarity between student attribute names/descriptions, and CoI model indicators. Path and BERT similarities were identified as the best performers compared to human annotators. K-means, DBSCAN, and Kernel K-means are used for the clustering step, followed by LassoCV for regression-based prediction, & K-nearest neighbors for classification-based prediction. In order to prove that the proposed framework is generally applicable, three real life datasets were used as a case study. Best-performing trials enhanced outcome prediction as follows: In StudentLife Dataset, Adjusted R2 is enhanced by 3% (95% to 98%), and MSE decreased by 2.375 % (0.126 to 0.031). In social network dataset, Adjusted R2 was enhanced by 17% (65% to 82%). The MSE decreased by 4.4% (0.164 to 0.12). For the “Open university learning Analytics dataset” (OULAD), accuracy is improved by 1.56%, F1-score enhanced by 0.014. Precision is enhanced by 3.1%.}
}
@article{ZHAO2023107284,
title = {MSKD: Structured knowledge distillation for efficient medical image segmentation},
journal = {Computers in Biology and Medicine},
volume = {164},
pages = {107284},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107284},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523007497},
author = {Libo Zhao and Xiaolong Qian and Yinghui Guo and Jiaqi Song and Jinbao Hou and Jun Gong},
keywords = {Knowledge distillation, Medical image segmentation, Lightweight neural networks, Deep learning, Teacher-student model, Feature filtering distillation, Region graph distillation},
abstract = {In recent years, deep learning has revolutionized the field of medical image segmentation by enabling the development of powerful deep neural networks. However, these models tend to be complex and computationally demanding, posing challenges for practical implementation in clinical settings. To address this issue, we propose an efficient structured knowledge distillation framework that leverages a powerful teacher network to assist in training a lightweight student network. Specifically, we propose the Feature Filtering Distillation method, which focuses on transferring region-level semantic information while minimizing redundant information transmission from the teacher to the student network. This approach effectively mitigates the problem of inaccurate segmentation caused by similar internal organ characteristics. Additionally, we propose the Region Graph Distillation method, which exploits the higher-order representational capabilities of graphs to enable the student network to better imitate structured semantic information from the teacher. To validate the effectiveness of our proposed methods, we conducted experiments on the Synapse multi-organ segmentation and KiTS kidney tumor segmentation datasets using various network models. The results demonstrate that our method significantly improves the segmentation performance of lightweight neural networks, with improvements of up to 18.56% in Dice coefficient. Importantly, our approach achieves these improvements without introducing additional model parameters. Overall, our proposed knowledge distillation methods offer a promising solution for efficient medical image segmentation, empowering medical experts to make more accurate diagnoses and improve patient treatment.}
}
@article{SEMERARO2023128699,
title = {Guidelines for designing a digital twin for Li-ion battery: A reference methodology},
journal = {Energy},
volume = {284},
pages = {128699},
year = {2023},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2023.128699},
url = {https://www.sciencedirect.com/science/article/pii/S0360544223020935},
author = {Concetta Semeraro and Haya Aljaghoub and Mohammad Ali Abdelkareem and Abdul Hai Alami and Michele Dassisti and A.G. Olabi},
keywords = {Digital twin, Lithium battery, Battery energy storage systems, Unsupervised machine learning, Formal concept analysis},
abstract = {The integration of digital technologies is causing a significant change in the energy sector. These innovations have transformed traditional energy grids into intelligent grids. As a result, the digital replica of Battery Energy Storage Systems (BESS) has become one of the most crucial components in the energy sector. Digital twin technology enables the seamless integration of BESS into intelligent grids and offers numerous benefits, such as easy identification and prediction of faults, real-time system monitoring, optimization, temperature regulation, and estimation of parameters. As a result, the overall performance of BESS is improved by the digital twin technology. Consequently, this paper discusses the general guidelines that must be followed to develop a digital twin for a Li-ion BESS successfully. The main function is to define how to design a digital twin able to optimize the system and facilitate early and predictive fault detection and diagnosis.}
}
@article{CARLO2023474,
title = {The importance of cybersecurity frameworks to regulate emergent AI technologies for space applications},
journal = {Journal of Space Safety Engineering},
volume = {10},
number = {4},
pages = {474-482},
year = {2023},
issn = {2468-8967},
doi = {https://doi.org/10.1016/j.jsse.2023.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468896723000678},
author = {Antonio Carlo and Nebile Pelin Mantı and Bintang Alam Semesta W．A．M and Francesca Casamassima and Nicolò Boschetti and Paola Breda and Tobias Rahloff},
keywords = {Cybersecurity, Artificial intelligence, Earth observation, Cyber risk, Emerging disruptive technologies},
abstract = {Over the past decades, industries and governments have progressively been relying upon space data-centric and data-dependant systems. This led to the emergence of malicious activities, also known as cyber-threats, targeting such systems. To counter these threats, new technologies such as Artificial Intelligence (AI) have been implemented and deployed. Today, AI is highly capable of delivering fast, precise, and reliable command-and-control decision-making, as well as providing reliable vulnerability analysis using well-proven cutting-edge techniques, at least when applied to terrestrial applications. In fact, this might not yet be the case when used for space applications. AI can also play a transformative and important role in the future of space cybersecurity, and it poses questions on what to expect in the near-term future. Challenges and opportunities deriving from the adoption of AI-based solutions to achieve cybersecurity and later cyber defence objectives in both civil and military operations require rethinking of a new framework and new ethical requirements. In fact, most of these technologies are not designed to be used or to overcome challenges in space. Because of the highly contested and congested environment, as well as the highly interdisciplinary nature of threats to AI and Machine Learning (ML) technologies, including cybersecurity issues, a solid and open understanding of the technology itself is required, as well as an understanding of its multidimensional uses and approaches. This includes the definition of legal and technical frameworks, ethical dimensions and other concerns such as mission safety, national security, and technology development for future uses. The continuous endeavours to create a framework and regulate interdependent uses of combined technologies such as AI and cybersecurity to counter “new” threats require the investigation and development of “living concepts” to determine in advance the vulnerabilities of networks and AI. This paper defines a cybersecurity risk and vulnerability taxonomy to enable the future application of AI in the space security field. Moreover, it assesses to what extent a network digital twins’ simulation can still protect networks against relentless cyber-attacks in space against users and ground segments. Both concepts are applied to the case study of Earth Observation (EO) operations, which allows for conclusions to be drawn based on the business impact (reputational, environmental, and social) of a cyber malicious activity. Since AI technologies are developing on a daily basis, a regulatory framework is proposed using ethical and technical approaches for this technology and its use in space.}
}
@article{LI2023107327,
title = {Cross-user gesture recognition from sEMG signals using an optimal transport assisted student-teacher framework},
journal = {Computers in Biology and Medicine},
volume = {165},
pages = {107327},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107327},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523007928},
author = {Xinhui Li and Xu Zhang and Xiang Chen and Xun Chen and Aiping Liu},
keywords = {Myoelectric interfaces, Gestural recognition, Cross-user variability, Domain adaptation, Student-teacher framework},
abstract = {The cross-user gesture recognition is a puzzle in the myoelectric control system, owing to great variability in muscle activities across different users. To address this problem, a novel optimal transport (OT) assisted student-teacher (ST) framework (termed OT-ST) was proposed in this paper to facilitate transfer across user domains in an unsupervised domain adaptation (UDA) manner. In this framework, the initial parameters of the ST models were trained with the labeled data from users in the source domain. In the model transfer stage for a new user in the target domain, the teacher model was utilized to generate pseudo labels for unlabeled testing samples, providing guidance to the adaptation of the student model. The OT algorithm was employed to optimize the pseudo labels generated from the teacher model, avoiding the model bias and further improving the effect of domain adaptation. The performance of the proposed OT-ST framework was evaluated via experiments of classifying seven hand gestures using high-density surface electromyogram (HD-sEMG) recordings from extensor digitorum muscles of eight intact-limbed subjects. The OT-ST framework yielded a high accuracy of 96.50 ± 2.88% for new users, and outperformed other common machine learning and UDA methods significantly (p < 0.01), demonstrating its effectiveness. The OT-ST framework does not require special repetitive training or any labeled data for calibration. In addition, it can incrementally learn from new testing samples and improve the recognition ability. This study provides a promising method for developing user-generic myoelectric pattern recognition, with wide applications in human-computer interaction, consumer electronics and prosthesis control.}
}
@article{DENG2023104955,
title = {Deep reinforcement learning for fuel cost optimization in district heating},
journal = {Sustainable Cities and Society},
volume = {99},
pages = {104955},
year = {2023},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2023.104955},
url = {https://www.sciencedirect.com/science/article/pii/S2210670723005668},
author = {Jifei Deng and Miro Eklund and Seppo Sierla and Jouni Savolainen and Hannu Niemistö and Tommi Karhela and Valeriy Vyatkin},
keywords = {Deep reinforcement learning, Digital twin, District heating, Setpoint optimization},
abstract = {This study delves into the application of deep reinforcement learning (DRL) frameworks for optimizing setpoints in district heating systems, which experience hourly fluctuations in air temperature, customer demand, and fuel prices. The potential for energy conservation and cost reduction through setpoint optimization, involving adjustments to supply temperature and thermal energy storage utilization, is significant. However, the inherent nonlinear complexities of the system render conventional manual methods ineffective. To address these challenges, we introduce a novel learning framework with an expert knowledge module tailored for DRL techniques. The framework leverages system status information to facilitate learning. The training is performed by employing model-free DRL methods and a refined digital twin of the Espoo district heating system. The expert module, accounting for power plant capacities, ensures actionable directives aligned with operational feasibility. Empirical validation through comprehensive simulations demonstrates the efficacy of the proposed approach. Comparative analyses against manual methods and evolutionary techniques highlight the approach's superior ability to curtail fuel costs. This study advances the understanding of DRL in district heating optimization, offering a promising avenue for enhanced energy efficiency and cost savings.}
}
@article{CHEN2023103522,
title = {Building and road detection from remote sensing images based on weights adaptive multi-teacher collaborative distillation using a fused knowledge},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {124},
pages = {103522},
year = {2023},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2023.103522},
url = {https://www.sciencedirect.com/science/article/pii/S1569843223003461},
author = {Ziyi Chen and Liai Deng and Jing Gou and Cheng Wang and Jonathan Li and Dilong Li},
keywords = {Knowledge distillation, Remote sensing, Building extraction, Road extraction},
abstract = {Knowledge distillation is one effective approach to compress deep learning models. However, the current distillation methods are relatively monotonous. There are still rare studies about the combination of distillation strategies using multiple types of knowledge and employing multiple teacher models. Besides, how to optimize the weights among different teacher models is still an open problem. To address these issues, this paper proposes a novel approach for knowledge distillation, which effectively enhances the robustness of the distilled student model by a weights adaptive multi-teacher collaborative distillation. Moreover, the proposed method utilizes feature knowledge exchange guidance between teacher networks to transfer more comprehensive feature knowledge to the student model, which further improves the learning capability of hidden layers’ details. The extensive experimental results demonstrate that the proposed method achieves state-of-the-art performance on Massachusetts Roads Dataset, LRSNY Roads Dataset, and WHU Building Dataset. Specifically, under the guidance of the first ensemble of teacher networks, we obtained IoU scores of 47.33%, 78.15%, and 80.71%, respectively. Under the guidance of the second ensemble of teacher networks, we obtained IoU scores of 48.56%, 79.51%, and 81.35%, respectively.}
}
@article{SELVARAJAN2023,
title = {PUDT: Plummeting Uncertainties in Digital Twins for Aerospace Applications using Deep Learning Algorithms},
journal = {Future Generation Computer Systems},
year = {2023},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2023.11.034},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2300448X},
author = {Shitharth Selvarajan and Hariprasath Manoharan and Achyut Shankar and Alaa O. Khadidos and Adil O. Khadidos and Antonino galletta},
keywords = {Digital twins, Aerospace applications, Deep learning, Uncertainty},
abstract = {Identifying objects in aircraft monitoring systems poses significant challenges due to the presence of extreme loading conditions. Despite the presence of several sensor units, the transmission of precise data to multiple data units is hindered by an increase in time intervals. Therefore, the suggested methodology is specifically developed for the purpose of generating digital replicas for aeronautical applications, wherein an aero transfer function is correlated with the digital twins. Mapping functions are utilized in the monitoring of diverse parameters that are associated with the identification of objects inside data transmission networks, with the aim of minimizing uncertainty. The suggested system model is enhanced by incorporating analytical representations and deep learning methods, resulting in the provision of zero point twin functionalities. The present study investigates the aforementioned integrated procedure through the analysis of four different situations. In these settings, an aero communication tool box is employed to transform the device configuration into simulation outputs. The results obtained from the comparison of these scenarios reveal that the projected model significantly enhances the maintenance period while minimizing data errors.}
}
@article{ALRBEAWI2023100098,
title = {A Review of Modern Approaches of Digitalization in Oil and Gas Industry},
journal = {Upstream Oil and Gas Technology},
volume = {11},
pages = {100098},
year = {2023},
issn = {2666-2604},
doi = {https://doi.org/10.1016/j.upstre.2023.100098},
url = {https://www.sciencedirect.com/science/article/pii/S2666260423000130},
author = {Salam Al-Rbeawi},
keywords = {Digitization, Data Science, machine learning, Artificial Intelligence},
abstract = {This paper introduces a review of the modern approaches of digitalization in the oil and gas industry. The objective is understanding the current applications of the traditional technologies used in the petroleum industry and studying the opportunities for implementing innovative digital tools and systems that could enhance the operational efficiency and reduce the cost, risk, and environmental impacts. The paper consists of several tasks starting from reviewing the present technologies used mainly in the upstream activities: exploration, field development, drilling and completion, and operation and production. The techniques used for gathering and analyzing the big data packages received from unlimited digitalized resources is the second task covered in this paper while the computing technologies such as cloud and cognitive computing as well as the advanced analytical and numerical solutions developed by real-time algorithms is the third task. Detail information about the short- and long-term digitalization technologies in both hardware and software parts is represented in this paper such as robotics and automation, powerful sensors and measuring tools, unmanned vehicles and drones, 3D printers and wearable gadgets as well as artificial inelegance, machine learning, and digital-twin computing. Real examples of currently used digitalized applications in different upstream sections of the petroleum industry are demonstrated while the expected added values created by the digitalization for the industry and communities and the possible changes either positively or negatively in the operational costs, maintenance patterns, workforce safety, environmental impacts, job positions, and the required skills and experiences during digitalization era are explained. The outcomes are summarized in the following points. The digitalization should be the priority for most upstream companies in order to enhance and optimize the production system. The big volume of data may require innovative computing tools that could develop powerful analytical models used for calibrating the production environment and maximizing the production capacity of oil and gas fields. Data transfer and data sharing are two key factors in the digital transformation where the integrated data platforms could enhance the collaboration among the participants of the oil and gas ecosystems and accelerate innovative solutions. The digital era may lead to a sharp decline in the workforce and significant changes in the job position description as the human intervention with the production system might be minimized. The expected added value of the digital transformation during the next decades will be very big wherein the upstream petroleum industry may have the biggest share that could be more than 60% of the total investments while the midstream industry may have only 10%. There will be also a lot of challenges represented by the fact that the petroleum industry has not yet made the necessary shift in mindset to embrace the digitalization potential. Moreover, the digitalization era may require new revolutionized regulations especially in terms of sharing the data and changing the structures of the organizations as well as the workforces.}
}
@article{GAO2023111872,
title = {An optimal management architecture based on digital twin for smart solar-based islands incorporating deep learning and modified particle swarm optimization},
journal = {Solar Energy},
volume = {262},
pages = {111872},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.111872},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23005054},
author = {LiPeng Gao and Zhe Gao},
keywords = {Optimal management, Deep learning, Interruptible load, Digital twin, Power shifting, solar unit},
abstract = {Smart island (SI) energy management is a type of energy management system used to ensure that energy is used efficiently on islands. It is designed to reduce energy consumption and costs while also improving the sustainability of the island. Smart island energy management systems use a combination of technologies such as solar, wind, and other renewable energy sources, energy storage systems, smart meters, and advanced analytics to monitor and manage energy usage. The system can be used to provide islanders with real-time energy usage data, allowing them to make informed decisions about their energy use. Using the effects on the environment and economics of the SI as a basis for fully modeling the optimum performance of the SI in grid-connected operations, the feasibility and balance of the SI power grid are ensured. In addition, taking into account the impact of interruptible loads (IL) on SI operation costs, a power shift for IL can be performed using storage batteries in a digital twin environment. A new ecology-driven optimization algorithm has been developed that continuously adjusts migration rates with habitat suitability indexes of normalized individuals and adds a differential perturbation to the migration operator of the migration process. The enhanced particle swarm optimization algorithm has been implemented as the SI optimization dispatching algorithm. In order to have a precise prediction of the renewable energy sources, their output power is predicted using the recurrent neural network (RNN) deep learning model. Based on the simulation outcomes, it is evident that the suggested power dispatching model could greatly decrease the overall price of the system by implementing the advanced and effective algorithm and model presented in the study.}
}
@article{GONG2023341758,
title = {RamanCMP: A Raman spectral classification acceleration method based on lightweight model and model compression techniques},
journal = {Analytica Chimica Acta},
volume = {1278},
pages = {341758},
year = {2023},
issn = {0003-2670},
doi = {https://doi.org/10.1016/j.aca.2023.341758},
url = {https://www.sciencedirect.com/science/article/pii/S0003267023009790},
author = {Zengyun Gong and Chen Chen and Cheng Chen and Chenxi Li and Xuecong Tian and Zhongcheng Gong and Xiaoyi Lv},
keywords = {Raman spectroscopy, RamanCMP, Lightweight model, Model compression},
abstract = {In recent years, Raman spectroscopy combined with deep learning techniques has been widely used in various fields such as medical, chemical, and geological. However, there is still room for optimization of deep learning techniques and model compression algorithms for processing Raman spectral data. To further optimize deep learning models applied to Raman spectroscopy, in this study time, accuracy, sensitivity, specificity and floating point operations numbers(FLOPs) are used as evaluation metrics to optimize the model, which is named RamanCompact(RamanCMP). The experimental data used in this research are selected from the RRUFF public dataset, which consists of 723 Raman spectroscopy data samples from 10 different mineral categories. In this paper, 1D-EfficientNet adapted to the spectral data as well as 1D-DRSN are proposed to improve the model classification accuracy. To achieve better classification accuracy while optimizing the time parameters, three model compression methods are designed: knowledge distillation using 1D-EfficientNet model as a teacher model to train convolutional neural networks(CNN), proposing a channel conversion method to optimize 1D-DRSN model, and using 1D-DRSN model as a feature extractor in combination with linear discriminant analysis(LDA) model for classification. Compared with the traditional LDA and CNN models, the accuracy of 1D-EfficientNet and 1D-DRSN is improved by more than 20%. The time of the distilled model is reduced by 9680.9s compared with the teacher model 1D-EfficientNet under the condition of losing 2.07% accuracy. The accuracy of the distilled model is improved by 20% compared to the CNN student model while keeping inference efficiency constant. The 1D-DRSN optimized with channel conversion method saves 60% inference time of the original 1D-DRSN model. Feature extraction reduces the inference time of 1D-DRSN model by 93% with 94.48% accuracy. This study innovatively combines lightweight models and model compression algorithms to improve the classification speed of deep learning models in the field of Raman spectroscopy, forming a complete set of analysis methods and laying the foundation for future research.}
}
@article{ZHANG2023108181,
title = {Digital twin perception and modeling method for feeding behavior of dairy cows},
journal = {Computers and Electronics in Agriculture},
volume = {214},
pages = {108181},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.108181},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923005690},
author = {Yi Zhang and Yu Zhang and Meng Gao and Baisheng Dai and Shengli Kou and Xinjie Wang and Xiao Fu and Weizheng Shen},
keywords = {Digital twin, Indoor positioning, IMUs, Dairy cow, Deep learning},
abstract = {The digital twin of cows holds significant promise for advancing animal welfare and production efficiency. This paper aims to propose an architecture for digital twins of cows that covers their entire lifecycle. A digital twin solution has been developed that utilizes indoor positioning data and inertial measurement unit (IMU) data to construct a cow’s digital shadow. As an example, the paper utilizes the classification of cow feeding and non-feeding behaviors to study the digital twin perception and modeling methods. A custom-made collar integrated with utilized ultra-wideband (UWB) chips and inertial measurement units (IMUs) was utilized to collect real-time location and neck movement data from five healthy non-lactating Holstein cows. The collected data was transmitted via UWB signals to the positioning anchor and subsequently forwarded to a local server. To classify the feeding and non-feeding behaviors of the cows, three methods were employed: Support Vector Machines (SVM), K-Nearest Neighbor (KNN), and Long Short-Term Memory (LSTM). According to the experimental results, all three classification methods were effective, however, LSTM outperformed the others. Employing solely IMU data and implementing the LSTM, the precision of identifying bovine foraging behavior reached 91.05%, with concomitant precision and recall rates of 92.23 and 91.35%, respectively. Through an integration of the data from indoor position detection and IMU devices and the employment of LSTM, the accuracy of identification increased to 94.97%, with a precision rate of 99.99% and a recall rate of 93.86%. The trial of the digital twin solution demonstrated the rationality and technical feasibility of the digital twin architecture, which holds significant reference value for the development of animal digital twins in the animal husbandry industry.}
}
@article{MAO2023108242,
title = {A teacher-to-student information recovery method toward energy-efficient animal activity recognition at low sampling rates},
journal = {Computers and Electronics in Agriculture},
volume = {213},
pages = {108242},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.108242},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923006300},
author = {Axiu Mao and Meilu Zhu and Endai Huang and Xi Yao and Kai Liu},
keywords = {Behavioral classification, Deep learning, Resampling, Reconstruction, Knowledge distillation},
abstract = {Automated animal activity recognition (AAR) has advanced greatly through recent advances in sensing technologies and deep learning, and improved livestock management efficiency, animal health, and welfare monitoring. In practical automated AAR systems where animals need to be monitored over a long period, the sampling rate dramatically affects the energy consumption and battery life of sensing devices due to continuous data collection and transmission. Considering real-world benefits, existing works have often lowered the sampling rate to reduce energy costs. However, when the sampling rate falls below a threshold, the AAR performance degrades rapidly due to many relevant signals being missed. Therefore, this study proposed a novel method, dubbed teacher-to-student information recovery (T2S-IR), to improve the performance of AAR at low sampling rates. This approach effectively leverages the knowledge obtained from high-sampling-rate data, to assist in recovering the missing information in features extracted by the classification network trained on low-sampling-rate data. The workflow of the T2S-IR contains two main steps. (1) we utilize high-sampling-rate data for training teacher classification and reconstruction networks sequentially. (2) Then, we train a student classification network using low-sampling-rate data, while promoting its performance by exploiting the knowledge learned by trained teacher networks via two novel modules, namely the reconstruction-based information recovery (RIR) module and the correlation-distillation-based information recovery (CDIR) module. Specifically, the RIR module employs the pretrained teacher reconstruction network to enforce the student classification network to learn complete and descriptive features. The CDIR module enforces the feature maps of student network to mimic internal correlations within feature maps of pretrained teacher classification network along temporal and sensor axes directions. To validate our proposed T2S-IR, we conducted experiments on two public datasets acquired for horses and goats using triaxial accelerometers and gyroscopes with an initial sampling rate of 100 Hz. Data having low sampling rates were obtained by downsampling the original data at different frequencies (i.e., 50, 25, 12.5, 10, 5, and 2 Hz). The results demonstrated that our method remarkably boosted the classification network trained on low-sampling-rate data (e.g., percentage-point increments in the precision, recall, F1-score, and accuracy of 3.33%, 3.58%, 3.45%, and 2.19%, respectively, for the 12.5-Hz horse data and 7.6%, 4.44%, 6.9%, and 0.79%, respectively, for the 5-Hz goat data) while outperforming existing knowledge distillation methods. The enhanced classification network can be directly applied in practical AAR tasks with low sampling rates, significantly beneficial for scenarios with constrained energy sources for wearable devices.}
}
@article{BRAHMBHATT2023100127,
title = {Digital twin assisted decision support system for quality regulation and leak localization task in large-scale water distribution networks},
journal = {Digital Chemical Engineering},
volume = {9},
pages = {100127},
year = {2023},
issn = {2772-5081},
doi = {https://doi.org/10.1016/j.dche.2023.100127},
url = {https://www.sciencedirect.com/science/article/pii/S2772508123000455},
author = {Parth Brahmbhatt and Abhilasha Maheshwari and Ravindra D. Gudi},
keywords = {Water quality management, Leak detection, Digital twins, Optimization & control, Water distribution network, Neural Networks},
abstract = {Effective water resource management is essential in large metropolitan cities. Digital Twins (DT), supported by IIoT and machine learning technologies, provide opportunities for real-time prediction and optimization for effective decision-making in water distribution systems. A framework for the digital twin of the Water Distribution Network (WDN) is developed in this paper to achieve higher operational efficiency using ‘WNTR’, the Python-based library of EPANET. All computational experiments and methods were validated on the benchmark hydraulic C-TOWN network (Ostfeld et al., 2011). The hydraulic parameters and quality parameters of the DT model for the water network were calibrated using the Differential Evolution (DE) algorithm. The calibrated DT served as a real-time proxy to generate simulation data, which is used for two different applications in large-scale water networks: (i) Disinfectant dosage regulation task using booster stations and (ii) pipe leakage localization task. The calibrated DT was utilized to estimate the optimal disinfectant dosing rates, ensuring water quality control within an acceptable range using optimization. The results highlight the effectiveness of the neural network and real-time optimization strategy to achieve the optimal dosing rate. For the leakage localization task, the Graph Convolution Networks (GCN) based neural network trained on the DT was found to predict leakage location very accurately.}
}
@article{CHEN2023581,
title = {The advance of digital twin for predictive maintenance: The role and function of machine learning},
journal = {Journal of Manufacturing Systems},
volume = {71},
pages = {581-594},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S027861252300211X},
author = {Chong Chen and Huibin Fu and Yu Zheng and Fei Tao and Ying Liu},
keywords = {Digital twin, Predictive maintenance, Machine learning, Prognostic and health management},
abstract = {The recent advance of digital twin (DT) has greatly facilitated the development of predictive maintenance (PdM). DT for PdM enables accurate equipment status recognition and proactive fault prediction, enhancing reliability. This shift from reactive to proactive services optimizes maintenance schedules, minimizes downtime, and improves enterprise profitability and competitiveness. However, the research and application of DT for PdM are still in their infancy, probably because the role and function of machine learning (ML) in DT for PdM have not yet been fully investigated by the industry and academia. This paper focuses on a systematic review of the role of ML in DT for PdM and identifies, evaluates and analyses a clear and systematic approach to the published literature relevant to DT and PdM. Subsequently, the state-of-the-art applications of ML in various application areas of DT for PdM are introduced. Finally, the challenges and opportunities of ML for DT-PdM are revealed and discussed. The outcome of this paper can bring tangible benefits to the research and implementation of ML in DT-PdM.}
}
@article{ZOHDI2023116261,
title = {Machine-learning a perfect bending soccer goal shot},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {415},
pages = {116261},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2023.116261},
url = {https://www.sciencedirect.com/science/article/pii/S0045782523003857},
author = {T.I. Zohdi},
keywords = {Soccer, Kicks, Goal optimization, Machine-learning},
abstract = {The objective of this work is to ascertain the optimal bending kick velocity and spin that a player should impart to exactly hit a target within a soccer goal, using machine-learning optimization. Specifically, the work develops a model of a kicking player producing a high-velocity spinning soccer ball which interacts with the surrounding air that induces drag forces and the Magnus effect, both of which are functions of the Reynolds number. This yields a set of highly nonlinear, coupled, differential equations. The framework is designed to enable digital-twin type technologies, i.e. digital replicas that run in real time with the physical system on laptops or other mobile systems for rapid feedback. The overall guiding motivation is to provide a useful tool to assist coaches and to rapidly train players. Numerical examples are provided to illustrate the process.}
}
@article{MOTSA2023116912,
title = {A data-driven, machine learning scheme used to predict the structural response of masonry arches},
journal = {Engineering Structures},
volume = {296},
pages = {116912},
year = {2023},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2023.116912},
url = {https://www.sciencedirect.com/science/article/pii/S0141029623013275},
author = {Siphesihle Mpho Motsa and Georgios Ε. Stavroulakis and Georgios Α. Drosopoulos},
keywords = {FEM, Machine Learning, Artificial Neural Network, Multi-hinge failure, Damage Prediction, Masonry Arches, Data-driven Mechanics, Digital Twin},
abstract = {A data-driven methodology is proposed, for the investigation of the ultimate response of masonry arches. Aiming to evaluate their structural response in a computationally efficient framework, machine learning metamodels, in the form of artificial neural networks, are adopted. Datasets are numerically built, integrating Matlab, Python and commercial finite element software. Heyman’s assumptions are adopted within non-linear finite element analysis, incorporating contact-friction laws between adjacent stones, to capture failure in the arch. The artificial neural networks are trained, validated, and tested using the least square minimization technique. It is shown that the proposed scheme can be used to provide a fast and accurate prediction of the deformed geometry, the collapse mechanism and the ultimate load. Cases studies demonstrate the efficiency of the method in random, new arch geometries. Relevant Matlab/Python scripts and datasets are provided. The method can be extended towards structural health monitoring and the concept of digital twin.}
}
@article{CHEN2023102196,
title = {Improving completeness and accuracy of 3D point clouds by using deep learning for applications of digital twins to civil structures},
journal = {Advanced Engineering Informatics},
volume = {58},
pages = {102196},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102196},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623003245},
author = {Shihong Chen and Gao Fan and Jun Li},
keywords = {Deep learning, Depth completion, Digital twin, Structural modeling, 3D reconstruction},
abstract = {In the Architecture, Engineering, and Construction (AEC) sector, digital twins rely on precise 3D models to convey digital information about physical structures in a virtual space. However, due to the vulnerability to measurement errors in weak-textured regions, 3D point clouds generated by conventional photometric consistency or deep learning-based Multi-View Stereo (MVS) algorithms are often incomplete or inaccurate. Therefore, this paper integrates the consistency constraint across multiple views and the inferential capacity of deep learning to propose a novel approach for refining the missing regions of the depth maps generated by photo-consistency based MVS algorithms. The proposed solution involves a cost volume pyramid-based depth completion (CVP-DC) network with three multi-level pyramid structures, which sequentially estimates and completes depth maps in a coarse-to-fine manner. A dataset that consists of input images and the corresponding depth maps generated by photo-consistency based MVS algorithms, along with output ground truth depth maps, is developed using an open DTU MVS dataset. CVP-DC demonstrates competitive performance when tested on the public DTU MVS dataset, outperforming existing MVS algorithms in terms of both completeness and accuracy. Additionally, experimental studies are conducted utilizing UAV-collected RTK (Real-Time Kinematic) images of an outdoor bridge pier to reconstruct point clouds with absolute scales. Experimental validations demonstrate the effectiveness and applicability of the proposed approach in filling uneven and incomplete depth maps, thereby enhancing the completeness of the generated point clouds. The proposed approach holds promise for establishing precise 3D models for the digital twin of the AEC sector.}
}
@article{ESDERS2023108574,
title = {Scaling up machine learning-based chemical plant simulation: A method for fine-tuning a model to induce stable fixed points},
journal = {Computers & Chemical Engineering},
pages = {108574},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108574},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423004441},
author = {Malte Esders and Gimmy Alex Fernandez Ramirez and Michael Gastegger and Satya Swarup Samal},
keywords = {Machine learning, Surrogate model, Flowsheet simulation, End-to-end training, Cycle solving, Fixed point iteration, Model initialization, Digital twin},
abstract = {Idealized first-principles models of chemical plants can be inaccurate. An alternative is to fit a Machine Learning (ML) model directly to plant sensor data. We use a structured approach: Each unit within the plant gets represented by one ML model. After fitting the models to the data, the models are connected into a flowsheet-like directed graph. We find that for smaller plants, this approach works well, but for larger plants, the complex dynamics arising from large and nested cycles in the flowsheet lead to instabilities in the solver during model initialization. We show that a high accuracy of the single-unit models is not enough: The gradient can point in unexpected directions, which prevents the solver from converging to the correct stationary state. To address this problem, we present a way to fine-tune ML models such that initialization, even with very simple solvers, becomes robust.}
}
@article{ZHAO2023,
title = {Mixed noise-guided mutual constraint framework for unsupervised anomaly detection in smart industries},
journal = {Computer Communications},
year = {2023},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2023.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0140366423004723},
author = {Qing Zhao and Yan Wang and Yuxuan Lin and Shaoqi Yan and Wei Song and Boyang Wang and Jun Huang and Yang Chang and Lizhe Qi and Wenqiang Zhang},
keywords = {Anomaly detection, Mixed noise, Mutual constraint},
abstract = {Large-scale sensor and data acquisition systems, integrated with deep learning methodologies, play a pivotal role in enhancing the sustainability and security of smart city environments, exemplifying the critical significance of anomaly detection techniques. Anomaly detection in complex industrial scenarios presents various challenges, such as intricate working environments, limited anomaly samples, and lack of a priori information. Unsupervised anomaly detection based on knowledge distillation enables anomaly detection using only normal samples. However, the similarity in structure between teacher and student models, along with identical input data flow, hampers accurate anomaly detection and localization. To address these issues, we propose MNMC, an unsupervised anomaly detection model consisting of a mixed noise generation module emulating real defects, a mutual constraint module, and an anomaly segmentation module. Firstly, to enhance the student network’s ability to learn robust features, we construct a hybrid noise model comprising dead-leaves noise and perlin noise. This generates features with structural texture and distributional characteristics closer to real anomalies. Secondly, we design a mutual constraint framework to further improve the learning ability of the student network for normal features by constraining representations containing only a single noise. Lastly, for the detection of anomalies at different scales, we propose a new evaluation metric based on equal importance of normal and anomalous regions. Through ablation experiments, we demonstrate the effectiveness of the simulated real defect generation module and the mutual constraints module. Performance experiments on the MVTec dataset show that our method achieves competitive results compared to the current state-of-the-art anomaly detection methods.}
}
@article{MARU2023107520,
title = {Improved building facade segmentation through digital twin-enabled RandLA-Net with empirical intensity correction model},
journal = {Journal of Building Engineering},
volume = {78},
pages = {107520},
year = {2023},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2023.107520},
url = {https://www.sciencedirect.com/science/article/pii/S235271022301700X},
author = {Michael Bekele Maru and Yusen Wang and Hansun Kim and Hyungchul Yoon and Seunghee Park},
keywords = {Digital twin, RandLA-Net, Building facade, Intensity, Lidar},
abstract = {The Architectural Engineering and Construction (AEC) industry can benefit from accurate building facade segmentation, which can provide valuable insights into building maintenance, urban planning, and security efforts. Light Detection and Ranging (LiDAR) sensors are effective in recognizing building facade components from (three-dimensional) 3D point clouds by registering 3D spatial coordinates and radiometric information, which reveal the spectral property of a scanned surface. Although the radiometric information (i.e., intensity feature) can be used for segmentation, its accuracy may be reduced by factors such as scanning geometry and external factors that affect the object’s radiometric information. To address this issue, this study proposes a robust and automated method for segmenting building facade components using LiDAR point cloud data and an empirical-based intensity correction model to ensure proper segmentation. The proposed method employs RandLA-Net, a deep learning model capable of effectively processing large-scale point cloud data, to classify building facade components based on their spatial features combined with corrected intensity features. By incorporating the proposed method into a digital twin, it is possible to perform accurate building facade segmentation and generate valuable insights into the building’s physical condition, energy efficiency, and aesthetic value in real-time. The effectiveness of the proposed method was experimentally validated using a school building facade, which demonstrated significant improvements in the recognition of facade components and highlighted the potential of digital twin-enabled building facade segmentation for the AEC industry.}
}
@article{CHOWDHURY2023166432,
title = {Climate change and coastal morphodynamics: Interactions on regional scales},
journal = {Science of The Total Environment},
volume = {899},
pages = {166432},
year = {2023},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2023.166432},
url = {https://www.sciencedirect.com/science/article/pii/S004896972305057X},
author = {Piyali Chowdhury and Naresh Kumar Goud Lakku and Susana Lincoln and Jaya Kumar Seelam and Manasa Ranjan Behera},
keywords = {Coastal morphodynamics, Climate change, Coastal zone management, Coastal resilience framework, Digital Twin},
abstract = {Climate change and its impacts, combined with unchecked human activities, intensify pressures on coastal environments, resulting in modification of the coastal morphodynamics. Coastal zones are intricate and constantly changing areas, making the monitoring and interpretation of data a challenging task, especially in remote beaches and regions with limited historical data. Traditionally, remote sensing and numerical methods have played a vital role in analysing earth observation data and supporting the monitoring and modelling of complex coastal ecosystems. However, the emergence of artificial intelligence-based techniques has shown promising results, offering the additional advantage of filling data gaps, predicting data in data-scarce regions, and analysing multidimensional datasets collected over extended periods of time and larger spatial scales. The main objective of this study is to provide a comprehensive review of the existing literature, discussing both traditional methods and various emerging artificial intelligence-based approaches used in studying the coastal dynamics, shoreline change analysis, and coastal monitoring. Ultimately, the study proposes a climate resilience framework to enhance coastal zone management practices and policies, fostering resilience among coastal communities. The outcome of this study aligns with and supports particularly SDG 13 of the UN (Climate Action) and advances it by identifying relevant methods in coastal erosion studies and proposing integrated management plans informed by real-time data collection and analysis/modelling using physics-based models.}
}
@article{WILSDON2023104813,
title = {Autonomous control of heat pipes through digital twins: Application to fission batteries},
journal = {Progress in Nuclear Energy},
volume = {163},
pages = {104813},
year = {2023},
issn = {0149-1970},
doi = {https://doi.org/10.1016/j.pnucene.2023.104813},
url = {https://www.sciencedirect.com/science/article/pii/S0149197023002482},
author = {Katherine Wilsdon and Joshua Hansel and M. Ross Kunz and Jeren Browning},
keywords = {Fission battery, Digital twin, Unattended operation},
abstract = {Fission batteries are envisioned as nuclear energy systems and associated technology that can be fully utilized in a battery-like operation, where the system is delivered as a ‘plug-and-play’ service. Several key attributes define the desired functionality of these systems: economic, standardized, installed, unattended, and reliable. The construction and operation of unattended, plug-and-play fission batteries will require sufficiently robust hardware and software technologies. Using a digital twin (DT) may reduce costs and risk associated with employing fission batteries through the integration of the disparate systems used in the design, construction, and operation of these nuclear energy systems. A DT employing machine-learning (ML) and physics-based representations to forecast future performance could potentially be used for anticipatory control. Before application of a DT in the fission domain, the DT technology should be validated in a non-fission environment. A DT of a single-heat-pipe test article in the Microreactor AGile Non-nuclear Experimental Testbed (MAGNET) was demonstrated with predictive, self-adjusting capability on 30 March 2022. The test plan stated that: (1) the operators will manually change the temperature set point of the heat pipe to an upper limit or lower limit; and (2) the DT will predict the temperature will go beyond this temperature threshold, and then will update the temperature set point to the baseline temperature without any human intervention. The DT used a two-step process including a least absolute shrinkage and selection operator (LASSO) for variable selection between the sensors followed by vector autoregressive (VAR) models for multivariate forecasting to predict future performance of the heat pipe within MAGNET. Additionally, a physics model was created within the Sockeye framework that would be applied in future tests. With controlled rates of temperature change, the DT successfully self-adjusted the heat pipe before reaching the lower limit under expected conditions. Ultimately, this DT could be leveraged as a foundational framework in future fission battery applications for continuously monitoring and actively self-adjusting a heat pipe.}
}
@article{ZHENG2023108926,
title = {Artificial intelligence-driven rechargeable batteries in multiple fields of development and application towards energy storage},
journal = {Journal of Energy Storage},
volume = {73},
pages = {108926},
year = {2023},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2023.108926},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X23023241},
author = {Li Zheng and Shuqing Zhang and Hao Huang and Ruxiang Liu and Mian Cai and Yinghui Bian and Long Chang and Huiping Du},
keywords = {Rechargeable batteries, Machine learning, Artificial intelligence, Material discovery, Status prediction},
abstract = {Rechargeable batteries are vital in the domain of energy storage. However, traditional experimental or computational simulation methods for rechargeable batteries still pose time and resource constraints. Artificial intelligence (AI), especially machine learning (ML) technology, has experienced rapid growth in recent years. The excellent classification and regression abilities of ML have been successfully applied to various fields of rechargeable battery research, resulting in numerous outstanding achievements. Herein, it is worthwhile to summarize the work of AI in rechargeable battery technology. This review aims to present a comprehensive account of the multiple fields where AI has been utilized for rechargeable battery research. First, the concept of ML and the key steps of processing are summarized. We then discuss how AI enables prediction of battery states and parameters in battery management systems, mainly including state of charge, state of health. Following this, the applications of AI to the discovery of key materials for rechargeable batteries, including cathodes, anodes, and electrolytes, are stated. We subsequently provide illustrations of how rechargeable batteries are utilized in charging protocols for energy storage. Additionally, we briefly outline the potential for developing AI’s new elements of machine vision and digital twins in battery research. Finally, we conclude by addressing challenges and perspectives for ML to drive innovations in battery technology.}
}
@article{ROUHOLLAHI2023102289,
title = {CardioVision: A fully automated deep learning package for medical image segmentation and reconstruction generating digital twins for patients with aortic stenosis},
journal = {Computerized Medical Imaging and Graphics},
volume = {109},
pages = {102289},
year = {2023},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2023.102289},
url = {https://www.sciencedirect.com/science/article/pii/S0895611123001076},
author = {Amir Rouhollahi and James Noel Willi and Sandra Haltmeier and Alireza Mehrtash and Ross Straughan and Hoda Javadikasgari and Jonathan Brown and Akinobu Itoh and Kim I. {de la Cruz} and Elena Aikawa and Elazer R. Edelman and Farhad R. Nezami},
keywords = {Aortic stenosis, Automated AI platform, Calcium distribution, Digital twin},
abstract = {Aortic stenosis (AS) is the most prevalent heart valve disease in western countries that poses a significant public health challenge due to the lack of a medical treatment to prevent valve calcification. Given the aging population demographic, the prevalence of AS is projected to rise, resulting in a progressively significant healthcare and economic burden. While surgical aortic valve replacement (SAVR) has been the gold standard approach, the less invasive transcatheter aortic valve replacement (TAVR) is poised to become the dominant method for high- and medium-risk interventions. Computational simulations using patient-specific models, have opened new research avenues for optimizing emerging devices and predicting clinical outcomes. The traditional techniques of generating digital replicas of patients’ aortic root, native valve, and calcification are time-consuming and labor-intensive processes requiring specialized tools and expertise in anatomy. Alternatively, deep learning models, such as the U-Net architecture, have emerged as reliable and fully automated methods for medical image segmentation. Two-dimensional U-Nets have been shown to produce comparable or more accurate results than trained clinicians’ manual segmentation while significantly reducing computational costs. In this study, we have developed a fully automatic AI tool capable of reconstructing the digital twin geometry and analyzing the calcification distribution on the aortic valve. The developed automatic segmentation package enables the modeling of patient-specific anatomies, which can then be used to simulate virtual interventional procedures, optimize emerging prosthetic devices, and predict clinical outcomes.}
}
@article{WANG2023105071,
title = {Automatic high-level motion sequencing methods for enabling multi-tasking construction robots},
journal = {Automation in Construction},
volume = {155},
pages = {105071},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.105071},
url = {https://www.sciencedirect.com/science/article/pii/S092658052300331X},
author = {Xi Wang and Shuoqi Wang and Carol C. Menassa and Vineet R. Kamat and Wes McGee},
keywords = {Human-robot collaboration, Learning from demonstration, Construction robot, Digital twin, Building information modeling, Robot sequential motions},
abstract = {Robots are expected to play an important role in future construction work. However, they are not yet widely adopted by the industry because it is difficult and expensive to program robots to conduct a variety of construction tasks. This paper presents a method for intuitively and flexibly teaching robots to perform various construction tasks through demonstrations. Robots are first programmed with basic skill primitives and then learn the sequencing of these primitive skills to perform different types of construction work under the guidance of human supervisors. The construction workflow and the interaction processes are enabled by a process-level digital twin system. Case studies with three assembly scenarios and a wooden frame construction experiment are used to present and verify the proposed method. The proposed approach enables automatic robot motion sequencing abilities through Learning from Demonstration and has the potential to enable the widespread adoption of robots on construction sites.}
}
@article{WANG2023109368,
title = {Digital twin based multi-objective energy management strategy for energy internet},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {154},
pages = {109368},
year = {2023},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2023.109368},
url = {https://www.sciencedirect.com/science/article/pii/S0142061523004258},
author = {Danlu Wang and Ruyi Fan and Yushuai Li and Qiuye Sun},
keywords = {Digital twin, Parallel system, Multi-objective energy management, Deep reinforcement learning},
abstract = {Energy management problem (EMP) has been a widely researched topic in optimal operation of Energy Internet (EI). However, the rapid growth in energy network scale and penetration of distributed renewable generations (DRGs) bring new challenges to energy management. Therefore, a digital twin (DT) based parallel energy management strategy is proposed for the large-scale EI which consists of We-energy (WE). Firstly, a parallel energy management framework is proposed. By establishing this triple parallel structure, states of energy networks can be observed realtimely, which enables flexible responses to fluctuations of DRGs and energy plug-and-play. Abandoned renewable energy is taken into account in the optimization model, which promotes the utilization of renewable energy. Then, a multi-timescale optimization strategy is proposed to handle different timescales of multi-energy networks. Furthermore, for better obtaining and processing information and avoiding dimensional curse, a DT based deep Q-learning algorithm (DQN) is proposed. Eventually, compared with the traditional benefit consensus based strategy, the simulation verifies the effectiveness of the DT based parallel energy management strategy.}
}
@article{YUCESAN2023110921,
title = {Physics-informed digital twin for wind turbine main bearing fatigue: Quantifying uncertainty in grease degradation},
journal = {Applied Soft Computing},
volume = {149},
pages = {110921},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110921},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623009390},
author = {Yigit A. Yucesan and Felipe A.C. Viana},
keywords = {Physics-informed neural network, Wind turbines, Digital twins, Uncertainty quantification},
abstract = {In the field of prognostics and health management for industrial equipment, digital twins stand out as essential tools. Wind park operators can harness the potential of digital twins to monitor component health, enabling proactive measures to optimize energy production while reducing maintenance costs. This study introduces a novel hybrid digital twin application tailored for monitoring wind turbine main bearing fatigue. It combines physics-based and data-driven kernels to address variable grease quality and biased observations. Our study covers model initialization, cross-validation, fleet management, and the influence of sampled turbines on prediction. Our approach offers two key advantages: (a) It reduces the need for extensive datasets, typical in other machine learning methods, by incorporating physics-based knowledge into the network architecture, and (b) it quantifies output uncertainties using tailored network layers and loss functions. Our findings conclude that even under compound uncertainty scenario, our hybrid model can estimate fleet unreliability only off by 4.7 weeks. However, it is essential to note that computational costs are tied to data processing, similar to other recurrent neural networks. A limitation is that the physics-based kernels must align with common machine learning linear algebra practices.}
}
@article{WU2023110824,
title = {ADCL: Adversarial Distilled Contrastive Learning on lightweight models for self-supervised image classification},
journal = {Knowledge-Based Systems},
volume = {278},
pages = {110824},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110824},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123005749},
author = {Ran Wu and Huanyu Liu and Jun-Bao Li},
keywords = {Adversarial distillation, Lightweight models, Self-supervised learning},
abstract = {With the development of modern sensors, numerous images are collected in edge application scenarios; however, their utilization is quite expensive because a massive effort is required to label them for further usage. Self-supervised learning, with no need for labeled data, shows great potential in this context; however, notable performance degradations can be observed when training lightweight networks which are essential in edge implementation. We propose an effective distillation method called Adversarial Distilled Contrastive Learning (ADCL) to mitigate this issue. Specifically, we introduced knowledge distillation into self-supervised learning to transfer underlying feature clustering relations from teacher models to shallow models. We adopted an online-updated rather than a pretrained teacher model to realize convenient implementation to specific data domains. An adversarial loss item was introduced to alleviate unstable optimization caused by an online trained teacher by forcing the teacher model to find feature relations beyond the recognition of the student model. Compared with other self-supervised knowledge distillation methods that maintain data queues consisting of positive and negative examples, the asymmetric contrastive learning method was employed to further relieve the memory bottleneck during training. The experimental results prove the effectiveness of our method. When ResNet-50 is used as a teacher to teach ResNet-18 on ImageNet, ADCL achieves top-1 accuracies of 60.3% , which surpasses other knowledge distillation methods with online teachers and is comparable to approaches using pretrained teachers and data queues.}
}
@article{DESAI2023103525,
title = {Enhanced multi-fidelity modeling for digital twin and uncertainty quantification},
journal = {Probabilistic Engineering Mechanics},
volume = {74},
pages = {103525},
year = {2023},
issn = {0266-8920},
doi = {https://doi.org/10.1016/j.probengmech.2023.103525},
url = {https://www.sciencedirect.com/science/article/pii/S0266892023001145},
author = {Aarya Sheetal Desai and Navaneeth N. and Sondipon Adhikari and Souvik Chakraborty},
keywords = {Multi-fidelity, Deep-H-PCFE, Uncertainty quantification, Surrogate models, Digital twin},
abstract = {The increasing significance of digital twin technology across engineering and industrial domains, such as aerospace, infrastructure, and automotive, is undeniable. However, the lack of detailed application-specific information poses challenges to its seamless implementation in practical systems. Data-driven models play a crucial role in digital twins, enabling real-time updates and predictions by leveraging data and computational models. Nonetheless, the fidelity of available data and the scarcity of accurate sensor data often hinder the efficient learning of surrogate models, which serve as the connection between physical systems and digital twin models. To address this challenge, we propose a novel framework that begins by developing a robust multi-fidelity surrogate model, subsequently applied for tracking digital twin systems. Our framework integrates polynomial correlated function expansion (PCFE) with the Gaussian process (GP) to create an effective surrogate model called H-PCFE. Going a step further, we introduce deep-HPCFE, a cascading arrangement of models with different fidelities, utilizing nonlinear auto-regression schemes. These auto-regressive schemes effectively address the issue of erroneous predictions from low-fidelity models by incorporating space-dependent cross-correlations among the models. To validate the efficacy of the multi-fidelity framework, we first assess its performance in uncertainty quantification using benchmark numerical examples. Subsequently, we demonstrate its applicability in the context of digital twin systems.}
}
@article{LIANG2023102543,
title = {Trained teacher: Who is good at teaching},
journal = {Displays},
volume = {80},
pages = {102543},
year = {2023},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2023.102543},
url = {https://www.sciencedirect.com/science/article/pii/S0141938223001762},
author = {Xingzhu Liang and Feilong Bi and Wen Liu and Xinyun Yan and Chunjiong Zhang and Chenxing Xia},
keywords = {Knowledge distillation, Trained teacher, Knowledge transfer, Teacher-student model},
abstract = {Knowledge distillation is an emerging method for acquiring efficient, small-scale networks. The main idea is to transfer knowledge from a complex teacher model with high learning capacity to a simple student model. To this end, various approaches to knowledge distillation have been proposed in the past few years, focusing mainly on modifications to student learning styles and less on changes to teacher teaching styles. Therefore, our new approach to knowledge distillation teacher training involves adapting the trained teachers to the knowledge distillation model in order to minimize the gap between the student model and the teacher model. We introduced the idea of a “Trained Teacher”: Our approach involves using a specially trained teacher network that, by incorporating knowledge distillation constraints during its own training, adapts to the teaching model in advance and performs nearly identically to a typical teacher network. This allows students to absorb the teacher's knowledge more effectively, thereby increasing their competence. In addition, the methods of mainstream knowledge distillation currently in use are equally appropriate to our educated teachers. Extensive tests on numerous datasets reveal that our technique outperforms the original knowledge distillation in accuracy on standard KD by 2%. Our code and pre-trained models can be found at https://github.com/JSJ515-Group/Trained_teacher.}
}
@article{HIELSCHER2023105248,
title = {A neural network based digital twin model for the structural health monitoring of reinforced concrete bridges},
journal = {Structures},
volume = {57},
pages = {105248},
year = {2023},
issn = {2352-0124},
doi = {https://doi.org/10.1016/j.istruc.2023.105248},
url = {https://www.sciencedirect.com/science/article/pii/S235201242301336X},
author = {T. Hielscher and S. Khalil and N. Virgona and S.A. Hadigheh},
keywords = {Structural health monitoring, Digital twin, Machine learning, Fibre-optic sensors, Fibre Bragg grating, Artificial neural network},
abstract = {Developments in Structural Health Monitoring (SHM) research over the past few decades have demonstrated potential in optimising maintenance solutions for degrading infrastructure. The scale of structural deterioration worldwide and the inadequacy of current non-destructive evaluation techniques necessitate the adoption of accessible, quantitative, continuous SHM technology into mainstream asset management practice. This paper seeks to address this significant demand by proposing a robust, end-to-end, fibre-optic sensor (FOS) monitoring prototype which utilises deep neural networks to convert FOS strain output into an interactive digital twin (DT) visualisation. Finite-element validation demonstrated that the prototype was capable of capturing reliable structural analytics, recording an average error of less than 2kNm and an absolute error of less than 0.15 mm for bending moment and deflection respectively. Furthermore, the predictive mean absolute error of the integrated artificial neural network was less than 1με during testing, demonstrating the accuracy of the digital twin when generating baseline strain data for structural analysis.}
}
@article{TAY2023103701,
title = {Artificial neural network framework for prediction of hydroelastic response of very large floating structure},
journal = {Applied Ocean Research},
volume = {139},
pages = {103701},
year = {2023},
issn = {0141-1187},
doi = {https://doi.org/10.1016/j.apor.2023.103701},
url = {https://www.sciencedirect.com/science/article/pii/S0141118723002420},
author = {Zhi Yung Tay},
keywords = {Feed-forward neural network, Very large floating structure, Hydroelastic response, Irregular wave, Machine learning, Surrogate model},
abstract = {The response of a very large floating structure (VLFS) must take into consideration the elastic deformation of the structure (commonly termed hydroelastic response) under wave action. Conventionally, the hydroelastic response could be computed by using the coupled finite element-boundary element (FE-BE) method, where the mat-like structure is modelled using plate theory and the water modelled using the potential theory. The FE-BE method requires the structure to be discretised into finer elements and the wetted surface boundary to be represented by smaller panels to accurately capture the hydroelastic response of the structure. Thus, the coupled FE-BE method could be computationally expensive when the structure gets larger or when subjected to waves of smaller wavelengths. To accelerate the computational time in predicting the hydroelastic response of the VLFS, a surrogate model trained using the feed-forward neural network is proposed. The hydroelastic responses under different wavelengths, structural stiffnesses and wave directions are first generated where these data are split into three groups for training, validation, and testing (prediction) purposes. The accuracy of the prediction in terms of correlation coefficient R is compared for the different train datasets, the number of neurons and hidden layers as well as the optimisation techniques. The finding shows that an accuracy of close to 99% to the ground truth could be achieved with only 80% of the train dataset. The hydroelastic response under irregular wave conditions predicted using the feed-forward neural network framework is also presented.}
}
@article{GUO2023200070,
title = {Design and Optimization of an Open Personalized Human-Computer Interaction System for Yearbook Painting Based on the Learner's Model},
journal = {Systems and Soft Computing},
pages = {200070},
year = {2023},
issn = {2772-9419},
doi = {https://doi.org/10.1016/j.sasc.2023.200070},
url = {https://www.sciencedirect.com/science/article/pii/S2772941923000236},
author = {Zaozao Guo and Muhamad Firdaus Ramli and Wenpeng Zhang},
keywords = {Learner modeling, human-computer interaction, emotion, database, yearbooks},
abstract = {Abstracts
With the rapid development of information technology such as big data and learning analytics, intelligent systems, a product of the deep integration of technology and education, have emerged. In this paper, a human-computer interaction teaching system for traditional art yearbooks is proposed based on the learner model. Firstly, the attention mechanism based long and short term memory network is used to mine the emotion from the course review text of learners, and the association rule algorithm and ID3 algorithm are used to initialize and dynamically update the text. Constructing a personalized HCI teaching system with the learner as the center. Based on the smart learning model, the functional modules of the human-computer interaction teaching system are analyzed and designed in detail, including online learning, online testing and educational information. The design of the database of the intelligent teaching system is proposed, and the design process of the database is fully demonstrated in terms of both database relationship design and database table structure design, taking into account the security of the database. Finally, the learner model and personalized human-computer interaction system that incorporate the emotions of this paper are tested for performance, and the results show that the prediction accuracy of this paper's model is about 3% higher than the standard model DKT on the 2009 dataset, about 3% higher than the standard model DKT on the AUC index, and about 4% lower than the standard model DKT on the RMSE index. Students learn through the personalized human-computer interaction system, and their mastery of the traditional art of New Year's Paintings is more thorough, and the learning effect is significantly improved.}
}
@article{ZOHDI2023116220,
title = {Rapid machine-learning enabled design and control of precise next-generation cryogenic surgery in dermatology},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {417},
pages = {116220},
year = {2023},
note = {A Special Issue in Honor of the Lifetime Achievements of T. J. R. Hughes},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2023.116220},
url = {https://www.sciencedirect.com/science/article/pii/S0045782523003444},
author = {Tarek I. Zohdi and Mona Zohdi-Mofid},
keywords = {Cryogenics, Dermatology, Digital-twin, Machine-learning},
abstract = {In the field of dermatology, the use of cryogenic processes, such as cryoablation, cryotherapy, etc., have grown dramatically over the last decade. This usually entails using a cryoprobe to freeze and destroy unwanted tissue, such as cancer cells. The focus of this work is to develop a digital-twin (a digital replica) of the performance of a cryogenic probe, which can be used to pre-plan and optimize surgical procedures, in order to maximize successful outcomes. Specifically, we model the optimal cryoprobe-induced cooling protocol needed to eliminate cells/tissue in specific regions, while minimizing damage to nearby tissue. The modeling approach is to develop mathematical surface point-source heat extraction kernels and then to create optimal surface patterns that the cryoprobe induces, by arranging the point-sources accordingly. Spatial and temporal control of the heat extraction is modeled. The entire subdermal thermal field is then constructed by superposing the solutions, enabling precise cryogenic treatment. Finally, a Machine Learning Algorithm (MLA) is then applied to optimize the set of parameters to deliver a precise response, making it an ideal real-time surgical tool.}
}
@article{KOPROV20231009,
title = {Systems and methods for authenticating manufacturing Machines through an unobservable fingerprinting system},
journal = {Manufacturing Letters},
volume = {35},
pages = {1009-1018},
year = {2023},
note = {51st SME North American Manufacturing Research Conference (NAMRC 51)},
issn = {2213-8463},
doi = {https://doi.org/10.1016/j.mfglet.2023.08.051},
url = {https://www.sciencedirect.com/science/article/pii/S2213846323001086},
author = {Pavel Koprov and Shyam Gadhwala and Aniket Walimbe and Xiaolei Fang and Binil Starly},
keywords = {Cybersecurity, Connected Manufacturing, Authentication, Physical Unclonable Function, Digital Twin, Vibration},
abstract = {Digital transformation leads to the inevitable change in the security paradigm for machines on a factory production floor. A unified namespace for machines in an Industrial Internet of Things (IIoT) network is only reliable when machine assets can trust and verify the identity of assets connected to the IIoT system. Current methods of asset authentication do not consider physical unclonable functions (PUFs) and can easily be spoofed or misused. Our work proposes using PUFs for industrial equipment such as CNC machines, robots, and 3D printers for identifying machines on a network and providing authentication procedures. In this work, we chose to use the vibration associated with machines and its embedded moving parts as a means to identify machine assets on a network. It is hypothesized that the vibrations associated with specific machine movements will be unique to each machine even when machines look exactly the same. The moving parts within a machine may produce a unique vibration pattern that can be used for machine identification throughout the working cycle. Our method requires light computing and relatively cheap measuring devices to capture the ‘fingerprints’ of machines and verify the signal's integrity. An adequate number of equipment has been tested for the worst-case scenario, i.e. when two machines look exactly the same with the same moving parts and produce exactly similar motion to generate the vibration signal. Data preprocessing and standard machine learning techniques like RF, LASSO, and SVM show great performance on raw time series data, enabling 100% TPR and more than 94% TNR in detecting the false class of the machines.}
}
@article{SHI2023102973,
title = {A deep weakly semi-supervised framework for endoscopic lesion segmentation},
journal = {Medical Image Analysis},
volume = {90},
pages = {102973},
year = {2023},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2023.102973},
url = {https://www.sciencedirect.com/science/article/pii/S1361841523002335},
author = {Yuxuan Shi and Hong Wang and Haoqin Ji and Haozhe Liu and Yuexiang Li and Nanjun He and Dong Wei and Yawen Huang and Qi Dai and Jianrong Wu and Xinrong Chen and Yefeng Zheng and Hongmeng Yu},
keywords = {Endoscopic lesion segmentation, Weakly semi-supervised learning, Regularization consistency},
abstract = {In the field of medical image analysis, accurate lesion segmentation is beneficial for the subsequent clinical diagnosis and treatment planning. Currently, various deep learning-based methods have been proposed to deal with the segmentation task. Albeit achieving some promising performances, the fully-supervised learning approaches require pixel-level annotations for model training, which is tedious and time-consuming for experienced radiologists to collect. In this paper, we propose a weakly semi-supervised segmentation framework, called Point Segmentation Transformer (Point SEGTR). Particularly, the framework utilizes a small amount of fully-supervised data with pixel-level segmentation masks and a large amount of weakly-supervised data with point-level annotations (i.e., annotating a point inside each object) for network training, which largely reduces the demand of pixel-level annotations significantly. To fully exploit the pixel-level and point-level annotations, we propose two regularization terms, i.e., multi-point consistency and symmetric consistency, to boost the quality of pseudo labels, which are then adopted to train a student model for inference. Extensive experiments are conducted on three endoscopy datasets with different lesion structures and several body sites (e.g., colorectal and nasopharynx). Comprehensive experimental results finely substantiate the effectiveness and the generality of our proposed method, as well as its potential to loosen the requirements of pixel-level annotations, which is valuable for clinical applications.}
}
@article{VASILIKIS2023115927,
title = {A digital twin approach for maritime carbon intensity evaluation accounting for operational and environmental uncertainty},
journal = {Ocean Engineering},
volume = {288},
pages = {115927},
year = {2023},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2023.115927},
url = {https://www.sciencedirect.com/science/article/pii/S0029801823023119},
author = {Nikolaos Vasilikis and Rinze Geertsma and Andrea Coraddu},
keywords = {Digital twin, Carbon intensity, Operational uncertainties, Environmental uncertainties, Data-driven methods, Hybrid propulsion},
abstract = {Maritime industry has set ambitious goals to drastically reduce its greenhouse gas emissions through stipulating and enforcing a number of energy assessment measures. Unfortunately, measures like the EEDI, EEXI, SEEMP and CII do not account for the operational and environmental uncertainty of operations at sea, even though they do provide a first means of evaluating the carbon footprint of ships. The increasing availability of high-frequency operational data offers the opportunity to quantify and account for this uncertainty in energy performance predictions. Current methods to evaluate and predict energy performance at a whole energy system level do not sufficiently account for operational and environmental uncertainty. In this work, we propose a digital twin that accurately predicts the fuel consumption and carbon footprint of the hybrid propulsion system of an Ocean-going Patrol Vessel (OPV) of the Royal Netherlands Navy under the aggregate effect of operational and environmental uncertainty. It combines first-principle steady-state models with machine learning algorithms to reach an accuracy of less than 5% MAPE on both mechanical and electrical propulsion, while bringing a 40% to 50% improvement over a model that does not utilise machine learning algorithms. Results over actual voyage intervals indicate a prediction accuracy of consumed fuel and carbon intensity within 2.5% accounting for a confidence interval of 95%. Finally, the direct comparison between mechanical and electrical propulsion showed no clear energy-saving benefits and a strong dependency of the results on each voyage’s specific operational and environmental conditions.}
}
@article{KUMAR2023102465,
title = {Improving public school productivity: Evidence from model schools in India},
journal = {Economics of Education Review},
volume = {97},
pages = {102465},
year = {2023},
issn = {0272-7757},
doi = {https://doi.org/10.1016/j.econedurev.2023.102465},
url = {https://www.sciencedirect.com/science/article/pii/S0272775723001127},
author = {G. Naveen Kumar},
keywords = {Education quality, Education policy, School productivity, Public school, India},
abstract = {This paper studies the impact of India’s “model” school program which aimed to provide high quality education to economically disadvantaged students. Model schools combine better infrastructure with more accountability, contract teachers, and lower per-pupil spending than regular public schools. Using a fuzzy Regression Discontinuity Design based on entrance exam cutoffs, I find attending a model school for five years increases test scores in math by 0.38 standard deviations, in science by 0.26 sd, and in social science by 0.26 sd on average. Furthermore, model schools increase the probability of joining pre-university by 11.5 percentage points. The results suggest it is possible to deliver substantial improvement of outcomes in public schools at a slightly lower level of school spending through a package of reforms.}
}
@article{LI2023206,
title = {Digital twin model-based smart assembly strategy design and precision evaluation for PCB kit-box build},
journal = {Journal of Manufacturing Systems},
volume = {71},
pages = {206-223},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0278612523001929},
author = {Xurui Li and Guangshuai Liu and Si Sun and Wenyu Yi and Bailin Li},
keywords = {3D point cloud, Printed circuit board, 6-DoF pose, Robotic assembly, Digital twin},
abstract = {Research concerning microelectronics assembly has attracted increasing attention from the manufacturing industry. In this context, achieving precise placement of the printed circuit board (PCB) inside the enclosure is the most critical aspect of the kit-box build assembly task. However, automating the PCB kit-box build assembly (PKBA) process remains a challenging work. This study presents a Digital Twin (DT) model that enables accurate perception of object pose for intelligent PKBA assembly, facilitating real-time monitoring and evaluation of its service status. In our system, a symmetry-drive method is proposed to optimize the initial pose in 6-DoF matching during DT assembly. Based on the developed technology, a three-stage learning method is established to achieve grasping point localization and robotic assembly trajectory planning. To ensure accurate and robust robot assembly, we developed a PKBA quality prediction model based on the DT system, which predicts the uncertainty of actual PCB assembly positioning by small displacement torsor (SDT) theory and Monte Carlo methods. Particularly, the assembly quality of the actual product is effectively monitored when the state of the virtual simulation model corresponds to the physical assembly object. Finally, a prototype system and a case study involving dexterous assembly tasks are conducted to verify the effectiveness and feasibility of the proposed method. The results indicate that the proposed PKBA strategy achieves an 82% assembly success rate. By employing well-designed strategies, our method ensures that the majority of errors are below 0.8 mm and 0.6 degrees.}
}
@article{ZHANG2023103454,
title = {DMSC-Net: A deep Multi-Scale context network for 3D object detection of indoor point clouds},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {122},
pages = {103454},
year = {2023},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2023.103454},
url = {https://www.sciencedirect.com/science/article/pii/S1569843223002789},
author = {Zhenxin Zhang and Dixiang Xu and P. Takis Mathiopoulos and Qiang Wang and Liqiang Zhang and Zhihua Xu and Jincheng Jiang and Zhen Li},
keywords = {Indoor point cloud, Object detection, Multi-head attention mechanism, Deep multi-scale contextual feature, Deep learning},
abstract = {Indoor object detection has emerged as one of the key technologies for the success of numerous indoor system applications, such as autonomous navigation, accurate modeling of indoor environments, digital twin and terra Hertz (THz) communications. This paper first proposes a flexible and inter-operational detection module, termed deep multi-scale context (DMSC) module, aiming at the development of efficient indoor object detection techniques using the point clouds. More specifically, by combining the deep contextual information of indoor objects and multi-scale features, a novel deep multi-scale contextual feature is designed. Furthermore, we introduce the decoder part of the vision transformer into the indoor object proposal generation by means of a multi-head attention (MHA) module from a three-dimensional (3D) point cloud to accurately extract object proposals generating high-quality bounding boxes. Extensive experiments have shown that, the effective interoperability of the proposed DMSC module with three object detection networks, namely VoteNet, GroupFree 3D and RBGNet, leads to improvements in their mAP@0.25 by 6.5%, 0.9% and 0.4% on the ScanNetV2 datasets, respectively. The proposed end-to-end network, termed as DMSC-Net, consists of an indoor point cloud feature learning backbone (FLB) unit, and three modules, namely the DMSC, a voting decision (VD) module, and an MHA module. Extensive experiments have shown that the DMSC-Net outperforms other advanced indoor 3D detection networks, such as RBGNet, by 1.1% and 0.9% of mAP@0.25 when applied on ScanNet and SUN RGB-D datasets, respectively. The developed code is publicly available at: https://github.com/CNU-DLandCV-lab/MHA_DMSC.}
}
@article{ROBLES2023104007,
title = {OpenTwins: An open-source framework for the development of next-gen compositional digital twins},
journal = {Computers in Industry},
volume = {152},
pages = {104007},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.104007},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523001574},
author = {Julia Robles and Cristian Martín and Manuel Díaz},
keywords = {Digital twin composition, Open-source digital twin framework, Kafka-ML, 3D visualizations, Industry 4.0},
abstract = {Although digital twins have recently emerged as a clear alternative for reliable asset representations, most of the solutions and tools available for the development of digital twins are tailored to specific environments. Furthermore, achieving complex digital twins often requires the orchestration of technologies and paradigms such as machine learning, the Internet of Things, and 3D visualization, which are rarely seamlessly aligned in open-source solutions. In this paper, we present an open-source framework for the development of compositional digital twins, i.e., advanced digital twins that link individual entities or subsystems to create a higher degree digital twin, allowing knowledge sharing and data relationships. In this open framework, digital twins can be easily developed and orchestrated with 3D-connected visualizations, IoT data streams, and real-time machine-learning predictions. To demonstrate the feasibility of the framework, a use case in the Petrochemical Industry 4.0 has been developed.}
}
@article{LIU2023106961,
title = {A novel seminar learning framework for weakly supervised salient object detection},
journal = {Engineering Applications of Artificial Intelligence},
volume = {126},
pages = {106961},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106961},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623011454},
author = {Yan Liu and Yunzhou Zhang and Zhenyu Wang and Fei Yang and Feng Qiu and Sonya Coleman and Dermot Kerr},
keywords = {Salient object detection, Weakly supervised, Seminar learning framework, Cross attention guided network, Consistency transformation mechanism, Multiple pseudo labels},
abstract = {Weakly supervised salient object detection (SOD) is a challenging task and has drawn much attention from several research perspectives, it has revealed two problems while driving the rapid development of saliency detection. (1) Large divergence in the characteristics of saliency regions in terms of location, shape and size makes them difficult to recognize. (2) The properties of convolutional neural networks dictate that it is insensitive to various transformations, which will lead to hardly balance the application of various disturbances. To tackle these limitations, this paper proposes a novel seminar learning framework with consistent transformation ensembling (SLF-CT) for scribble supervised SOD. The framework consists of the teacher–student model and the student–student model for segmenting the salient objects. Specifically, we first design a cross attention guided network (CAGNet) as a baseline model for saliency prediction. Then we assign CAGNet to the teacher–student model, where the teacher network is based on the exponential moving average and guides the training of the student network. Moreover, we adopt multiple pseudo labels to transfer the information among students from different conditions. To further enhance the regularization of the network, a consistency transformation mechanism is also incorporated, which encourages the saliency prediction and input image of the network to be consistent. The experimental results demonstrate that the proposed approach performs favorably comparable with the state-of-the-art weakly supervised methods. As far as we know, the proposed approach is the first application of seminar learning in the SOD area.}
}
@article{GHIENNE2023107155,
title = {Learning structural stress virtual sensors from on-board instrumentation of a commercial aircraft},
journal = {Computers & Structures},
volume = {289},
pages = {107155},
year = {2023},
issn = {0045-7949},
doi = {https://doi.org/10.1016/j.compstruc.2023.107155},
url = {https://www.sciencedirect.com/science/article/pii/S0045794923001852},
author = {Martin Ghienne and Alexandre Limare},
keywords = {Structural stress virtual sensors, Time series regression, Ensemble model learning, Challenge AI for industry, Aircraft Digital Twin},
abstract = {This work aims to predict the mechanical stress on the structure of a business jet in service phase from flight instrument only. A significant database obtained from test flights using aircraft instrumented with strain gauges has been provided as part of an Artificial Intelligence challenge organized by the French Ile-de-France region and the aircraft manufacturer Dassault Aviation. Learning techniques are considered to train a prediction model of the aircraft structural stress. The proposed baseline includes a clustering step for phase identification in time series and an ensemble model with two stacked regressors. The model is trained on a dataset of 117 flights and its overall performance is evaluated on a validation set of flight sequences from 186 flights. The main advantages of the proposed learning approach are its prediction accuracy, its training frugality and its interpretability. This paper presents a global data science workflow applied to a problem of structural stress prediction. Despite a development in a constrained time period with no direct access to the data, the proposed approach demonstrates the feasibility of the concept of learned virtual sensor of aircraft structural stress and paves the way for applications to other structures.}
}
@article{LIU2023127,
title = {A novel bionic decision-making mechanism for digital twin-based manufacturing system},
journal = {Manufacturing Letters},
volume = {35},
pages = {127-131},
year = {2023},
note = {51st SME North American Manufacturing Research Conference (NAMRC 51)},
issn = {2213-8463},
doi = {https://doi.org/10.1016/j.mfglet.2023.08.119},
url = {https://www.sciencedirect.com/science/article/pii/S2213846323001803},
author = {Shimin Liu and Pai Zheng and Suiyan Shang},
keywords = {Digital twin, Manufacturing system, Bionic decision-making, Smart manufacturing},
abstract = {As an innovative smart manufacturing system, the virtual entities-based decision-making process is the most typical difference between the digital twin-based manufacturing system (DTMS) and other smart manufacturing systems. Therefore, the accuracy of virtual entity-driven decision-making is the key to affecting the system reliability of the DTMS. Normally, the manufacturing process is often accompanied by complex state changes, which are collected by the perception module of the DTMS in the form of high-dimensional information. Then, the decision-making model needs to respond to these state changes in real-time and give reasonable decision results back to physical space, which has become an important scientific issue of DTMS. To fill this gap, a novel bionic decision-making mechanism for DTMS is put forward by introducing the biological sequential learning mechanism into the decision-making process. Subsequently, the systematic decision-making process imitates biological instinct and learning behavior mechanisms to explore the short-term and long-term process of decision-making. The bionic decision-making mode formed by combining the above two modes provides adaptive decision-making in different scenarios. It is believed that the bionic decision-making mechanism can help to quickly and accurately give decision-making feedback to guide on-site manufacturing and ensure product quality and manufacturing efficiency.}
}
@article{JEUNG2023129973,
title = {Data assimilation for urban stormwater and water quality simulations using deep reinforcement learning},
journal = {Journal of Hydrology},
volume = {624},
pages = {129973},
year = {2023},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2023.129973},
url = {https://www.sciencedirect.com/science/article/pii/S0022169423009150},
author = {Minhyuk Jeung and Jiyi Jang and Kwangsik Yoon and Sang-Soo Baek},
keywords = {Data assimilation, Deep reinforcement learning, Stormwater management model, Extreme rainfall event, Sensitivity analysis},
abstract = {Hydrological models have been used to understand the transportation of water quantity and quality in drainage systems, and the stormwater management model (SWMM) is one of the most widely-used models for runoff quantity and quality simulations in urban areas. Although significant efforts have been made to identify the appropriate input parameters of the SWMM model in various watersheds, it is difficult to reflect the variability of the real environment using a fixed input parameter. Data assimilation (DA) is a compatibility method that improves prediction accuracy by merging observations and simulation outputs. It is useful to reduce the forecast error from temporal transferability with information interaction between the model output and observation data. However, conventional DA approaches cannot completely overcome their unrealistic assumptions such as linearity, normality, and error covariances. To address these challenges, we used deep reinforcement learning (RL) to develop an automatic assimilation model that interactively optimizes the SWMM parameters in a real environment (SWMM-RL). In the SWMM-RL model, the agent is trained by rewarding and/or punishing the action (modulated SWMM input parameter) in real time according to the state changes. The model was constructed to minimize the error of runoff and pollutant load simulation of suspended solids (SS), total nitrogen (TN), and total phosphorus (TP) in each stormwater monitoring event. The results demonstrated that the SWMM-RL model primarily outperformed the fixed input parameter SWMM model (SWMM-PS) in simulating the runoff and the three different pollutant loads (the median value of Nash–Sutcliffe efficiency (NSE) for 10 stormwater events was increased by 0.11, 0.31, 0.36, and 0.07 for runoff, SS, TN, and TP, respectively). The SWMM-PS has disadvantages in simulating low rainfall events because of the high sensitivity of runoff peaks to heavy rainfall conditions. Furthermore, the effects of extreme rainfall events were estimated using the SWMM-RL model. This study showed how SWMM-RL combined with the DA method increased forecast accuracy by providing sensitivity and temporal transitions of input parameters.}
}
@article{ISICHEI2023e00321,
title = {Cybersecurity and privacy in smart bioprinting},
journal = {Bioprinting},
volume = {36},
pages = {e00321},
year = {2023},
issn = {2405-8866},
doi = {https://doi.org/10.1016/j.bprint.2023.e00321},
url = {https://www.sciencedirect.com/science/article/pii/S2405886623000647},
author = {Joan C. Isichei and Sajad Khorsandroo and Salil Desai},
keywords = {3D printing, Artificial intelligence, Bioprinting, Cybersecurity, Digital twin (DT), Internet of things (IoT)},
abstract = {Bioprinting is a versatile technology gaining rapid adoption in healthcare fields such as tissue engineering, regenerative medicine, drug delivery, and surgical planning. Although the current state of the technology is in its infancy, it is envisioned that its evolution will be enabled by the integration of the following technologies: Internet of Things (IoT), Cloud computing, Artificial Intelligence/Machine Learning (AI/ML), NextGen Networks, and Blockchain. The product of this integration will eventually be a smart bioprinting ecosystem. This paper presents the smart bioprinting ecosystem as a multilayered architecture and reviews the cyber security challenges, vulnerabilities, and threats in every layer. Furthermore, the paper presents privacy preservation solutions and provides a purview of the open research challenges in the smart bioprinting ecosystem.}
}
@article{CHEN2023422,
title = {Novel learning framework for optimal multi-object video trajectory tracking},
journal = {Virtual Reality & Intelligent Hardware},
volume = {5},
number = {5},
pages = {422-438},
year = {2023},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2023.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2096579623000220},
author = {Siyuan Chen and Xiaowu Hu and Wenying Jiang and Wen Zhou and Xintao Ding},
keywords = {Web3D, Virtual evacuation, Multi-object tracking, Trajectory extraction, Trajectory optimization},
abstract = {Background
With the rapid development of Web3D, virtual reality, and digital twins, virtual trajectories and decision data considerably rely on the analysis and understanding of real video data, particularly in emergency evacuation scenarios. Correctly and effectively evacuating crowds in virtual emergency scenarios are becoming increasingly urgent. One good solution is to extract pedestrian trajectories from videos of emergency situations using a multi-target tracking algorithm and use them to define evacuation procedures.
Methods
To implement this solution, a trajectory extraction and optimization framework based on multi-target tracking is developed in this study. First, a multi-target tracking algorithm is used to extract and preprocess the trajectory data of the crowd in a video. Then, the trajectory is optimized by combining the trajectory point extraction algorithm and Savitzky–Golay smoothing filtering method. Finally, related experiments are conducted, and the results show that the proposed approach can effectively and accurately extract the trajectories of multiple target objects in real time.
Results
In addition, the proposed approach retains the real characteristics of the trajectories as much as possible while improving the trajectory smoothing index, which can provide data support for the analysis of pedestrian trajectory data and formulation of personnel evacuation schemes in emergency scenarios.
Conclusions
Further comparisons with methods used in related studies confirm the feasibility and superiority of the proposed framework.}
}
@article{FANG2023107645,
title = {A digital twin modeling method based on multi-source crack growth prediction data fusion},
journal = {Engineering Failure Analysis},
volume = {154},
pages = {107645},
year = {2023},
issn = {1350-6307},
doi = {https://doi.org/10.1016/j.engfailanal.2023.107645},
url = {https://www.sciencedirect.com/science/article/pii/S135063072300599X},
author = {Xin Fang and Guijie Liu and Honghui Wang and Xiaojie Tian},
keywords = {Digital twin, Crack growth prediction, Theoretical model, Machine learning, Consistency retention, Data fusion},
abstract = {This paper proposes a digital twin method based on multi-source crack growth prediction data fusion. In this method, two different prediction methods based on theoretical model correction and machine learning model correction are constructed, which avoids the inapplicability of a single method in practical applications. Meantime, based on the consistency retention method corresponding to each model, the influence of uncertainty factors on crack growth prediction is gradually reduced by inputting crack detection data. Subsequently, by fusing the historical data and prediction data, the crack growth prediction result with the smallest deviation and higher reliability is output. The verification results show that the digital twin model proposed in this paper can effectively reduce the influence of uncertainty factors on crack growth prediction and realize the dynamic prediction of crack growth.}
}
@article{FAN2023111867,
title = {Energy management of renewable based power grids using artificial intelligence: Digital twin of renewables},
journal = {Solar Energy},
volume = {262},
pages = {111867},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.111867},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23005005},
author = {Xuezhou Fan and Yajuan Li},
keywords = {Renewable power grids, Cloud-fog computing, Artificial intelligence, Server broker policies, Digital twin},
abstract = {This paper proposes fog computing as a method of minimizing latency and maximizing performance by storing the information in the cloud to give a wide range of services to users using cloud computing. Also, consumer requests have been handled by several cloud Data Centers (DCs). Due to the fog's ability to attract more users and provide more services, load balancing has become increasingly crucial. It is therefore necessary to enhance the method that balances the fog's load. The study proposes a three-layer model comprising a cloud layer, a fog layer, and a user layer for optimal energy management in renewable power grids. The renewable energy sources are all modeled within the digital twin environment to make sure that very accurate monitoring is made. It is proposed for balancing the fog load using an artificial intelligence based optimization algorithm called the Whale optimization algorithm (WOA). Services are provided by fog servers in response to requests from users. In case of failure of the fog layer, all consumers' records are saved and services are provided to them through the cloud. Moreover, the service broker policies (SBP) have been applied to select the DCs efficiently. This paper compares the suggested algorithm to three previously developed algorithms including the particle swarm optimization (PSO), differential devolution (DE), and teaching–learning-based optimization (TLBO). It uses the three SBPs of closest data center, optimize response time (RT), reconfigure dynamically with load, and an improved SBP. It also minimizes RT and process time to improve the efficiency. The results show that there is an improvement in WOA's performance by approximately 5% compared to that of other algorithms.}
}
@article{YANG2023114692,
title = {Identification of industrial exhaust based on an electronic nose with an interleaved grouped residual convolutional compression network},
journal = {Sensors and Actuators A: Physical},
volume = {363},
pages = {114692},
year = {2023},
issn = {0924-4247},
doi = {https://doi.org/10.1016/j.sna.2023.114692},
url = {https://www.sciencedirect.com/science/article/pii/S0924424723005411},
author = {Shuangjing Yang and Huisheng Zhang and Zhe Li and Shukai Duan and Jia Yan},
keywords = {E-nose, Convolutional neural network, Interleaved grouped residual convolution, Knowledge distillation, Industrial exhaust identification},
abstract = {Industrial exhaust detection helps to identify pollution sources, assess the distribution of environmental pollutants, and reduce disease. In this paper, an electronic nose (E-nose) system for industrial exhaust detection is established, and an interleaved grouped residual convolutional compression network (IGRCCN) based on knowledge distillation (KD) is proposed to achieve industrial exhaust identification. First, a detection system based on 15 cross-sensitive gas sensors is constructed to detect 10 common industrial exhaust gases. Second, the KD-based IGRCCN, which couples a novel teacher model and a lightweight student model, is designed. Specifically, combining the working principle of the mammalian olfactory system and the characteristics of E-nose data, we propose using two interleaved grouped residual convolution block at the sensor level and channel level to construct the teacher model, which extracts signal features while preventing feature degradation. In addition, the KD framework enables the lightweight student model to efficiently classify gases, with a performance comparable to that of the teacher model, thus realizing model compression. The experimental results show that the classification accuracy of the IGRCCN is 98.33%, which vastly outperforms other deep learning models. In addition, IGRCCN obtained promising classification accuracies of 88.66% and 92.92% for small sample training and early identification, respectively, which showed the advantages of the proposed method in practical applications.}
}
@article{ALIMAM2023101846,
title = {The resurrection of digital triplet: A cognitive pillar of human-machine integration at the dawn of industry 5.0},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {35},
number = {10},
pages = {101846},
year = {2023},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101846},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823004007},
author = {Hassan Alimam and Giovanni Mazzuto and Nicola Tozzi and Filippo {Emanuele Ciarapica} and Maurizio Bevilacqua},
keywords = {Digital Triplet , Cognitive Digital Twin , Artificial Intelligence , Human-Machine Integration, Brain-Computer Interface , Industry 5.0},
abstract = {The integration of AI technology with digital transformation has profoundly shaped the evolution towards digital triplet architecture, grounded in human-centric methodologies. By infusing human intellectual activities into both physical and cyberspace, innovative links between humans and machines are established. Despite limitations in transitioning from tangible human presence to the digital realm in cyberspace, extensive efforts are underway to harness emotional, visual, and oral responses, thereby enhancing the reasoning and predictive capabilities of digital twins. These advancements aim to elevate real-time human interactions with physical and virtual systems by integrating intelligent AI algorithms and cognitive computing systems into digital twins. This paper meticulously analyses recent trends in digital twins, tracing their evolution from traditional concepts and applications to a nuanced digital triplet hierarchy that incorporates human intuition, knowledge, and creativity within cyberspace. we delve into the hierarchical framework of the digital triplet, resonating with maturity, domination, and volition levels, enhances cognitive and perceptual capabilities in cyberspace. The study provides a systematic overview of the development of ultra-realistic digital models, incorporating real-time data-driven artefacts that integrate intelligent activities with multidomain, multiphysics, and multiscale simulations. The research scope is focused on augmenting the perceptive and heuristic capabilities of the digital triplet framework by utilizing AI in data analytics, retrieving heterogeneous data from virtual entities using semantic artificial intelligence technologies, and amalgamating AI and machine learning with human insight and perceptual knowledge. The proposed digital triplet hierarchy aims to enhance cyberspace's capacity for learning, cognitive skills, and knowledge transfer. It can be a guideline for the researcher to promote cognitive augmentation of the human brain through brain-machine/computer interface, virtual, augmented, and extended reality, fostering a symbiotic relationship between humans and machines in the industrial metaverse and industry 5.0. The paper discusses future directions for research and the challenges involved in developing intelligent digital twins towards the digital triplet paradigm, aiming to embody intelligent activities and cognitive capabilities within the framework of human–machine symbiosis.}
}
@article{YASSIN2023100039,
title = {Digital twin in power system research and development: Principle, scope, and challenges},
journal = {Energy Reviews},
volume = {2},
number = {3},
pages = {100039},
year = {2023},
issn = {2772-9702},
doi = {https://doi.org/10.1016/j.enrev.2023.100039},
url = {https://www.sciencedirect.com/science/article/pii/S2772970223000263},
author = {Mohammed A.M. Yassin and Ashish Shrestha and Suhaila Rabie},
keywords = {Communication channel, Cyber-physical systems, Digital twin, Internet of things, Machine learning},
abstract = {In order to address the issues that arise in modern power systems, such as system dynamics, stability, control, efficiency, reliability, economy, planning and policy, and so on, efforts have been made to develop new tools and techniques, components, methodologies, and scientific innovations in a variety of fields. These efforts have been undertaken to address these issues. The term “digital twin” (DT) refers to one of the most reliable and rapidly developing technologies that have recently been incorporated into a variety of applications, platforms, and real-time projects. The authors of this study offered a scoping review of DT technologies with a primary emphasis on power systems. It has been established that the underlying notion behind this technology, as well as its operating principle, types, communication channels and protocols, and standards, have all been thoroughly examined. In addition, the possibility of integrating other technologies with DT has also been considered, along with the potential benefits of doing so and the potential difficulties that may arise. Based on the information gained from the current projects, the finished projects, the research publications, as well as the research and industry insights, a critical discussion has been made.}
}
@article{LI2023109590,
title = {Digital twin-driven focal modulation-based convolutional network for intelligent fault diagnosis},
journal = {Reliability Engineering & System Safety},
volume = {240},
pages = {109590},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109590},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023005045},
author = {Sheng Li and Qiubo Jiang and Yadong Xu and Ke Feng and Yulin Wang and Beibei Sun and Xiaoan Yan and Xin Sheng and Ke Zhang and Qing Ni},
keywords = {Rolling bearing, Fault diagnosis, Digital twin, Lightweight, Focal modulation},
abstract = {Rolling bearings are essential components of various rotating machinery and are critical in ensuring safe and reliable industrial production. Deep learning techniques have demonstrated outstanding potential for real-time monitoring of bearings, contributing to the safe operation of machinery and equipment. However, deep learning-based fault diagnosis methods typically rely on training datasets comprising samples of all potential failure modes that may not be acquirable in specific industrial settings. To tackle the challenge above, this paper introduces a digital twin approach to generate synthetic data to supplement and enhance the quality and availability of training data in deep learning methods. Specifically, the main contributions of this research are: (1) constructing a digital twin model of rolling bearings to generate an approximation of the physical entity bearing status data. (2) investigating the efficient combination of CNNs and focal modulation mechanism, and proposing a novel lightweight architecture, FM-LCN, aims to learn local-global representations of simulated data to improve diagnostic performance. Experiments demonstrate that FM-LCN outperforms five state-of-the-art competitive models by a large margin in accuracy with lower computational cost.}
}
@article{LI2023120441,
title = {Establishing boundary conditions in sewer pipe/soil heat transfer modelling using physics-informed learning},
journal = {Water Research},
volume = {244},
pages = {120441},
year = {2023},
issn = {0043-1354},
doi = {https://doi.org/10.1016/j.watres.2023.120441},
url = {https://www.sciencedirect.com/science/article/pii/S0043135423008813},
author = {Jiuling Li and Nur Nabilah Naina Mohamad and Keshab Sharma and Zhiguo Yuan},
keywords = {Heat transfer, Boundary conditions, Temperature modelling, Physics-informed model, Digital twin, Sewer system, Pipe-soil heat transfer},
abstract = {Modelling heat transfer in sewers and the surrounding soil is important for effective sewer maintenance, and for heat recovery from wastewater. The boundary conditions, including both the thickness of the soil layer to be modelled and the temperature distribution around the boundary of the soil layer, directly determine both the efficiency and accuracy of the models. Yet there is no systematic method to establish these conditions. This study presents a novel and generic approach to establishing efficient boundary conditions for sewer heat transfer modelling. Fourier transform is applied to identify the dominant frequencies of the temperatures of the heat sources/sinks, namely the atmosphere, sewer air and wastewater. A simple data-driven model for determining the thickness of the soil-layer to be included, and three physics-informed models for predicting the temperatures at the soil-layer boundary are then learnt from mechanistic models for sewer heat transfer, taking into consideration the frequency spectra. The methodology achieved high fidelity to the mechanistic models in predicting the soil-layer boundary temperatures and sewer wall temperatures for real-life sewers. This approach offers an easy yet reliable way to obtain efficient boundary conditions that significantly improve both the accuracy and speed of sewer heat transfer modelling.}
}
@article{STEED2023436,
title = {Deep active-learning based model-synchronization of digital manufacturing stations using human-in-the-loop simulation},
journal = {Journal of Manufacturing Systems},
volume = {70},
pages = {436-450},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0278612523001619},
author = {Clint Alex Steed and Namhun Kim},
keywords = {Human-centric manufacturing, Digital twin, Virtual reality (VR), AI and machine learning, Virtual manufacturing, Digital transformation},
abstract = {The effective and accurate modeling of human performance is one of the key technologies in virtual/smart manufacturing systems. However, a significant challenge lies in acquiring sufficient data for such modeling. Virtual Reality (VR) emerges as a promising solution, making human manufacturing experiments more practical and accessible. In this paper, we present a novel framework that efficiently models human assembly duration by leveraging VR to prototype data-acquisition systems for assembly tasks. Central to the framework is an active learning model, which intelligently selects experimental conditions to yield the most informative results, effectively reducing the number of experiments required. As a result, the system demands fewer experimental trials and operates on an automated basis. In VR experiments involving throughput rate, the active model significantly reduces the data requirement, thereby expediting the experiment and modeling process. While this framework demonstrates remarkable efficiency, it does exhibit sensitivity to non-constant noise and may necessitate prior data from similar assembly tasks to identify high-noise. Notably, this proposed method extends beyond manufacturing, allowing the quick generation of human performance models in virtual systems and enhancing experiment scalability across various fields. With its potential to revolutionize human performance modeling, our framework represents a promising avenue for advancing virtual/smart manufacturing systems and other related applications.}
}
@article{ANTONELLO2023,
title = {Surrogate model-based calibration of a flying Earth observation satellite},
journal = {Advances in Space Research},
year = {2023},
issn = {0273-1177},
doi = {https://doi.org/10.1016/j.asr.2023.10.043},
url = {https://www.sciencedirect.com/science/article/pii/S0273117723008633},
author = {Federico Antonello and Daniele Segneri and Vemund Reggestad},
keywords = {Spacecraft, European Space Agency (ESA), Calibration, Artificial Intelligence, Surrogate Model, Digital Twin},
abstract = {At the European Space Agency (ESA), Modeling and Simulation (M&S) plays a fundamental role during the lifetime of a spacecraft, being used from the design phase to the testing and during operations in space. M&S tools embed general physics-based models and disciplines characterized by configurable parameters which have to be calibrated in order to mimic the behavior of the actual flying spacecraft. However, their calibration requires a large number of simulations which are unfeasible to be obtained through computationally expensive high-fidelity simulation models. Thus, the inability to calibrate the high-fidelity simulation models poses limitations for the use of M&S tools during spacecraft operations. In this light, the present work proposes the use of a surrogate model-based approach for the calibration of simulation models of spacecraft. The approach integrates a computationally inexpensive deep-learning-based surrogate model, which mimics the high-fidelity simulation model without requiring the same computational burden, and a metaheuristic optimization algorithm, to identify the optimal values of the simulation model configurable parameters. This enhances the capabilities of M&S tools and allows their use in operations. The approach’s effectiveness is shown by its application to real flying Earth observation satellite data and simulation models.}
}
@article{DING2023107416,
title = {Intelligent emergency digital twin system for monitoring building fire evacuation},
journal = {Journal of Building Engineering},
volume = {77},
pages = {107416},
year = {2023},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2023.107416},
url = {https://www.sciencedirect.com/science/article/pii/S2352710223015966},
author = {Yifei Ding and Yuxin Zhang and Xinyan Huang},
keywords = {Fire emergency, Computer vision, Human behaviour, Digital twin, Building evacuation},
abstract = {The provision of real-time and detailed evacuation information feedback is vitally significant for the formulation and adaptation of the onsite evacuation strategy. The conventional surveillance system relying on surveillance cameras is limited to processing video and fails to extract human behaviour or provide privacy protection. This work proposes an Intelligent Emergency Digital Twin system based on computer vision and deep learning. The system comprises (1) CCTV network, (2) YOLOv4 evacuee detector, (3) DeepSORT evacuee tracker, (4) Perspective transformer, and (5) Digital Twin interface. It enables the detection and tracking of evacuees, the calculation of their egress speed, and the protection of their privacy in a digital interface. The proposed system was evaluated in a staircase of an office building through two types of tests with positive results: ratio of successfully detecting is 100% in individual objects test and about 90% in multiple objects test. The evacuation data generated by the digital twin system would be useful for guiding evacuations out of fire scenarios. This proposed digital twin framework can lay the foundation for the implementation of smart human monitoring in fire scenarios for buildings.}
}
@article{ELADLY2023101544,
title = {Enhancing circular economy via detecting and recycling 2D nested sheet waste using Bayesian optimization technique based-smart digital twin},
journal = {Results in Engineering},
volume = {20},
pages = {101544},
year = {2023},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2023.101544},
url = {https://www.sciencedirect.com/science/article/pii/S2590123023006710},
author = {Amira M. Eladly and Ahmed M. Abed and Moustafa H. Aly and Wessam M. Salama},
keywords = {Bayesian optimization technique, Circular economy, Classification, Deep learning, Segmentation, 2D nested waste, Sustainability, Waste management},
abstract = {The recycling process is controversial on a worldwide scale since it is based on the concept of sustainability and minimizing the environmental footprint. From this perspective, a practical framework for managing the 2D nesting waste is presented in this paper, which is a crucial phase in many production processes. Deep Learning (DLs) models are used to detect (i.e., segmentation) and categorize (i.e., classification) waste area sizes to enhance the circular economy via recycling procedures. Moreover, the apparel industry for having huge 2D nesting waste is implemented in this paper. Furthermore, data augmentation is performed in this paper to overcome the lack of datasets. The segmentation stage is applied based on the SegNet deep convolutional neural network (DCNN). In addition to, the classification stage based on the DLs, ResNet34, InceptionV3, and DenseNet121 is implemented to classify our datasets. The experimental results demonstrate that the proposed framework outperforms other existing techniques, where the Area Under the Curve (AUC) of 99.87 %, detection success rate (DSR) of 99.88 %, sensitivity of 99.98 %, precision of 99.98 %, F1-score of 98.99 %, mean square error (MSE) from 0.01 % to 2.49 %, efficiency of 97.41 %, and computational time of 3.9 s. Therefore, our proposed framework achieves the best performance compared with the literature. The future work will focus on enhancing the circular economy by utilizing the 3D nested sheet waste.}
}
@article{GUO2023102965,
title = {A digital twin to quantitatively understand aging mechanisms coupled effects of NMC battery using dynamic aging profiles},
journal = {Energy Storage Materials},
volume = {63},
pages = {102965},
year = {2023},
issn = {2405-8297},
doi = {https://doi.org/10.1016/j.ensm.2023.102965},
url = {https://www.sciencedirect.com/science/article/pii/S2405829723003434},
author = {Wendi Guo and Yaqi Li and Zhongchao Sun and Søren Byg Vilsen and Daniel Ioan Stroe},
keywords = {Digital twin, Aging mechanisms, NMC battery, Dynamic aging profiles, Charging protocols},
abstract = {Traditional lithium-ion battery modeling does not provide sufficient information to accurately verify battery performance under real-time dynamic operating conditions, particularly when considering various aging modes and mechanisms. To improve the current methods, this paper proposes a lithium-ion battery digital twin that can capture real-time data and integrate the strong coupling between SEI layer growth, anode crack propagation, and lithium plating. It can be utilized to estimate aging behavior from macroscopic full-cell level to microscopic particle level, including voltage-current profiles in dynamic aging conditions, predict the degradation behavior of Nickel-Manganese-Cobalt-Oxide (NMC) based lithium-ion batteries, and assist in electrochemical analysis. This model can improve the root cause analysis of cell aging, enabling a quantitative understanding of aging mechanism coupled effects. Three charging protocols with dynamic discharging profiles are developed to simulate real vehicle operation scenarios and used to validate the digital twin, combining operando impedance measurements, post-mortem analysis, and SEM to further prove the conclusions. The digital twin can accurately predict battery capacity fade within 0.4% MAE. The results indicate that SEI layer growth is the primary contributor to capacity degradation and resistance increase. Based on the analysis of the model, it is concluded that one of the proposed multi-step charging protocols, in comparison to a standard continuous charging protocol, can reduce the degradation of NMC-based lithium-ion batteries. This paper represents a firm physical foundation for future physics-informed machine learning development.}
}
@article{KHAN2023S127,
title = {10526 The World's First Proof of Concept of the Practical Potential in Artificially Intelligent Digital Twins in Advanced Laparoscopic Training},
journal = {Journal of Minimally Invasive Gynecology},
volume = {30},
number = {11, Supplement },
pages = {S127},
year = {2023},
note = {SI: Abstracts of the 52nd AAGL Global Congress on Minimally Invasive Gynecology},
issn = {1553-4650},
doi = {https://doi.org/10.1016/j.jmig.2023.08.404},
url = {https://www.sciencedirect.com/science/article/pii/S1553465023007355},
author = {ZR Khan},
abstract = {Study Objective
To develop the world's first digital twins of healthcare educators and trainers in advanced laparoscopic gynaecological surgery, utilising deep machine learning to produce a human-like interface which can lead tutorials and training on an online platform autonomously.
Design
Using a third generation neural network-based language prediction model a purpose coded artificial intelligence (AI) system was prompted to develop training modules for a AI-powered advanced laparoscopic gynaecological surgery training programme. The avatars for the training modules were custom built, based on the lead trainer's facial features and voice. The AI-powered modules were made part of a larger hybrid training programme with an online / webinar component, alongside live training by the same lead trainers.
Setting
The bespoke AI-generated training modules were added to an already existing advanced laparoscopic training programme for Consultants and Residents in Gynaecology.
Patients or Participants
10 Consultants and Residents in Gynaecology with an interest in laparoscopic surgery were taught by the digital twins of the lead trainers. The subject matter of the training modules was similar but the content was not the same.
Interventions
N/A.
Measurements and Main Results
Feedback was collected after the training programme with particular interest in the performance of the digital twins. The feedback was overwhelmingly positive. The digital twins have now also been purposed to carry out assessments in the form of multiple choice questions and collect trainee feedback with subjective responses.
Conclusion
For a fraction of the true cost of healthcare education, digital twins can enable remote learning, in multiple languages, allowing educators and trainers to reach a wider audience of students without the need for physical classroom space. This can be particularly important in healthcare education, where access to specialized training can be limited in certain geographic regions, not to mention the advantage of objectively tracking and analyzing every nuance of learning performance in the realm of advanced laparoscopic skills.}
}
@article{TAO2023113461,
title = {A digital twin-based fault diagnostic method for subsea control systems},
journal = {Measurement},
volume = {221},
pages = {113461},
year = {2023},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2023.113461},
url = {https://www.sciencedirect.com/science/article/pii/S0263224123010254},
author = {Haohan Tao and Peng Jia and Xiangyu Wang and Xi Chen and Liquan Wang},
keywords = {Digital twin, Fault diagnosis, Hydraulic system, Subsea control system},
abstract = {A digital twin (DT) based framework is proposed for data-driven fault diagnosis in a subsea control system (SCS). A novel modeling technique, the physics informed temporal convolution network (PITCN), is first developed by combining a traditional physics-based simulation with collected sensor signals (e.g., pressure and flowrate). The DT is then used to generate simulated signals under different operation and fault conditions, for the purpose of training the convolutional neural network (CNN) based data-driven fault diagnostic model. In addition, an online model modification technique is proposed to label the SCS real-time data used for continuously training the PITCN and CNN during the SCS production period. Experimental results showed the proposed diagnostic framework is superior to traditional CNN based diagnostic methods, as measured by diagnostic accuracy, particularly when labeled sample volumes are limited. The proposed online model modification improved diagnostic accuracy from 91.87% to 97.5% using real-time collected data.}
}
@article{ZHU2023116444,
title = {A super-real-time three-dimension computing method of digital twins in space nuclear power},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {417},
pages = {116444},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2023.116444},
url = {https://www.sciencedirect.com/science/article/pii/S0045782523005686},
author = {Enping Zhu and Tao Li and Jinbiao Xiong and Xiang Chai and Tengfei Zhang and Xiaojing Liu},
keywords = {Digital twin, GPU and multi-core CPU, Machine learning, Super-real-time, Space nuclear reactor},
abstract = {Digital twins (DTs) have attracted widespread attention in academia and industry in recent years. It can accurately reflect the physical world in real-time, enabling online monitoring, control, and prediction operations. Their foundation is super-real-time computing and high data representation capabilities. However, current DTs do not achieve 3D super-real-time computing. This study proposes a novel 3D computational method for solving fluid–solid coupling problems in a super-real-time. The method is based on a mixed solution framework that combines traditional numerical methods with deep learning operators. Specifically, the method employs multi-core CPU parallel acceleration to solve the solid equations while leveraging the computing power of GPU to solve the fluid equations. The fluid–solid coupling is achieved through information exchange between the GPU and the multi-core CPU. In addition, the proposed method introduces a new deep learning operator framework based on the DeepONET. The framework is accompanied by a database structure that facilitates model training and validation and a loss function that guides the training. The space nuclear reactor, an improved TOPAZ-II system, was selected to demonstrate its feasibility. Four non-training transient conditions were simulated to test the generalization performance. The results show that the proposed method achieves an average error between the calculated results and reference values below 2.5%, with the average error of thermodynamic parameters below 1.5%. The average deviation between system parameter peak values during the transient process and the reference value was less than 5 s. The result meets the acceptable error level and satisfies the super-real-time requirements with a time acceleration ratio of approximately 1.17, which is 60 times faster than traditional numerical methods. The results demonstrate the accuracy and efficiency of the proposed method for DT.}
}
@article{CAO2023111868,
title = {Fault detection and classification in solar based distribution systems in the presence of deep learning and social spider method},
journal = {Solar Energy},
volume = {262},
pages = {111868},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.111868},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23005017},
author = {Hanhua Cao and Huanping Zhang and Changle Gu and Yuhuai Zhou and Xiu He},
keywords = {Fault classification and detection, Generative adversarial networks (GANs), Social spider optimization algorithm, Digital twin, Solar based distribution systems},
abstract = {This research proposes an intelligent method for fault detection and classification (FDC) in solar based distribution systems using Generative Adversarial Networks (GANs) and Social Spider method. The suggested method is constructed using the combination of GANs and Social Spider method, which is a hybrid system to increase its capability for the classification purposes. The GANs model is used to detect fault signatures in the system, while the Improved Social Spider method is used to reinforce its training process. The proposed method is evaluated on the big data gathered using the digital twin of a solar based distribution system for different situations of operation. The results show that GANs can detect fault signatures with high accuracy and the Improved Social Spider method can classify the fault types with high accuracy. The proposed method compared with other existing methods and the results show that the suggested method outperforms the existing methods considering accuracy, recall, precision and speed. The proposed method can be used for FDC in solar based distribution systems, and can be developed to other distribution systems.}
}
@article{MARTINEZGUTIERREZ2023103136,
title = {Convergence of Virtual Reality and Digital Twin technologies to enhance digital operators’ training in industry 4.0},
journal = {International Journal of Human-Computer Studies},
volume = {180},
pages = {103136},
year = {2023},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2023.103136},
url = {https://www.sciencedirect.com/science/article/pii/S1071581923001453},
author = {Alberto Martínez-Gutiérrez and Javier Díez-González and Paula Verde and Hilde Perez},
keywords = {Industry 4.0, Digital twin, Virtual reality, Training},
abstract = {Industry 4.0 technologies enable the generation of added value throughout the production process. Among them, Digital Twins (DT) allow the modelization of cyber–physical systems in the virtual world and Virtual Reality (VR) allows an immersive perspective of the behavior of industrial equipment in a digitized environment. The combination of DT and VR can generate a digital platform for operators’ training where the industrial operator can perceive a more realistic environment for digital learning. In this paper, we introduce the convergence of DT and VR to enhance the digital learning process of driving an industrial mobile robot. To validate this proposal, an experimental methodology looking for measuring the transfer of skills from digital training into the real world has been set. This experiment consists of handling a mobile robot in a predefined course looking for committing the lowest number of failures in the minimum possible time. The experiment has been carried out by defining three different training methods: training with real equipment as the control group and two different experimental groups following digital training (VR and computer application-supported techniques). The abilities of their subjects have been measured in the initial and final stages of the experiment showing an improvement of 47% through real training, 38% through VR and 28% through the computer application. Results demonstrate the utility of using DT to attain significant digital learning and validate the initial hypothesis demonstrating the enhancement of digital learning through VR-supported training.}
}
@article{CAO2023116156,
title = {Flow field distribution and structural strength performance evaluation of fixed offshore wind turbine based on digital twin technology},
journal = {Ocean Engineering},
volume = {288},
pages = {116156},
year = {2023},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2023.116156},
url = {https://www.sciencedirect.com/science/article/pii/S0029801823025404},
author = {Yu Cao and Xiaobo Tang and Jie Li and Wenhua Chu and Fang Wang},
keywords = {Offshore wind turbine, Digital twin, Rapid monitoring, Flow field distribution, Structural strength},
abstract = {Due to the adverse impact of the offshore environment, the cost of on-site monitoring, operation and maintenance of offshore wind turbines is greatly increased. Here, a digital twin (DT) method based on digital model and computational fluid dynamics (CFD) simulation database is proposed, which is used to rapidly predict and synchronously display the distribution of the wake field, structural deformation and stress of fixed OWTs. First, a large number of data have been calculated by using CFD method. Second, the three-dimensional finite element model is reduced to a digital model by the proper orthogonal decomposition method, all data is stored in a multi-source heterogeneous database. Furthermore, the anisotropic inverse distance weighted interpolation and particle swarm optimization algorithm methods are used to obtain uncalculated data results and supplement database. Then the Bayesian regularization-back propagation neural network method is developed to correct the data with large errors. The results show that the learning error of the flow field and structural strength is less than 10% and 4% compared with the CFD method, respectively. This study could provide a rapid monitoring engineering reference for the safety assessment of turbine flow field distribution and structural strength.}
}
@article{CHENGULA2023100510,
title = {Improving road safety with ensemble learning: Detecting driver anomalies using vehicle inbuilt cameras},
journal = {Machine Learning with Applications},
volume = {14},
pages = {100510},
year = {2023},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2023.100510},
url = {https://www.sciencedirect.com/science/article/pii/S2666827023000634},
author = {Tumlumbe Juliana Chengula and Judith Mwakalonge and Gurcan Comert and Saidi Siuhi},
keywords = {Driver anomaly detection, Road safety, XGBoost, Learner models, Vehicle cameras},
abstract = {The adoption of Advanced Driver Assistance Systems (ADAS) has expanded dramatically in recent years, with the goal of improving road safety and driving comfort. Driver monitoring is important to ADAS since it identifies abnormalities such as sleepiness, distraction, and impairment to guarantee safe vehicle operation. Traditional methods of detecting driver anomalies rely on intrusive physiological measures, while ADAS with built-in cameras offers a non-intrusive and cost-effective option. This study investigates the application of ensemble model learning for driver anomaly detection in automobiles employing ADAS and in-vehicle cameras. Deep learning models such as ResNet50, DenseNet201, and Inception V3 were deployed as learner models to classify driving behavior. The raw dataset used in this study was in the form of videos obtained from the National Tsinghua Driver Drowsiness Detection (NTHUDD) dataset. Amongst the two ensemble models used, the eXtreme Gradient Boost (XGBoost) classifier pooled predictions from the learner models. It attained a remarkable average accuracy and precision of 99% on the validation dataset. Classes such as laugh_talk and yawning were properly and separately distinguished. The ensemble technique capitalized on the strengths of various models while mitigating their weaknesses, resulting in robust and trustworthy forecasts. The findings highlight the potential of ensemble modeling to enhance driver anomaly detection systems, providing valuable insights for improving road safety. By continually monitoring driver behavior and detecting abnormalities, ADAS can provide timely warnings and interventions to prevent accidents and save human lives.}
}
@article{ZHANG2023117507,
title = {Digital twin of wind farms via physics-informed deep learning},
journal = {Energy Conversion and Management},
volume = {293},
pages = {117507},
year = {2023},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2023.117507},
url = {https://www.sciencedirect.com/science/article/pii/S0196890423008531},
author = {Jincheng Zhang and Xiaowei Zhao},
keywords = {Digital twin, Lidar, NS equations, Physics-informed machine learning, Wind farm wake},
abstract = {The spatiotemporal flow field in a wind farm determines the wind turbines’ energy production and structural fatigue. However, it is not obtainable by the current measurement, modeling, and prediction tools in wind industry. Here we propose a novel data and knowledge fusion approach to create the first digital twin for onshore/offshore wind farm flow system, which can predict the in situ spatiotemporal wind field covering the entire wind farm. The digital twin is developed by integrating the Lidar measurements, the Navier–Stokes equations, and the turbine modeling using actuator disk method, via physics-informed neural networks. The design enables the seamless integration of Lidar measurements and turbine operating data for real-time flow characterization, and the fusion of flow physics for retrieving unmeasured wind field information. It thus addresses the limitations of existing wind prediction approaches based on supervised machine learning, which cannot achieve such prediction because the training targets are not available. Case studies of a wind farm under typical operating scenarios (i.e. a greedy case, a wake-steering case, and a partially-operating case) are carried out using high-fidelity numerical experiments, and the results show that the developed digital twin achieves very accurate mirroring of the physical wind farm, capturing detailed flow features such as wake interaction and wake meandering. The prediction error for the flow fields, on average, is just 4.7% of the value range. With the accurate flow field information predicted, the digital twin is expected to enable brand new research across wind farm lifecycle including monitoring, control, and load assessment.}
}
@article{SHI2023217,
title = {Multi-UAV-assisted computation offloading in DT-based networks: A distributed deep reinforcement learning approach},
journal = {Computer Communications},
volume = {210},
pages = {217-228},
year = {2023},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2023.07.041},
url = {https://www.sciencedirect.com/science/article/pii/S0140366423002748},
author = {Junling Shi and Chunyu Li and Yunchong Guan and Peiyu Cong and Jie Li},
keywords = {Mobile edge computing, Computation offloading, Unmanned aerial vehicle, Digital twin, Deep reinforcement learning, Federated learning},
abstract = {In the industrial Internet, Mobile Edge Computing (MEC) can provide the ability to transfer a large number of delay-sensitive and compute-intensive tasks to MEC servers, thus improving Quality of Service (QoS). Considering Unmanned Aerial Vehicles (UAVs) have the advantages of wide communication coverage and low deployment cost, UAVs have great potential to be employed as aerial base stations to provide computation resources for Intelligent Mobile Devices (IMDs). Due to the limited computation resources and energy of IMDs, we designed a multi-UAV-assisted MEC system in ground cells. To minimize the weighted sum of task completion delay and energy consumption, and ensure the QoS requirements of IMDs, we jointly consider the dynamic channel state, renewable energy utilization, UAVs trajectory, and tasks offloading ratio. To solve the non-convexity problem of complex high-dimensional states, we propose a model-free Deep Reinforcement Learning (DRL) offloading scheme based on the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm. Moreover, we adopt Federated Learning (FL) to train DRL models to enhance the robustness of the model and the security of IMDs data. Meanwhile, the real environment is modeled as Digital Twin (DT) to monitor network changes and train the local DRL model, and the central cloud server can obtain the local model in real-time to aggregate the global model. Extensive experimental numerical results show that the proposed algorithm improves the system energy efficiency and reduces task completion delay.}
}
@article{RENTERIADELTORO2023,
title = {Digitalization as an aggregate performance in the energy transition for nuclear industry},
journal = {Nuclear Engineering and Technology},
year = {2023},
issn = {1738-5733},
doi = {https://doi.org/10.1016/j.net.2023.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S1738573323005296},
author = {Florencia de los Angeles {Renteria del Toro} and Chen Hao and Akira Tokuhiro and Mario Gomez-Fernandez and Armando Gomez-Torres},
keywords = {Digitalization, New-energy transition era (NETE), Analytical network process (ANP), Nuclear power infrastructure development (NPID), Nuclear-technologies},
abstract = {The emerging technologies at the industrial level have deployed rapidly within the energy transition process innovations. The nuclear industry incorporates several technologies like Artificial Intelligence (AI), Machine Learning (ML), Digital Twins, High-Performance-Computing (HPC) and Quantum Computing (QC), among others. Factors identifications are explained to set up a regulatory framework in the digitalization era, providing new capabilities paths for nuclear technologies in the forthcoming years. The Analytical Network Process (ANP) integrates the quantitative-qualitative decision-making analysis to assess the implementation of different aspects in the digital transformation for the New-Energy Transition Era (NETE) with a Nuclear Power Infrastructure Development (NPID). 2023 Elsevier Ltd. All rights reserved.}
}
@article{SCHIRMANN2023115608,
title = {A comparison of physics-informed data-driven modeling architectures for ship motion predictions},
journal = {Ocean Engineering},
volume = {286},
pages = {115608},
year = {2023},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2023.115608},
url = {https://www.sciencedirect.com/science/article/pii/S0029801823019923},
author = {Matthew L. Schirmann and James W. Gose and Matthew D. Collette},
keywords = {Machine learning, Ship motions, Digital twin, Neural network, Gaussian process, Research vessel},
abstract = {How to select the optimal formulations for building blended physics-machine learning models for ship motions is not currently clear. This work compares and contrasts two approaches to this problem: (1) A black-box deep learning approach based on a new neural network architecture that can better handle varying wave conditions, and (2) a clear-box model based on updates to linear response amplitude operators via a Gaussian process regression. Both models are trained and evaluated on a dataset consisting of more than 15,000 30-minute-long motion observation windows from two research vessels at sea in the Atlantic and Pacific oceans. Three different hindcast weather services are used, including two models from the EU’s Copernicus system and NOAA’s WAVEWATCH III. The evaluation shows that a tradeoff exists between the formulations, with the black-box formulation offering higher accuracy and the cost of less transparency. The weather hindcast used has a small impact on the results, and the ability of both models to generalize predictions between near-sister ships is also encouraging for the practical application of these techniques.}
}
@article{MCMANUS2023110000,
title = {Digital twin-enabled domain adaptation for zero-touch UAV networks: Survey and challenges},
journal = {Computer Networks},
volume = {236},
pages = {110000},
year = {2023},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2023.110000},
url = {https://www.sciencedirect.com/science/article/pii/S1389128623004450},
author = {Maxwell McManus and Yuqing Cui and Josh (Zhaoxi) Zhang and Jiangqi Hu and Sabarish Krishna Moorthy and Nicholas Mastronarde and Elizabeth Serena Bentley and Michael Medley and Zhangyu Guan},
keywords = {UAV, Digital twin, Domain adaptation, Network softwarization, AI/ML},
abstract = {In existing wireless networks, the control programs have been designed manually and for certain predefined scenarios. This process is complicated and error-prone, and the resulting control programs are not resilient to disruptive changes. Data-driven control based on Artificial Intelligence and Machine Learning (AI/ML) has been envisioned as a key technique to automate the modeling, optimization and control of complex wireless systems. However, existing AI/ML techniques rely on sufficient well-labeled data and may suffer from slow convergence and poor generalizability. In this article, focusing on digital twin-assisted wireless unmanned aerial vehicle (UAV) systems, we provide a survey of emerging techniques that can enable fast-converging data-driven control of wireless systems with enhanced generalization capability to new environments. These include simultaneous localization and sensing (SLAM)-based sensing and network softwarization for digital twin construction, robust reinforcement learning and system identification for domain adaptation, and testing facility sharing and federation. The corresponding research opportunities are also discussed.}
}