@article{UHLEMANN2017113,
title = {The Digital Twin: Demonstrating the Potential of Real Time Data Acquisition in Production Systems},
journal = {Procedia Manufacturing},
volume = {9},
pages = {113-120},
year = {2017},
note = {7th Conference on Learning Factories, CLF 2017},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2017.04.043},
url = {https://www.sciencedirect.com/science/article/pii/S2351978917301610},
author = {Thomas H.-J. Uhlemann and Christoph Schock and Christian Lehmann and Stefan Freiberger and Rolf Steinhilper},
keywords = {Digital Twin, Industry 4.0, Process optimization},
abstract = {The acquisition of data and the development of different options in production system and factory planning requires up to 2/3rds of the total needed time resources. The digitization of production systems offers the possibility of automated data acquisition. Nevertheless, approaches concerning fully automated data acquisition systems are not widely spread among SME (small and medium sized enterprises). On the one hand, this is caused by the heterogeneous databases, on the other hand by insufficient data processing systems. Furthermore, the advantages of The Digital Twin are not sufficiently known due to the lack of competence in SME concerning matters of Industry 4.0. In order to transfer knowledge about the benefits of digitalization, the development of demonstrating platforms is crucial. This paper introduces a learning factory based concept to demonstrate the potentials and advantages of real time data acquisition and subsequent simulation based data processing. Therefore, an existing learning factory will be upgraded regarding both, multi-modal data acquisition technologies as well as a locally independent optimization environment. Thereby the requirements of SME concerning flexible, easy to use, scalable and service oriented digitization applications are met. The approach is part of a concept for the realization of a Cyber Physical Production System (CPPS) in SME that ensures the development of an image of the production with the aid of a multi-modal data acquisition.}
}
@article{MULDNER2015127,
title = {Utilizing sensor data to model students’ creativity in a digital environment},
journal = {Computers in Human Behavior},
volume = {42},
pages = {127-137},
year = {2015},
note = {Digital Creativity: New Frontier for Research and Practice},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2013.10.060},
url = {https://www.sciencedirect.com/science/article/pii/S074756321300410X},
author = {Kasia Muldner and Winslow Burleson},
keywords = {Creativity, Student modeling, Eye tracking, EEG, Skin conductance, Intelligent Tutoring Systems},
abstract = {While creativity is essential for developing students’ broad expertise in Science, Technology, Engineering, and Math (STEM) fields, many students struggle with various aspects of being creative. Digital technologies have the unique opportunity to support the creative process by (1) recognizing elements of students’ creativity, such as when creativity is lacking (modeling step), and (2) providing tailored scaffolding based on that information (intervention step). However, to date little work exists on either of these aspects. Here, we focus on the modeling step. Specifically, we explore the utility of various sensing devices, including an eye tracker, a skin conductance bracelet, and an EEG sensor, for modeling creativity during an educational activity, namely geometry proof generation. We found reliable differences in sensor features characterizing low vs. high creativity students. We then applied machine learning to build classifiers that achieved good accuracy in distinguishing these two student groups, providing evidence that sensor features are valuable for modeling creativity.}
}
@article{WESIAK201413,
title = {Iterative augmentation of a medical training simulator: Effects of affective metacognitive scaffolding},
journal = {Computers & Education},
volume = {76},
pages = {13-29},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2014.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S036013151400061X},
author = {Gudrun Wesiak and Christina M. Steiner and Adam Moore and Declan Dagger and Gordon Power and Marcel Berthold and Dietrich Albert and Owen Conlan},
keywords = {Adult learning, Evaluation of CAL systems, Simulations, Teaching/learning strategies, Metacognition},
abstract = {Experiential training simulators are gaining increasing popularity for job-related training due to their potential to engage and motivate adult learners. They are designed to provide learning experiences that are directly connected to users' work environments and support self-regulated learning. Nevertheless, learners often fail to transfer the knowledge gained in the simulated environment to real-world contexts. The EU-funded ImREAL project aimed to bridge that gap by developing a suite of intelligent services designed to enhance existing training simulators. This paper presents work that was a subset of this research project, reporting the iterative development and evaluation of a scaffolding service, which was integrated into a simulator for training medical students to perform diagnostic interviews. The study comprises three evaluation phases, comparing the pure simulator to a first version with metacognitive scaffolding and then to a final version with affective metacognitive scaffolding and enriched user modelling. The scaffolding service provides the learner with metacognitive prompts; affective elements are realized by an integrated affect reporting tool and affective prompts. Using a mixed-method approach by analysing questionnaires (N = 106) and log-data (N = 426), the effects of the services were investigated with respect to real-world relevance, self-regulated learning support, learning experience, and integration. Despite some limitations, the outcomes of this study demonstrate the usefulness of affective metacognitive scaffolding in the context of experiential training simulators; significant post-simulation increases in perceived relevance of the simulator, reflective note-taking, overall motivation, and feeling of success could be identified. Perceived usability and flow of the simulation increased, whereas overall workload and frustration decreased. However, low response rates to specific functions of the simulation point to a need to further investigate how to raise users' awareness and understanding of the provided tools, to encourage interaction with the services, and to better convey the benefits of using them. Thus, future challenges concern not so much technological developments for personalizing learning experiences, but rather new ways to change user attitudes towards an open approach to learning systems that enables them to benefit from all offered features.}
}
@article{KORDAKI201526,
title = {A Constructivist, Modeling Methodology for the Design of Educational Card Games},
journal = {Procedia - Social and Behavioral Sciences},
volume = {191},
pages = {26-30},
year = {2015},
note = {The Proceedings of 6th World Conference on educational Sciences},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.04.669},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815029365},
author = {Maria Kordaki},
keywords = {Contructivism, design, modelling, educational card games ;},
abstract = {This paper presents a specific modeling methodology for the creation of educational card games. This methodology is based on the creation of the following three models: (a) the model of the subject matter; including all aspects of the learning subject in question, (b) the learners’ model; including learners’ non scientific conceptions about the aforementioned learning subject, and (c) the learning model; consisting of an appropriate learning strategy for the learning of the subject in question through card-game play, taking into account basic social and constructivist views of learning in combination with as well as key structural characteristics of games which can contribute to players’ engagement. Based on the aforementioned methodology, the design of various types of cards is proposed.}
}
@article{CHENG201658,
title = {Understanding and enhancing personal transfer of creative learning},
journal = {Thinking Skills and Creativity},
volume = {22},
pages = {58-73},
year = {2016},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2016.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1871187116300955},
author = {Vivian M.Y. Cheng},
keywords = {Personal transfer, Creative learning, Creativity, Thematic curriculum, Higher education},
abstract = {The ‘actor-orientated transfer’ approach was adopted to examine the personal transfer of creative learning in a thematic course on toys in a higher education of Hong Kong. The personal transfers of creative learning were found to be spontaneous, far, diverse, multidirectional, highly individual and, sometimes, quite unexpected. Creativity-related attitudes, conceptions, habits and thinking strategies were commonly transferred from the initial study over to daily life, new learning and teaching, all because the learning was impressive, useful, full of surprises and easy to remember. A number of curricular, contextual and student's personal factors were identified to be either facilitating or hindering these transfers. It is concluded that significant parts of creative learning can be transferred in personal ways, if the curriculum is suitably designed and implemented to meet the needs of students in local context. A model for personal transfer of creative learning, which consisted of four core themes (i.e. context, content, impact and factor of personal transfer) and their sub-themes, was depicted. The ‘transfer in pieces’ theory was applied to explain the nature of personal transfer. Ultimately, this study helps to establish a new conception of creativity education as a type of education that values and facilitates personal transfer.}
}
@article{LIU201744,
title = {Scientific modeling with mobile devices in high school physics labs},
journal = {Computers & Education},
volume = {105},
pages = {44-56},
year = {2017},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2016.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0360131516302019},
author = {Chia-Yu Liu and Chao-Jung Wu and Wing-Kwong Wong and Yunn-Wen Lien and Tsung-Kai Chao},
keywords = {Architectures for educational technology system, Teaching/learning strategies, Improving classroom teaching, Pedagogical issues, Applications in subject areas},
abstract = {Scientific modeling is thought to help students understand the world and scientific phenomenon. Science laboratory in school should provide well-designed activities to promote students' model building skills. Thus, this study aims to propose microcomputer based labs with several data acquisition tools and a modeling tool, which can assist students to collect and visualize data in faster and fancier ways, and generate mathematical models to fit the data, thus exercising their skills of scientific modeling. Thirty-two high school students participated in the science laboratory courses within two semesters for four labs. Results showed that students' overall success rates of model building were approaching 50%; the duration of participants' modeling time decreased with the increase of the experimental labs; the benefits of doing physics labs with smartphones were confirmed by the success rates, personal preferences, and students' feedback. Regarding students' spontaneous model building behavior in the first lab, almost 90% of the participants fitted data with linear equation; most participants adjusted coefficients to fit the data, instead of changing the highest degree of equation; and different strategies were used by successful participants and the others. These results indicated that the combination of modern data acquisition tools and fitting data with a modeling tool would provide an alternative and meaningful approach to doing physics labs at high school.}
}
@article{PAIVA2016769,
title = {What do students do on-line? Modeling students' interactions to improve their learning experience},
journal = {Computers in Human Behavior},
volume = {64},
pages = {769-781},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.07.048},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216305386},
author = {Ranilson Paiva and Ig Ibert Bittencourt and Thyago Tenório and Patricia Jaques and Seiji Isotani},
keywords = {User modeling, Gamified learning environments, Interactional characteristics, Pedagogical decision-making, Data-informed decision-making},
abstract = {In this work, we present an approach to model and analyze students interactions, within a gamified on-line learning environment, in order to assist teachers and tutors (education professionals) decision-making, regarding their students learning experience. We noticed that asking students this information might not bring precise and dynamic results for all students. This way, we characterize the educational resources available in the studied environment, and collected data from students interactions with these resources. Our objective was to generate the students’ interactional profile (a model of their interactions). The information, then, is presented to teachers and tutors, who should use it to guide their pedagogical decision-making process. In this study, the types of interactions were used to personalize gamification elements named missions. We experimented the approach with two groups of users from the studied environment (MeuTutor). The data analysis showed differences in the way these groups were performing, where group B was considerably above group A. We sent the personalized missions (following our approach) to every student from group A, and waited some time for them to interact with it. In the end we checked the effect of this treatment, which, according to the results, promoted relevant improvement in group A interactions.}
}
@article{BRENNER2017198,
title = {Digital Twin as Enabler for an Innovative Digital Shopfloor Management System in the ESB Logistics Learning Factory at Reutlingen - University},
journal = {Procedia Manufacturing},
volume = {9},
pages = {198-205},
year = {2017},
note = {7th Conference on Learning Factories, CLF 2017},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2017.04.039},
url = {https://www.sciencedirect.com/science/article/pii/S2351978917301579},
author = {Beate Brenner and Vera Hummel},
keywords = {Digital twin, business ecosystem, cloud- and app-based platform, digital factory, software agents, indoor localization, sensor combinations, digital shopfloor management},
abstract = {Technologies for mapping the “digital twin” have been under development for approximately 20 years. Nowadays increasingly intelligent, individualized products encourages companies to respond innovatively to customer requirements and to handle the rising product variations quickly. An integrated engineering network, spanning across the entire value chain, is operated to intelligently connect various company divisions, and to generate a business ecosystem for products, services and communities. The conditions for the digital twin are thereby determined in which the digital world can be fed into the real, and the real world back into the digital to deal such intelligent products with rising variations. The term digital twin can be described as a digital copy of a real factory, machine, worker etc., that is created and can be independently expanded, automatically updated as well as being globally available in real time. Every real product and production site is permanently accompanied by a digital twin. First prototypes of such digital twins already exist in the ESB Logistics Learning Factory on a cloud- and app-based software that builds on a dynamic, multidimensional data and information model. A standardized language of the robot control systems via software agents and positioning systems has to be integrated. The aspect of the continuity of the real factory in the digital factory as an economical means of ensuring continuous actuality of digital models looks as the basis of changeability. For the indoor localization sensor combinations that in addition to the hardware already contain the software required for the sensor data fusion should be used. Processing systems, scenario-live-simulations and digital shop floor management results in a mandatory procedural combination. Essential to the digital twin is the ability to consistently provide all subsystems with the latest state of all required information, methods and algorithms.}
}
@article{ZHAO2015159,
title = {A local learning algorithm for random weights networks},
journal = {Knowledge-Based Systems},
volume = {74},
pages = {159-166},
year = {2015},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2014.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S0950705114004067},
author = {Jianwei Zhao and Zhihui Wang and Feilong Cao and Dianhui Wang},
keywords = {Random weights networks, Local learning algorithm, Regularization model, Moving least squares method, Feedforward neural networks},
abstract = {Robust modelling is significant to deal with complex systems with uncertainties. This paper aims to develop a novel learning algorithm for training regularized local random weights networks (RWNs). The learner model, terms as RL-RWN, is built on regularized moving least squares method and generalizes the solution obtained from the standard least square technique. Simulations are carried out using two benchmark datasets, including Auto-MPG data and surface reconstruction data. Results demonstrate that our proposed RL-RWN outperforms the original RWN and radial basis function networks.}
}
@article{ARAR2016106,
title = {Deriving thresholds of software metrics to predict faults on open source software: Replicated case studies},
journal = {Expert Systems with Applications},
volume = {61},
pages = {106-121},
year = {2016},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2016.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0957417416302366},
author = {Ömer Faruk Arar and Kürşat Ayan},
keywords = {Machine learning, Software quality metrics, Threshold, Software fault prediction, Logistic regression, Bender method},
abstract = {Object-oriented metrics aim to exhibit the quality of source code and give insight to it quantitatively. Each metric assesses the code from a different aspect. There is a relationship between the quality level and the risk level of source code. The objective of this paper is to empirically examine whether or not there are effective threshold values for source code metrics. It is targeted to derive generalized thresholds that can be used in different software systems. The relationship between metric thresholds and fault-proneness was investigated empirically in this study by using ten open-source software systems. Three types of fault-proneness were defined for the software modules: non-fault-prone, more-than-one-fault-prone, and more-than-three-fault-prone. Two independent case studies were carried out to derive two different threshold values. A single set was created by merging ten datasets and was used as training data by the model. The learner model was created using logistic regression and the Bender method. Results revealed that some metrics have threshold effects. Seven metrics gave satisfactory results in the first case study. In the second case study, eleven metrics gave satisfactory results. This study makes contributions primarily for use by software developers and testers. Software developers can see classes or modules that require revising; this, consequently, contributes to an increment in quality for these modules and a decrement in their risk level. Testers can identify modules that need more testing effort and can prioritize modules according to their risk levels.}
}
@article{SHAHBAZI201739,
title = {Generation of rhythmic hand movements in humanoid robots by a neural imitation learning architecture},
journal = {Biologically Inspired Cognitive Architectures},
volume = {19},
pages = {39-48},
year = {2017},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2016.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X16300354},
author = {Hamed Shahbazi and Reyhaneh Parandeh and Kamal Jamshidi},
keywords = {Imitation learning, Neural networks, Central pattern generator},
abstract = {This paper presents a two layer system for imitation learning in humanoid robots. The first layer of this system records complicated and rhythmic movement of the trainer using a motion capture device. It solves an inverse kinematic problem with the help of an adaptive Neuro-Fuzzy Inference system. Then it can achieve angles records of any joints involved in the desired motion. The trajectory is given as input to the systems second layer. The layer deals with extracting optimal parameters of the trajectories obtained from the first layer using a network of oscillator neurons and Particle Swarm Optimization algorithm. This system is capable to obtain any complex motion and rhythmic trajectory via first layer and learns rhythmic trajectories in the second layer then converge towards all these movements. Moreover, this two layer system is able to provide various features of a learner model, for instance resistance against perturbations, modulation of trajectories amplitude and frequency. The simulation results of the learning system is performed in the robot simulator WEBOTS linked with MATLAB software. Practical implementation on an NAO robot demonstrate that the robot has learned desired motion with high accuracy. These results show that proposed system in this paper produces high convergence rate and low test error.}
}
@article{KAR2014243,
title = {Applications of neuro fuzzy systems: A brief review and future outline},
journal = {Applied Soft Computing},
volume = {15},
pages = {243-259},
year = {2014},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2013.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S1568494613003487},
author = {Samarjit Kar and Sujit Das and Pijush Kanti Ghosh},
keywords = {Neuro fuzzy system, Neuro fuzzy system applications, Methodologies, Literature review},
abstract = {This paper surveys neuro fuzzy systems (NFS) development using classification and literature review of articles for the last decade (2002–2012) to explore how various NFS methodologies have been developed during this period. Based on the selected journals of different NFS applications and different online database of NFS, this article surveys and classifies NFS applications into ten different categories such as student modeling system, medical system, economic system, electrical and electronics system, traffic control, image processing and feature extraction, manufacturing and system modeling, forecasting and predictions, NFS enhancements and social sciences. For each of these categories, this paper mentions a brief future outline. This review study indicates mainly three types of future development directions for NFS methodologies, domains and article types: (1) NFS methodologies are tending to be developed toward expertise orientation. (2) It is suggested that different social science methodologies could be implemented using NFS as another kind of expert methodology. (3) The ability to continually change and learning capability is the driving power of NFS methodologies and will be the key for future intelligent applications.}
}
@article{WAGNER20142023,
title = {A model for profile management applied to ubiquitous learning environments},
journal = {Expert Systems with Applications},
volume = {41},
number = {4, Part 2},
pages = {2023-2034},
year = {2014},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2013.08.098},
url = {https://www.sciencedirect.com/science/article/pii/S0957417413007203},
author = {André Wagner and Jorge Luis Victória Barbosa and Débora Nice Ferrari Barbosa},
keywords = {Profile management, Ubiquitous computing, User modeling, Trails, Profile inference, Entity-adapted interaction},
abstract = {Ubiquitous systems have the challenge of implicitly collect relevant information about entities, and use this information to understand and predict their behavior. This allows the applications to adapt themselves to the entities, thus avoiding to overflow them with inquires and information. The analysis of trails, the context-aware history of actions, can further improve the relevance of information. This paper proposes a model that allows applications to register entities’ actions in trails and infer profile information from these trails, using semantic interoperability and thus allowing different applications to share information and infer a unified profile. An application was developed and integrated with two different softwares in a scenario of ubiquitous learning, where the student profiles were dynamically updated, allowing them to better adapt to the environment. The contributions of this model are the use of trails for extracting profiles and the capability of managing dynamic inference rules for profile generation.}
}
@article{MCCUTCHEON2017605,
title = {Interprofessional objective structured teaching exercise (iOSTE) to train preceptors},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {9},
number = {4},
pages = {605-615},
year = {2017},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2017.03.023},
url = {https://www.sciencedirect.com/science/article/pii/S1877129716300806},
author = {Livia R.M. McCutcheon and Kathryn Whitcomb and Craig D. Cox and Mary S. Klein and Hansel Burley and Terrance Youngblood and Cynthia Raehl},
keywords = {Preceptor development, Objective structured teaching exercise, Objective structured teaching examination, Simulation, Interprofessional education, Debriefing},
abstract = {Background and purpose
Interprofessional education (IPE) is important in the education of all health care students, yet limited IPE training has been provided to preceptors who train these students in the clinical setting. Simulation using the standardized student model has been used to train health care preceptors in medicine. To our knowledge, there are no reports utilizing interprofessional objective structured teaching exercises (iOSTE) to train pharmacy preceptors. The primary objectives of this pilot study were to evaluate the effects of iOSTE on the pharmacy preceptors’ perceived importance of the Interprofessional Education Collaborative (IPEC) core competencies and confidence in precepting interprofessional students. Additionally, data were collected regarding pharmacy preceptors' prior experiences in simulation and debriefing.
Educational activity and setting
Preceptors (n=23) participated in an iOSTE and debriefed with trained standardized nursing and pharmacy students caring for a trained standardized asthma patient.
Findings
Pre- versus post-iOSTE survey data showed statistically significant improvements in all self-confidence related items, including the following abilities: precept students from different disciplines (p=0.004), facilitate a simulation activity (p=0.001), conduct the debriefing process (p<0.001), and discuss with students the IPE core competencies (p=0.001). Additionally, responses to post-iOSTE survey questions assessing the learning activity showed high ratings (median=5, interquartile range=4 to 5). Pharmacy preceptors increased their teaching ability and confidence level in communicating with students from other health care professions.
Summary
These findings indicate that iOSTE is a useful and well-received method for preceptor development.}
}
@article{WANG2017210,
title = {Robust stochastic configuration networks with kernel density estimation for uncertain data regression},
journal = {Information Sciences},
volume = {412-413},
pages = {210-222},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.05.047},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517307636},
author = {Dianhui Wang and Ming Li},
keywords = {Stochastic configuration networks, Robust data regression, Randomized algorithms, Kernel density estimation, Alternating optimization techniques},
abstract = {Neural networks have been widely used as predictive models to fit data distribution, and they could be implemented through learning a collection of samples. In many applications, however, the given dataset may contain noisy samples or outliers which may result in a poor learner model in terms of generalization. This paper contributes to a development of robust stochastic configuration networks (RSCNs) for resolving uncertain data regression problems. RSCNs are built on original stochastic configuration networks with weighted least squares method for evaluating the output weights, and the input weights and biases are incrementally and randomly generated by satisfying with a set of inequality constrains. The kernel density estimation (KDE) method is employed to set the penalty weights for each training samples, so that some negative impacts, caused by noisy data or outliers, on the resulting learner model can be reduced. The alternating optimization technique is applied for updating a RSCN model with improved penalty weights computed from the kernel density estimation function. Performance evaluation is carried out by a function approximation, four benchmark datasets and a case study on engineering application. Comparisons to other robust randomised neural modelling techniques, including the probabilistic robust learning algorithm for neural networks with random weights and improved RVFL networks, indicate that the proposed RSCNs with KDE perform favourably and demonstrate good potential for real-world applications.}
}
@article{SADOWSKI201810,
title = {Pull-off adhesion prediction of variable thick overlay to the substrate},
journal = {Automation in Construction},
volume = {85},
pages = {10-23},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2017.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517308816},
author = {Łukasz Sadowski and Jerzy Hoła and Sławomir Czarnecki and Dianhui Wang},
keywords = {Layered concrete elements, Variable thickness, Interlayer bond, Pull-off adhesion, Non-destructive testing, Artificial intelligence},
abstract = {Non-destructive identification of the pull-off adhesion of a concrete substrate to an overlay mortar with variable thickness using artificial neural networks (ANNs) is studied in this paper. Selected ANNs with various training algorithms were tested on the basis of the parameter which describes the thickness of the overlay and also the parameters specified experimentally using non-destructive testing (NDT) methods. Real world data collected from experiments of pull-off adhesion were used for building our learner models. The tests were carried out in the same place where tests using NDT methods were performed. Three variant analyses of the possibility of such identification were conducted. The variance was calculated for these testing methods and parameters obtained with their usage, without considering the parameter that describes the thickness of the overlay in this work.}
}
@article{PENAAYALA2014131,
title = {Activity theory as a framework for building adaptive e-learning systems: A case to provide empirical evidence},
journal = {Computers in Human Behavior},
volume = {30},
pages = {131-145},
year = {2014},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2013.07.057},
url = {https://www.sciencedirect.com/science/article/pii/S0747563213002963},
author = {Alejandro Peña-Ayala and Humberto Sossa and Ignacio Méndez},
keywords = {Activity theory, Adaptive e-learning systems, Proactive student model, Anticipation principle, Teaching–learning experience},
abstract = {We apply activity theory (AT) to design adaptive e-learning systems (AeLS). AT is a framework to study human’s behavior at learning; whereas, AeLS enhance students’ apprenticeship by the personalization of teaching–learning experiences. AeLS depict users’ traits and predicts learning outcomes. The approach was successfully tested: Experimental group took lectures chosen by the anticipation AT principle; whilst, control group received randomly selected lectures. Learning achieved by experimental group reveals a correlation quite significant and high positive; but, for control group the correlation it is not significant and medium positive. We conclude: AT is a useful framework to design AeLS and provide student-centered education.}
}
@article{ORTIGOSA2014527,
title = {Sentiment analysis in Facebook and its application to e-learning},
journal = {Computers in Human Behavior},
volume = {31},
pages = {527-541},
year = {2014},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2013.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0747563213001751},
author = {Alvaro Ortigosa and José M. Martín and Rosa M. Carro},
keywords = {Sentiment analysis, Social networks, User modeling, Adaptive e-learning},
abstract = {This paper presents a new method for sentiment analysis in Facebook that, starting from messages written by users, supports: (i) to extract information about the users’ sentiment polarity (positive, neutral or negative), as transmitted in the messages they write; and (ii) to model the users’ usual sentiment polarity and to detect significant emotional changes. We have implemented this method in SentBuk, a Facebook application also presented in this paper. SentBuk retrieves messages written by users in Facebook and classifies them according to their polarity, showing the results to the users through an interactive interface. It also supports emotional change detection, friend’s emotion finding, user classification according to their messages, and statistics, among others. The classification method implemented in SentBuk follows a hybrid approach: it combines lexical-based and machine-learning techniques. The results obtained through this approach show that it is feasible to perform sentiment analysis in Facebook with high accuracy (83.27%). In the context of e-learning, it is very useful to have information about the users’ sentiments available. On one hand, this information can be used by adaptive e-learning systems to support personalized learning, by considering the user’s emotional state when recommending him/her the most suitable activities to be tackled at each time. On the other hand, the students’ sentiments towards a course can serve as feedback for teachers, especially in the case of online learning, where face-to-face contact is less frequent. The usefulness of this work in the context of e-learning, both for teachers and for adaptive systems, is described too.}
}
@article{LABIB2017433,
title = {On the way to learning style models integration: a Learner's Characteristics Ontology},
journal = {Computers in Human Behavior},
volume = {73},
pages = {433-445},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.03.054},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217302133},
author = {A. Ezzat Labib and José H. Canós and M. Carmen Penadés},
keywords = {Learning style models, Ontology, E-learning, Adaptive learning, Personalized learning, Learning characteristics},
abstract = {On the way to increasing customization in e-learning systems, the learner model is the main source of variability. Such a model includes a number of psychological characteristics and study preferences that describe the learner's personality traits related to learning. During the last decades, the design methods and tools for e-learning have been designed assuming specific learner models. Therefore, in the search for a learning environment suitable for as many learner models as possible, we need tools to explore -and exploit- such models. In general, the learner's characteristics can be linked to the so-called learner's learning style (which is a part of the learner model) to provide the instructor with extensive knowledge about the learner's characterization in perceiving and processing information. Numerous learning styles have been proposed in the last decades, in some cases with overlapping characteristics with the same or different names. Thus, the heterogeneity of the learning style space makes it difficult to handle customization effectively. In this paper, we introduce a Learner's Characteristics Ontology based on creating interconnections between the different learning style model dimensions and learning styles with the relevant learner's characteristics, that: (1) helps instructors to improve and personalize the learning content; (2) can recommend learning materials to learners according to their learning characteristics and preferences; (3) can provide both instructors and learners with extensive knowledge about how they can improve their teaching and learning abilities; and (4) can improve communications and interaction between humans and computers by specifying the semantics of the learning style models' characteristics.}
}
@article{CLEMENTE2014508,
title = {Applying a student modeling with non-monotonic diagnosis to Intelligent Virtual Environment for Training/Instruction},
journal = {Expert Systems with Applications},
volume = {41},
number = {2},
pages = {508-520},
year = {2014},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2013.07.077},
url = {https://www.sciencedirect.com/science/article/pii/S0957417413005642},
author = {Julia Clemente and Jaime Ramírez and Angélica {de Antonio}},
keywords = {Intelligent Tutoring System, Student model, Pedagogic diagnosis},
abstract = {We present a student modeling approach that has been designed to be part of an Intelligent Virtual Environment for Training and/or Instruction (IVET). In order to provide the proper tutoring to a student, an IVET needs to keep and update dynamically a student model taking into account the student’s behaviour in the Virtual Environment. For that purpose, the proposed student model employs a student ontology, a pedagogic diagnosis module and a Conflict Solver module. The goal of the pedagogic diagnosis module is to infer which learning objectives have been acquired or not by the student. Nevertheless, the diagnosis process can be complicated by the fact that while learning the student will not only acquire new knowledge, but he/she may also forget some previously acquired knowledge, or he/she may have some oversights that could mislead the tutor about the true state of the student’s knowledge. All of these situations will lead to contradictions in the student model that must be solved so that the diagnosis can continue. Thus, our approach consists in applying diagnosis rules until a contradiction arises. At that moment, a conflict solver module is responsible of classifying and solving the contradiction. Next, the student ontology is updated according to the resolution adopted by the Conflict Solver and the diagnosis can continue. This paper mainly focuses on the design of the proper mechanisms of the student model to deal with the non monotonic nature of the pedagogic diagnosis.}
}
@article{LI201567,
title = {Integrating representation learning and skill learning in a human-like intelligent agent},
journal = {Artificial Intelligence},
volume = {219},
pages = {67-91},
year = {2015},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2014.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0004370214001349},
author = {Nan Li and Noboru Matsuda and William W. Cohen and Kenneth R. Koedinger},
keywords = {Agent learning, Representation learning, Student modeling},
abstract = {Building an intelligent agent that simulates human learning of math and science could potentially benefit both cognitive science, by contributing to the understanding of human learning, and artificial intelligence, by advancing the goal of creating human-level intelligence. However, constructing such a learning agent currently requires manual encoding of prior domain knowledge; in addition to being a poor model of human acquisition of prior knowledge, manual knowledge-encoding is both time-consuming and error-prone. Previous research has shown that one of the key factors that differentiates experts and novices is their different representations of knowledge. Experts view the world in terms of deep functional features, while novices view it in terms of shallow perceptual features. Moreover, since the performance of learning algorithms is sensitive to representation, the deep features are also important in achieving effective machine learning. In this paper, we present an efficient algorithm that acquires representation knowledge in the form of “deep features”, and demonstrate its effectiveness in the domain of algebra as well as synthetic domains. We integrate this algorithm into a machine-learning agent, SimStudent, which learns procedural knowledge by observing a tutor solve sample problems, and by getting feedback while actively solving problems on its own. We show that learning “deep features” reduces the requirements for knowledge engineering. Moreover, we propose an approach that automatically discovers student models using the extended SimStudent. By fitting the discovered model to real student learning curve data, we show that it is a better student model than human-generated models, and demonstrate how the discovered model may be used to improve a tutoring system's instructional strategy.}
}
@article{SALMERONMAJADAS2014691,
title = {An Evaluation of Mouse and Keyboard Interaction Indicators towards Non-intrusive and Low Cost Affective Modeling in an Educational Context},
journal = {Procedia Computer Science},
volume = {35},
pages = {691-700},
year = {2014},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.08.151},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914011168},
author = {Sergio Salmeron-Majadas and Olga C. Santos and Jesus G. Boticario},
keywords = {Affective Computing, Affective States, User Modeling, Human-Computer Interaction, Keyboard, Mouse.},
abstract = {In this paper we propose a series of indicators, which derive from user's interactions with mouse and keyboard. The goal is to evaluate their use in identifying affective states and behavior changes in an e-learning platform by means of non-intrusive and low cost methods. The approach we have followed study user's interactions regardless of the task being performed and its presentation, aiming at finding a solution applicable in any domain. In particular, mouse movements and clicks, as well as keystrokes were recorded during a math problem solving activity where users involved in the experiment had not only to score their degree of valence (i.e., pleasure versus displeasure) and arousal (i.e., high activation versus low activation) of their affective states after each problem by using the Self-Assessment-Manikin scale, but also type a description of their own feelings. By using that affective labeling, we evaluated the information provided by these different indicators processed from the original user's interactions logs. In total, we computed 42 keyboard indicators and 96 mouse indicators.}
}
@article{CUI2016505,
title = {High dimensional data regression using Lasso model and neural networks with random weights},
journal = {Information Sciences},
volume = {372},
pages = {505-517},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.08.060},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516306314},
author = {Caihao Cui and Dianhui Wang},
keywords = {High dimensional data regression, Lasso model, Ensemble features, Neural networks with random weights, NMR data},
abstract = {This paper aims to develop a framework for high dimensional data regression, where the model interpretation and prediction accuracy are regularized. Taking application background into account, we supposed that the collected samples for building learner models are expensive and limited. Our technical contributions include the generation of ensemble features (EF) using Lasso models with some selective regularizing factors estimated via a cross-validation procedure; and predictive model building using neural networks with random weights, where the weights and biases of the hidden nodes are assigned randomly in a specific interval, and the output weights are evaluated analytically by a regularized least square method. Experiments with comparisons on estimating protein content of milk from its NMR spectrum are carried out by a data set with 31,570 dimensions (spectrum size) and 120 samples. Results demonstrate that our proposed solution for data regression problems with small samples and high dimensionality is promising, and the learning system performs robustly with respect to a key parameter setting in the ensemble feature generation.}
}
@article{CAO2016546,
title = {An iterative learning algorithm for feedforward neural networks with random weights},
journal = {Information Sciences},
volume = {328},
pages = {546-557},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2015.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0020025515006568},
author = {Feilong Cao and Dianhui Wang and Houying Zhu and Yuguang Wang},
keywords = {Neural networks with random weights, Learning algorithm, Stability, Convergence},
abstract = {Feedforward neural networks with random weights (FNNRWs), as random basis function approximators, have received considerable attention due to their potential applications in dealing with large scale datasets. Special characteristics of such a learner model come from weights specification, that is, the input weights and biases are randomly assigned and the output weights can be analytically evaluated by a Moore–Penrose generalized inverse of the hidden output matrix. When the size of data samples becomes very large, such a learning scheme is infeasible for problem solving. This paper aims to develop an iterative solution for training FNNRWs with large scale datasets, where a regularization model is employed to potentially produce a learner model with improved generalization capability. Theoretical results on the convergence and stability of the proposed learning algorithm are established. Experiments on some UCI benchmark datasets and a face recognition dataset are carried out, and the results and comparisons indicate the applicability and effectiveness of our proposed learning algorithm for dealing with large scale datasets.}
}
@article{RUIPEREZVALIENTE2015139,
title = {ALAS-KA: A learning analytics extension for better understanding the learning process in the Khan Academy platform},
journal = {Computers in Human Behavior},
volume = {47},
pages = {139-148},
year = {2015},
note = {Learning Analytics, Educational Data Mining and data-driven Educational Decision Making},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2014.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0747563214003689},
author = {José A. Ruipérez-Valiente and Pedro J. Muñoz-Merino and Derick Leony and Carlos {Delgado Kloos}},
keywords = {Learning analytics, Architectures, Decision making, Visualizations, Data processing},
abstract = {The Khan Academy platform enables powerful on-line courses in which students can watch videos, solve exercises, or earn badges. This platform provides an advanced learning analytics module with useful visualizations. Nevertheless, it can be improved. In this paper, we describe ALAS-KA, which provides an extension of the learning analytics support for the Khan Academy platform. We herein present an overview of the architecture of ALAS-KA. In addition, we report the different types of visualizations and information provided by ALAS-KA, which have not been available previously in the Khan Academy platform. ALAS-KA includes new visualizations for the entire class and also for individual students. Individual visualizations can be used to check on the learning styles of students based on all the indicators available. ALAS-KA visualizations help teachers and students to make decisions in the learning process. The paper presents some guidelines and examples to help teachers make these decisions based on data from undergraduate courses, where ALAS-KA was installed. These courses (physics, chemistry, and mathematics) for freshmen were developed at Universidad Carlos III de Madrid (UC3M) and were taken by more than 300 students.}
}
@incollection{KALZ201593,
title = {Lifelong Learning and Its Support with New Technologies},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {93-99},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.92006-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868920063},
author = {Marco Kalz},
keywords = {Contextualized learning, Learning analytics, Learning networks, Lifelong learning, Mobile learning, Open educational practices, Open educational resources, Open learner models, Technology-enhanced learning},
abstract = {This article provides an overview of the use of new technologies for lifelong learning. While in the past learning technologies were mostly provided by educational institutions to support a specific lifetime or shorter learning episodes, nowadays more personal technologies are used for lifelong learning to support self-organized learning. Four important developments are introduced in this article, namely, open learner models and learning analytics, learning networks and networked learning, open educational resources and practices, and last but not least, mobile and contextualized learning. The state of the art in these research fields is summarized and the future potential and requirements for lifelong learning are highlighted.}
}
@article{KORDAKI20141631,
title = {On the Design of Educational Digital Stories: The Ed-W Model},
journal = {Procedia - Social and Behavioral Sciences},
volume = {116},
pages = {1631-1635},
year = {2014},
note = {5th World Conference on Educational Sciences},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.01.447},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814004649},
author = {Maria Kordaki},
keywords = {Constructivism, storyboarding, modelling, educational digital stories},
abstract = {This paper focuses on the presentation of an educational, modeling methodology (the Ed-W methodology) that is appropriate for the design of storyboards for educational digital stories. This methodology is based on the creation of the following three models:(a) the model of the subject matter; including all aspects of the learning subject in question, (b) the learners’ model; including learners’ non scientific conceptions about the aforementioned learning subject, and (c) the Ed-W learning model; consisting of a 5-step digital story boarding strategy for the learning of the subject in question, while at the same time acknowledging the students’ non scientific conceptions. The aforementioned 5 steps are: (a) the hero faces a problematic situation where she/he needs to use the knowledge of the subject matter in question, (b) the situation is worsened, due to actions which are based on the hero's non scientific conceptions described in the learners’ model, (c) the situation is improved due to external, uncontrollable factors, (d) the situation becomes terrible because the hero coninues to act in the previously mentioned way, and (e) the hero is forced to reflect on her/his thoughts and practices, and makes appropriate corrections. Then, all problems are finally resolved. To illustrate the aforementioned design methodology, an example of the design of a concrete digital story will be also demonstrated.}
}
@article{WANG201755,
title = {Stochastic configuration networks ensemble with heterogeneous features for large-scale data analytics},
journal = {Information Sciences},
volume = {417},
pages = {55-71},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516319739},
author = {Dianhui Wang and Caihao Cui},
keywords = {Stochastic configuration networks, Large-scale data analytics, Heterogeneous features, Ensemble learning, Negative correlation learning},
abstract = {This paper presents a fast decorrelated neuro-ensemble with heterogeneous features for large-scale data analytics, where stochastic configuration networks (SCNs) are employed as base learner models and the well-known negative correlation learning (NCL) strategy is adopted to evaluate the output weights. By feeding a large number of samples into the SCN base models, we obtain a huge sized linear equation system which is difficult to be solved by means of computing a pseudo-inverse used in the least squares method. Based on the group of heterogeneous features, the block Jacobi and Gauss–Seidel methods are employed to iteratively evaluate the output weights, and a convergence analysis is given with a demonstration on the uniqueness of these iterative solutions. Experiments with comparisons on two large-scale datasets are carried out, and the system robustness with respect to the regularizing factor used in NCL is given. Results indicate that the proposed ensemble learning techniques have good potential for resolving large-scale data modelling problems.}
}
@article{LUNA20151387,
title = {An ontology-based approach for representing the interaction process between user profile and its context for collaborative learning environments},
journal = {Computers in Human Behavior},
volume = {51},
pages = {1387-1394},
year = {2015},
note = {Computing for Human Learning, Behaviour and Collaboration in the Social and Mobile Networks Era},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2014.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0747563214005275},
author = {Vladimir Luna and Rolando Quintero and Miguel Torres and Marco Moreno-Ibarra and Giovanni Guzmán and Imelda Escamilla},
keywords = {Collaborative learning, User profile ontology, Context ontology, Interaction process},
abstract = {Recent researches about the personalized content generation have focused their efforts on two main topics: the first topic is the user model definition, i.e. the dimensions to be taken into account to represent the user, and the second topic is about the techniques used by recommender systems to provide recommendations according to the user requirements, such as adaptive approaches for context-aware systems, collaborative learning, and recommender systems for mobile environments. In this work, an approach based on ontologies to represent the interaction process between user profile and its context for collaborative learning is presented. We also analyzed the role assignments, permissions, restrictions and the definition of rules that are applied to the user, particularly in the collaborative learning context where the subject is involved. A case study related to the context of a school as well as the defined roles by the occupations in the context of locations is proposed.}
}
@article{CHOU2015215,
title = {Negotiation based adaptive learning sequences: Combining adaptivity and adaptability},
journal = {Computers & Education},
volume = {88},
pages = {215-226},
year = {2015},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2015.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S036013151500127X},
author = {Chih-Yueh Chou and K. Robert Lai and Po-Yao Chao and Chung Hsien Lan and Tsung-Hsin Chen},
keywords = {Architectures for educational technology system, Evaluation of CAL systems, Intelligent tutoring systems, Interactive learning environments},
abstract = {This study proposes a negotiation-based approach to combine the notion of adaptivity (system-controlled adaptation) and adaptability (user-controlled adaptation) for an adaptive learning system. The system suggests adaptations and the student also submits his/her adaptation preference. When the student preference opposes the system suggestion, the student then negotiates with the system to reach an agreement of adaptation. A negotiation-based adaptive learning system (NALS) is implemented to support the generation of personalized adaptive learning sequences by system negotiations with students regarding assessments of learning performance (i.e. negotiated open student model) of the current content and choices of the next learning content (i.e. negotiation of adaptation). Students require two metacognitions in deciding adaptive learning sequences: self-assessment for evaluating their understanding of the current content and regulation for choosing appropriate learning content. Negotiated open student model are used for assist student self-assessment and negotiation of adaptation are used for assist student regulation of content choices. An experiment was conducted to compare a system-controlled adaptive learning system (SALS, adaptivity), a user-controlled adaptive learning system (UALS, adaptability), and a NALS. The results revealed that NALS promoted better metacognitions in student calibration (i.e. self-assessment) accuracy and learning content choices (i.e. regulation). Preliminary evidences also showed that NALS promoted better student performance in a delay test. The results further suggested that students with poor calibration accuracy and inappropriate content choices were not suitable to use UALS and were suitable to use SALS. The NALS can also be used for training students to make appropriate adaptation for learning.}
}
@article{SYKES2014625,
title = {A Cloud-based Interaction Management System Architecture for Mobile Devices},
journal = {Procedia Computer Science},
volume = {34},
pages = {625-632},
year = {2014},
note = {The 9th International Conference on Future Networks and Communications (FNC'14)/The 11th International Conference on Mobile Systems and Pervasive Computing (MobiSPC'14)/Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.07.086},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914009417},
author = {Edward R. Sykes},
keywords = {Human Computer Interaction, mobile devices, user modeling, intelligent agents, machine learning.},
abstract = {The number of interruptions people experience on a daily basis has grown considerably over the last decade and this growth has not shown any signs of subsiding. In fact, with the exponential growth of mobile computing, interruptions are permeating the user experience. Systems must be developed to manage interruptions by reasoning about ideal timings of interactions and determining appropriate notification formats. In this work, an architecture for a cloud-based interruption management system for mobile device users is presented. The system draws from rich contextual information from the mobile device (i.e., user, task and environment dimensions) and real-time observations of the user's activities and then reasons about ideal times to interact with the user. The reasoning component (interruption algorithm) is situated in the cloud and implemented using a novel machine learning technique (an Adaptive Neuro Fuzzy Inference System). This research addresses the complex problem of determining the precise time to interact with a mobile device user and in so doing aims to reduce the negative aspects of interruptions. This paper also presents a new interruption taxonomy built on an existing framework, and a report on the current prototype developed.}
}
@article{OZYURT2015349,
title = {Learning style based individualized adaptive e-learning environments: Content analysis of the articles published from 2005 to 2014},
journal = {Computers in Human Behavior},
volume = {52},
pages = {349-358},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215004604},
author = {Özcan Özyurt and Hacer Özyurt},
keywords = {Adaptive educational hypermedia, Individualized e-learning, Learning style, Content analysis},
abstract = {The studies on creating learning environments based on differences in learning styles have gained importance in recent years. Learning styles are one of the most important parameters in determining individual differences. Accordingly, traditional web-based learning environments have been replaced by individualized adaptive e-learning environments on the basis of learning styles which are more innovative. This study deals with the content analysis of the recent studies on Adaptive Educational Hypermedia (AEH) based on learning styles. 69 articles published from 2005 to 2014 were obtained through a comprehensive and detailed review. Afterwards, these studies were subjected to document analysis. The studies were categorized under the titles of purpose, nature, method, characteristics of examinees, level, data collection tool, learner modelling, learning styles, subject, and findings. Some of the studies offered a framework or proposed a model for AEH while others focused on the influence of AEH on academic achievement and learning outputs as well as learning satisfaction. This study examines the existing tendencies and gaps in the literature and discusses the potential research topics.}
}
@article{SHAHBAZI201694,
title = {Implementation of Imitation Learning using Natural Learner Central Pattern Generator Neural Networks},
journal = {Neural Networks},
volume = {83},
pages = {94-108},
year = {2016},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2016.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608016300983},
author = {Hamed Shahbazi and Reyhaneh Parandeh and Kamal Jamshidi},
keywords = {Imitation learning, Neural networks, Oscillatory neurons, Central pattern generator, Natural policy gradient},
abstract = {In this paper a new design of neural networks is introduced, which is able to generate oscillatory patterns. The fundamental building block of the neural network is O-neurons that can generate an oscillation in its transfer functions. Since the natural policy gradient learning has been used in training a central pattern generator paradigm, it is called Natural Learner CPG Neural Networks (NLCPGNN). O-neurons are connected and coupled to each other in order to shape a network and their unknown parameters are found by a natural policy gradient learning algorithm. The main contribution of this paper is design of this learning algorithm which is able to simultaneously search for the weights and topology of the network. This system is capable to obtain any complex motion and rhythmic trajectory via first layer and learn rhythmic trajectories in the second layer and converge towards all these movements. Moreover this two layers system is able to provide various features of a learner model for instance resistance against perturbations, modulation of trajectories amplitude and frequency. Simulation of the learning system in the robot simulator (WEBOTS) that is linked with MATLAB software has been done. Implementation on a real NAO robot demonstrates that the robot has learned desired motion with high accuracy. These results show proposed system produces high convergence rate and low test errors.}
}
@article{PAPAMITSIOU2017423,
title = {Exhibiting achievement behavior during computer-based testing: What temporal trace data and personality traits tell us?},
journal = {Computers in Human Behavior},
volume = {75},
pages = {423-438},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.05.036},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217303576},
author = {Zacharoula Papamitsiou and Anastasios A. Economides},
keywords = {Assessment analytics, BFI, Computer-based testing, Personality traits, Student behavior modelling, Supervised classification},
abstract = {Personalizing computer-based testing services to examinees can be improved by considering their behavioral models. This study aims to contribute towards deeper understanding the examinee’s time-spent and achievement behavior during testing according to the five personality traits by exploiting assessment analytics. Further, it aims to investigate assessment analytics appropriateness for classifying students and generating enhanced student models to guide personalization of testing services. In this study, the LAERS assessment environment and the Big Five Inventory were used to track the response times of 112 undergraduate students and to extract their personality traits respectively. Partial Least Squares was used to detect fundamental relationships between the collected data, and Supervised Learning Algorithms were used to classify students. Results indicate a positive effect of extraversion and agreeableness on goal-expectancy, a positive effect of conscientiousness on both goal-expectancy and level of certainty, and a negative effect of neuroticism and openness on level of certainty. Further, extraversion, agreeableness and conscientiousness have statistically significant indirect impact on students’ response-times and level of achievement. Moreover, the ensemble RandomForest method provides accurate classification results, indicating that a time-spent driven description of students’ behavior could have added value towards dynamically reshaping the respective models. Further implications of these findings are also discussed.}
}
@article{PELANEK2016169,
title = {Applications of the Elo rating system in adaptive educational systems},
journal = {Computers & Education},
volume = {98},
pages = {169-179},
year = {2016},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2016.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S036013151630080X},
author = {Radek Pelánek},
keywords = {Architectures for educational technology system, Interactive learning environments, Applications in subject areas, Student modeling},
abstract = {The Elo rating system was originally developed for rating chess players, nowadays it is widely used for ranking players of many other games. The system can be used in educational systems when we interpret student's answer to an item as a match between the student and the item. In this way we can easily dynamically estimate the skill of students and difficulty of items. We provide a systematic overview of different variants of the Elo rating system and their application in education. We compare the Elo rating system to alternative methods and describe a specific case study (an adaptive practice of geography facts) to illustrate the application of the Elo rating system in education. We argue that the Elo rating system is simple, robust, and effective and thus suitable for use in the development of adaptive educational systems. We provide specific guidelines for such applications.}
}
@article{HEUNG201751,
title = {Comparing the use of training data derived from legacy soil pits and soil survey polygons for mapping soil classes},
journal = {Geoderma},
volume = {290},
pages = {51-68},
year = {2017},
issn = {0016-7061},
doi = {https://doi.org/10.1016/j.geoderma.2016.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0016706116309491},
author = {Brandon Heung and Matúš Hodúl and Margaret G. Schmidt},
keywords = {Digital soil mapping, Machine-learning, Soil classification, Data-mining, Model comparison, Ensemble-learning},
abstract = {Machine-learners used for digital soil mapping are generally trained using either data derived from field-observed soil pits or from soil survey polygons - although no direct comparison of the accuracy resulting from the two methods has yet to be undertaken. This study examined such a comparison over the Okanagan Valley and Kamloops region of British Columbia where good quality soil pit and soil survey data were available. A standard set of environmental variables including vegetative, climatic, and topographic indices were used to predict soil Great Groups in accordance with the Canadian System of Soil Classification. The pit-derived training dataset was developed using n=478 points from the British Columbia Soil Information System while the polygon-derived training dataset was developed through random sampling of single-component soil survey map units based on an area-weighted approach. In both cases, the training points were intersected with a suite of 18 environmental covariates, reduced from 27 covariates using principal component analysis, and submitted to a machine-learner for predictions at a 100m spatial resolution. Four single-model learners (CART, k-nearest neighbor, multinomial logistic regression, and logistic model tree) and five ensemble-model learners (CART with bagging, k-nearest neighbor with bagging, multinomial logistic regression with bagging, logistic model trees with bagging, and Random Forest) were compared. Surfaces of prediction uncertainty were produced using ignorance uncertainty and results were validated using a 5-fold cross-validation procedure. Predictions made using polygon-derived training data were consistently higher in accuracy across all models where the Random Forest model was the most effective learner with C=61% accuracy when using pit-derived training data and C=68% accuracy when using polygon-derived training data. Comparing single-model and ensemble-learner models, the bagging algorithm resulted in a 2–11% increase in accuracy when using pit-derived training data. Ensemble-models allowed for the visualization of prediction uncertainty. This study provides further insight into the use of legacy soil data and the development of training data for digital soil mapping.}
}
@article{ORTIGOSA201457,
title = {Predicting user personality by mining social interactions in Facebook},
journal = {Journal of Computer and System Sciences},
volume = {80},
number = {1},
pages = {57-71},
year = {2014},
issn = {0022-0000},
doi = {https://doi.org/10.1016/j.jcss.2013.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S002200001300072X},
author = {Alvaro Ortigosa and Rosa M. Carro and José Ignacio Quiroga},
keywords = {Data mining in social networks, User modeling, Personality inference},
abstract = {Adaptive applications may benefit from having models of usersʼ personality to adapt their behavior accordingly. There is a wide variety of domains in which this can be useful, i.e., assistive technologies, e-learning, e-commerce, health care or recommender systems, among others. The most commonly used procedure to obtain the user personality consists of asking the user to fill in questionnaires. However, on one hand, it would be desirable to obtain the user personality as unobtrusively as possible, yet without compromising the reliability of the model built. On the other hand, our hypothesis is that users with similar personality are expected to show common behavioral patterns when interacting through virtual social networks, and that these patterns can be mined in order to predict the tendency of a user personality. With the goal of inferring personality from the analysis of user interactions within social networks, we have developed TP2010, a Facebook application. It has been used to collect information about the personality traits of more than 20,000 users, along with their interactions within Facebook. Based on all the collected data, automatic classifiers were trained by using different machine-learning techniques, with the purpose of looking for interaction patterns that provide information about the usersʼ personality traits. These classifiers are able to predict user personality starting from parameters related to user interactions, such as the number of friends or the number of wall posts. The results show that the classifiers have a high level of accuracy, making the proposed approach a reliable method for predicting the user personality}
}
@article{FENG20165,
title = {Social network regularized Sparse Linear Model for Top-N recommendation},
journal = {Engineering Applications of Artificial Intelligence},
volume = {51},
pages = {5-15},
year = {2016},
note = {Mining the Humanities: Technologies and Applications},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2016.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0952197616000233},
author = {Xiaodong Feng and Ankit Sharma and Jaideep Srivastava and Sen Wu and Zhiwei Tang},
keywords = { recommendation, Social network, User modeling, Sparse Linear Model, Local learning},
abstract = {Social recommendation techniques have been developed to employ user׳s social connections for both rating prediction and Top-N recommendation. However, they are mostly using social network enhanced matrix factorization (MF) where the objective is to minimize the prediction error of rating scores, which makes it impractical and unsuccessful for Top-N recommendation. This paper thus focuses on developing more effective methods to utilize social network information for Top-N recommendation. Social network regularized Sparse LInear Model (SocSLIM) with its extensions incorporating local learning (LocSocSLIM) to improve efficiency are proposed. SocSLIM learns sparse coefficient matrix for users by solving a sparse representation problem over user-item rating/purchase matrix and user–user social network׳s adjacency matrix at the same time by sharing coefficient matrix. The coefficient matrix is used to predict the recommendation scores, which are then combined with a proposed item based Distance regularized Sparse LInear Model (DSLIM) to generate recommendations for the users. The experimental results demonstrate that SocSLIM effectively uses the social information to outperform the state-of-the-art methods by at least 12%. Moreover, the local weight learning extension LocSocSLIM significantly improves the efficiency up to 10 times as compared to SocSLIM as the original SLIM while achieving the close performance guarantees.}
}
@article{SCHADENBERG2017222,
title = {Personalising game difficulty to keep children motivated to play with a social robot: A Bayesian approach},
journal = {Cognitive Systems Research},
volume = {43},
pages = {222-231},
year = {2017},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2016.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041716300523},
author = {B.R. Schadenberg and M.A. Neerincx and F. Cnossen and R. Looije},
keywords = {Social robotics, User modeling, Rating system, Child-robot interaction, Motivation},
abstract = {For effective child education, playing games with a social robot should be motivating for a longer period of time. One aspect that can affect the motivation of a child is the difficulty of a game. The game should be perceived as challenging, while at the same time, the child should be confident to meet the challenge. We designed a user modelling module that adapts the difficulty of a game to the child’s skill level, in order to provide children with the optimal challenge. This module applies a Bayesian rating method that estimates the child’s skill and game item’s difficulty levels to personalise the game progress. In an experiment with 22 children (aged between 10 and 12years old), we tested whether the personalisation leads to a higher motivation to play with the robot. Although the personalised system did not challenge the participants optimally, this study shows that the Bayesian rating system is in principle able to measure the skill and performance of children in playing a game with a robot (even without accurate estimates of the difficulty of items). We outline multiple ways in which the rating method and module can be used to further personalise and enhance the child-robot interaction, other than adapting the difficulty of games (e.g. by adapting the dialogue and feedback).}
}
@article{LI2017170,
title = {Insights into randomized algorithms for neural networks: Practical issues and common pitfalls},
journal = {Information Sciences},
volume = {382-383},
pages = {170-178},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S002002551631917X},
author = {Ming Li and Dianhui Wang},
keywords = {Randomized algorithms, Neural networks, Incremental learning, Function approximation},
abstract = {Random Vector Functional-link (RVFL) networks, a class of learner models, can be regarded as feed-forward neural networks built with a specific randomized algorithm, i.e., the input weights and biases are randomly assigned and fixed during the training phase, and the output weights are analytically evaluated by the least square method. In this paper, we provide some insights into RVFL networks and highlight some practical issues and common pitfalls associated with RVFL-based modelling techniques. Inspired by the folklore that “all high-dimensional random vectors are almost always nearly orthogonal to each other”, we establish a theoretical result on the infeasibility of RVFL networks for universal approximation, if a RVFL network is built incrementally with random selection of the input weights and biases from a fixed scope, and constructive evaluation of its output weights. This work also addresses the significance of the scope setting of random weights and biases in respect to modelling performance. Two numerical examples are employed to illustrate our findings, which theoretically and empirically reveal some facts and limits of such class of randomized learning algorithms.}
}
@article{SHAKSHUKI2015356,
title = {Dynamic Healthcare Interface for Patients},
journal = {Procedia Computer Science},
volume = {63},
pages = {356-365},
year = {2015},
note = {The 6th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2015)/ The 5th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2015)/ Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.354},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915024898},
author = {Elhadi M. Shakshuki and Malcolm Reid and Tarek R. Sheltami},
keywords = {Multi-Agent Systems, Healthcare Technology ;Adaptive User Interface, Reinforcement Learning},
abstract = {Canadian healthcare is a fundamental part of society. Challenges such as the aging baby boomer generation require the healthcare industry to meet higher demands while using fewer resources. Computer systems designed to record and report physical health properties of an individual personcan be used in part to accomplish this task. In this paper, we present the architecture of a hypothetical multi-agent system designed to provide healthcare information about specific patients through continuous monitoring. The resulting data from the system is accessible by the patient to whom it belongs as well as his or her healthcare professional. Furthermore, the proposed system utilizes an adaptive user interface for the purpose of improving the overall experience for users with poor vision or motor skills. Specifically, we focus on the implementation of several of the key components involved in the adaptive user interface: learning component and the user model. To demonstrate the feasibility of the implementation two scenarios are provided. We conclude with several possible future directions for this research.}
}
@article{SCARDAPANE2015271,
title = {Distributed learning for Random Vector Functional-Link networks},
journal = {Information Sciences},
volume = {301},
pages = {271-284},
year = {2015},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2015.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0020025515000298},
author = {Simone Scardapane and Dianhui Wang and Massimo Panella and Aurelio Uncini},
keywords = {Random Vector Functional-Link, Distributed learning, Consensus, Distributed Optimization},
abstract = {This paper aims to develop distributed learning algorithms for Random Vector Functional-Link (RVFL) networks, where training data is distributed under a decentralized information structure. Two algorithms are proposed by using Decentralized Average Consensus (DAC) and Alternating Direction Method of Multipliers (ADMM) strategies, respectively. These algorithms work in a fully distributed fashion and have no requirement on coordination from a central agent during the learning process. For distributed learning, the goal is to build a common learner model which optimizes the system performance over the whole set of local data. In this work, it is assumed that all stations know the initial weights of the input layer, the output weights of local RVFL networks can be shared through communication channels among neighboring nodes only, and local datasets are blocked strictly. The proposed learning algorithms are evaluated over five benchmark datasets. Experimental results with comparisons show that the DAC-based learning algorithm performs favorably in terms of effectiveness, efficiency and computational complexity, followed by the ADMM-based learning algorithm with promising accuracy but higher computational burden.}
}
@article{YANG201739,
title = {ExploreTree: Interactive tree modeling in semantic trait space with online intent learning},
journal = {Graphical Models},
volume = {91},
pages = {39-51},
year = {2017},
issn = {1524-0703},
doi = {https://doi.org/10.1016/j.gmod.2017.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S1524070317300103},
author = {Yinhui Yang and Rui Wang and Hongxin Zhang and Hujun Bao},
keywords = {Tree modeling, Parametirc space exploration, Online learning, Semantic traits},
abstract = {Perceptually modeling realistic trees is important for many graphics applications. However, existing methods are mainly rule-based. Few have directly associated control parameters with user modeling intent and semantic tree shape descriptions. In this paper, we propose a new interactive tree modeling system, ExploreTree, that automatically deduces user modeling intent and supports iteratively design of 3D tree models. It consists of two major phases. The first phase is an off-line learning process, where semantic tree traits perceived by humans are learned. Crowdsourced data on example tree models are collected and analyzed to construct the semantic trait space as well as the embedding of trees into this space. Built upon it, the second phase is an interactive exploration of tree models via a few user clicks, where a user intent evaluation model is learned online to guide the modeling process. Modeled trees and user studies demonstrate the efficiency and capability of ExploreTree.}
}
@article{RAYBOURN2014471,
title = {A new paradigm for serious games: Transmedia learning for more effective training and education},
journal = {Journal of Computational Science},
volume = {5},
number = {3},
pages = {471-481},
year = {2014},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2013.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S1877750313001014},
author = {Elaine M. Raybourn},
keywords = {Transmedia learning, Serious games, Transmedia campaigns, Storytelling, Social media, Data mining, xAPI, MOOC},
abstract = {Serious games present a relatively new approach to training and education for international organizations such as NATO (North Atlantic Treaty Organization), non-governmental organizations (NGOs), the U.S. Department of Defense (DoD) and the U.S. Department of Homeland Security (DHS). Although serious games are often deployed as stand-alone solutions, they can also serve as entry points into a comprehensive training pipeline in which content is delivered via different media to rapidly scale immersive training and education for mass audiences. The present paper introduces a new paradigm for more effective and scalable training and education called transmedia learning. Transmedia learning leverages several new media trends including the peer communications of social media, the scalability of massively openonline course (MOOCs), and the design of transmedia storytelling used by entertainment, advertising, and commercial game industries to sustain audience engagement. Transmedia learning is defined as the scalable system of messages representing a narrative or core experience that unfolds from the use of multiple media, emotionally engaging learners by involving them personally in the story. In the present paper, we introduce the transmedia learning paradigm as offering more effective use of serious games for training and education. This approach is consistent with the goals of international organizations implementing approaches similar to those described by the Army Learning Model (ALM) to deliver training and education to Soldiers across multiple media. We discuss why the human brain is wired for transmedia learning and demonstrate how the Simulation Experience Design Method can be used to create transmedia learning story worlds for serious games. We describe how social media interactions and MOOCs may be used in transmedia learning, and how data mining social media and experience tracking can inform the development of computational learner models for transmedia learning campaigns. Examples of how the U.S. Army has utilized transmedia campaigns for strategic communication and game-based training are provided. Finally, we provide strategies the reader can use today to incorporate transmedia storytelling elements such as Internet, serious games, video, social media, graphic novels, machinima, blogs, and alternate reality gaming into a new paradigm for training and education: transmedia learning.}
}
@article{OUF2017796,
title = {A proposed paradigm for smart learning environment based on semantic web},
journal = {Computers in Human Behavior},
volume = {72},
pages = {796-818},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.08.030},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216305957},
author = {Shimaa Ouf and Mahmoud {Abd Ellatif} and S.E. Salama and Yehia Helmy},
keywords = {E-Learning ecosystem, Personalization, Ontology, Software architecture, Semantic Web Rule Language, Learner model},
abstract = {The current approaches of e-learning face challenges, in isolation of learners from learning process, and shortage of learning process quality. The researchers mentioned that the next generation of e-learning is e-learning ecosystem. E-learning ecosystem has many advantages, in which, learners form groups, collaborate with each other and with educators, and content designed for interaction. E-learning ecosystem faces some issues. It applies teacher-student model, in which, fixed learning pathway is considered suitable for all learners. Consequently, learners are presented with limited personalized materials. E-learning ecosystem needs to merge the personalization's concept. Semantic web ontology based personalization of learning environment plays a leading role to build smart e-learning ecosystem. This paper previews a detailed study which addresses research papers that apply ontology within learning environment. Most of these studies focus on personalizing e-learning by providing learners with suitable learning objects, ignoring the other learning process components. This paper proposes and implements framework for smart e-learning ecosystem using ontology and SWRL. A new direction is proposed. This direction fosters the creation of a separate four ontologies for the personalized full learning package which is composed of learner model and all the learning process components (learning objects, learning activities and teaching methods).}
}
@article{VALORMIRO201565,
title = {Efficiency and usability study of innovative computer-aided transcription strategies for video lecture repositories},
journal = {Speech Communication},
volume = {74},
pages = {65-75},
year = {2015},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2015.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167639315001016},
author = {Juan Daniel {Valor Miró} and Joan Albert Silvestre-Cerdà and Jorge Civera and Carlos Turró and Alfons Juan},
keywords = {Video lecture repositories, Usability study, Computer-assisted transcription, Interface design strategies, Automatic speech recognition},
abstract = {Video lectures are widely used in education to support and complement face-to-face lectures. However, the utility of these audiovisual assets could be further improved by adding subtitles that can be exploited to incorporate added-value functionalities such as searchability, accessibility, translatability, note-taking, and discovery of content-related videos, among others. Today, automatic subtitles are prone to error, and need to be reviewed and post-edited in order to ensure that what students see on-screen are of an acceptable quality. This work investigates different user interface design strategies for this post-editing task to discover the best way to incorporate automatic transcription technologies into large educational video repositories. Our three-phase study involved lecturers from the Universitat Politècnica de València (UPV) with videos available on the poliMedia video lecture repository, which is currently over 10,000 video objects. Simply by conventional post-editing automatic transcriptions users almost reduced to half the time that would require to generate the transcription from scratch. As expected, this study revealed that the time spent by lecturers reviewing automatic transcriptions correlated directly with the accuracy of said transcriptions. However, it is also shown that the average time required to perform each individual editing operation could be precisely derived and could be applied in the definition of a user model. In addition, the second phase of this study presents a transcription review strategy based on confidence measures (CM) and compares it to the conventional post-editing strategy. Finally, a third strategy resulting from the combination of that based on CM with massive adaptation techniques for automatic speech recognition (ASR), achieved to improve the transcription review efficiency in comparison with the two aforementioned strategies.}
}
@article{COCEA201548,
title = {Participatory Learner Modelling Design: A methodology for iterative learner models development},
journal = {Information Sciences},
volume = {321},
pages = {48-70},
year = {2015},
note = {Security and privacy information technologies and applications for wireless pervasive computing environments},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2015.05.032},
url = {https://www.sciencedirect.com/science/article/pii/S0020025515003916},
author = {Mihaela Cocea and George D. Magoulas},
keywords = {Learner/user models, Adaptive systems, Participatory design, Methodology, Iterative development},
abstract = {Learner models are built to offer personalised solutions related to learning. They are often developed in parallel to the development of adaptive learning systems and thus, linked to the system’s development. The adaptive learning systems literature reports numerous accounts of learner model development, but there are no reports on the methodological aspects of developing learner models and the relation between the development of the learner model component and the rest of the system. This paper presents the Participatory Learner Modelling Design methodology, which outlines the steps for learner model development and their relation to the development of the system. The methodology is illustrated with a case study of an adaptive educational system.}
}
@article{COSTA2017247,
title = {Evaluating the effectiveness of educational data mining techniques for early prediction of students' academic failure in introductory programming courses},
journal = {Computers in Human Behavior},
volume = {73},
pages = {247-256},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.01.047},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217300596},
author = {Evandro B. Costa and Baldoino Fonseca and Marcelo Almeida Santana and Fabrísia Ferreira {de Araújo} and Joilson Rego},
keywords = {Artificial intelligence in education, Automatic instructional planner, Automatic prediction, Educational data mining, Interactive learning environment, Learner modeling},
abstract = {The data about high students' failure rates in introductory programming courses have been alarming many educators, raising a number of important questions regarding prediction aspects. In this paper, we present a comparative study on the effectiveness of educational data mining techniques to early predict students likely to fail in introductory programming courses. Although several works have analyzed these techniques to identify students' academic failures, our study differs from existing ones as follows: (i) we investigate the effectiveness of such techniques to identify students likely to fail at early enough stage for action to be taken to reduce the failure rate; (ii) we analyse the impact of data preprocessing and algorithms fine-tuning tasks, on the effectiveness of the mentioned techniques. In our study we evaluated the effectiveness of four prediction techniques on two different and independent data sources on introductory programming courses available from a Brazilian Public University: one comes from distance education and the other from on-campus. The results showed that the techniques analyzed in our study are able to early identify students likely to fail, the effectiveness of some of these techniques is improved after applying the data preprocessing and/or algorithms fine-tuning, and the support vector machine technique outperforms the other ones in a statistically significant way.}
}
@article{QUIROGABAQUERO201618,
title = {Efectos de diferentes tipos de entrenamiento por modelado en tareas de igualación a la muestra},
journal = {Revista Latinoamericana de Psicología},
volume = {48},
number = {1},
pages = {18-29},
year = {2016},
issn = {0120-0534},
doi = {https://doi.org/10.1016/j.rlp.2015.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0120053415000333},
author = {Luis Alberto {Quiroga Baquero} and María Antonia {Padilla Vargas} and Santiago {Ordoñez Riaño} and Luis Carlos {Fonseca León}},
keywords = {Modelamiento, Igualación a la muestra, Control abstracto de estímulos, Transferencia, Modelling, Matching-to-sample, Abstract stimulus control, Transfer},
abstract = {Resumen
Se evaluó el efecto de tres tipos de entrenamiento por modelado, sobre el aprendizaje y la transferencia en una tarea de igualación a la muestra de segundo orden. Participaron 30 estudiantes de psicología (15 mexicanos y 15 colombianos). Cada muestra fue dividida en tres condiciones experimentales: entrenamiento por exposición a modelo experto, modelo aprendiz o modelo antiexperto. Los resultados muestran que: (a) en las dos muestras, los desempeños en pruebas de aprendizaje y transferencia fueron significativamente superiores a los obtenidos en las prepuebas; (b) se encontraron mejores ejecuciones en las pruebas de aprendizaje y transferencia para los grupos con exposición a modelo experto; (c) la condición de exposición a modelo antiexperto produjo porcentajes de aciertos bajos en pruebas de aprendizaje y transferencia; (d) entre las pruebas de transferencia, las ejecuciones en la prueba extrarrelacional fueron las más bajas; y (e) en la prueba de construcción, la proporción de relaciones construidas fue homogénea. Estos hallazgos son discutidos en términos de la identificación de algunos factores implicados en el establecimiento de control abstracto de estímulo por modelado, y del efecto de las condiciones de remuneración sobre el desempeño en tareas experimentales de resolución de problemas.
This study evaluated the effects of three types of training models on the learning and transfer of a second-order matching-to-sample task. Thirty psychology students (15 Mexicans and 15 Colombians) took part. Each sample was divided into three experimental conditions: training by exposure to an expert model, learner model or anti-expert model. The results show that: (a) in both samples, performances in transfer and learning tests are significantly higher than those obtained in the pre-tests; (b) best performances were found in tests of learning and transfer for groups with exposure to the expert model; (c) the anti-expert model condition produced lower percentages of correct answers on tests of learning and transfer; (d) performance in extra-relational tests were the lowest in transfer tests; and (e) the ratio of relationships constructed was homogeneous in the construction test. These findings are discussed in terms of the identification of some factors involved in the establishment of abstract stimulus control by modelling, and the effect of the conditions of remuneration on performance in experimental problem-solving tasks.}
}
@article{BENT2017456,
title = {Modeling user behavior data in systems of engagement},
journal = {Future Generation Computer Systems},
volume = {68},
pages = {456-464},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.05.038},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1630156X},
author = {Oliver Bent and Prasenjit Dey and Komminist Weldemariam and Mukesh K. Mohania},
keywords = {User engagement, User modeling, Instrumentation, Mobile sensors},
abstract = {The proliferation of mobile devices has changed the way digital information is consumed and its efficacy measured. These personal devices know a lot about user behavior from embedded sensors along with monitoring the daily activities users perform through various applications on these devices. This data can be used to get a deep understanding of the context of the users and provide personalized services to them. However, there are a lot of challenges in capturing, modeling, storing, and processing such data from these systems of engagement, both in terms of achieving the right balance of redundancy in the captured and stored data, along with ensuring the usefulness of the data for analysis. There are additional challenges in balancing how much of the captured data should be processed through client or server applications. In this article, we present the modeling of user behavior in the context of personalized education which has generated a lot of recent interest. More specifically, we present an architecture and the issues of modeling student behavior data, captured from different activities the student performs during the process of learning. The user behavior data is modeled and sent to the cloud-enabled backend where detailed analytics are performed to understand different aspects of a student, such as engagement, difficulties, and preferences and to also analyze the quality of the data.}
}
@article{SM201610,
title = {Efficient online and offline template update mechanisms for speaker recognition},
journal = {Computers & Electrical Engineering},
volume = {50},
pages = {10-25},
year = {2016},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2015.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0045790615004309},
author = {Anzar S.M. and Amala K. and Remya Rajendran and Ashwin Mohan and Ajeesh P.S. and Mohammed Sabeeh K. and Febin Aziz},
keywords = {Template update, Mel frequency Cepstral coefficient, MFCC super template, GMM super model, Online update, Offline update},
abstract = {Sample variations are one of the main problems associated with speaker recognition. Most approaches use multiple templates in the gallery database. But, this requires enormous memory space. In order to minimize classification errors and intra-class variations, adaptive online and offline template update methods using vector quantization (VQ) and Gaussian mixture model (GMM) are proposed. Online and offline feature update as well as model update techniques are considered here. Feature update utilizes the vector quantization approach, while Gaussian mixture model approach is considered for model updating. The proposed methods automatically update the feature (model) in accordance with the biometric sample variations over time and they continually adapt the templates (user model) based on semi-supervised learning strategies. Experiments with 50 subjects reveal that the proposed template update strategies, improve the recognition accuracy and reduce the classification errors for voice recognition systems, even under sample variations.}
}
@article{WANG2016490,
title = {A computer vision-based algorithm to predict false positive errors in radiology trainees when interpreting digital breast tomosynthesis cases},
journal = {Expert Systems with Applications},
volume = {64},
pages = {490-499},
year = {2016},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2016.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S0957417416304171},
author = {Mengyu Wang and Meng Wang and Lars J. Grimm and Maciej A. Mazurowski},
keywords = {Radiology education, False positive error prediction, Training plan optimization, Digital breast tomosynthesis, Image processing, Clustering},
abstract = {Objectives
Digital breast tomosynthesis (DBT) is a new imaging modality that improves invasive cancer detection rates compared to mammography. In this work, we aim to advance adaptive computer-based education in DBT by computer algorithm.
Methods
First, a set of potentially difficult locations are identified based on locations marked by other trainees using a regional clustering algorithm. Second, the candidate location is segmented to identify potential abnormal objects. Third, 18 features are extracted from the location from the segmented image. Finally, a classifier uses the 18 features to predict whether the candidate location would result in a false positive error for the trainee. The classifier is personalized for each trainee by using data from the trainee's prior DBT interpretations.
Results
Our algorithm successfully identified locations more likely associated with false positive errors as compared to randomly identified locations. The prevalence of errors among the difficult locations was 20.7% when 1 location per trainee was predicted and 17.2% when 10 locations were predicted. In comparison, the prevalence of errors for random locations generated within a breast region with 1 and 10 identified locations was 0% and 4.8%, respectively.
Conclusions
We developed an algorithm to successfully identify locations on DBT where trainees are more likely to commit false positive errors.
Advances in knowledge
Our user model can be used to select the most challenging cases for each trainee from the perspective of committing false positive errors. Our model improved the status quo of case presentation with random selection to trainee in breast tomosynthesis.}
}
@article{CESTA201498,
title = {Training for crisis decision making – An approach based on plan adaptation},
journal = {Knowledge-Based Systems},
volume = {58},
pages = {98-112},
year = {2014},
note = {Intelligent Decision Support Making Tools and Techniques: IDSMT},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2013.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S0950705113003614},
author = {Amedeo Cesta and Gabriella Cortellessa and Riccardo {De Benedictis}},
keywords = {Strategic decision making, Training systems, Crisis management, Continuous plan adaptation, Biofeedback, Mixed-initiative system, User modeling},
abstract = {The human ability to take the right decisions is very important in real world critical situations. An interesting problem always worth being investigated concerns how to teach decision making skills to humans. The real nature of taking decisions is extremely difficult to describe in detail and, as a consequence, training it according to fixed protocols is also challenging. This is because it comes out as a combination of natural talent, competence from previous experience, ability to quick reasoning, leadership, resilience to stress, and so on. We have addressed this problem while building a new learning environment to train crisis decision makers. The environment, called Pandora, is grounded on Artificial Intelligence planning techniques known as “timeline-based”. This technology is used to create and manipulate segments of lesson’s content over time. Planning a lesson corresponds to logically organize events over time that are then rendered in front of trainees during the lesson’s actual enactment. This paper shows how the machinery of continuous plan adaptation is functional to create variety and novelty in the lessons thus engaging the trainees during the teaching interaction. In particular, it shows the different uses of plan adaptation to take into account the basic reactivity of the trainees, the background deductions from user modeling, and the mixed-initiative interactions guided by the trainer.}
}
@article{KISTNER2016446,
title = {Model development in scientific discovery learning with a computer-based physics task},
journal = {Computers in Human Behavior},
volume = {59},
pages = {446-455},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.02.041},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216300930},
author = {Saskia Kistner and Regina Vollmeyer and Bruce D. Burns and Ulrich Kortenkamp},
keywords = {Scientific discovery learning, Multiple problem spaces, Computer simulations, Physics concepts, Misconceptions, Conceptual change},
abstract = {Based on theories of scientific discovery learning (SDL) and conceptual change, this study explores students' preconceptions in the domain of torques in physics and the development of these conceptions while learning with a computer-based SDL task. As a framework we used a three-space theory of SDL and focused on model space, which is supposed to contain the current conceptualization/model of the learning domain, and on its change through hypothesis testing and experimenting. Three questions were addressed: (1) What are students' preconceptions of torques before learning about this domain? To do this a multiple-choice test for assessing students' models of torques was developed and given to secondary school students (N = 47) who learned about torques using computer simulations. (2) How do students' models of torques develop during SDL? Working with simulations led to replacement of some misconceptions with physically correct conceptions. (3) Are there differential patterns of model development and if so, how do they relate to students’ use of the simulations? By analyzing individual differences in model development, we found that an intensive use of the simulations was associated with the acquisition of correct conceptions. Thus, the three-space theory provided a useful framework for understanding conceptual change in SDL.}
}
@article{SHIN20171826,
title = {The role of affordance in the experience of virtual reality learning: Technological and affective affordances in virtual reality},
journal = {Telematics and Informatics},
volume = {34},
number = {8},
pages = {1826-1836},
year = {2017},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2017.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0736585317301223},
author = {Dong-Hee Shin},
keywords = {Virtual reality learning, Critical incident technique, Amultimixed approach, Educational affordance, Virtual reality, Affordance},
abstract = {As virtual reality becomes more and more mainstream, the role of affordances in virtual environments becomes an important question. The goal of this study is to explicate users’ motivational affordances and examine how they influence the acceptance of a virtual reality learning environment (VLE). It examines how motivational affordances in an educational virtual reality (VR) system affect user experience to track and achieve goals for users. A multimixed approach was used by combining qualitative methods and a quantitative survey. First, a critical incident technique was used to explore a range of affordance factors related to VLE. Second, based on the affordance factors identified from the qualitative methods, a survey was conducted to examine the effects of affordance on user cognitive processes and the influence of affordance on the learning process. The results of the user model confirmed the heuristic role of presence and immersion affordance regarding their underlying link to educational affordances, such as empathy and embodied cognition. The findings imply the embodied cognition process of VLE in which technological qualities are shaped by users’ perception and context. The results establish a foundation for VR technologies through a heuristic assessment tool from a user-embodied cognitive process. They confirm the validity and utility of applying affordances to the design of VR as a useful concept and prove that the optimum mix of affordances is crucial to the success of VR design.}
}
@article{WANG20161,
title = {Predicting false negative errors in digital breast tomosynthesis among radiology trainees using a computer vision-based approach},
journal = {Expert Systems with Applications},
volume = {56},
pages = {1-8},
year = {2016},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2016.01.053},
url = {https://www.sciencedirect.com/science/article/pii/S0957417416300173},
author = {Mengyu Wang and Jing Zhang and Lars J. Grimm and Sujata V. Ghate and Ruth Walsh and Karen S. Johnson and Joseph Y. Lo and Maciej A. Mazurowski},
keywords = {Radiology education, False negative error prediction, Training protocol optimization, Tomosynthesis},
abstract = {Purpose
Digital breast tomosynthesis (DBT) can improve lesion visibility in comparison to mammography by eliminating breast tissue superimposition. While the benefits of DBT in breast cancer screening rely on well trained radiologists, the optimal training regimen in DBT is unknown. We propose a computer-aided educational system that individually selects the optimal training cases for each trainee. The first step towards this goal is to capture the individual weaknesses of each trainee. In this study, we present and evaluate a computer algorithm for this purpose with particular focus on false negative errors.
Methods
We developed an algorithm (a user model) that predicted the likelihood of a trainee missing an abnormal location. An individual model is applied for each trainee. The algorithm consists of three steps. First, the lesions on DBT images are segmented by a 3D active contour method with a level set algorithm. Then, 16 features are extracted automatically for the segmented lesions. Finally a multivariate logistic regression classifier predicts the likelihood of error based on the extracted features. The classifier is trained using the previous interpretation data of the trainee. We evaluated the individual predictive algorithms experimentally using data from a reader study in which 29 trainees and 3 expert breast radiologists read 60 DBT cases. Receiver operating characteristic (ROC) analysis, along with a repeated holdout approach, was used to evaluate the predictive performance of our algorithm.
Results
The average area under the ROC curve (AUC) of the algorithms which predicted which lesions will be detected and which will be missed by a specific trainee was 0.627 (95% CI: 0.579–0.675). The average performance was statistically significantly better than chance (p<0.001). Under the status quo, training involves no specific strategy for case presentation, and this random behavior corresponds to AUC of 0.5. Therefore, the proposed algorithm may provide a significant improvement in distinguishing abnormal locations that will be detected by a trainee from those that will be missed.
Conclusions
Our algorithm was able to distinguish abnormal locations that will be detected by a trainee from those that will be missed. This could be used to enrich the training set with cases that are likely to prompt error for the individual trainee while still maintaining a range of cases necessary for comprehensive education.}
}
@article{SADOWSKI201649,
title = {Non-destructive neural identification of the bond between concrete layers in existing elements},
journal = {Construction and Building Materials},
volume = {127},
pages = {49-58},
year = {2016},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2016.09.146},
url = {https://www.sciencedirect.com/science/article/pii/S0950061816315975},
author = {Łukasz Sadowski and Jerzy Hoła and Sławomir Czarnecki},
keywords = {Concrete layers, Non-destructive testing, Acoustic methods, Impact-echo, Impulse response, Artificial intelligence, Neural networks, Interlayer bond, Pull-off adhesion, Methodology},
abstract = {The paper presents the results regarding the identification of the value of the pull-off adhesion between a concrete added layer with a constant thickness and a substrate concrete layer in existing elements. A method of identification, which is based solely on the use of artificial neural networks (ANNs) and two non-destructive acoustic methods: impact-echo and impulse response on the surface of the added layer, was developed. The methodology of identifying the pull-off adhesion between a concrete added layer and a substrate layer in existing elements was developed and presented in the paper and is useful in construction practice.}
}