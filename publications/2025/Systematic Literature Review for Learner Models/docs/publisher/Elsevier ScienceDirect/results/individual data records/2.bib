@article{UDUGAMA202363,
title = {Digital tools in chemical engineering education: The needs and the desires},
journal = {Education for Chemical Engineers},
volume = {44},
pages = {63-70},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000192},
author = {Isuru A. Udugama and Martin Atkins and Christoph Bayer and James Carson and Duygu Dikicioglu and Krist V. Gernaey and Jarka Glassey and Matthew Taylor and Brent R. Young},
keywords = {Digitalisation, Digital tools in education, Non-technical barriers, Digital twins},
abstract = {Educators in chemical engineering have a long and rich history of employing digital tools to solve fundamental engineering problems. Today, with the megatrend of digitalisation, there is a growing set of tools that can be used for chemical engineering education. However, identifying which tool is ideally suited to support teaching a given chemical engineering concept can be challenging. To answer this question a survey was distributed to Heads of Departments at IChemE institutions and members of the IChemE committees focused on digitalisation. The survey respondents rated Microsoft Excel (VBA), commercial simulators, and scripting tools as ideal for teaching core subjects such as mass and energy balances, mass transfer and reaction engineering while respondents found 3D Models, and Virtual/Augmented Reality models as being most suited for teaching subjects such as process design, safety and sustainability. Mathematical/programming simplicity, ease of maintenance, and low initial investment costs were identified as key non-technical aspects that will hinder the adoption of a given digital tool. Weighing the benefits of education and non-technical hurdles, the respondents preferred the use of simpler digitalisation platforms such as Excel and scripting languages over the more advanced platforms such as Virtual/Augmented Reality where possible. It was identified that the widespread adoption of more advanced digitalisation tools will require removal of the above mentioned non-technical barriers as well as other barriers such as tool shareability.}
}
@article{ZHOU2023120327,
title = {Synthetic data generation method for data-free knowledge distillation in regression neural networks},
journal = {Expert Systems with Applications},
volume = {227},
pages = {120327},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120327},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423008291},
author = {Tianxun Zhou and Keng-Hwee Chiam},
keywords = {Data-free knowledge distillation, Knowledge distillation, Neural network, Regression, Machine learning},
abstract = {Knowledge distillation is the technique of compressing a larger neural network, known as the teacher, into a smaller neural network, known as the student, while still trying to maintain the performance of the larger neural network as much as possible. Existing methods of knowledge distillation are mostly applicable for classification tasks. Many of them also require access to the data used to train the teacher model. To address the problem of knowledge distillation for regression tasks in the absence of original training data, the existing method uses a generator model trained adversarially against the student model to generate synthetic data to train the student model. In this study, we propose a new synthetic data generation strategy that directly optimizes for a large but bounded difference between the student and teacher model. Our results on benchmark experiments demonstrate that the proposed strategy allows the student model to learn better and emulate the performance of the teacher model more closely.}
}
@article{ZHANG2023102571,
title = {A deep learning-enabled human-cyber-physical fusion method towards human-robot collaborative assembly},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {83},
pages = {102571},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102571},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000479},
author = {Chao Zhang and Guanghui Zhou and Dongxu Ma and Rui Wang and Jiacheng Xiao and Dan Zhao},
keywords = {Human-cyber-physical system, Human-robot collaboration, Deep learning, Smart assembly, Augmented reality, Digital twin},
abstract = {Human-robot collaborative (HRC) assembly has become popular in recent years. It takes full advantage of the strength, repeatability and accuracy of robots and the high-level cognition, flexibility and adaptability of humans to achieve an ergonomic working environment with better overall productivity. However, HRC assembly is still in its infancy nowadays. How to ensure the safety and efficiency of HRC assembly while reducing assembly failures caused by human errors is challenging. To address the current challenges, this paper proposes a novel human-cyber-physical assembly system (HCPaS) framework, which combines the powerful perception and control capacity of digital twin with the virtual-reality interaction capacity of augmented reality (AR) to achieve a safe and efficient HRC environment. Based on the framework, a deep learning-enabled fusion method of HCPaS is proposed from the perspective of robot-level fusion and part-level fusion. Robot-level fusion perceives the pose of robots with the combination of PointNet and iterative closest point (ICP) algorithm, where the status of robots together with their surroundings could be registered into AR environment to improve the human's cognitive ability of complex assembly environment, thus ensuring the safe HRC assembly. Part-level fusion recognizes the type and pose of parts being assembled with a parallel network that takes an extended Pixel-wise Voting Network (PVNet) as the base architecture, on which assembly sequence/process information of the part could be registered into AR environment to provide smart guidance for manual work to avoid human errors. Eventually, experimental results demonstrate the effectiveness and efficiency of the approach.}
}
@article{LI2023110016,
title = {Constructing a probability digital twin for reactor core with Bayesian network and reduced-order model},
journal = {Annals of Nuclear Energy},
volume = {193},
pages = {110016},
year = {2023},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2023.110016},
url = {https://www.sciencedirect.com/science/article/pii/S0306454923003353},
author = {Wenhuai Li and Jiejin Cai and Haoliang Lu and Junling Wang and Li Cai and Zhihong Tang and Jinggang Li and Chao Wang},
keywords = {Data assimilation, Machine learning, Bayesian neural network, Model order reduction, Digital twins, Reactor core},
abstract = {In constructing a digital twin for a nuclear reactor core, it is important to consider the influence of randomness from various sources. Data assimilation (DA) can combine time distribution observations with dynamic models to approximate the real state of a physical system. Machine learning (ML) and DA share similarities under the Bayesian framework, and using probabilistic ML may provide a way to improve or replace current DA techniques. This paper proposes using a probabilistic ML as Bayesian neural network (BNN) to solve an inverse problem of core monitoring and demonstrates its feasibility through a pressurized water reactor core simulation analysis. Model order reduction technology is also analyzed, and the feasibility and benefit of using it to achieve core monitoring under steady-state conditions is preliminarily verified and discussed. Future work will focus on improving estimation and prediction models under transient operating conditions by unifying DA and ML under the Bayesian framework.}
}
@article{JIANG2023106370,
title = {Graph Neural Networks (GNNs) based accelerated numerical simulation},
journal = {Engineering Applications of Artificial Intelligence},
volume = {123},
pages = {106370},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106370},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623005547},
author = {Chunhao Jiang and Nian-Zhong Chen},
keywords = {Surrogate model, Graph neural networks, Machine learning, Numerical simulation},
abstract = {Finite element method (FEM) based high-fidelity simulation can be computationally demanding and time-consuming as engineering problems become more complicated. It is thus necessary to develop a surrogate model that only requires a small amount of computational time but retains sufficient accuracy. A graph neural network (GNN) based framework is proposed as a general surrogate model for FEM to simulate the Von Mises stress distribution. The mesh body is embedded to a graph and a novel global attribute representation is introduced to capture the geometry and boundary conditions while overcoming the common problem of over smoothing in graph deep learning. The challenge to deal with varying geometry and boundary conditions is overcome by the proposed model and thus it outperforms existing methods such as proper orthogonal decomposition (POD) and greedy algorithm in terms of generalization. Numerical experiments are given to demonstrate the capability of the model developed and the results show that the proposed model not only accurately predicts the stress distribution but also speed-ups hundreds of times faster compared to a FEM-based simulator, enabling real-time structural response analysis for the application of digital twin and structural health monitoring. It is indicated that GNNs can be a powerful tool for resolving complex physical problems, thereby assisting in advancing science and enhancing engineering productivity.}
}
@article{PERNO2023103987,
title = {A machine learning digital twin approach for critical process parameter prediction in a catalyst manufacturing line},
journal = {Computers in Industry},
volume = {151},
pages = {103987},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.103987},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523001379},
author = {Matteo Perno and Lars Hvam and Anders Haug},
keywords = {Digital twin, Machine learning, Industry 4.0, Catalyst, Virtual reality, Process industry},
abstract = {Digital twins (DTs) are rapidly changing how manufacturing companies leverage the large volumes of data they generate daily to gain a competitive advantage and optimize their supply chains. When coupled with recent developments in machine learning (ML), DTs have the potential to generate invaluable insights for process manufacturing companies to help them optimize their manufacturing processes. However, this potential has yet to be fully exploited due to the challenges that process manufacturing companies face in developing and implementing DTs in their organizations. Although DTs are receiving increasing attention in both industry and academia, there is limited literature on how to apply them in the process industry. To address this gap, this paper presents a framework for developing ML-based DTs to predict critical process parameters in real time. The proposed framework is tested through a case study at an international process manufacturing company in which it was used to collect and process plant data, build accurate predictive models for two critical process parameters, and develop a DT application to visualize the models’ predictions. The case study demonstrated the usefulness of the proposed DT–ML framework in the sense that it provided the company with more accurate predictions than the models it previously applied. The study provides insights into the value of applying ML-based DT in the process industry and sheds light on some of the challenges associated with the application of this technology.}
}
@article{ZHAO2023103903,
title = {Super learner ensemble model: A novel approach for predicting monthly copper price in future},
journal = {Resources Policy},
volume = {85},
pages = {103903},
year = {2023},
issn = {0301-4207},
doi = {https://doi.org/10.1016/j.resourpol.2023.103903},
url = {https://www.sciencedirect.com/science/article/pii/S0301420723006141},
author = {Jue Zhao and Shahab Hosseini and Qinyang Chen and Danial {Jahed Armaghani}},
keywords = {Metal prices, Copper prices, Super-learner, SVR, XGBoost, ANN, Cubist},
abstract = {Companies and governments dependent on copper mining need to be able to predict copper prices in order to make important decisions. Despite the nonlinear and nonstationary nature of copper prices, their periods may vary as they fluctuate due to potential growth, cyclical fluctuations and errors. A trend-cycle refers to the combination of trend and cyclical components. Trend-cycles are characterized by different characteristics, which are crucial to making predictions. Therefore, this study focuses on developing and proposing a novel model based on an ensemble machine learning technique to predict monthly copper prices in the future by using different soft computing methods, including multi-layer perception (MLP) neural network, support vector regression (SVR), and extreme gradient boosting (XGBoost). The monthly copper price dataset from August 2001 to August 2021 was gathered for this aim based on the 14 effective parameters. These parameters were selected based on the suggestions of previous research. The main novelty of this study is the development most accurate model to predict monthly copper prices using Cubist algorithm-based super learner model as the new predictive system. The results indicated that the proposed super learner models outperformed of MLP, SVR, and XGBoost models based on the determination coefficient (R-squared), value account for (VAF), root mean square of errors (RMSE), Accuracy (Acc) and Mean Absolute Relative Error (MARE). A comprehensive comparison of different artificial intelligence models demonstrates that MLP neural network is the best model for predicting monthly copper prices. However, the standalone models involving MLP, SVR, and XGBoost, presented higher error with an RMSE in the interval of [278.3826 - 502.6946], and MARE in the interval of [0.056 - 0.1277]. Hence, Cubist-based super learner can be employed as a reliable system to predict monthly copper prices in the future. Besides, this study presents a rational mathematical model based on gene expression programming (GEP) for copper price prediction in future and for use by other researchers. Noteworthy, the final step of the study was sensitivity analysis conducting, which the results revealed that “lead price” and “euro to USD” parameters have respectively the lowest and highest impact on the monthly copper price.}
}
@article{WANG2023107200,
title = {A lightweight crack segmentation network based on knowledge distillation},
journal = {Journal of Building Engineering},
volume = {76},
pages = {107200},
year = {2023},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2023.107200},
url = {https://www.sciencedirect.com/science/article/pii/S2352710223013803},
author = {Wenjun Wang and Chao Su and Guohui Han and Heng Zhang},
keywords = {Crack segmentation, Deep learning, Knowledge distillation, Lightweight network, Channel-wise distillation},
abstract = {This paper presents a novel approach for addressing the challenges of large parameter volumes and high computational complexity in existing deep learning models for crack detection. This method involves training a student model using a pretrained teacher model to guide the learning process. The novelty of the method is the use of channel-wise knowledge distillation to normalize activation maps between the teacher and student models, followed by the minimization of the asymmetric Kullback–Leibler divergence to achieve optimal model performance. By focusing on imitating regions with prominent activation values, the student model achieves accurate crack localization. Test results show that the method improves crack segmentation, based on improvements in the F1_score and intersection over union by 2.17% and 3.55%, respectively, and outperforms other compared knowledge distillation methods. A lightweight crack segmentation model that ensures accuracy and efficiency is established in this study, which can provide an efficient solution for crack segmentation in real-world scenarios.}
}
@article{DEKONING2023916,
title = {Digital twins: dynamic model-data fusion for ecology},
journal = {Trends in Ecology & Evolution},
volume = {38},
number = {10},
pages = {916-926},
year = {2023},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2023.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0169534723000903},
author = {Koen {de Koning} and Jeroen Broekhuijsen and Ingolf Kühn and Otso Ovaskainen and Franziska Taubert and Dag Endresen and Dmitry Schigel and Volker Grimm},
keywords = {digital twins, biodiversity conservation, evidence-based conservation, model-data integration, real-time monitoring, digital conservation},
abstract = {Digital twins (DTs) are an emerging phenomenon in the public and private sectors as a new tool to monitor and understand systems and processes. DTs have the potential to change the status quo in ecology as part of its digital transformation. However, it is important to avoid misguided developments by managing expectations about DTs. We stress that DTs are not just big models of everything, containing big data and machine learning. Rather, the strength of DTs is in combining data, models, and domain knowledge, and their continuous alignment with the real world. We suggest that researchers and stakeholders exercise caution in DT development, keeping in mind that many of the strengths and challenges of computational modelling in ecology also apply to DTs.}
}
@article{LIANG2023108833,
title = {Data-driven digital twin method for leak detection in natural gas pipelines},
journal = {Computers and Electrical Engineering},
volume = {110},
pages = {108833},
year = {2023},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2023.108833},
url = {https://www.sciencedirect.com/science/article/pii/S0045790623002574},
author = {Jing Liang and Li Ma and Shan Liang and Hao Zhang and Zhonglin Zuo and Juan Dai},
keywords = {Digital twin, Leak detection, Natural gas pipeline, Deep learning},
abstract = {Leak detection in natural gas pipelines is an extremely important and persistent problem in the oil and gas industry. The construction of accurate physical models of pipelines is limited by the high complexity, unavailable closed-form solution, and strict experienced personnel requirements. Moreover, industrial automation has the common problems of large amount of data with little information. This paper proposes a data-driven digital twin (DT) method for leak detection as a new paradigm solution to these challenges. From the perspective of knowledge-based data-driven, a DT pipeline learning and updating scheme based on normal data directly from operational data during the entity pipelines life-cycle is proposed to enhance DT adaptability. A DT-driven leak detection method is proposed, making effective use of data interaction and fusion of DT. The effectiveness and performance of the proposed approach is illustrated by deploying the DT pipeline in a simulated leak scenario of a real running natural gas pipeline. © 2012 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of Global Science and Technology Forum Pte Ltd}
}
@article{SOMMER2023100462,
title = {Automated generation of digital twin for a built environment using scan and object detection as input for production planning},
journal = {Journal of Industrial Information Integration},
volume = {33},
pages = {100462},
year = {2023},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2023.100462},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X23000353},
author = {Markus Sommer and Josip Stjepandić and Sebastian Stobrawa and Moritz von Soden},
keywords = {Digital twin, Digital factory, Object recognition, Indoor object acquisition, Simulation, Artificial intelligence},
abstract = {The simulation of production processes using a digital twin can be utilized for prospective planning, analysis of existing systems or process-parallel monitoring. In all cases, the digital twin offers manufacturing companies room for improvement in production and logistics processes leading to cost savings. However, many companies, especially small and medium-sized enterprises, do not apply the technology, because the generation of a digital twin in a built environment is cost-, time- and resource-intensive and IT expertise is required. These obstacles will be overcome by generating a digital twin using a scan of the shop floor and subsequent object recognition. This paper describes the approach with multiple steps, parameters, and data which must be acquired in order to generate a digital twin automatically. It is also shown how the data is processed to generate the digital twin and how object recognition is integrated into it. An overview of the entire process chain is given as well as results in an application case.}
}
@article{DHAKANE2023100264,
title = {A Graph Dynamical neural network approach for decoding dynamical states in ferroelectrics.},
journal = {Carbon Trends},
volume = {11},
pages = {100264},
year = {2023},
issn = {2667-0569},
doi = {https://doi.org/10.1016/j.cartre.2023.100264},
url = {https://www.sciencedirect.com/science/article/pii/S2667056923000196},
author = {Abhijeet Dhakane and Tian Xie and Dundar E. Yilmaz and Adri C.T. van Duin and Bobby G. Sumpter and P. Ganesh},
keywords = {Ferroelectrics, Machine-Learning, Neural-Networks, Digital Twin, Phase-transitions, Domain walls},
abstract = {Ferroelectric materials such as BaTiO3 show tremendous potential for emerging advances in memory devices, particular neuromorphic type devices. High density of memory can be obtained by stabilising polar domain walls at the nanoscale, regions of discontinuity between the well-defined polarization order parameter, but little is known about what controls their structure and dynamics in real nanoscale materials. Indeed, chiral polar domain walls have been observed in heterogeneous ferroelectrics, such as oxygen-deficient BaTiO3, but very little is known about how such polar-domains walls interact with defects. Indeed, a critical understanding of how dynamics of domain-walls depend on point-defects is crucial to create engineered ferroelectric memory devices. We perform large-scale simulations of nansocale domain-wall dynamics in pristine and defective BaTiO3 using reactive force-field developed by us earlier (Phys. Chem. Chem. Phys., 2019, 21, 18240–18249), and capture their dynamical dependence on point defects using a graph dynamical neural-network approach, which we adapted to interrogate solids with well-defined order-parameters, and implemented using Pytorch based libraries. Our machine learning (ML) approach goes beyond the traditional post-processing methods to capture both spatial and temporal heterogeneities of large-scale molecular dynamics simulations of complex defective ferroelectric oxide materials. We crucially find that isolated oxygen vacancies introduce very localized spatial regions (∼ 1–2 unit-cell in length) that show slow dipole relaxation due to formation of defect-dipoles, and that these defect-dipoles in turn slow the intrinsic dynamics of domain walls. Further, the roughness of domain walls, also influenced by vacancies, introduce dynamic heterogeneity along the domain-wall [1]. As such we find a novel mechanism by which quenched disorder due to defects introduce dynamic heterogeneity thereby influencing response to external fields (particularly time varying fields) in a ferroelectric. Our study also emphasizes the need for creating digital twins of dynamical quantities to achieve autonomous in operando control of nanoscale switching.}
}
@article{SHAO2023109781,
title = {Conditional pseudo-supervised contrast for data-Free knowledge distillation},
journal = {Pattern Recognition},
volume = {143},
pages = {109781},
year = {2023},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2023.109781},
url = {https://www.sciencedirect.com/science/article/pii/S003132032300479X},
author = {Renrong Shao and Wei Zhang and Jun Wang},
keywords = {Model compression, Knowledge distillation, Representation learning, Contrastive learning, Privacy protection},
abstract = {Data-free knowledge distillation (DFKD) is an effective manner to solve model compression and transmission restrictions while retaining privacy protection, which has attracted extensive attention in recent years. Currently, the majority of existing methods utilize a generator to synthesize images to support the distillation. Although the current methods have achieved great success, there are still many issues to be explored. Firstly, the outstanding performance of supervised learning in deep learning drives us to explore a pseudo-supervised paradigm on DFKD. Secondly, current synthesized methods cannot distinguish the distributions of different categories of samples, thus producing ambiguous samples that may lead to an incorrect evaluation by the teacher. Besides, current methods cannot optimize the category-wise diversity samples, which will hinder the student model learning from diverse samples and further achieving better performance. In this paper, to address the above limitations, we propose a novel learning paradigm, i.e., conditional pseudo-supervised contrast for data-free knowledge distillation (CPSC-DFKD). The primary innovations of CPSC-DFKD are: (1) introducing a conditional generative adversarial network to synthesize category-specific diverse images for pseudo-supervised learning, (2) improving the modules of the generator to distinguish the distributions of different categories, and (3) proposing pseudo-supervised contrastive learning based on teacher and student views to enhance diversity. Comprehensive experiments on three commonly-used datasets validate the performance lift of both the student and generator brought by CPSC-DFKD. The code is available at https://github.com/RoryShao/CPSC-DFKD.git}
}
@article{GALEAZZI2023108252,
title = {Development of a surrogate model of an amine scrubbing digital twin using machine learning methods},
journal = {Computers & Chemical Engineering},
volume = {174},
pages = {108252},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108252},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423001229},
author = {Andrea Galeazzi and Kristiano Prifti and Carlo Cortellini and Alessandro {Di Pretoro} and Francesco Gallo and Flavio Manenti},
keywords = {Machine-learning, Surrogate modeling, Digital twin, Amine scrubbing, Design of experiments, Latin hypercube},
abstract = {Advancements in the process industry require building more complex simulations and performing computationally intensive operations like optimization. To overcome the numerical limit of conventional process simulations a surrogate model is a viable strategy. In this work, a surrogate model of an industrial amine scrubbing digital twin has been developed. The surrogate model has been built based on the process simulation created in Aspen HYSYS and validated as a digital twin against real process data collected during a steady-state operation. The surrogate relies on an accurate Design of Experiments procedure. In this case, the Latin-Hypercube method has been chosen and several nested domains have been defined in ranges around the nominal steady state operative condition. Several machine learning models have been trained using cross-validation, and the most accurate has been selected to predict each target. The resulting surrogate model showed a satisfactory performance, given the data available.}
}
@article{BRAHMA2023100754,
title = {Learning impact of recent ICT advances based on virtual reality IoT sensors in a metaverse environment},
journal = {Measurement: Sensors},
volume = {27},
pages = {100754},
year = {2023},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2023.100754},
url = {https://www.sciencedirect.com/science/article/pii/S2665917423000909},
author = {Mahul Brahma and M. Anline Rejula and Bhavana Srinivasan and S.N. Kumar and W. Aisha Banu and K. Malarvizhi and S. Sharon Priya and Abhishek Kumar},
keywords = {ICT, Women in technology, Digital twin, IoMT},
abstract = {The use of avatars in the Metaverse and virtual reality technology in education is a rapidly developing field that has the potential to revolutionize the way students learn. In the context of the Indian EdTech market, virtual reality could play a significant role in enhancing the learning experience for students, although more research is needed to explore its full potential.ICT has already made a significant impact on education, with academic programming, technical instruction, and theoretical concepts being taught through digital platforms. Virtual reality has the potential to take this a step further, allowing students to experience immersive and interactive learning environments that simulate real-world scenarios.However, as mentioned in the paragraph, there is still limited research on the use of virtual reality in education, particularly in the Indian context. Further studies are needed to assess the effectiveness of this technology and ensure that it can be integrated effectively into the educational system.Overall, the use of virtual reality in education is an exciting development in the ICT industry and has the potential to make a significant impact on the learning experience for students. Various non-governmental organizations (NGOs) seek to improve women's lives and provide them with self-sufficiency training. The government is likewise concerned about this issue and has established a number of programs to assist women. Information and communication technology (ICT) is significant in this context. ICT has improved the security, knowledge, education, employability, confidence, and popularity of women. The significance of ICT for the empowerment of women is highlighted in this study. To illuminate the various facets of ICT's impact on society, various examples have been addressed. Because of ICT, new generations of women all over the globe have defied all expectations and proven themselves in every aspect of life, even the most complicated and time-consuming realm of enterprise. In this regard, ICT may possibly become a magic wand for improving women's current situations. In this research, the eight factors that influence how ICT affects rural women's empowerment were found.}
}
@article{XU2023110139,
title = {Deep-learning-enhanced digital twinning of complex composite structures and real-time mechanical interaction},
journal = {Composites Science and Technology},
volume = {241},
pages = {110139},
year = {2023},
issn = {0266-3538},
doi = {https://doi.org/10.1016/j.compscitech.2023.110139},
url = {https://www.sciencedirect.com/science/article/pii/S0266353823002324},
author = {Xiaoyao Xu and Guowen Wang and Han Yan and Laibin Zhang and Xuefeng Yao},
keywords = {Digital twin, Machine learning, Fabric rubber composites, Anisotropy, Mechanical properties},
abstract = {Digital twins are undergoing growth that enables highly informative and scaleable interaction between physical objects and virtual twins, which is of great significance to the life cycle analysis of composites. Real-time fine evolution is challenging due to vast combinations of input features and high-resolution calculated variables. Here, we systematically demonstrate an AI-based methodology for digital twinning of complex composite structures. First, three types of deep neural networks are created with optionally used autoencoders as surrogate models, with architectures and data processing inspired by the rule-of-mixture of composites. Second, the prediction accuracy and efficiency are evaluated quantitatively and qualitatively, demonstrating the feasibility of predicting 3D displacement and stress fields directly from sensing data of temperature, pressure and loading displacement, and the optimal architecture is selected to be the evolving digital twin. Finally, the real-time interactive experiments are relayed to the digital twin and demonstrated that it can interact with physical objects and evolve online with high accuracy. These results indicate that the computational time can be reduced by 3∼6 orders of magnitude with high information intensity and scalability compared with conventional numerical and experimental methods, which opens up the avenues for the cost-effective and efficient development of digital twin services for composites.}
}
@article{KLASS2023233308,
title = {Lifelong performance monitoring of PEM fuel cells using machine learning models},
journal = {Journal of Power Sources},
volume = {580},
pages = {233308},
year = {2023},
issn = {0378-7753},
doi = {https://doi.org/10.1016/j.jpowsour.2023.233308},
url = {https://www.sciencedirect.com/science/article/pii/S0378775323006845},
author = {Lukas Klass and Alexander Kabza and Frank Sehnke and Katharina Strecker and Markus Hölzle},
keywords = {Fuel cells, Performance monitoring, Artificial intelligence, Machine learning, Digital twin, LSTM},
abstract = {The development of fuel cells highly depends on the reliable operation of fuel cells on test benches for testing purposes. Even though the test bench’s control software contains an alarm module, it is only able to detect the most extreme failures due to the widespread operating parameter range of a fuel cell. This paper presents a novel machine learning based approach to monitor the operation of fuel cell stacks on a test bench and thereby ensuring the proper conduction of the tests. Methods for monitoring the operating conditions set by the test bench using clustering as well as methods to monitor the fuel cell’s performance using digital twins are proposed. The developed methods are applied on real testing data to demonstrate their ability to detect even slight deviations that remained undiscovered to the state of the art monitoring system of the test bench. After automating, the proposed methods allow a more sensitive monitoring of the fuel cell operation on test benches leading to more usable data and clearer test results and thereby speeding up the development of fuel cells.}
}
@article{MULLERZHANG2023103933,
title = {Towards live decision-making for service-based production: Integrated process planning and scheduling with Digital Twins and Deep-Q-Learning},
journal = {Computers in Industry},
volume = {149},
pages = {103933},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.103933},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523000830},
author = {Zai Müller-Zhang and Thomas Kuhn and Pablo Oliveira Antonino},
keywords = {Digital Twin, Reinforcement Learning, Deep-Q-Network integrated process planning and scheduling, Smart manufacturing},
abstract = {Production flow is becoming increasingly complex since manufacturers must react quickly to changing markets demands and diverse customer requirements. In order to ensure production efficiency, it is essential to have an adequate scheduling system capable of managing diverse process flows and handling unforseen changes. In this paper, we present an approach leveraging Digital Twins (DTs) and Deep-Q-Learning to perform integrated process planning and scheduling for service-based production. DTs of production assets provide live information about their physical entities for our approach to perform live decision-making based on the current operation conditions. We use Deep-Q-Learning which is a deep Reinforcement Learning (RL) algorithm to perform integrated process planning and scheduling. We present two RL-designs that deal with different situations of live decision-making. We have evaluated the learning efficiency and scalability of the RL-designs on a virtual aluminum cold rolling mill developed by the SMS Group,11https://www.sms-group.com/plants/cold-rolling-mills-for-aluminum. in the context of the BaSys 4.2 project.22https://www.eclipse.org/research/projects/basys_42/. The results show that the first RL-design is suitable for deriving schedules for individualized production with small lots where process plans must be re-calculated frequently, while the second RL-design is optimal for production with large job quantities where jobs arrive continuously.}
}
@article{WANG2023115027,
title = {Lifetime prediction of electronic devices based on the P-stacking machine learning model},
journal = {Microelectronics Reliability},
volume = {146},
pages = {115027},
year = {2023},
issn = {0026-2714},
doi = {https://doi.org/10.1016/j.microrel.2023.115027},
url = {https://www.sciencedirect.com/science/article/pii/S0026271423001270},
author = {Fei Wang and Ye Yang and Tao Huang and Yang Xu},
keywords = {Stacking algorithm, Pearson correlation analysis, Machine learning, IGBT device, Lithium-ion battery, Lifetime prediction},
abstract = {Nowadays the data-driven artificial intelligence (AI) and machine learning (ML) provide novel approaches for the effective lifetime prediction of the electronic devices with complicated mechanisms and multiple controlling factors. However, the existing ML prediction models cannot process both high accuracy and high efficiency at the meantime. To address this problem, this paper proposes the new P-Stacking ML algorithm model, which combines the Pearson correlation analysis and the Stacking multi-model fusion. The Pearson correlation analysis is first applied to select the multiple base learner models with weak correlations for the following Stacking multi-model fusion. Two neutral network layers are built to perform the Stacking algorithm. In this work, two distinct types of electronic devices are utilized to verify the effectiveness of the P-Stacking ML model, which are the IGBT devices and the lithium-ion batteries respectively. For the IGBT lifetime prediction, the results have shown that compared with the long-term and short-term memory neural network (LSTM) model in the previous literature, the mean square error (MSE) of the P-Stacking ML model is improved by 6 %, and the average model training time is reduced by 90 %. Moreover, for the lithium batteries, the lifetime prediction accuracy of the P-Stacking model is increased by 65 %, and the training time is decreased by 90 %. The results demonstrated that the P-Stacking ML model can significantly improve both the prediction accuracy and efficiency simultaneously.}
}
@article{CURRIE2023108337,
title = {The emerging role of artificial intelligence and digital twins in pre-clinical molecular imaging},
journal = {Nuclear Medicine and Biology},
volume = {120-121},
pages = {108337},
year = {2023},
issn = {0969-8051},
doi = {https://doi.org/10.1016/j.nucmedbio.2023.108337},
url = {https://www.sciencedirect.com/science/article/pii/S0969805123000240},
author = {Geoffrey M. Currie},
keywords = {Molecular imaging, Deep learning, Artificial intelligence, Digital twin, Mouse twin},
abstract = {Introduction
Pre-clinical molecular imaging, particularly with mice, is an essential part of drug and radiopharmaceutical development. There remain ethical challenges to reduce, refine and replace animal imaging where possible.
Method
A number of approaches have been adopted to reduce the use of mice including using algorithmic approaches to animal modelling. Digital twins have been used to create a virtual model of mice, however, exploring the potential of deep learning approaches to digital twin development may enhance capabilities and application in research.
Results
Generative adversarial networks produce generated images that sufficiently resemble reality that they could be adapted to create digital twins. Specific genetic mouse models have greater homogeneity making them more receptive to modelling and suitable specifically for digital twin simulation.
Conclusion
There are numerous benefits of digital twins in pre-clinical imaging including improved outcomes, fewer animal studies, shorter development timelines and lower costs.}
}
@article{RATHNASIRI2023102085,
title = {Data-driven approaches to built environment flood resilience: A scientometric and critical review},
journal = {Advanced Engineering Informatics},
volume = {57},
pages = {102085},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102085},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623002136},
author = {Pavithra Rathnasiri and Onaopepo Adeniyi and Niraj Thurairajah},
keywords = {Built assets, Data-driven, Computational methods, Community, Environment, Flood, Resilience, Society},
abstract = {Environmental hazards such as floods significantly frustrate the functionality of built assets. In addressing flood-induced challenges, data usage has become important. Despite existing vast flood-related research, no research has presented a comprehensive insight into global studies on data-driven built environment flood resilience. Hence, this study conducted a comprehensive review of data-driven approaches to flood resilience. Scientometric analysis revealed emerging countries, authorships, keywords, and research hotspots. The critical review revealed data-centric approaches such as Machine Learning (ML), Artificial Intelligence (AI), Flood Simulations, Bayesian Modelling, Building Information Modelling (BIM) and Geographic Information Systems (GIS). However, they were mainly deployed in hydraulic flood simulations for prediction, monitoring, risk, and damage assessments. Further, the potentials of computational methods in tackling built environment resilience challenges were identified. Deploying the approaches in the future requires a better understanding of the status quo. These methods include hybrid data-driven approaches, ontology-based knowledge representation, multiscale modelling, knowledge graphs, blockchain technology, convolutional neural networks, automated approaches integrated with social media data, data assimilation, BIM models linked with sensors and satellite imagery and ML and AI-based digital twin models. Nevertheless, reference to data-informed built-asset resilience decisions and clear-cut implications on built-asset resilience improvement remain indistinct in many studies. This suggests that more opportunities exist to contextualise data for built environment flood resilience. This study concluded with a conceptual map of flood context, methodologies, data types engaged, and future computational methods with directions for future research.}
}
@article{DRAKOULAS2023116155,
title = {FastSVD-ML–ROM: A reduced-order modeling framework based on machine learning for real-time applications},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {414},
pages = {116155},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2023.116155},
url = {https://www.sciencedirect.com/science/article/pii/S0045782523002797},
author = {G.I. Drakoulas and T.V. Gortsas and G.C. Bourantas and V.N. Burganos and D. Polyzos},
keywords = {Reduced order modeling, Machine learning, Parameterized PDEs, Digital twins},
abstract = {Digital twins have emerged as a key technology for optimizing the performance of engineering products and systems. High-fidelity numerical simulations constitute the backbone of engineering design, providing insight into the performance of complex systems. However, large-scale, dynamic, non-linear models require significant computational resources and are prohibitive for real-time digital twin applications. To this end, reduced order models (ROMs) are employed, to approximate the high-fidelity solutions while accurately capturing the dominant aspects of the physical behavior. The present work proposes a new machine learning (ML) platform for the development of ROMs to handle large-scale numerical problems dealing with transient nonlinear partial differential equations. Our framework, named as FastSVD-ML-ROM, utilizes (i) a singular value decomposition (SVD) update methodology, to compute a linear subspace of the multi-fidelity solutions during the simulation process, (ii) convolutional autoencoders for nonlinear dimensionality reduction, (iii) feed-forward neural networks to map the input parameters to the latent spaces, and (iv) long–short term memory networks to predict and forecast the dynamics of parametric solutions. The efficiency of the FastSVD-ML-ROM framework is demonstrated for a 2D linear convection–diffusion benchmark, the problem of fluid flow around a cylinder, the 2D lid-driven cavity problem at high Reynolds numbers, and the 3D blood flow inside an arterial segment. The accuracy of the reconstructed results indicates the robustness of the proposed approach.}
}
@article{YAZICI2023101455,
title = {A survey of applications of artificial intelligence and machine learning in future mobile networks-enabled systems},
journal = {Engineering Science and Technology, an International Journal},
volume = {44},
pages = {101455},
year = {2023},
issn = {2215-0986},
doi = {https://doi.org/10.1016/j.jestch.2023.101455},
url = {https://www.sciencedirect.com/science/article/pii/S2215098623001337},
author = {İbrahim Yazici and Ibraheem Shayea and Jafri Din},
keywords = {Cyber security, Deep learning, Digital twin, Intelligent transportation systems, Reinforcement learning, Smart energy, Smart healthcare, Supervised learning, Unsupervised learning, Unmanned Aerial Vehicle (UAV), 5G, 6G},
abstract = {Different fields have been thriving with the advents in mobile communication systems in recent years. These fields reap benefits of data collected by Internet of Things (IoT) in next generation (5G and 5BG) mobile networks. The IoT concept transforms different fields by providing large amount of data to be used in their operations. This is achieved by massively utilized sensors and mobile devices that acquire data from internet connected devices to keep track of physical systems. Hence, different use cases benefit from the data generated thanks to future mobile network systems. Intelligent Transportation Systems, Smart Energy, Digital Twins, Unmanned Aerial Vehicles (UAVs), Smart Health, Cyber Security are of significant use cases that big data plays an important role for them. Large amount of data entails more intelligent systems with respect to conventional methods, and it also entails highly reduced response time for use cases. Artificial intelligence and machine learning models are adept in satisfying the requirements of this big data situations for different use cases. In this sense, this paper provides a survey of machine learning and artificial intelligence applications for different use cases enabled by future mobile communication systems. An overview of machine learning types and artificial intelligence is presented to provide insights into the intelligent method concepts. Available studies are extensively summarized, and they are also grouped to provide a complete overview of the study. Discussions on the reviewed papers based on artificial intelligence and machine learning concepts are made, and some descriptive figures about the results of the discussions are also given in the paper. Finally, research challenges for artificial intelligence and machine learning applications in the use cases are introduced, future research directions and concluding remarks are presented accordingly.}
}
@article{DEWILDE2023113171,
title = {Building performance simulation in the brave new world of artificial intelligence and digital twins: A systematic review},
journal = {Energy and Buildings},
volume = {292},
pages = {113171},
year = {2023},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2023.113171},
url = {https://www.sciencedirect.com/science/article/pii/S0378778823004012},
author = {Pieter {de Wilde}},
keywords = {Digital twin, Machine learning, Artificial intelligence, Cyber-physical system, Internet of things, Data mining, Building performance simulation},
abstract = {In an increasingly digital world, there are fast-paced developments in fields such as Artificial Intelligence, Machine Learning, Data Mining, Digital Twins, Cyber-Physical Systems and the Internet of Things. This paper reviews and discusses how these new emerging areas relate to the traditional domain of building performance simulation. It explores the boundaries between building simulation and these other fields in order to identify conceptual differences and similarities, strengths and limitations of each of these areas. The paper critiques common notions about these new domains and how they relate to building simulation, reviewing how the field of building performance may evolve and benefit from the new developments.}
}
@article{ZHU2023106735,
title = {A review of distributed energy system optimization for building decarbonization},
journal = {Journal of Building Engineering},
volume = {73},
pages = {106735},
year = {2023},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2023.106735},
url = {https://www.sciencedirect.com/science/article/pii/S2352710223009142},
author = {Xiaoyu Zhu and Xingxing Zhang and Pu Gong and Yu Li},
keywords = {DES, Building decarbonization, Energy optimization, Digital twin, Smart cities},
abstract = {Building energy consumption has increased rapidly in the past decade, in particular for heat demand and electric vehicles, owning to the development of economy and improvement of living standard. Distributed Energy Systems (DESs), which can effectively improve the share of renewable energy in the energy mix, lower the energy cost and reduce environmental impact, is a promising approach to meet the increased energy demand. This paper presents a review of the system architecture of DESs for building decarbonization, including hybrid energy systems, energy storage technologies, building flexible loads, and electric vehicles. The uncertainties from both the environment and human interventions challenge the energy management due to the asynchrony between energy generation and energy consumption. Thus, the system should be optimally designed and operated to enhance the reliability, affordability, and flexibility of the DES. The paper highlights the adoption of optimization approaches. Finally, future trends and challenges are discussed. It is concluded that the digital transformation featured with IoT, AI, advanced machine learning, sophisticated optimization approaches, and Blockchain is the enabler for future smart cities.}
}
@article{ABDI2023107376,
title = {Modeling of capacitance for carbon-based supercapacitors using Super Learner algorithm},
journal = {Journal of Energy Storage},
volume = {66},
pages = {107376},
year = {2023},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2023.107376},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X23007739},
author = {Jafar Abdi and Tahereh Pirhoushyaran and Fahimeh Hadavimoghaddam and Seyed Ali Madani and Abdolhossein Hemmati-Sarapardeh and Seyyed Hamid Esmaeili-Faraj},
keywords = {Carbon-based materials, Capacitance prediction, Supercapacitors, Super Learner model, Sensitivity analysis},
abstract = {Due to some specifications such as high capacitance and power density, electrostatic double-layer capacitors (EDLCs) are more noticeable than other supercapacitors. Some physical and chemical properties, surface functional groups, and testing conditions affect the efficiency and in particular the capacitance of EDLCs with carbon-based electrodes. In this study, four machine learning models, including Super Learner (SL), Extremely Randomized Trees (Extra trees), Extreme learning machine (ELM), and Multivariate adaptive regression splines (MARS) were implemented to predict the EDLCs' capacitance based on different impressive properties. A large dataset was assigned to the 121 different carbonaceous electrodes collected under various conditions, including 13 physical and chemical properties: voltage window (V), specific surface area (SSA) and SSA of micropore, pore volume (PV), and micropore volume, the ratio of D-band and G-band (Id/Ig) and doping elements (inputs parameters). The results indicated that the SL model with the R2 values of 0.9781, 0.9717, and 0.9768 for training, testing, and total dataset, respectively, and the RSME value of 18.099 was the most accurate model in comparison with the others. Indeed, the sensitivity analysis results exhibited that SSA with the relevance factor of 0.323 is the most important feature in the capacitance of carbon-based electrodes, while the presence of boron, sulfur, fluorine, phosphorus doping elements and pore size can be ignored.}
}
@article{XIE2023100053,
title = {Federated selective aggregation for on-device knowledge amalgamation},
journal = {Chip},
volume = {2},
number = {3},
pages = {100053},
year = {2023},
issn = {2709-4723},
doi = {https://doi.org/10.1016/j.chip.2023.100053},
url = {https://www.sciencedirect.com/science/article/pii/S2709472323000163},
author = {Donglin Xie and Ruonan Yu and Gongfan Fang and Jiaqi Han and Jie Song and Zunlei Feng and Li Sun and Mingli Song},
keywords = {Federated learning, Knowledge amalgamation, Model reusing},
abstract = {ABSTRACT
In the current work, we explored a new knowledge amalgamation problem, termed Federated Selective Aggregation for on-device knowledge amalgamation (FedSA). FedSA aims to train an on-device student model for a new task with the help of several decentralized teachers whose pre-training tasks and data are different and agnostic. The motivation to investigate such a problem setup stems from a recent dilemma of model sharing. Due to privacy, security or intellectual property issues, the pre-trained models are, however, not able to be shared, and the resources of devices are usually limited. The proposed FedSA offers a solution to this dilemma and makes it one step further, again, the method can be employed on low-power and resource-limited devices. To this end, a dedicated strategy was proposed to handle the knowledge amalgamation. Specifically, the student-training process in the current work was driven by a novel saliency-based approach which adaptively selects teachers as the participants and integrated their representative capabilities into the student. To evaluate the effectiveness of FedSA, experiments on both single-task and multi-task settings were conducted. The experimental results demonstrate that FedSA could effectively amalgamate knowledge from decentralized models and achieve competitive performance to centralized baselines.}
}
@article{CHEN2023102581,
title = {Multisensor fusion-based digital twin for localized quality prediction in robotic laser-directed energy deposition},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {84},
pages = {102581},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102581},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000571},
author = {Lequn Chen and Guijun Bi and Xiling Yao and Chaolin Tan and Jinlong Su and Nicholas Poh Huat Ng and Youxiang Chew and Kui Liu and Seung Ki Moon},
keywords = {Additive Manufacturing, In-situ defect detection, Laser-directed energy deposition, Machine learning, Multisensor fusion},
abstract = {Early detection of defects, such as keyhole pores and cracks is crucial in laser-directed energy deposition (L-DED) additive manufacturing (AM) to prevent build failures. However, the complex melt pool behaviour cannot be adequately captured by conventional single-modal process monitoring approaches. This study introduces a multisensor fusion-based digital twin (MFDT) for localized quality prediction in the robotic L-DED process. The data used in multisensor fusion includes features extracted from a coaxial melt pool vision camera, a microphone, and an off-axis short wavelength infrared thermal camera. The key novelty of this work is a spatiotemporal data fusion method that synchronizes multisensor features with the real-time robot motion data to achieve localized quality prediction. Optical microscope (OM) images of the printed part are used to locate defect-free and defective regions (i.e., cracks and keyhole pores), which serve as ground truth labels for training supervised machine learning (ML) models for quality prediction. The trained ML model is then used to generate a virtual quality map that registers quality prediction outcomes within the 3D volume of the printed part, thus eliminating the need of physical inspections by destructive methods. Experiments show that the virtual quality map closely matches the actual quality observed by OM. Compared to traditional single-sensor-based quality prediction, the MFDT has achieved a significantly higher quality prediction accuracy (96%), a higher ROC-AUC score (99%), and a lower false alarm rate (4.4%). As a result, the MFDT is a more reliable method for defect prediction. The proposed MFDT also lays the groundwork for our future development of a self-adaptive hybrid processing strategy that combines machining with AM for defect removal and quality improvement.}
}
@article{CEVALLOS2023105510,
title = {Towards a more accurate characterization of granular media 2.0: Involving AI in the process},
journal = {Computers and Geotechnics},
volume = {160},
pages = {105510},
year = {2023},
issn = {0266-352X},
doi = {https://doi.org/10.1016/j.compgeo.2023.105510},
url = {https://www.sciencedirect.com/science/article/pii/S0266352X23002677},
author = {Stefano Buitrón Cevallos and Alex X. Jerves and Utkarsh Mital and David A. Medina and V. Santiago Quinteros and Maurizio Mulas and Øyvind Torgersrud},
keywords = {Granular materials, x-ray-CT scanning, Image processing, Level set, Convolutional neural network, Virtual laboratory testing},
abstract = {We introduce a Convolutional Neural Network (CNN) to reduce grains’ manual inspection time after image processing on raw 3D x-ray computed tomography (3DXRCT) images from a sample of granular material to obtain level-set function-based digital twins of individual grains. The CNN automatically distinguishes properly segmented digital grains with up to 90% of accuracy. This algorithm is trained using, ground-truth, level set-based digital grain representations from a natural soil sampled at Jaramijó (Ecuador). The implemented convolutional neural network provides groundbreaking processing power, reducing the, otherwise, manual inspection time expended for a small sample, e.g., 200 000 grains, from approximately a couple of weeks to only a few hours. Furthermore, transfer learning and training from scratch are compared for artificially graded granular materials such as Øysand (Norway) and Hostun sand (France). The CNN’s learning process is interpreted by means of grain morphological parameters, i.e., sphericity, roundness, grain diameter, and volume-surface ratio. Hence, being able to automatically segment a greater amount of grains from 3DXRCT images of natural and artificial soils in a short period of time, enables us, for first time, to perform actual 3DLS-DEM-based virtual laboratory testing (a plug-and-play one-stop shop). Providing unprecedented and unique data for engineering applications.}
}
@article{SITAPURE2023108339,
title = {CrystalGPT: Enhancing system-to-system transferability in crystallization prediction and control using time-series-transformers},
journal = {Computers & Chemical Engineering},
volume = {177},
pages = {108339},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108339},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423002090},
author = {Niranjan Sitapure and Joseph Sang-Il Kwon},
keywords = {Time-series-transformers (TST), Transfer learning, System-to-system transferability, Digital twins, Model predictive controller (MPC)},
abstract = {For prediction and real-time control tasks, machine-learning (ML)-based digital twins are frequently employed. However, while these models are typically accurate, they are custom-designed for individual systems, making system-to-system (S2S) transferability difficult. This occurs even when substantial similarities exist in the process dynamics across different chemical systems. To address this challenge, we developed a novel time-series-transformer (TST) framework that exploits the powerful transfer learning capabilities inherent in transformer algorithms. This was demonstrated using readily available process data obtained from different crystallizers operating under various operational scenarios. Using this extensive dataset, we trained a TST model (CrystalGPT) to exhibit remarkable S2S transferability not only across all pre-established systems, but also to an unencountered system. CrystalGPT achieved a cumulative error across all systems, which is eight times superior to that of existing ML models. Additionally, we coupled CrystalGPT with a model predictive controller to reduce the variance in setpoint tracking to just 1%.}
}
@article{SUN2023109404,
title = {Deep learning framework for gas turbine performance digital twin and degradation prognostics from airline operator perspective},
journal = {Reliability Engineering & System Safety},
volume = {238},
pages = {109404},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109404},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023003186},
author = {Jianzhong Sun and Zichen Yan and Ying Han and Xinyun Zhu and Caiqiong Yang},
keywords = {Gas turbine, Performance degradation, Digital twin, Prognostics, N-CMAPSS},
abstract = {Digital twin technology has emerged as a research hotspot in the field of intelligent operation and maintenance of gas turbines. This paper proposes a data-driven Digital Twin approach for gas turbine performance monitoring and degradation prognostics from an airline operator perspective. The framework adopts a semi-supervised deep learning method to construct a data-driven Performance Digital Twin (PDT) rather than a physics-based performance model. The PDT-derived multi-dimensional health features is used to characterize the performance degradation and enhance the input features for the prognostics network. Specifically, domain knowledge from the asset operator perspective is incorporated into the prognostics model to improve the performance. The proposed approach is evaluated on real-world turbofan engines and the NCMAPSS dataset, achieving promising results compared to the state-of-art approaches. The developed data-driven prognostics framework provides a low-cost alternative to an expensive physics-based prognostics approach for gas turbine operators. It enables asset users to implement their own data-driven prognostics and maintenance strategies.}
}
@article{CANCEMI2023112502,
title = {Unsupervised anomaly detection in pressurized water reactor digital twins using autoencoder neural networks},
journal = {Nuclear Engineering and Design},
volume = {413},
pages = {112502},
year = {2023},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2023.112502},
url = {https://www.sciencedirect.com/science/article/pii/S0029549323003515},
author = {S.A. Cancemi and R. {Lo Frano} and C. Santus and T. Inoue},
keywords = {Neural Network, Autoencoder, Predictive Maintenance, Safety, NPP, Unsupervised Anomaly Detection, LOCA},
abstract = {Deep learning (DL), that is becoming quite popular for prediction and analysis of complex patterns in large amounts of data is used to investigate the safety behaviour of the nuclear plant items. This is achieved by using multiple layers of artificial neural networks to process and transform input data, allowing for the creation of highly accurate predictive models. Particularly to the aim the unsupervised machine learning approach and the digital twin concept in form of pressurized water reactor 2-loop simulator are used. This innovative methodology is based on neural network algorithm that makes capable to predict failures of plant structure, system, and components earlier than the activation of safety and emergency systems. Moreover, to match the objective of the study several scenarios of loss of cooling accident (LOCA) of different break size were simulated. To make the acquisition platform realistic, Gaussian noise was added to the input signals. The neural network has been fed by synthetic dataset provide by PCTRAN simulator and the efficiency in event identification was studied. Further, due to the very limited studies on the unsupervised anomaly detection by means of autoencoder neural networks applied for plant monitoring and surveillance, the methodology has been validated with experimental data from resonant test rig designed for fatigue testing of tubular components. The obtained results demonstrate the reliability and the efficiency of the methodology in detecting anomalous events prior the activation of safety system. Particularly, if the difference between the expected readings and the collected data goes beyond the predetermined threshold, then the anomalous event is identified, e.g., the model detected anomalies up to 38 min before the reactor scram intervention.}
}
@article{ZAKIRHOSSAIN2023128646,
title = {Modeling of microbial fuel cell power generation using machine learning-based super learner algorithms},
journal = {Fuel},
volume = {349},
pages = {128646},
year = {2023},
issn = {0016-2361},
doi = {https://doi.org/10.1016/j.fuel.2023.128646},
url = {https://www.sciencedirect.com/science/article/pii/S0016236123012590},
author = {S.M. {Zakir Hossain} and Nahid Sultana and Shaker Haji and Shaikha {Talal Mufeez} and Sara {Esam Janahi} and Noof {Adel Ahmed}},
keywords = {Electricity generation, Fuel cell, Bayesian algorithm, Response surface methodology, Support vector regression, Boosted regression tree},
abstract = {Electricity generation from microbial fuel cells (MFCs) is a potential environment-friendly technology. This study provides Bayesian Algorithm (BA) based Support Vector Regression (SVR) and Boosted Regression Tree (BRT) as prospective super learner modeling tools (BA-SVR, BA-BRT) for predictions of electricity production from MFCs. The membrane thickness, external resistance, and anode area were considered independent variables, while power generation was taken as a response variable. The key novelties of this study include (i) hybridization of BA with SVR and BRT (separately) for forecasting power generation from fuel cells for the first time, (ii) performance comparison of the developed models (BA-SVR and BA-BRT) with the existing Response Surface Methodology (RSM) based on the coefficient of determination (R2), relative error (RE), mean absolute error (MAE), mean absolute percentage error (MAPE), root mean square error (RMSE), and computing efficiency, and the (iii) analysis of the models’ robustness by utilizing Gaussian white noise. Based on the performance indicators, the proposed super leaner models showed excellent performance compared to the existing M.J. Salar-García et al. RSM model. The BA-SVR model provided the lowest errors (MAE of 2.94, RSME of 7.2926, MAPE of 13.8341) with the highest R2 of 0.9981, compared to the BA-BRT and RSM models. The proposed BA-SVR model showed superior performance to the RSM and BA-BRT models in predicting the MFCs’ power generation, with a performance improvement of more than 90% regarding MAPE, as an example. The future prediction and high robustness of the proposed super learner model would ensure quick estimation for maximization of electricity generation that may lead to reducing massive lab trials and saving resources.}
}
@article{KEKIC2023100739,
title = {Evaluating vaccine allocation strategies using simulation-assisted causal modeling},
journal = {Patterns},
volume = {4},
number = {6},
pages = {100739},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100739},
url = {https://www.sciencedirect.com/science/article/pii/S266638992300079X},
author = {Armin Kekić and Jonas Dehning and Luigi Gresele and Julius {von Kügelgen} and Viola Priesemann and Bernhard Schölkopf},
keywords = {COVID-19, causality, vaccine, SEIR model, vaccine allocation, modeling},
abstract = {Summary
We develop a model to retrospectively evaluate age-dependent counterfactual vaccine allocation strategies against the coronavirus disease 2019 (COVID-19) pandemic. To estimate the effect of allocation on the expected severe-case incidence, we employ a simulation-assisted causal modeling approach that combines a compartmental infection-dynamics simulation, a coarse-grained causal model, and literature estimates for immunity waning. We compare Israel’s strategy, implemented in 2021, with counterfactual strategies such as no prioritization, prioritization of younger age groups, or a strict risk-ranked approach; we find that Israel’s implemented strategy was indeed highly effective. We also study the impact of increasing vaccine uptake for given age groups. Because of its modular structure, our model can easily be adapted to study future pandemics. We demonstrate this by simulating a pandemic with characteristics of the Spanish flu. Our approach helps evaluate vaccination strategies under the complex interplay of core epidemic factors, including age-dependent risk profiles, immunity waning, vaccine availability, and spreading rates.}
}
@article{CHE20231405,
title = {Opportunities for battery aging mode diagnosis of renewable energy storage},
journal = {Joule},
volume = {7},
number = {7},
pages = {1405-1407},
year = {2023},
issn = {2542-4351},
doi = {https://doi.org/10.1016/j.joule.2023.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S2542435123002647},
author = {Yunhong Che and Xiaosong Hu and Remus Teodorescu},
abstract = {Lithium-ion batteries are key energy storage technologies to promote the global clean energy process, particularly in power grids and electrified transportation. However, complex usage conditions and lack of precise measurement make it difficult for battery health estimation under field applications, especially for aging mode diagnosis. In a recent issue of Nature Communications, Dubarry et al. shed light on this issue by investigating the solution based on machine learning and battery digital twins. They achieved aging modes diagnosis of photovoltaics-connected batteries working for 2 years with more than 10,000 degradation paths under different seasons and cloud shading conditions.}
}
@article{LANDERS2023113738,
title = {TEMGYM Advanced: Software for electron lens aberrations and parallelised electron ray tracing},
journal = {Ultramicroscopy},
volume = {250},
pages = {113738},
year = {2023},
issn = {0304-3991},
doi = {https://doi.org/10.1016/j.ultramic.2023.113738},
url = {https://www.sciencedirect.com/science/article/pii/S0304399123000554},
author = {David Landers and Ian Clancy and Rafal E. Dunin-Borkowski and Dieter Weber and Andrew Stewart},
keywords = {Ray Tracing, Parallelisation, Differential Algebra, Aberration Integral, NanoMi},
abstract = {Characterisation of the electron beams trajectory in an electron microscope is possible in a few select commercial software packages, but these tools and their source code are not available in a free and accessible manner. This paper introduces the free and open-source software TEMGYM Advanced, which implements ray tracing methods that calculate the path of electrons through a magnetic or electrostatic lens and allow evaluation of the first-order properties and third-order geometric aberrations. Validation of the aberration coefficient calculations is performed by implementing two independent methods – the aberration integral and differential algebra (DA) methods and by comparing the results of each. This paper also demonstrates parallelised electron ray tracing through a series of magnetic components, which enables near real-time generation of a physically accurate beam-spot including aberrations and brings closer the realisation of a digital twin of an electron microscope. TEMGYM Advanced represents a valuable resource for the electron microscopy community, providing an accessible and open source means of characterising electron lenses. This software utilises the Python programming language to complement the growing ecosystem of free and open-source software within the electron microscopy community, and to facilitate the application of machine learning to an electron microscope digital twin for instrument automation. The software is available under GNU Public License number Three (GPL 3).}
}
@article{CUI2023100732,
title = {Long-sequence voltage series forecasting for internal short circuit early detection of lithium-ion batteries},
journal = {Patterns},
volume = {4},
number = {6},
pages = {100732},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100732},
url = {https://www.sciencedirect.com/science/article/pii/S2666389923000727},
author = {Binghan Cui and Han Wang and Renlong Li and Lizhi Xiang and Jiannan Du and Huaian Zhao and Sai Li and Xinyue Zhao and Geping Yin and Xinqun Cheng and Yulin Ma and Hua Huo and Pengjian Zuo and Guokang Han and Chunyu Du},
keywords = {lithium-ion battery, internal short circuit detection, voltage prediction, power prediction, time-series forecasting, deep learning, encoder-decoder, attention model},
abstract = {Summary
Accurate early detection of internal short circuits (ISCs) is indispensable for safe and reliable application of lithium-ion batteries (LiBs). However, the major challenge is finding a reliable standard to judge whether the battery suffers from ISCs. In this work, a deep learning approach with multi-head attention and a multi-scale hierarchical learning mechanism based on encoder-decoder architecture is developed to accurately forecast voltage and power series. By using the predicted voltage without ISCs as the standard and detecting the consistency of the collected and predicted voltage series, we develop a method to detect ISCs quickly and accurately. In this way, we achieve an average percentage accuracy of 86% on the dataset, including different batteries and the equivalent ISC resistance from 1,000 Ω to 10 Ω, indicating successful application of the ISC detection method.}
}
@article{CHEN2023120519,
title = {Consistency- and dependence-guided knowledge distillation for object detection in remote sensing images},
journal = {Expert Systems with Applications},
volume = {229},
pages = {120519},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120519},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423010217},
author = {Yixia Chen and Mingwei Lin and Zhu He and Kemal Polat and Adi Alhudhaif and Fayadh Alenezi},
keywords = {Deep learning, Object detection, Remote sensing, Knowledge distillation},
abstract = {As one of the challenging tasks in the remote sensing (RS), object detection has been successfully applied in many fields. Convolution neural network (CNN) has recently attracted extensive attention and is widely used in the natural image processing. Nevertheless, RS images have cluttered scenes compared with natural images. As a result, the existing detectors perform poorly in RS images, especially with the complicated backgrounds. Moreover, the detection inference time and model volume of detectors in RS images often go unrecognized. To address the above issues, this study proposes a novel method for object detection in RS images, which is called the consistency- and dependence-guided knowledge distillation (CDKD). To this end, the spatial- and channel-oriented structure discriminative modules (SCSDM) are put forward to extract the discriminative spatial locations and channels to which the teacher model pays attention. SCSDM improves the feature representation of the student model by effectively eliminating the influence of noises and the complicated backgrounds. Then, the consistency and dependence of the features between the teacher model and the student model are constructed under the guidance of SCSDM. Experimental results over public datasets for RS images demonstrate that our CDKD method surpasses the state-of-the-art methods effectively. Most of all, on the RSOD dataset, our CDKD method achieves 92% mean average precision with 3.3 M model volume and 588.2 frames per second.}
}
@article{MOINGEON2023103605,
title = {Virtual patients, digital twins and causal disease models: Paving the ground for in silico clinical trials},
journal = {Drug Discovery Today},
volume = {28},
number = {7},
pages = {103605},
year = {2023},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2023.103605},
url = {https://www.sciencedirect.com/science/article/pii/S1359644623001216},
author = {Philippe Moingeon and Marylore Chenel and Cécile Rousseau and Emmanuelle Voisin and Mickael Guedj},
keywords = {Artificial intelligence, causal disease model, computational precision medicine, digital twins,  trial simulation, machine learning, virtual patient},
abstract = {Computational models are being explored to simulate in silico the efficacy and safety of drug candidates and medical devices. Disease models that are based on patients’ profiling data are being produced to represent interactomes of genes or proteins and to infer causality in the pathophysiology, which makes it possible to mimic the impact of drugs on relevant targets. Virtual patients designed from medical records as well as digital twins are generated to simulate specific organs and to predict treatment efficacy at the individual patient level. As the acceptance of digital evidence by regulators grows, predictive artificial intelligence (AI)-based models will support the design of confirmatory trials in humans and will accelerate the development of efficient drugs and medical devices.}
}
@article{LIU2023120122,
title = {Intelligent digital-twin prediction and reverse control system architecture for thermal errors enabled by deep learning and cloud-edge computing},
journal = {Expert Systems with Applications},
volume = {225},
pages = {120122},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120122},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423006243},
author = {Jialan Liu and Chi Ma and Hongquan Gui and Shilong Wang},
keywords = {Intelligent system, Precision machine tools, Digital twin, LSTM neural network, Error prediction model, Edge computing},
abstract = {The heat generation is significant in the machining process, leading to thermal errors, and finally the geometric precision of machined parts is reduced. So the precision machine tool is a key factor in determining the geometric precision of complex parts. In recent years, the error control method is applied. But the method fails in reducing thermal errors because it cannot effectively process large-volume data, resulting from its low executing efficiency. To solve above issues, a new intelligent digital-twin prediction and reverse control system is designed for thermally induced errors based on the user-edge-cloud architecture to expedite the executing efficiency. The data-driven error modeling method is augmented by an error mechanism-based modeling to express the thermal error as a function with the temperature, armature current, rotational speed, and ambient temperature as independent variables, and then the long-term memorizing behavior of thermal errors is demonstrated. The error model is established based on an improved wavelet threshold denoising (IWTD) and a (long short-term memory) LSTM network to describe the memorizing behavior, and IWTD-LSTM network error prediction model is embedded into the digital-twin system. The digital-twin system and IWTD-LSTM network model were verified on a precision machine tool. With the implementation of the digital-twin system, the thermal error and the volume of the transferred data are reduced by 88.72% and 56.36%, respectively.}
}
@article{LUO2023106855,
title = {Optimal sensor placement for reconstructing wind pressure field around buildings using compressed sensing},
journal = {Journal of Building Engineering},
volume = {75},
pages = {106855},
year = {2023},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2023.106855},
url = {https://www.sciencedirect.com/science/article/pii/S2352710223010343},
author = {Xihaier Luo and Ahsan Kareem and Shinjae Yoo},
keywords = {Sensor placement, Compressed sensing, Pressure measurements, Wind pressure field reconstruction},
abstract = {Deciding how to optimally deploy sensors in a large, complex, and spatially extended structure is critical to ensure that the surface pressure field is accurately captured for subsequent analysis and design. In some cases, reconstruction of missing data is required in downstream tasks such as the development of digital twins. This paper presents a data-driven sparse sensor selection algorithm, aiming to provide the most information contents for reconstructing aerodynamic characteristics of wind pressures over tall building structures parsimoniously. The algorithm first fits a set of basis functions to the training data, then applies a computationally efficient QR algorithm that ranks existing pressure sensors in order of importance based on the state reconstruction to this tailored basis. The findings of this study show that the proposed algorithm successfully reconstructs the aerodynamic characteristics of tall buildings from sparse measurement locations, generating stable and optimal solutions across a range of conditions. As a result, this study serves as a promising first step toward leveraging the success of data-driven and machine learning algorithms to supplement traditional genetic algorithms currently used in wind engineering.}
}
@article{MARDANPOUR2023119073,
title = {Human activity recognition based on multiple inertial sensors through feature-based knowledge distillation paradigm},
journal = {Information Sciences},
volume = {640},
pages = {119073},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119073},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523006588},
author = {Malihe Mardanpour and Majid Sepahvand and Fardin Abdali-Mohammadi and Mahya Nikouei and Homeyra Sarabi},
keywords = {Human activity recognition, Knowledge distillation, Edge device, Deep learning, Tensor decomposition},
abstract = {In recent years, numerous high accuracy methods have been developed for classifying activities using multi inertial sensors. Despite their reliability and precision, they suffer from high computational cost and which make them improper for deploying in edge devices that are limited resources. This paper addresses this drawback by employing a knowledge distillation (KD) paradigm which maps tri-axial multi signals into single axis signals, thus; it can recognize activities with fewer number of signals and consequently less computation. In this method, a big teacher model is trained in advanced with three IMU sensors each of which have tri-axial signals. Then, a small student model is trained with just one of the axes of these sensors under monitoring of teacher which reduces the number of signals. Tucker decomposition is also exploited in order to improve KD performance by separating a core tensor from feature maps that has more informative knowledge. Evaluation of our method on REALDISP dataset demonstrates that the student model could achieve accuracy of 92.90% with much less complexity making it suitable for embedded devices. Moreover, it outperforms in comparison to other state-of-the-art KD approaches.}
}
@article{NAGARAJ2023e251,
title = {Augmenting digital twins with federated learning in medicine},
journal = {The Lancet Digital Health},
volume = {5},
number = {5},
pages = {e251-e253},
year = {2023},
issn = {2589-7500},
doi = {https://doi.org/10.1016/S2589-7500(23)00044-4},
url = {https://www.sciencedirect.com/science/article/pii/S2589750023000444},
author = {Divya Nagaraj and Priya Khandelwal and Sandra Steyaert and Olivier Gevaert}
}
@article{XU2023,
title = {Comparative study on landslide susceptibility mapping based on different ratios of training samples and testing samples by using RF and FR-RF models},
journal = {Natural Hazards Research},
year = {2023},
issn = {2666-5921},
doi = {https://doi.org/10.1016/j.nhres.2023.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2666592123000732},
author = {Ke Xu and Zhou Zhao and Wei Chen and Jianquan Ma and Fei Liu and Yihao Zhang and Zijun Ren},
keywords = {Comparative study, Landslide susceptibility, Sample , RF model, FR-RF model},
abstract = {Evaluation of landslide susceptibility is essential to planning of land and space utilization. For this purpose, the paper presents a case study from Fugu County, Shaanxi Province, China. Firstly, the geological environment and current state of landslides in Fugu County were investigated. Then, slope, aspect, terrain relief, curvature, lithology, land type, and normalized difference vegetation index (NDVI) were considered as the landslide susceptibility condition factors, and the correlation between these carried out by using Multicollinearity Analysis method. Next, landslide and non-landslide samples were divided into training samples and testing samples according to the sample ratios of 8/2, 7/3, 6/4, and 5/5, respectively. The landslide susceptibility mapping was carried out by using Random Forest (RF) model and Frequency Ratio coupled with Random Forest (FR-RF) model, respectively. Lastly, the landslide density (LD), landslide frequency ratio (LFR), the area under the curve (AUC) of the receiver operator, and other indicators were used to validate the rationality, accuracy, and performance of the landslide susceptibility maps produced from different models and ratios. The results indicated that all maps are reasonable, except the map when ratio is 5/5. For each map, regardless of ratios, the LD and LFR are the greatest in the zones classed as having a very high susceptibility, followed by those with a high, moderate, low, and very low classes. In the Random Forest (RF) model, when the training test set is not at the same time its in the area of extremely high sensitivity of LD and the size of the FR value respectively 7/3 (201.026) > 8/2 (154.440) > 6/4 (93.696) >5/5 (136.364) and 7/3 (4.806) > 8/2 (3.692) > 6/4 (3.260) > 5/5 (2.240); in the Frequency Ratio coupled with Random Forest (FR-RF) model, Inall the training test sets the size of the proportion of LD and FR value respectively 7/3 (145.693) > 6/4 (127.151) > 5/5 (122.857) > 8/2 (113.263) and 7/3 (3.334) > 6/4 (3.073) > 5/5 (2.811) > 8/2 (2.592). What else, from the comparison of ROC curves, when ratio is 7/3, the accuracy of the two models is higher than that of other ratios. Similarly, the results of the ensemble model (A combination of two models with different learning abilities.) are not more reasonable than the results of the single model, which reflects that the combination of a weaker learner model (Frequency Ratio model here) with a stronger learner model (Random Forest model here) can diminish the performance of the stronger model.}
}
@article{LAI202376,
title = {Digital twin-based structural health monitoring by combining measurement and computational data: An aircraft wing example},
journal = {Journal of Manufacturing Systems},
volume = {69},
pages = {76-90},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0278612523001085},
author = {Xiaonan Lai and Liangliang Yang and Xiwang He and Yong Pang and Xueguan Song and Wei Sun},
keywords = {Digital twin, Structural health monitoring, Load identification, Multi-fidelity modeling, Fatigue damage estimation},
abstract = {Digital twin is a concept that utilizes digital technologies to mirror the real-time states of physical assets and extract the hidden yet valuable information of physical assets for optimization, decision-making or scheduling. By combining measurement and computational data, this paper presents a digital twin-based structural health monitoring framework of physical assets. The process for building the measurement-computation combined digital twin (MCC-DT) involves four steps. First, an artificial intelligence-driven load identification method combining measurement and computational data is employed to recognize the loads applied on physical assets. Two approaches were proposed to realize load identification, based on single fidelity surrogate models and deep learning techniques, respectively. Second, multi-fidelity surrogate (MFS) models are applied to improve the accuracy in the MCC-DT. Two routes for implementing the MFS models are introduced and the advantages and shortcomings of both are analyzed. Third, an online rainflow counting algorithm is developed to calculate the degradation of the physical assets. The main advantage of the algorithm is that it can provide a near real-time estimation for the damage accumulated of physical assets. Finally, the data generated from the first three steps can be fused into a three-dimensional scene using Web graphics library to provide an intuitive view of the MCC-DT. To describe the implementation details of the framework and verify its applicability and effectiveness, the MCC-DT was established using an aircraft model as an example.}
}
@article{HASHMI2023101070,
title = {Consensus based phase connectivity identification for distribution network with limited observability},
journal = {Sustainable Energy, Grids and Networks},
volume = {34},
pages = {101070},
year = {2023},
issn = {2352-4677},
doi = {https://doi.org/10.1016/j.segan.2023.101070},
url = {https://www.sciencedirect.com/science/article/pii/S2352467723000784},
author = {Md Umar Hashmi and David Brummund and Rickard Lundholm and Arpan Koirala and Dirk {Van Hertem}},
keywords = {Data-driven, Distribution network, Machine learning, Phase identification, Voltage time series},
abstract = {The mitigation of distribution network (DN) unbalance and the use of single-phase flexibility for congestion mitigation requires accurate phase connection information, which is often not available. For a large DN, the naïve phase identification proposed in the majority of the prior works using a single voltage reference, this does not scale well for a multi-feeder DN. We present a consensus algorithm-based phase identification mechanism which uses multiple three-phase reference points to improve the prediction of phases. Due to the absence of real measurements for a real-suburban German DN, the algorithms are developed and evaluated over synthetic data using a digital twin. To utilize strongly correlated measurements, the DN is clustered into zones. We observe those reference measurements located in the same zone as the single-phase consumer, with unknown phase connectivity, leads to accurate prediction of DN phases. Four consensus algorithms are developed and compared. Using numerical results, we recommend the most robust phase identification mechanism. In our evaluation, measurement error, and the impact of the neutral conductor are also assessed. We assume limited DN observability and apply our findings to a German DN without smart meters, but only less than 8% of nodes have measurement boxes along with single-phase consumers with a home energy management system. Voltage time series for 1 month (hourly sampled) is utilized. The numerical results indicate that for 1% accuracy class measurement, the phase connectivity of 308 out of 313 single-phase consumers in a German DN can be identified. Further, we also propose metrics quantifying the goodness of the phase identification. The phase identification framework based on consensus algorithms for DN zones is scalable for large DN and robust towards measurement errors as the estimation is not dependent on a single measurement point.}
}
@article{MAITY2023113278,
title = {Real-time temperature monitoring of weld interface using a digital twin approach},
journal = {Measurement},
volume = {219},
pages = {113278},
year = {2023},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2023.113278},
url = {https://www.sciencedirect.com/science/article/pii/S0263224123008424},
author = {D. Maity and R. Premchand and M. Muralidhar and V. Racherla},
keywords = {Dissimilar metal joining, Friction processing, Weld interface temperature prediction, Finite element simulations, Machine learning model, Digital twin},
abstract = {A new friction processing technique is developed for lap welding of Al–Cu sheets using inter diffusion of copper and aluminium at their interface. The metals selectively melt at the interface at a temperature near their eutectic point. This paper proposes a digital twin approach for real-time temperature monitoring at the joint interface using the machine’s real-time current data. The real time temperature data is used to predict exact instance of interface melting and to control the resulting weld microstructure. The digital twin model is calibrated using a finite element model which is in turn calibrated using experiments. Moving average of machine current and temperature history are used to predict real time interface temperature using a linear regression based recursive machine learning model with high precision. The model predictions have an R2 value of 99.5%. The digital twin approach resulted in significant increase in joint strength and fracture energy.}
}
@article{RUMIN2023113157,
title = {Utilization of measurements, machine learning, and analytical calculation for preventing belt flip over on conveyor belts},
journal = {Measurement},
volume = {218},
pages = {113157},
year = {2023},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2023.113157},
url = {https://www.sciencedirect.com/science/article/pii/S0263224123007212},
author = {Przemysław Rumin and Janusz Kotowicz and Daniel Hogg and Anna Zastawna-Rumin},
keywords = {Anomaly detection, Belt conveyor, Machine learning, Predictive maintenance},
abstract = {The use of information technology in modern industry is becoming increasingly important to ensure the failure-free operation of devices. Innovatively, this article describes methods to predict belt flip over. The article describes the tested installation and the acquisition and processing of a unique data set gathered from hilly and very long belt conveyors. Values are predicted using novel analytical algorithms with a combination of machine learning algorithms. A simulation study is presented to demonstrate the effectiveness of the proposed method. The simulation results and case studies show that the proposed method generates accurate results and can be used to predict belt flip over for large-scale belt conveyors.}
}
@article{DHARMADHIKARI2023103556,
title = {A reinforcement learning approach for process parameter optimization in additive manufacturing},
journal = {Additive Manufacturing},
volume = {71},
pages = {103556},
year = {2023},
issn = {2214-8604},
doi = {https://doi.org/10.1016/j.addma.2023.103556},
url = {https://www.sciencedirect.com/science/article/pii/S2214860423001690},
author = {Susheel Dharmadhikari and Nandana Menon and Amrita Basak},
keywords = {Reinforcement learning, Q-learning, Additive manufacturing, Directed energy deposition, Process optimization},
abstract = {Process optimization for metal additive manufacturing (AM) is crucial to ensure repeatability, control microstructure, and minimize defects. Despite efforts to address this via the traditional design of experiments and statistical process mapping, there is limited insight on an on-the-fly optimization framework that can be integrated into a metal AM system. Additionally, most of these methods, being data-intensive, cannot be supported by a metal AM alloy or system due to budget restrictions. To tackle this issue, the article introduces a Reinforcement Learning (RL) methodology transformed into an optimization problem in the realm of metal AM. An off-policy RL framework based on Q-learning is proposed to find optimal laser power (P)- scan velocity (v) combinations with the objective of maintaining steady-state melt pool depth. For this, an experimentally validated Eagar–Tsai formulation is used as a digital twin emulating the laser-directed energy deposition (L-DED) environment, where the laser operates as the agent across the P−v space such that it maximizes rewards for a melt pool depth closer to the optimum. The culmination of the training process yields a Q-table where the state (P,v) with the highest Q-value corresponds to the optimized process parameters. For a desired melt pool depth of 1 mm for SS316L, the proposed algorithm predicts an optimal P−v combination of 888.9 W - 566.7 mm/min that yields a melt pool depth within 50 μm of the experimental observation. The framework, therefore, provides a model-free approach to learning without any prior.}
}
@article{YANG2023102595,
title = {Meta-model-based shop-floor digital twin architecture, modeling and application},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {84},
pages = {102595},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102595},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000716},
author = {Xiaolang Yang and Xuemei Liu and Heng Zhang and Ling Fu and Yanbin Yu},
keywords = {Shop-floor digital twin, Meta-model, MBSE, RAMI 4.0, Intelligent manufacturing},
abstract = {Digital twin is regarded as the virtual counterpart of physical entities, which can mirror the physical behavior and performance. Digital twin technology provides strong support for the achievement of cyber-physical system and intelligent manufacturing. Many investigations have been carried out for the digital twin of specific products. However, there are less researches on digital twin in the shop-floor domain, and there is a lack of model-driven digital twin comprehensive architecture. The modeling approach to the full lifecycle of digital twin is not considered enough. This paper proposes a meta-model-based shop-floor digital twin construction approach and a comprehensive architecture. A meta-model based on RAMI 4.0 is constructed, which provide a novel idea for the description of manufacturing resources and their status. The proposed shop-floor digital twin architecture consists of three key implementation elements: the meta-model construction, data modeling (including data interaction between cyber-physical spaces) and constructing different integration level models of shop-floor digital twin based on iteration feedback between the demands and models. The proposed approach is validated through a case study of the fischer learning factory 4.0.}
}
@article{ZHANG2023120542,
title = {Towards deep probabilistic graph neural network for natural gas leak detection and localization without labeled anomaly data},
journal = {Expert Systems with Applications},
volume = {231},
pages = {120542},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120542},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423010448},
author = {Xinqi Zhang and Jihao Shi and Xinyan Huang and Fu Xiao and Ming Yang and Jiawei Huang and Xiaokang Yin and Asif {Sohail Usmani} and Guoming Chen},
keywords = {Variation Bayesian Inference, Graph deep learning, Leakage detection, Leakage localization, Digital twin},
abstract = {Deep learning has been widely applied to automated leakage detection and location of natural gas pipe networks. Prevalent deep learning approaches do not consider the spatial dependency of sensors, which limits leakage detection performance. Graph deep learning is a promising alternative to prevailing approaches as it can model spatial dependency. However, the challenge of collecting real-world anomaly data for training limits the accuracy and robustness of currently used graph deep learning approaches. This study proposes a deep probabilistic graph neural network in which attention-based graph neural network is built to model spatial sensor dependency. Variational Bayesian inference is integrated to model the posterior distribution of sensor dependency so that the leakage can be localized. An urban natural gas pipe network experiment is employed to construct the benchmark dataset, in which normal time-series data is applied to develop our proposed model while anomaly leakage data is used for performance comparison between our model and other state-of-the-art models. The results demonstrate that our model exhibits competitive detection accuracy (AUC) = 0.9484, while the additional uncertainty interval provides more comprehensive leakage detection information compared to state-of-the-art deep learning models. In addition, our model’s posterior distribution enhances the leakage localization with the accuracy of positioning (PAc) = 0.8, which is higher than that of other state-of-the-art graph deep learning models. This study provides a comprehensive and robust alternative for subsequent decision-making to mitigate natural gas leakage from pipe networks.}
}
@article{MARTENS2023102076,
title = {Cross domain matching for semantic point cloud segmentation based on image segmentation and geometric reasoning},
journal = {Advanced Engineering Informatics},
volume = {57},
pages = {102076},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102076},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623002045},
author = {Jan Martens and Timothy Blut and Jörg Blankenbach},
keywords = {Infrastructure, Machine learning, Cross domain matching, Point clouds, Semantic segmentation, BIM},
abstract = {Many infrastructure assets in transportation such as roads and bridges represent challenges for inspection and maintenance due to advanced age, structural deficiencies and modifications. Concepts such as Building Information Modelling (BIM) aim to alleviate the problem of health monitoring and asset management by providing digital building models constructed from survey data to all stakeholders. Ageing and oftentimes poorly-documented infrastructure objects such as bridges in particular benefit from a continuous integration of changes to form a digital twin which reflects the asset’s as-is state. However, the process of reconstructing geometric–semantic models from survey data is a manual and labour-intensive process and makes continuously updating the models a difficult task. To automate this process, a cross-domain approach using an artificial neural network is presented which performs semantic segmentation in the image domain and transfers the results over to the point cloud. For the following fine segmentation, geometric knowledge in the 3D domain is used for post-processing and filtering via geometric reasoning. Using this method, a 3D semantic segmentation is achieved which does not require any 3D point cloud training data and only a low amount of image training data.}
}
@article{HOSSEINI2023116019,
title = {Single-track thermal analysis of laser powder bed fusion process: Parametric solution through physics-informed neural networks},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {410},
pages = {116019},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2023.116019},
url = {https://www.sciencedirect.com/science/article/pii/S0045782523001433},
author = {E. Hosseini and P. Scheel and O. Müller and R. Molinaro and S. Mishra},
keywords = {Physics informed neural networks, Additive manufacturing, Thermal simulation, Parametric analysis},
abstract = {Modelling the highly localised and rapid phenomena occurring during metal additive manufacturing (MAM) processes such as the laser powder bed fusion (LPBF) demands the adoption of very fine time- and space-discretisation and therefore high computational cost for the classical simulation approaches, namely the finite element method (FEM). Particularly, when the solution is required for a range of scenarios, e.g. in sensitivity or optimisation analyses, computation costs of such simulations are not affordable. As an alternative strategy, this study explores the application of physics informed neural networks (PINNs) as a low-cost physics-based simulation approach for the thermal analysis of the LPBF process, through which reliable transient and steady-state temperature profiles for single-track LPBF depositions are achieved. An unsupervised learning strategy is employed for PINNs to parametrically solve the heat transfer equation for the LPBF process. The trained PINNs calculate the temperature profiles and the melt-pool dimensions evolving during the LPBF process for any given set of material’s thermal properties and process conditions at practically zero computational cost. The reliability of the PINNs outcomes is verified through ground-truth data generated based on several benchmark equivalent finite element simulations.}
}
@article{CHOU2023113611,
title = {A perceptron-based learning method for solving the inverse problem of the brain model via poroelastodynamics},
journal = {Chaos, Solitons & Fractals},
volume = {172},
pages = {113611},
year = {2023},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2023.113611},
url = {https://www.sciencedirect.com/science/article/pii/S096007792300512X},
author = {Dean Chou and Po-Yen Chen},
keywords = {Brain model, Inverse problem, Neural networks, Perceptron-based model, Water transfer coefficients},
abstract = {Computer simulations and in silico models are currently the best tools for understanding complex biological processes. However, the complexity of biological tissues, with multiple cellular mechanisms in response to changing physical and chemical external stimuli, makes the corresponding mathematical models highly nonlinear with numerous parameters. These parameters are crucial to the models but are often fitted for specific conditions, making the conclusions drawn difficult to generalize. Moreover, some of these parameters will be hard to obtain through either clinical measurements or experiments. Hence, in this study, we introduced a perceptron-based method to determine unknown parameters of water transfer coefficients in the cerebral multi-compartmental poroelasticity model. Based on the nature and conditions of the available data, we designed a straightforward and functional model to solve a steady-state inverse problem. Moreover, we added an analytical solution to restrict the learning tendency of the model. It is to be noted that we only evaluated the unknown parameters without fitting the solution of PDEs. We believe that this study presents a functional perceptron-based approach for investigating and demonstrating unknown parameters using the cerebral multi-compartmental poroelasticity model. Besides, the algorithm was fully presented since we believed that our scheme has the ability to utilise in various field for those who need to estimate unknown parameters in PDEs. Furthermore, we tested the efficiency and effectiveness of the proposed method and demonstrated how the framework can help estimate the parameters rapidly. Finally, we discussed the unmet needs and forecasted future tasks of this framework.}
}
@article{XIONG2023102912,
title = {Ability-aware knowledge distillation for resource-constrained embedded devices},
journal = {Journal of Systems Architecture},
volume = {141},
pages = {102912},
year = {2023},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2023.102912},
url = {https://www.sciencedirect.com/science/article/pii/S1383762123000917},
author = {Yi Xiong and Wenjie Zhai and Xueyong Xu and Jinchen Wang and Zongwei Zhu and Cheng Ji and Jing Cao},
keywords = {Embedded devices, Model compression, Knowledge distillation},
abstract = {Deep Neural Network (DNN) models have notably improved the efficiency of machine learning tasks. However, their high storage and computational costs restrict their deployment on resource-limited embedded devices. Knowledge distillation (KD) has emerged as a promising approach for compressing DNN models. However, two challenges in KD, namely the capacity gap problem and the time-consuming redundancy problem, have hindered its performance and efficiency in compression. To alleviate these challenges, this paper proposes a novel framework, called Ability-Aware Knowledge Distillation (AAKD). AAKD introduces a knowledge sample selection strategy and an adaptive teacher switching strategy based on the dynamic awareness of the student’s ability. This enables the framework to automatically select suitable knowledge samples and teacher networks according to the increasing representation ability of students. Extensive experiments on different datasets and models have demonstrated that AAKD can enhance the performance of compact student models, significantly improve the efficiency of distillation, and lead to higher compression rates.}
}
@article{EATY2023120444,
title = {Digital twin for electric vehicle battery management with incremental learning},
journal = {Expert Systems with Applications},
volume = {229},
pages = {120444},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120444},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423009466},
author = {Naga Durga Krishna Mohan Eaty and Priyanka Bagade},
keywords = {Digital Twin, SoH (State of Health), SoC (State of Charge), Continual learning, Internet of things, Cloud computing, Microsoft Azure},
abstract = {The current Industry 4.0 revolution promotes the use of cyber–physical systems to enhance manufacturing and other industrial processes via automation, real-time analysis, etc. Data communication between individual systems plays an important role in this revolution’s success. As defined by researchers, Digital Twin is the digital representation of a physical system that enables predictive maintenance. Due to the increase in environmental pollution, battery-powered electric vehicles (EVs) are regarded as the urgent solution to internal combustion engines in the transportation business, despite obstacles such as safety concerns and range estimation. State of Health (SoH) and State of Charge (SoC) are two battery metrics that, when precisely anticipated, permit safer and longer battery use. Predicting these parameters online is computationally and financially expensive. Alternately, some of these factors could be predicted in the cloud rather than on the vehicle, hence cutting costs. Consequently, the EV business is one example where cloud-to-vehicle data connection saves total costs. A digital twin for an EV battery would aid in the estimate of battery parameters for predictive maintenance. This paper presents a Digital Twin paradigm for EV battery management in which SoH is predicted in the cloud and SoC is estimated on-vehicle. A continuous learning method is also proposed for forecasting SoH, whereas the Kalman filter is used to estimate SoC. The proposed framework predicts the SoH with a mean square error of 0.022.}
}
@article{HUANG2023,
title = {DTAIS: Distributed Trusted Active Identity Resolution Systems for the Industrial Internet},
journal = {Digital Communications and Networks},
year = {2023},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2023.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S2352864823001128},
author = {Tao Huang and Renchao Xie and Yuzheng Ren and F. Richard Yu and Zhuang Zou and Lu Han and Yunjie Liu and Demin Cheng and Yinan Li and Tian Liu},
keywords = {Industrial Internet, NFT, IPFS, trust, identity resolution system},
abstract = {In recent years, the Industrial Internet and Industry 4.0 came into being. With the development of modern industrial intelligent manufacturing technology, digital twins, Web3 and many other digital entity applications are also proposed. These applications apply architectures such as distributed learning, resource sharing, and arithmetic trading, which make high demands on identity authentication, asset authentication, resource addressing, and service location. Therefore, an efficient, secure, and trustworthy Industrial Internet identity resolution system is needed. However, most of the traditional identity resolution systems follow DNS architecture or tree structure, which has the risk of a single point of failure and DDoS attack. And they cannot guarantee the security and privacy of digital identity, personal assets, and device information. So we consider a decentralized approach for identity management, identity authentication, and asset verification. In this paper, we propose a distributed trusted active identity resolution system based on the inter-planetary file system (IPFS) and non-fungible token (NFT), which can provide distributed identity resolution services. And we have designed the system architecture, identity service process, load balancing strategy and smart contract service. In addition, we use Jmeter to verify the performance of the system, and the results show that the system has good high concurrent performance and robustness.}
}
@article{ASANTEOKYERE2023100089,
title = {Estimating total organic carbon (TOC) of shale rocks from their mineral composition using stacking generalization approach of machine learning},
journal = {Upstream Oil and Gas Technology},
volume = {11},
pages = {100089},
year = {2023},
issn = {2666-2604},
doi = {https://doi.org/10.1016/j.upstre.2023.100089},
url = {https://www.sciencedirect.com/science/article/pii/S266626042300004X},
author = {Solomon Asante-Okyere and Solomon Adjei Marfo and Yao Yevenyo Ziggah},
keywords = {Total organic carbon, Stacking, Mineral composition, Multivariate adaptive regression spline, Machine learning},
abstract = {A fundamental parameter in the exploration and development of unconventional shale reservoirs is total organic carbon (TOC). To achieve reliable TOC values, it requires a labour intensive and time-consuming laboratory experiment. On the other hand, models have been proposed using geophysical well logs as input variables with little attention paid to the contribution of mineralogical parameters in the evaluation of TOC. In this paper, a novel stacking machine learning technique is examined to generate accurate TOC predictions from the mineral content of the shale rock in the Sichuan Basin. The stacking machine learning model involves first-level models of multivariate adaptive regression spline (MARS), random forest (RF) and gradient boosted machine (GBM) known as base learners, while MARS was further used in the next step as the meta learner model. The research result indicated that the stacking TOC model outperformed the single applied models of MARS, GBM and RF. The proposed stacking TOC model generated estimates having the least error statistics of 0.29, 0.54 and 0.54 for MSE, RMSE and MAPE respectively while producing the highest correlation of 0.86 during the model validation stage. Therefore, stacking machine learning approach permits an improved estimation of TOC from the mineralogy of the rock.}
}
@article{HUA2023121128,
title = {Digital twin based reinforcement learning for extracting network structures and load patterns in planning and operation of distribution systems},
journal = {Applied Energy},
volume = {342},
pages = {121128},
year = {2023},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2023.121128},
url = {https://www.sciencedirect.com/science/article/pii/S0306261923004920},
author = {Weiqi Hua and Bruce Stephen and David C.H. Wallom},
keywords = {Digital twin, Distribution network, Fitted Q-iteration, Load pattern, Network configuration, Reinforcement learning},
abstract = {Low voltage distribution networks deliver power to the last mile of the network, but are often legacy assets from a time when low carbon technologies, e.g., electrified heat, storage, and electric vehicles, were not envisaged. Furthermore, exploiting emerging data from distribution networks to provide decision support for adapting planning and operational strategies with system transitions presents a challenge. To overcome these challenges, this paper proposes a novel application of digital twins based reinforcement learning to improve decision making by a distribution system operator, with key metrics of predictability, responsiveness, interoperability, and automation. The power system states, i.e., network configurations, technological combinations, and load patterns, are captured via a convolutional neural network, chosen for its pattern recognition capability with high-dimensional inputs. The convolutional neural networks are iteratively trained through the fitted Q-iteration algorithm, as a batch mode reinforcement learning, to adapt the planning and operational decisions with the dynamic system transitions. Case studies demonstrate the effectiveness of the proposed model by reducing 50% of the investment cost when the system transitions towards the winter and maintaining the power loss and loss of load within 5% compared to the benchmark optimisation. Doubled power consumption was observed in winter under future energy scenarios due to the electrification of heat. The trained model can accurately adapt optimal decisions according to the system changes while reducing the computational time of solving optimisation problems, for a range of scales of distribution systems, demonstrating its potential for scalable deployment by a system operator.}
}
@article{RAKIC2023144836,
title = {Liquid organic hydrogen carrier hydrogenation–dehydrogenation: From ab initio catalysis to reaction micro-kinetics modelling},
journal = {Chemical Engineering Journal},
volume = {472},
pages = {144836},
year = {2023},
issn = {1385-8947},
doi = {https://doi.org/10.1016/j.cej.2023.144836},
url = {https://www.sciencedirect.com/science/article/pii/S1385894723035672},
author = {Emilija Rakić and Miha Grilc and Blaž Likozar},
keywords = {Liquid organic hydrogen carrier (LOHC) molecules, Multiscale modelling chemical reaction kinetics, Density functional theory (DFT), Computational fluid dynamics (CFD), Machine learning (ML), Catalysis, H storage},
abstract = {The continued selective focus on the exploitation of fossil fuel chemicals as one of the main environment-depleting sources of energy is one of the reasons for the carbon dioxide emissions, severe air pollution and market crisis of today. The related easy transition to efficient renewable resources also brings challenges, such as the storing of performance generated year round. Consistent application option is to convert the formed transferred electricity produced into the hydrogen through electrolysis, store gaseous H2, and reversibly proceed with reforming or cracking. This routine way is also referred to in literature as evolving green H2. A relatively new method of storage is liquid organic carriers (LOHCs). These are molecules that are in a (l) state at room temperature measurements, contain unsaturated covalent bonds, and can be hydrogenated/dehydrogenated in the many loading cycles without catalytic decomposition products. Paper presents possible structure systems that have been previously investigated as an alternative to conventional. The process of catalysis, reduction and coking, catalysts, and the most commonly used elementary groups, interactions, and reaction condition analyses are listed, while an overview of studies that have assessed technical transfer phenomena is also provided. Reports, dealing with derived micro-kinetic modelling/computational fluid dynamics (CFD), which is a direction for further research activities, are few. As for multiscale, review ranges from the density functional theory (DFT) to CFD. The review paper also addresses the latest studies on LOHCs in the field of artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). The progress within the area with approaches is highlighted. Mesoscale surface–selectivity relationships, the robustness towards deactivation and techno-economics are dominant in linking the digital twin design to operation.}
}
@article{HUANG2023103697,
title = {Collective reinforcement learning based resource allocation for digital twin service in 6G networks},
journal = {Journal of Network and Computer Applications},
volume = {217},
pages = {103697},
year = {2023},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2023.103697},
url = {https://www.sciencedirect.com/science/article/pii/S1084804523001169},
author = {Zhongwei Huang and Dagang Li and Jun Cai and Hua Lu},
keywords = {Digital twin, Resource allocation, Internet of Things, Collective reinforcement learning},
abstract = {The 6th generation (6G) mobile communications technology will realize the interconnection of humans, machines, things as well as virtual space. The development of digital twins (DTs) and 6G has accelerated the Internet of Things (IoT) in an unprecedented way. The combination of DTs and edge intelligence (EI) enables powerful digital space synchronized with the real world constructed in the intelligent edge, bringing real-time, and adaptive services delivery of IoT. However, the dynamic features and heterogeneous resources in 6G-enabled IoT make the resource allocation for computation-intensive and delay-sensitive DTs services more challenging. In this paper, we first define the DTs implementation process as a DT service function chain (DTSFC) and address the resource allocation problem of DTs-empowered networks in form of dynamic DTSFCs orchestration. We further propose a novel collective reinforcement learning (CRL) method which is inspired by human collaboration, to realize the effective resource allocation of DTSFCs. Numerical results verify that the proposed CRL algorithm improves the learning efficiency and generalization ability compared with the benchmarks.}
}
@article{XIE2023115098,
title = {Probabilistic real-time natural gas jet fire consequence modeling of offshore platforms by hybrid deep learning approach},
journal = {Marine Pollution Bulletin},
volume = {192},
pages = {115098},
year = {2023},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2023.115098},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X23005301},
author = {Weikang Xie and Junjie Li and Jihao Shi and Xinqi Zhang and Asif Sohail Usmani and Guoming Chen},
keywords = {Real-time jet fire modeling, Offshore platform, Deep learning, Variational Bayesian inference, Digital twin},
abstract = {Natural gas jet fire induced by igniting blowouts has the potential to cause critical structure damage and great casualties of offshore platforms. Real-time natural gas jet fire plume prediction is essential to support the emergency planning to mitigate subsequent damage consequence and ocean pollution. Deep learning based on a large amount of Computational fluid dynamics (CFD) simulations has recently been applied to real-time fire modeling. However, existing approaches based on point-estimation theory are ‘over-confident’ when prediction deficiency exists, which reduce robustness and accuracy for emergency planning support. This study proposes probabilistic deep learning approach for real-time natural gas jet fire consequence modeling by integrating variational Bayesian inference with deep learning. Numerical model of natural gas jet fire from offshore platform is built and the natural gas jet fire scenarios are simulated to construct the benchmark dataset. Sensitivity analysis of pre-defined parameters such as MC (Monte Carlo) sampling number m and dropout probability p is conducted to determine the trade-off between model's accuracy and efficiency. The results demonstrated our model exhibits competitive accuracy with R2 = 0.965 and real-time capacity with an inference time of 12 ms. In addition, the predicted spatial uncertainty corresponding to spatial jet fire flame plume provides more comprehensive and reliable support for the following mitigation decision-makings compared to the state-of-the-art point-estimation based deep learning model. This study provides a robust alternative for constructing a digital twin of fire and explosion associated emergency management on offshore platforms.}
}
@article{SON2023102035,
title = {A novel physics-informed neural network for modeling electromagnetism of a permanent magnet synchronous motor},
journal = {Advanced Engineering Informatics},
volume = {57},
pages = {102035},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102035},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623001635},
author = {Seho Son and Hyunseung Lee and Dayeon Jeong and Ki-Yong Oh and Kyung {Ho Sun}},
keywords = {Physics-informed neural network, Electromagnetics, Governing equation, Domain decomposition, Interface loss, Adaptive weight},
abstract = {This study presents a novel physics-informed neural network (PINN) architecture designed to address the challenges of replicating an electric motor. The proposed architecture has three key features. First, it uses three partial differential equations with rotational coordinate transformation to supervise the neural network during training with limited data, which improves the accuracy of the solution. One of the differential equations is expressed in variational form to effectively compute the numerical integration. Second, separate networks are proposed for the rotor and stator domains due to their distinct characteristics during operation, namely, that the rotor rotates while the stator remains fixed. An interface loss is included in the entire loss function to compensate for the significant discontinuity and incompatibility between the separate networks when estimating the results of both domains. Third, a learning rate annealing method is introduced to update the adaptive weights of each loss term, thus improving the accuracy and robustness during the training of the neural network. The performance of the proposed PINN was validated using electromagnetic response datasets obtained from both measurements and finite element analyses. Systematic analysis demonstrated that the three features significantly improved the accuracy and robustness of the neural network when estimating the electromagnetic responses of an electric motor. Furthermore, the inference time of the PINN is ten times faster than that of a finite element analysis with a similar level of accuracy, making it suitable for control and design purposes in various real-world applications. Consequently, the versatility of the proposed PINN can accelerate the development of digital twins for intelligent systems by deploying an electric motor, and it could also be used for prognostics and health management because it can estimate electromagnetic responses under both normal and failure conditions.}
}
@article{TONG2023110611,
title = {Two-stage reverse knowledge distillation incorporated and Self-Supervised Masking strategy for industrial anomaly detection},
journal = {Knowledge-Based Systems},
volume = {273},
pages = {110611},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110611},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123003611},
author = {Guoxiang Tong and Quanquan Li and Yan Song},
keywords = {Anomaly detection, Self-supervised mask training, Anomaly feature diffusion, Normalized embedding memory bank},
abstract = {In recent years, unsupervised anomaly detection based on knowledge distillation has gained special attention and some promising results have been reported in the literature. However, there is still room to improve the sensitivity of the model to anomalies. To do so, in this paper, a novel two-stage training method in terms of reverse knowledge distillation is proposed for anomaly detection and localization. Firstly, self-supervised mask training is introduced after the initial training of reverse knowledge distillation, which contributes greatly to the model detection against random unknown anomalies by self-simulating anomalies and forcing repair so as to reinforce learning single-category prototype patterns. Then, with the aim to facilitate the anomaly localization, an anomaly feature diffusion module is employed, which strengthens the correlation between pixels and helps spread the anomaly information to the surrounding area by covering the central pixel and reconstructing the representation for features after diffused. Furthermore, inspired by the human memory mechanism, an innovative normalized embedding memory bank is adopted to regulate the low-dimensional representations after embedding the encoding, inhibit the flow of anomalous information to the student decoder, and encourage the high-quality reconstruction of the model. Finally, the contextual similarity loss is used to guide the student model to learn knowledge representations from a contextual perspective, capture higher-order similarities between teachers and students, and delicately evaluate the differences between teachers and students. The empirical experiments conducted on the MVTec dataset show that the proposed SSMRKD method can achieve the best performance compared to other state-of-the-art methods, meanwhile extensive experiments of the ablation study validate the contribution of each component of the model. In addition, the advanced performance achieved on four commonly used datasets verifies the generalizability of the model in the industrial domain. Overall, the proposed SSMRKD method has significant advantages over the state-of-the-art anomaly detection methods.}
}
@article{GEURTSEN2023170,
title = {Deep reinforcement learning for optimal planning of assembly line maintenance},
journal = {Journal of Manufacturing Systems},
volume = {69},
pages = {170-188},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0278612523000845},
author = {M. Geurtsen and I. Adan and Z. Atan},
keywords = {Scheduling, Maintenance, Deep reinforcement learning, Simulation, Case-study, Flexibility},
abstract = {Discovering the optimal maintenance planning strategy can have a substantial impact on production efficiency, yet this aspect is often overlooked in favor of production planning. This is a missed opportunity as maintenance and production activities are deeply intertwined. Our study sheds light on the significance of maintenance planning, particularly in the dynamic setting of an assembly line. By maximizing the average production rate and incorporating flexible planning windows, buffer content, and machine production states, a unique problem is addressed in which a policy for planning maintenance on the final machine of a serial assembly line is developed. To achieve this, novel average-reward deep reinforcement learning techniques are employed and pitted against generic dispatching methods. Using a digital twin with real-world data, experiments demonstrate the immense potential of this new deep reinforcement learning technique, producing policies that outperform generic dispatching strategies and practitioner policies.}
}
@article{CHAI2023105251,
title = {Incremental learning model for dynamical identification and classification of abnormal vibration in operational underground facilities},
journal = {Tunnelling and Underground Space Technology},
volume = {140},
pages = {105251},
year = {2023},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2023.105251},
url = {https://www.sciencedirect.com/science/article/pii/S0886779823002717},
author = {Fu Chai and Biao Zhou and Xiongyao Xie and Zixin Zhang and Chen Wang},
keywords = {Underground infrastructure, Monitoring, Incremental learning, Variational autoencoder, Metric function},
abstract = {Underground infrastructures are rapidly growing in size and complexity. However, their operations are affected by several hazards, including hidden structural deterioration and effects of random external constructions. Dynamic monitoring of these hazards is essential to provide early warning. We propose a vibration-based self-supervised incremental learning model for dynamic monitoring of emerging operational threats by recognizing abnormal responses. The model comprises teacher and student models based on a variational autoencoder (VAE) with a metric function. When the teacher model detects a new category of abnormal vibration, the student model is trained to recognize this abnormality through sample rehearsals and knowledge distillations. Subsequently, it becomes the teacher model for the next round of incremental learning. We demonstrate through a case study that catastrophic forgetting can be avoided and memory consumption can be reduced during dynamic network updates. Moreover, the use of a metric function in the VAE increases the vibration identification accuracy.}
}
@article{S2023100186,
title = {MUD enabled deep learning framework for anomaly detection in IoT integrated smart building},
journal = {e-Prime - Advances in Electrical Engineering, Electronics and Energy},
volume = {5},
pages = {100186},
year = {2023},
issn = {2772-6711},
doi = {https://doi.org/10.1016/j.prime.2023.100186},
url = {https://www.sciencedirect.com/science/article/pii/S2772671123000815},
author = {Mirdula S and Roopa M},
keywords = {Smart building, Deep learning, Manufacturer usage description, Anomaly detection},
abstract = {Nowadays, many Internet of Things (IoT) devices of different types are used in creating smart applications like smart cities, smart industries, smart environments, and the applications of industry-4.0. IoT devices are used for different purposes, such as security, remote monitoring, resource allocation, threats, ecosystems, and vulnerabilities. This paper proposed a deep learning algorithm-based solution to tighten the security level in the IoT-Smart environment network. The Intrusion Detection System (IDS) considered in this paper is Network IDS, which investigates the manufacturer usage description, digital twins, and deep learning-based user behavior information. IoT devices' communication and the users in smart buildings are automatically connected in the Intelligent Communication system. Since many devices and users are interconnected in smart buildings, the probability of cyber-attack is high. Thus, better security is needed in smart buildings and smart environments. It should focus on securing IoT devices, users, and their communication. Hence, this paper developed a deep learning-based anomaly detection framework to dynamically monitor the issues and problems with MUD profiles and detect the anomaly behavior. The Manufacturer Usage Description (MUD) profiles, dynamic user behavior, IoT devices' traffic data the pattern of abnormal/anomaly traffic at the device level is predicted while traffic occurs. The MUD-ML-based model is implemented in Python software, verifying the results.}
}
@article{WESCOAT202357,
title = {Redefining the digital triplet for surrogate system integration},
journal = {Manufacturing Letters},
volume = {36},
pages = {57-61},
year = {2023},
issn = {2213-8463},
doi = {https://doi.org/10.1016/j.mfglet.2023.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2213846323000159},
author = {Ethan Wescoat and Matthew Krugh and Vinita Jansari and Laine Mears},
keywords = {Purposeful failure twin, Purposeful failure methodology, Digital twin, Digital triplet},
abstract = {Predictive Maintenance (PdM) requires methods and tools to convey process information to maintenance planners allowing for data-driven repair decisions. Cyber-Physical Systems (CPS) and Digital Twins (DT) are current tools that transform data for informed decision making; however, the successful deployment of these tools is hampered by missing or low levels of training data for machine specific events such as failure. This paper proposes a standardized framework for adapting data from offline environments to train online systems without real world failure training data. This novel process, the Surrogate Digital Triplet (SDTr) framework, incorporates a third system, the surrogate triplet, to transfer data between the lab (offline) and production (online) environment. SDTr standardizes the data, information, and knowledge interfaces between systems to pass offline learning to the real world in a traceable manner.}
}
@article{DAI2023164858,
title = {Achieving better indoor air quality with IoT systems for future buildings: Opportunities and challenges},
journal = {Science of The Total Environment},
volume = {895},
pages = {164858},
year = {2023},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2023.164858},
url = {https://www.sciencedirect.com/science/article/pii/S0048969723034812},
author = {Xilei Dai and Wenzhe Shang and Junjie Liu and Min Xue and Congcong Wang},
keywords = {Indoor air quality, Data-driven modeling, Machine learning, Internet of things, Occupant-centric control, Digital twins},
abstract = {With the development of IoT technology and low-cost indoor air quality (IAQ) sensors, the IoT-based IAQ monitoring platform has garnered significant research interest and demonstrated its potential in enhancing IAQ management. This study presents a comprehensive review of previous research on the development and application of IoT-based IAQ platforms in different built environments. It offers detailed insights into the design and implementation of recent IoT-based IAQ platforms. The findings indicate that the IoT-based IAQ platforms are able to provide reliable information for IAQ monitoring. To ensure quality control of the IoT-based IAQ platform, it is suggested to replace the sensors every 4–6 months for reliable monitoring. In another aspect, integrating data-driven technology into the platform is crucial for IAQ prediction and efficient control of ventilation systems, leveraging the wealth of data available from the IoT platform. According to recent studies that applied data-driven algorithms for IAQ management, it can be confirmed that the data-driven algorithms are able to prompt IAQ by providing either more information or a control strategy. However, it should be noted that only 9.1 % of the developed platforms integrated data-driven models for IAQ management. Based on our findings, current challenges and further opportunities are discussed. Future studies should focus on integrating data-driven algorithms into IoT-based IAQ platforms and developing digital twins that can be used for real building IAQ management. However, there is obvious tension between controlling ventilation for energy efficiency versus better air quality. It is important to make a balance between energy efficiency and better air quality according to the current situations of specific built environments. Also, the next generation of IoT-based IAQ platforms should include occupants in the loop to create a more occupant-centric IAQ management approach.}
}
@article{ZOHDI2023115991,
title = {A machine-learning digital-twin for rapid large-scale solar-thermal energy system design},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {412},
pages = {115991},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2023.115991},
url = {https://www.sciencedirect.com/science/article/pii/S0045782523001147},
author = {T.I. Zohdi},
keywords = {Solar-thermal, Energy management systems, Digital-twin, Machine-learning},
abstract = {In many industrialized regions of the world, large-scale photovoltaic systems now contribute a significant part to the energy portfolio during daylight operation. However, as energy demands peak shortly before sunset and persist for several hours afterwards, the integration of solar-thermal systems is extremely advantageous as a green “bridge” energy source. Accordingly, this work develops a digital-twin model to track and optimize the flow of incoming solar power through a complex solar-thermal storage system, consisting of a large array of adaptable mirrors, an optical-receiver and a power distribution system for customers to extract energy. Specifically, the solar power flow is rapidly computed with a reduced order model of Maxwell’s equations, based on a high-frequency decomposition of the irradiance into multiple rays that experience mirror reflections, losses and ultimately receiver absorption and customer delivery. The method allows for rapid testing (in microseconds) of the performance of large numbers of mirror-receiver layout configurations in design space, over extremely long time periods, such as weeks, months and years, using a genetic-based machine-learning digital-twin framework, which integrates submodels for: •optics and tracking of the Fresnel multi-mirror system,•thermal absorption of the optical energy by the receiver and•optimal operating temperatures balancing radiative losses with heat storage. The overall machine-learning digital-twin optimizes the configuration layout to balance meeting customer demands and operational efficiency. Numerical examples are provided to illustrate the approach. Finally, a deep-learning algorithm is developed and applied to the create an Artificial Neural-Net representation, which allows for even further simulation speedup.}
}
@article{ERDOGDU2023101042,
title = {Mathematical modeling of food thermal processing: current and future challenges},
journal = {Current Opinion in Food Science},
volume = {51},
pages = {101042},
year = {2023},
issn = {2214-7993},
doi = {https://doi.org/10.1016/j.cofs.2023.101042},
url = {https://www.sciencedirect.com/science/article/pii/S2214799323000565},
author = {Ferruh Erdogdu},
abstract = {Food industry still relies on conventional canning and aseptic processing for thermal applications, while novel approaches have been introduced for process and energy efficiency with their environmentally-friendly features. Designing and optimizing a thermal process are the main concerns of the food industry where equipment design with manufacturing and process control features are also considered. Therefore, current and future challenges of mathematical approaches and their benefits for the upcoming challenges were introduced. Evolution of modeling studies was also presented, and new enabling technologies combined with mathematical modeling for the food processing were explained for the view of a sustainable and efficient processing.}
}
@article{ZHANG2023102601,
title = {Digital twin-enabled grasp outcomes assessment for unknown objects using visual-tactile fusion perception},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {84},
pages = {102601},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102601},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000777},
author = {Zhuangzhuang Zhang and Zhinan Zhang and Lihui Wang and Xiaoxiao Zhu and Huang Huang and Qixin Cao},
keywords = {Grasp outcomes assessment, Visual-tactile perception, Deep learning, Multimodal fusion, Digital twin},
abstract = {Humans can instinctively predict whether a given grasp will be successful through visual and rich haptic feedback. Towards the next generation of smart robotic manufacturing, robots must be equipped with similar capabilities to cope with grasping unknown objects in unstructured environments. However, most existing data-driven methods take global visual images and tactile readings from the real-world system as input, making them incapable of predicting the grasp outcomes for cluttered objects or generating large-scale datasets. First, this paper proposes a visual-tactile fusion method to predict the results of grasping cluttered objects, which is the most common scenario for grasping applications. Concretely, the multimodal fusion network (MMFN) uses the local point cloud within the gripper as the visual signal input, while the tactile signal input is the images provided by two high-resolution tactile sensors. Second, collecting data in the real world is high-cost and time-consuming. Therefore, this paper proposes a digital twin-enabled robotic grasping system to collect large-scale multimodal datasets and investigates how to apply domain randomization and domain adaptation to bridge the sim-to-real transfer gap. Finally, extensive validation experiments are conducted in physical and virtual environments. The experimental results demonstrate the effectiveness of the proposed method in assessing grasp stability for cluttered objects and performing zero-shot sim-to-real policy transfer on the real robot with the aid of the proposed migration strategy.}
}
@article{LIU202395,
title = {An effective energy management Layout-Based reinforcement learning for household demand response in digital twin simulation},
journal = {Solar Energy},
volume = {258},
pages = {95-105},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23002967},
author = {Huafeng Liu and Qine Liu and Chaoping Rao and Fei Wang and Fahad Alsokhiry and Alexey V. Shvetsov and Mohamed A. Mohamed},
keywords = {Fuzzy reasoning, Reinforcement learning, Solar-based smart home, Home energy management, Demand response, digital twin},
abstract = {With the growth in energy consumption, demand response (DR) programs in the power network have gained popularity and can be expected to become more widespread in the future. Through DR programs, users are encouraged for utilizing renewable energy and reducing their power consumption at peak times, thereby helping to balance supply and demand on the grid, as well as generating revenue from the sale of excess power. This paper presents an effective energy management layout (EML) for household DR employing Reinforcement Learning (RL) and Fuzzy Reasoning (FR). RL would be a model-free control method that consists of doing measures and assessing the outcomes as it interacts with the environments. Through direct integration of customer feedback into its control logic, the suggested method takes into account user satisfaction by utilizing FR as a reward function. Through the shift of controllable devices from peak hours, whenever energy cost is higher, to off-peak periods, whenever energy cost is low, Q-learning, an RL method according to a reward scheme, has been applied for scheduling the execution of smart home devices. With the suggested method, 14 home devices can be controlled by one agent, and many status-action pairs as well as fuzzy logic for the reward function are used to assess the actions taken for a particular status. Simulations are implemented in the digital twin environment and demonstrate that the suggested device planning method smooths the energy usage and minimizes the energy price by taking into account the consumers' satisfaction, the consumers' feedback, and their satisfaction settings. The Home EML has been presented with a consumer interface in MATLAB/Simulink for demonstrating the suggested DR approach. The simulation tools include smart devices, energy price signals, smart meters, solar photovoltaics, batteries, electric vehicle, and grid supply.}
}
@article{RACHMAWATI2023106430,
title = {Digital twin-enabled 3D printer fault detection for smart additive manufacturing},
journal = {Engineering Applications of Artificial Intelligence},
volume = {124},
pages = {106430},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106430},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623006140},
author = {Syifa Maliah Rachmawati and Made Adi Paramartha Putra and Jae Min Lee and Dong Seong Kim},
keywords = {Additive manufacturing, Deep learning, Digital twin, Fault detection, FDM printer},
abstract = {Early failure detection is required for Fused Deposition Modelling (FDM) 3D printers to reduce material waste. Typically, such systems are created based on images captured during printing or sensor data for tracking the extruder’s movement. This work presents a novel approach to sensor data-driven fault diagnosis, utilizing Artificial Intelligence (AI) technology to investigate the temperature imbalance in the extruder and printing surface. First, a Lightweight Convolutional Neural Network (LCNN) is proposed to detect faults from sensory data. The model’s architecture concatenates the CNN layer to extract additional features, improving the model’s performance while maintaining a lightweight configuration suitable for real-time monitoring systems. Second, the concept of Digital Twin (DT) technology for FDM 3D printer fault detection is introduced. The DT creates a virtual representation of a physical object, and its functionality is validated by examining the network’s latency and System Overhead (SO) as the number of clients increases. The simulation results show that the proposed LCNN with a DT environment can effectively monitor, detect, and control the physical workplace with an F1-Score of 0.9981 and an average latency of 995.4253ms. Additionally, this research contributes to the development of future technologies for virtual condition monitoring of 3D printer abnormalities, which will be essential for intelligent and autonomous factories.}
}
@article{IVANOV2023108938,
title = {Intelligent digital twin (iDT) for supply chain stress-testing, resilience, and viability},
journal = {International Journal of Production Economics},
volume = {263},
pages = {108938},
year = {2023},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2023.108938},
url = {https://www.sciencedirect.com/science/article/pii/S0925527323001706},
author = {Dmitry Ivanov},
keywords = {Supply chain resilience, Intelligent digital twin, Data analytics, Stress-test, Ripple effect, anyLogistix},
abstract = {A large variety of models have been developed in the last two decades aiming at supply chain (SC) stress-testing and resilience. New digital and artificial intelligence (AI) technologies allow to develop novel approaches and tools in this area for the transition from standalone models to intelligent decision-support systems (DSSs). However, the literature lacks concepts and guidelines for the design of such systems. In this paper, we offer a generalized decision-making framework for using digital twins in SC stress-testing and resilience analysis as well as delineate how digital twins can contribute to theory development in SC resilience and viability. We position our proposed approach as an intelligent digital twin (iDT) – a human–AI system which visualizes physical SCs in digital form, collects and processes data for modelling using analytics methods, mimics human decision-making rules, and creates new knowledge and decision-making algorithms through human–AI collaboration. We conclude that the iDT supports monitoring, disruption prediction (early signals), event-driven responses, learning, and proactive thinking, integrating proactive and reactive approaches to SC resilience. The iDT helps to make the unknown known and so contributes to the development of a proactive, adaptation-based view on SC resilience and viability. This research can be used to solve existing problems in the industry, and it develops new methods and infrastructures for solutions to future problems.}
}
@article{NTEFUASAAH2023106609,
title = {Blockchain technology in the AEC industry: Scientometric analysis of research activities},
journal = {Journal of Building Engineering},
volume = {72},
pages = {106609},
year = {2023},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2023.106609},
url = {https://www.sciencedirect.com/science/article/pii/S235271022300788X},
author = {Alvina Ekua {Ntefua Saah} and Jae-ho Choi},
keywords = {Blockchain technology, Smart contract, Digital technology, AEC industry, Scientometric review},
abstract = {The architectural, engineering and construction (AEC) industry is plagued with complex and difficult problems such as late payments, inadequate information sharing and supply chain issues. Thus, advances in blockchain technology are increasingly investigated as a viable digital technology to address such problems. This advantage has led to blockchain gaining significant traction within the AEC industry thus piquing the interests of researchers. Although prior reviews on blockchain have been well appreciated, those studies do not give a complete picture of blockhain in the AEC industry as a whole. For example, whereas some researchers focused their studies on the construction industry, others did so across multiple domains. And researchers who attempted to review blockchain in the AEC industry employed a qualitative methodology which have been criticized for its lack of reproducibility and susceptibility to subjective biases. Moreover, those studies which utilized a quantitative approach employed a single science mapping tool for its analysis, which did not meet the criteria for a robust science mapping research. Therefore, there is the need for further review research efforts to supplement the limitations of the previous works. Thus, this study presents a robust science-mapping based analysis of the state-of-the art research on blockchain technology in the AEC industry, by combining three scientometric tools to analyze quantitatively, 12,549 relevant bibliographic data retrieved from the Web of Science (WoS) database. The results revealed that blockchain can be used as an optimization technology to optimize processes, systems, activities, and decision-making in the AEC industry. The findings confirmed that blockchain is being utilized to resolve AEC management problems in supply chain, projects, risk, cost, privacy, and security. The study further disclosed Industry 4.0 technologies that have presently been integrated with blockchain to improve its practicability in the AEC industry, as well as the understudied research areas. Within the existing corpus of literature on blockchain, the research findings are informative in identifying and comprehending trends and patterns, including core research topics, countries, and institutions and their interconnection. This study contributes to the global body of knowledge in blockchain by providing a holistic view of the state-of-the-art development of blockchain and proposes the directions of future research efforts, while promoting the consciousness of blockchain in the AEC industry.}
}
@article{PAN2023100135,
title = {Building energy simulation and its application for building performance optimization: A review of methods, tools, and case studies},
journal = {Advances in Applied Energy},
volume = {10},
pages = {100135},
year = {2023},
issn = {2666-7924},
doi = {https://doi.org/10.1016/j.adapen.2023.100135},
url = {https://www.sciencedirect.com/science/article/pii/S2666792423000148},
author = {Yiqun Pan and Mingya Zhu and Yan Lv and Yikun Yang and Yumin Liang and Ruxin Yin and Yiting Yang and Xiaoyu Jia and Xi Wang and Fei Zeng and Seng Huang and Danlin Hou and Lei Xu and Rongxin Yin and Xiaolei Yuan},
keywords = {Building performance simulation, Performance-driven design, Operational optimization, Digital twin, Building-to-grid},
abstract = {As one of the most important and advanced technology for carbon-mitigation in the building sector, building performance simulation (BPS) has played an increasingly important role with the powerful support of building energy modelling (BEM) technology for energy-efficient designs, operations, and retrofitting of buildings. Owing to its deep integration of multi-disciplinary approaches, the researchers, as well as tool developers and practitioners, are facing opportunities and challenges during the application of BEM at multiple scales and stages, e.g., building/system/community levels and planning/design/operation stages. By reviewing recent studies, this paper aims to provide a clear picture of how BEM performs in solving different research questions on varied scales of building phase and spatial resolution, with a focus on the objectives and frameworks, modelling methods and tools, applicability and transferability. To guide future applications of BEM for performance-driven building energy management, we classified the current research trends and future research opportunities into five topics that span through different stages and levels: (1) Simulation for performance-driven design for new building and retrofit design, (2) Model-based operational performance optimization, (3) Integrated simulation using data measurements for digital twin, (4) Building simulation supporting urban energy planning, and (5) Modelling of building-to-grid interaction for demand response. Additionally, future research recommendations are discussed, covering potential applications of BEM through integration with occupancy and behaviour modelling, integration with machine learning, quantification of model uncertainties, and linking to building monitoring systems.}
}
@article{KAY2023107848,
title = {Foundations for Human-AI teaming for self-regulated learning with explainable AI (XAI)},
journal = {Computers in Human Behavior},
volume = {147},
pages = {107848},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107848},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223001991},
author = {Judy Kay},
keywords = {Self-regulated learning, Learner control, Explainable AI (XAI), Scrutability, Open learner model (OLM)},
abstract = {This discussion takes a human-centred perspective of the contributions of the collection. Its papers explore diverse, new uses of AI with rich, multimedia sensor data towards new ways to measure and understand self-regulated learning. This work can contribute to the learning sciences. It can also provide a foundation for future personalised teaching and learning systems with explainable AI (XAI) and learner control. I will discuss the papers from that perspective with a focus on an important form of XAI in education – the Open Learner Models (OLM). When suitably designed, OLMs can empower a learner to: (1) contribute data about themself and their self-regulated learning processes, complementing conventional and multimedia data; (2) scrutinise and control learner data collection and use in AI-based systems and (3) be the controlling partner in AI-teaming that scaffolds their self-regulated learning processes.}
}
@article{RODRIGUEZ2023103958,
title = {Updating digital twins: Methodology for data accuracy quality control using machine learning techniques},
journal = {Computers in Industry},
volume = {151},
pages = {103958},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.103958},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523001082},
author = {Fabio Rodríguez and William D. Chicaiza and Adolfo Sánchez and Juan M. Escaño},
keywords = {Adaptive digital twin, Neural network (NN), Fuzzy inference system, Fault detection, Adaptive decision making},
abstract = {The Digital Twin (DT) constitutes an integration between cyber and physical spaces and has recently become a popular concept in smart manufacturing and Industry 4.0. The related literature provides a DT characterisation and identifies the problem of updating DT models throughout the product life cycle as one of the knowledge gaps. The DT must update its performance by analysing the variable data in real time of the physical asset, whose behaviour is constantly changing over time. The automatic update process involves a data quality problem, i.e., ensuring that the captured values do not come from measurement or provoked errors. In this work, a novel methodology has been proposed to achieve data quality in the interconnection between digital and physical spaces. The methodology is applied to a real case study using the DT of a real solar cooling plant, acting as a learning decision support system that ensures the quality of the data during the update of the DT. The implementation of the methodology integrates a neurofuzzy system to detect failures and a recurrent neural network to predict the size of the errors. Experiments were carried out using historical plant data that showed great results in terms of detection and prediction accuracy, demonstrating the feasibility of applying the methodology in terms of computation time.}
}
@article{WANG202337,
title = {Mutual mentor: Online contrastive distillation network for general continual learning},
journal = {Neurocomputing},
volume = {537},
pages = {37-48},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.03.066},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223003132},
author = {Qiang Wang and Zhong Ji and Jin Li and Yanwei Pang},
keywords = {General continual learning, Online contrastive distillation, Knowledge distillation, Supervised contrastive learning, Image classfication},
abstract = {The goal of General Continual Learning (GCL) is to preserve learned knowledge and learn new knowledge with constant memory from infinite data stream where task boundaries are blurry. Distilling the model’s response of reserved samples between the old and new models is an effective way to achieve promising performance on GCL. However, it accumulates the inherent old model’s response bias and is not robust to model changes. To this end, we propose a Mutual Mentor General Continual Learning (MMGCL) framework to tackle these problems, which explores a training process in which the student and teacher models mentor each other. Concretely, the student model consolidates the learned knowledge by respectively aligning the relation and adaptive responses with those of the teacher model while the teacher model updates its parameters by integrating the parameters of the student model to accumulate new knowledge. To further improve the effectiveness of the mutual mentor, we integrate the inter-instance knowledge to optimize the outputs of the teacher model, which can not only supervise the student model but also indirectly optimize the teacher model. Extensive experiments on six benchmark datasets demonstrate that our MMGCL significantly outperforms state-of-the-art approaches under diverse continual learning settings with various buffer sizes.}
}
@article{ZHAO2023119363,
title = {Multi-view computable online learner modeling by heterogeneous network: An AI-enabled perspective},
journal = {Information Sciences},
volume = {645},
pages = {119363},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119363},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523009489},
author = {Anping Zhao and Yu Yu},
keywords = {Computable modeling, Multi-view, Semantic embeddings, Heterogeneous network},
abstract = {To support accurate personalized online intelligent education applications in the big data environment, computable online learner modeling is very important. It can accurately capture the unique needs and characteristics of learners in a computable way and provides customized learning experiences. We propose a structured semantic embedding-based approach for online learner modeling, which considers both the multidimensional learners' characteristics and heterogeneous information on the learning context to develop a comprehensive learner model. Specifically, an AI-enabled heterogeneous information network embedding technique is employed to encode complications of different learners' characteristics and rich relationships between them, which integrate different explicit characteristic information and implicit association information about inherent multidimensional interactions for computable learners modeling. Extensive experimental results and evaluations demonstrate that the proposed model achieves the optimal performance on the Precision@N and Recall@N metrics in course recommendation tasks, and the Accuracy and F−score metrics in learner clustering tasks are also better than other baseline models, which prove the ability to boost the performance of downstream tasks by incorporating and capturing the underlying semantic and structural information among different types of nodes to fuse the embedding for learner modeling.}
}
@article{RAUDMAE2023e00436,
title = {ROBOTONT – Open-source and ROS-supported omnidirectional mobile robot for education and research},
journal = {HardwareX},
volume = {14},
pages = {e00436},
year = {2023},
issn = {2468-0672},
doi = {https://doi.org/10.1016/j.ohx.2023.e00436},
url = {https://www.sciencedirect.com/science/article/pii/S2468067223000433},
author = {Renno Raudmäe and Sandra Schumann and Veiko Vunder and Maarika Oidekivi and Madis Kaspar Nigol and Robert Valner and Houman Masnavi and Arun Kumar Singh and Alvo Aabloo and Karl Kruusamäe},
keywords = {Open-source, Educational robotics, ROS (Robot Operating System), Holonomic, Mobile robot, Software, Hardware, Electronics, Professional education, University teaching},
abstract = {In order to achieve visionary concepts such as Society 5.0 and Industry 5.0, there is a growing need for people who are able to create innovative robotic technologies. Training students to become such skilled professionals requires transitioning from often toy-like educational platforms with significant hardware limitations to costly research robots with full ROS (Robot Operating System) support. To aid in this transition, we propose Robotont – an open-source omnidirectional mobile robot platform with both physical hardware and a digital twin. Robotont enables robotics education with professional tools as well as provides researchers with a capable mobility platform for validating and demonstrating scientific results. Robotont has successfully been used for university teaching, professional education, and online courses about ROS and robotics.}
}
@article{ELMAZ2023108310,
title = {Reinforcement learning-based approach for optimizing solvent-switch processes},
journal = {Computers & Chemical Engineering},
volume = {176},
pages = {108310},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108310},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423001801},
author = {Furkan Elmaz and Ulderico {Di Caprio} and Min Wu and Yentl Wouters and Geert {Van Der Vorst} and Niels Vandervoort and Ali Anwar and M. Enis Leblebici and Peter Hellinckx and Siegfried Mercelis},
keywords = {Reinforcement learning, Process control, Solvent-switch optimization, Separation process},
abstract = {In chemical and pharmaceutical industries, process control optimization is a crucial step to improve economical efficiency and the environmental impact. The current state-of-practice heavily relies on expert knowledge and extensive lab experiments. This not only increases the development time but also limits the discovery of new strategies. In this study, we propose Reinforcement Learning-based optimization approach for solvent-switch processes. We utilize a digital twin as the environment for a process designed to switch the THF to 1-propanol. A reward function is created for minimizing the process time and constraints are implemented using logarithmic barrier functions. A PPO agent is trained on the environment. The agent proposed a novel strategy that combines two conventionally separate phases, evaporation and constant volume distillation. This strategy resulted in an overall cost decrease of 24.9% compared to the baseline strategy. Moreover, results were verified experimentally on a pilot plant of Johnson & Johnson (J&J).}
}
@article{KISHIMOTO2023233411,
title = {Conditional generative adversarial network for generation of three-dimensional porous structure of solid oxide fuel cell anodes with controlled volume fractions},
journal = {Journal of Power Sources},
volume = {580},
pages = {233411},
year = {2023},
issn = {0378-7753},
doi = {https://doi.org/10.1016/j.jpowsour.2023.233411},
url = {https://www.sciencedirect.com/science/article/pii/S0378775323007875},
author = {Masashi Kishimoto and Yodai Matsui and Hiroshi Iwai},
keywords = {Solid oxide fuel cell, Synthetic structure, Machine learning, Generative adversarial network, Volume fraction, Digital twin},
abstract = {A structure generation model based on a generative adversarial network (GAN) is developed to synthesize artificial porous microstructures of solid oxide fuel cell (SOFC) anodes. Different from the conventional framework of GANs, additional training is performed for the generator to control statistical parameters, namely, volume fractions, of the generated structures. The developed model is validated by comparing the synthesized structures with the real electrode microstructures obtained by three-dimensional microscopy analysis. Microstructural parameters, such as volume fraction, specific surface area, and triple-phase boundary density, are used for the comparison in addition to the visual observation. The effect of the input vector size for the generator and the definition of the loss on the ability to generate realistic structures and control the volume fractions of the structures is investigated. The developed model successfully generates realistic anode microstructures with accurately controlled volume fractions, even for compositions not included in the training datasets. It is also found that the balance between the losses influences the accuracy of the volume fraction control and diversity of the generated structures. The GAN model developed is expected to be helpful in constructing a digital twin of electrode fabrication and evaluation processes.}
}
@article{ZHAO202330,
title = {Battery prognostics and health management for electric vehicles under industry 4.0},
journal = {Journal of Energy Chemistry},
volume = {84},
pages = {30-33},
year = {2023},
issn = {2095-4956},
doi = {https://doi.org/10.1016/j.jechem.2023.04.042},
url = {https://www.sciencedirect.com/science/article/pii/S2095495623002711},
author = {Jingyuan Zhao and Andrew F. Burke},
keywords = {Lithium-ion battery, Prognostics and health management, Machine learning, Cloud, Artificial intelligence, Digital twins, Lifelong learning}
}
@article{SOLIMAN2023106318,
title = {AI-based UAV navigation framework with digital twin technology for mobile target visitation},
journal = {Engineering Applications of Artificial Intelligence},
volume = {123},
pages = {106318},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106318},
url = {https://www.sciencedirect.com/science/article/pii/S095219762300502X},
author = {Abdulrahman Soliman and Abdulla Al-Ali and Amr Mohamed and Hend Gedawy and Daniel Izham and Mohamad Bahri and Aiman Erbad and Mohsen Guizani},
keywords = {Deep Reinforcement Learning, UAVs, Target visitation, Energy minimization, Digital twin, Testbed development},
abstract = {Unmanned Air Vehicles (UAVs), i.e. drones, have become a key enabler technology of many reconnaissance applications in different fields, such as military, maritime, and transportation. UAVs offer several benefits, such as affordability and flexibility in deployment. However, their limited flight time due to energy consumption is one of the key limitations. Therefore, it is crucial to ensure that UAVs can complete the mission while consuming the least energy possible. In this paper, we propose a novel framework for UAV smart navigation to minimize the time and energy of planning mobile targets visitation. We develop a Deep Reinforcement Learning (DRL) approach to allow the drone to learn the targets’ mobility pattern and build its least energy scanning strategy accordingly. We conduct an initial evaluation of the system and our proposed DRL model policy using simulation. Then, to overcome the time-consuming exploration phase of DRL, we develop a Digital Twin (DT) environment of 3D physics-based simulator, which can be used to train the DRL agent efficiently. We also developed a testbed based on hardware integration with the parrot ANAFI drone to verify the feasibility of the proposed methodology. Our findings confirm that the DRL-based agent can achieve performance close to that of a benchmark policy. Moreover, the testbed experiment validates the practicality of utilizing the DT environment for DRL exploration.}
}
@article{ZHAO2023111863,
title = {A novel deep learning based forecasting model for carbon emissions trading: A comparative analysis of regional markets},
journal = {Solar Energy},
volume = {262},
pages = {111863},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2023.111863},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X23004966},
author = {Yongchao Zhao and Lipeng Liu and Anqi Wang and Mengkai Liu},
keywords = {Deep learning, CNN-BFA, Carbon emission trading, Bacteria foraging algorithm, Forecasting},
abstract = {This paper proposes a deep learning-based forecasting system for carbon emissions trading in regional markets. The system utilizes a hybrid convolutional neural network (CNN) deep learning algorithm to predict future carbon emission levels and facilitate the trading of carbon emission allowances. The system is compared to traditional methods of forecasting in order to assess the accuracy and performance of the system. In order to enhance the CNN performance, a new optimization algorithm based on bacteria foraging algorithm (BFA) is proposed which uses a modification to make a global search. By leveraging digital twins in the markets, a comparison is conducted using data from three regional carbon markets: the European Union Emissions Trading System, the Regional Greenhouse Gas Initiative, and the China Carbon Market. Results show that the proposed BFA-CNN based deep learning-based system outperforms traditional forecasting methods in terms of accuracy and provides more reliable estimates of future carbon emissions. The proposed system is a novel approach to carbon emissions trading and has the potential to improve the efficiency of regional carbon markets.}
}
@article{LIU2023128992,
title = {Digital twin of the atmospheric turbulence channel based on self-supervised deep learning algorithm},
journal = {Physics Letters A},
volume = {481},
pages = {128992},
year = {2023},
issn = {0375-9601},
doi = {https://doi.org/10.1016/j.physleta.2023.128992},
url = {https://www.sciencedirect.com/science/article/pii/S0375960123003729},
author = {Ying Liu and HuiCun Yu and Jie Tang and YueXiang Cao and JiaHao Li and ZhiFeng Deng and Dan Wu and HuaZhi Lun and Lei Shi},
keywords = {Digital twin, Atmospheric turbulence, Deep learning, Self-supervised learning},
abstract = {High dimensional quantum entanglement based on orbital angular momentum (OAM) can provide infinite freedom theoretically, providing a significant improvement on the capacity of the quantum communication. However, the vortex beam that carries OAM signal can be easily distorted by atmospheric turbulence and can degrade the performance of the system. Consequently, for the operation, administration and maintenance of quantum system, an accurate digital twin model of the turbulent channel is necessary. Digital twin model is a mathematical model which can reflect the influence of atmospheric channel on quantum system by theoretical analysis. Nevertheless, it is challenging to achieve for the complex mechanism of atmospheric turbulence. To address this problem, deep learning (DL) techniques have been studied recently. Whereas, for the training of DL, a massive number of labeled samples are needed, i.e., the actual free-space channel, which are hard to be obtained in practical systems. The pool generalization also hinders the use of these DL-based algorithms in practice. To overcome the above challenges, we propose a self-supervised DL algorithm, which does not need any labeled samples in advance, meaning the training of the algorithm can be restarted any time once the environment changes. Compared with previous studies, the proposed algorithm can better suite as the digital twin of the turbulent channel. To verify the performance of the proposed algorithm, we perform extensive verification, whose results demonstrate the superior performance of the proposed method.}
}
@article{WANG2023168,
title = {The integration of digital twin and serious game framework for new normal virtual urban exploration and social interaction},
journal = {Journal of Urban Management},
volume = {12},
number = {2},
pages = {168-181},
year = {2023},
issn = {2226-5856},
doi = {https://doi.org/10.1016/j.jum.2023.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2226585623000225},
author = {Sheng-ming Wang and Lan Hong Vu},
keywords = {COVID-19, New normal, Serious game, Digital twin, Virtual urban exploration and social interaction, Urban planning},
abstract = {COVID-19 has disconnected humanity, reduced social interaction in physical urban areas, and led to the new normal, which describes the anticipated changes in human life and professionals due to the impact of the pandemic. In addition, as part of digital transformation, the post-pandemic New Normal includes accelerating digital solutions and new standards for virtual urban exploration and planning. This study applies the concept of digital twin and serious game design and uses Minecraft, a game-based platform that inspires creative, inclusive learning through play, for virtual urban exploration and the development of social interaction among participants. Dadaocheng, a historical area of Taipei city, is then studied as a case study with the Geoboxers application to develop the prototype for a co-creation experiment in Minecraft. The prototype development and the results of the experiment are then used in the Analytic Hierarchical Process (AHP) method to evaluate a set of influential criteria proposed in this study through pairwise comparisons by expert panelists. The results of the AHP analysis reveal users' simultaneous preferences for urban planning and social interaction with urban characteristics (22.14%), urban exploration (12.29%), and 3D models (11.97%). Subsequently, the research results showed a need to promote the integration of digital twins and serious game applications as digital tools for urban exploration and social interaction, increasing post-pandemic virtual urban planning and applying new urban design techniques. This study also contributes to the acceleration of digital transformation in urban planning and management.}
}
@article{TIAN2023109325,
title = {Digital twins of multiple energy networks based on real-time simulation using holomorphic embedding method, Part II: Data-driven simulation},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {153},
pages = {109325},
year = {2023},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2023.109325},
url = {https://www.sciencedirect.com/science/article/pii/S0142061523003824},
author = {Hang Tian and Haoran Zhao and Haoran Li and Xiaoli Huang and Xiaoyi Qian and Xu Huang},
keywords = {Digital twins, Holomorphic embedding, Multiple energy networks, Real-time simulation, Data-driven simulation},
abstract = {Digital twins can act as a transformative role in improving the operational performance of multiple energy networks (MEN) by examining the impact of implementing newer technologies, extra equipment, control strategies, etc. The objective of this series of papers is to present digital twins of MEN that can be simulated in real-time using the holomorphic embedding method. While Part I concentrated on mechanism-driven modeling of the holomorphic embedding-based model (HEM), this paper (Part II) focuses on data-driven simulation to ensure the twin is synchronized with actual physical objects. A parametric synchronization method (PSM) is proposed, which assists HEM in closely matching the actual dynamic behavior with time-varying characteristics. A machine learning surrogate model (MLSM) is proposed to accelerate the search of HEM’s convergence radius, which is critical to maintaining the twin’s real-time computational performance. Finally, the finalized digital twins are tested on the OPAL-RT simulation platform equipped with a real-time simulator. In a medium-sized MEN test case with a minor time step of 0.01s, the digital twins can be validated with a faster than real-time performance even without the assistance of parallel computing.}
}
@article{KAKLIS2023100178,
title = {Enabling digital twins in the maritime sector through the lens of AI and industry 4.0},
journal = {International Journal of Information Management Data Insights},
volume = {3},
number = {2},
pages = {100178},
year = {2023},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2023.100178},
url = {https://www.sciencedirect.com/science/article/pii/S2667096823000253},
author = {Dimitrios Kaklis and Iraklis Varlamis and George Giannakopoulos and Takis J. Varelas and Constantine D. Spyropoulos},
keywords = {Fuel oil consumption estimation, Digital twin, Splines, Quadratic estimators, Delaunay triangulation, Time-series forecasting, Unsupervised clustering, Ensemble learning, Deep learning, Least squares optimization},
abstract = {Sustainability and environmental compliance in ship operations is a prominent research topic as the waterborne sector is obliged to adopt ”green” mitigation strategies towards a low emissions operational blueprint. Fuel-Oil-Consumption (FOC) estimation, constitutes one of the key components in maritime transport information systems for efficiency and environmental compliance. This paper deals with FOC estimation in a more novel way than methods proposed in literature, by utilizing a reduced-sized feature set, which allows predicting vessel’s Main-Engine rotational speed (RPM). Furthermore, this work aims to place the deployment of such models in the broader context of a cutting-edge information system, to improve efficiency and regulatory adherence. Specifically, we integrate B-Splines in the context of two Deep Learning architectures and compare their performance against state-of-the-art regression techniques. Finally, we estimate FOC by combining velocity measurements and the predicted RPM with vessel-specific characteristics and illustrate the performance of our estimators against actual FOC data.}
}
@article{SUHAIL2023103961,
title = {ENIGMA: An explainable digital twin security solution for cyber–physical systems},
journal = {Computers in Industry},
volume = {151},
pages = {103961},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.103961},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523001112},
author = {Sabah Suhail and Mubashar Iqbal and Rasheed Hussain and Raja Jurdak},
keywords = {Cyber-physical system (CPS), Cybersecurity awareness, Digital twins (DTs), eXplainable AI (XAI), Gamification, Industry 5.0},
abstract = {Digital Twins (DTs), being the virtual replicas of their physical counterparts, share valuable knowledge of the underlying physical processes and act as data acquisition and dissemination sources to Cyber–Physical System (CPS). Moreover, without obstructing the ongoing operations, DTs also provide an assessment platform for evaluating the operational behavior and security of the CPS. Therefore, they become a potential source of data breaches and a broad attack surface for attackers to launch covert attacks. To detect and mitigate security loopholes in DTs, one of the potential solutions is to leverage a gamification approach that can assess the security level of DTs while providing security analysts with a controlled and supportive virtual training environment. Artificial Intelligence/Machine Learning (AI/ML)-based approaches can complement the idea of security orchestration and automation in the gamification approach. However, AI/ML-based DTs security solutions are generally constrained by the lack of transparency of AI operations, which results in less confidence in the decisions made by the AI models. To address the explainable security challenges of DTs, this article proposes a gamification approach called sEcuriNg dIgital twins through GaMification Approach (ENIGMA). While leveraging DTs as an offensive security platform, ENIGMA provides gaming scenarios to assess DTs’ security and train security analysts. The game players within ENIGMA are humans (the attacker team) and AI agents (the defender team). Furthermore, ENIGMA is supported by an eXplainable AI (XAI)-based DT security assessment model that explains the decisions made based on the SHAP values by the AI model on attack vectors for the defender team, i.e., the AI agent. The SHAP values illustrate the contribution of different features towards predicting the outcome of attack vectors. This explanation can help security analysts to take security measures based on reasoned and trustworthy decisions. Finally, experimental validation has been carried out to demonstrate the viability of ENIGMA.}
}
@article{NASERI2023113280,
title = {Digital twin of electric vehicle battery systems: Comprehensive review of the use cases, requirements, and platforms},
journal = {Renewable and Sustainable Energy Reviews},
volume = {179},
pages = {113280},
year = {2023},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2023.113280},
url = {https://www.sciencedirect.com/science/article/pii/S1364032123001363},
author = {F. Naseri and S. Gil and C. Barbu and E. Cetkin and G. Yarimca and A.C. Jensen and P.G. Larsen and C. Gomes},
keywords = {Artificial intelligence (AI), Battery management system (BMS), Battery passport, Battery recycling, Digital twin (DT), Electric vehicle (EV), Fault diagnosis, Internet-of-things (IoT), Machine learning (ML), Predictive maintenance, Remaining useful life (RUL), Second-life, Software architecture},
abstract = {Transportation electrification has been fueled by recent advancements in the technology and manufacturing of battery systems, but the industry yet is facing serious challenges that could be addressed using cutting-edge digital technologies. One such novel technology is based on the digital twining of battery systems. Digital twins (DTs) of batteries utilize advanced multi-layer models, artificial intelligence, advanced sensing units, Internet-of-Things technologies, and cloud computing techniques to provide a virtual live representation of the real battery system (the physical twin) to improve the performance, safety, and cost-effectiveness. Furthermore, they orchestrate the operation of the entire battery value chain offering great advantages, such as improving the economy of manufacturing, re-purposing, and recycling processes. In this context, various studies have been carried out discussing the DT applications and use cases from cloud-enabled battery management systems to the digitalization of battery testing. This work provides a comprehensive review of different possible use cases, key enabling technologies, and requirements for battery DTs. The review inclusively discusses the use cases, development/integration platforms, as well as hardware and software requirements for implementation of the battery DTs, including electrical topics related to the modeling and algorithmic approaches, software architectures, and digital platforms for DT development and integration. The existing challenges are identified and circumstances that will create enough value to justify these challenges, such as the added costs, are discussed.}
}
@article{ZAPAROLICUNHA2023110535,
title = {A review of machine learning methods applied to structural dynamics and vibroacoustic},
journal = {Mechanical Systems and Signal Processing},
volume = {200},
pages = {110535},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2023.110535},
url = {https://www.sciencedirect.com/science/article/pii/S0888327023004430},
author = {Barbara {Zaparoli Cunha} and Christophe Droz and Abdel-Malek Zine and Stéphane Foulard and Mohamed Ichchou},
keywords = {Machine learning, Structural health monitoring, Surrogate model, Active vibration control, Active noise control, Digital twin, Physics-guided machine learning},
abstract = {The use of Machine Learning (ML) has rapidly spread across several fields of applied sciences, having encountered many applications in Structural Dynamics and Vibroacoustic (SD&V). An advantage of ML algorithms compared to traditional techniques is that physical phenomena can be modeled using only sampled data from either measurements or simulations. This is particularly important in SD&V when the model of the studied phenomenon is either unknown or computationally expensive to simulate. This paper presents a survey on the application of ML algorithms in three classical problems of SD&V: structural health monitoring, active control of noise and vibration, and vibroacoustic product design. In structural health monitoring, ML is employed to extract damage-sensitive features from sampled data and to detect, localize, assess, and forecast failures in the structure. In active control of noise and vibration, ML techniques are used in the identification of state-space models of the controlled system, dimensionality reduction of existing models, and design of controllers. In vibroacoustic product design, ML algorithms can create surrogates that are faster to evaluate than physics-based models. The methodologies considered in this work are analyzed in terms of their strength and limitations for each of the three considered SD&V problems. Moreover, the paper considers the role of digital twins and physics-guided ML to overcome current challenges and lay the foundations for future research in the field.}
}
@article{PHUA2023382,
title = {Smart recoating: A digital twin framework for optimisation and control of powder spreading in metal additive manufacturing},
journal = {Journal of Manufacturing Processes},
volume = {99},
pages = {382-391},
year = {2023},
issn = {1526-6125},
doi = {https://doi.org/10.1016/j.jmapro.2023.04.062},
url = {https://www.sciencedirect.com/science/article/pii/S1526612523004152},
author = {Arden Phua and Peter S. Cook and Chris H.J. Davies and Gary W. Delaney},
keywords = {Digital twin, Additive manufacturing, Powder spreading},
abstract = {We present a new framework for learning novel operational strategies and dynamically controlling the layering process in metal additive manufacturing. Metal additive manufacturing technologies such as powder bed fusion (PBF) are generally constrained by a fixed action powder spreading process. At every layer, the print platform is lowered by a fixed amount, and the same recoating action is performed. Ideally this would lead to consistent layering and identical properties each time, but frequently process variability disrupts this procedure, leading to inconsistent layers. This can be mitigated by intelligently controlling the powder spreading process, which we achieve via a shift to digital methodologies that can reveal new process strategies and dynamically update the printer commands. We employ Bayesian optimisation as a method to build and train surrogate models for real-time control. We then demonstrate the utility of this Smart Recoating approach within an integrated simulation framework driven by realistic Discrete Element Method powder spreading simulations. Our results inform new strategies for controlling the recoater and print stage displacements, and demonstrate the potential of a digital twin control system to mitigate process variation and achieve consistent print quality in each layer.}
}
@article{KABLAN2023105090,
title = {Evaluation of stacked ensemble model performance to predict clinical outcomes: A COVID-19 study},
journal = {International Journal of Medical Informatics},
volume = {175},
pages = {105090},
year = {2023},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2023.105090},
url = {https://www.sciencedirect.com/science/article/pii/S1386505623001089},
author = {Rianne Kablan and Hunter A. Miller and Sally Suliman and Hermann B. Frieboes},
keywords = {Machine learning, Stacked ensemble, Stacked generalization, Meta learners, Clinical data analysis, COVID-19},
abstract = {Background
The application of machine learning (ML) to analyze clinical data with the goal to predict patient outcomes has garnered increasing attention. Ensemble learning has been used in conjunction with ML to improve predictive performance. Although stacked generalization (stacking), a type of heterogeneous ensemble of ML models, has emerged in clinical data analysis, it remains unclear how to define the best model combinations for strong predictive performance. This study develops a methodology to evaluate the performance of “base” learner models and their optimized combination using “meta” learner models in stacked ensembles to accurately assess performance in the context of clinical outcomes.
Methods
De-identified COVID-19 data was obtained from the University of Louisville Hospital, where a retrospective chart review was performed from March 2020 to November 2021. Three differently-sized subsets using features from the overall dataset were chosen to train and evaluate ensemble classification performance. The number of base learners chosen from several algorithm families coupled with a complementary meta learner was varied from a minimum of 2 to a maximum of 8. Predictive performance of these combinations was evaluated in terms of mortality and severe cardiac event outcomes using area-under-the-receiver-operating-characteristic (AUROC), F1, balanced accuracy, and kappa.
Results
The results highlight the potential to accurately predict clinical outcomes, such as severe cardiac events with COVID-19, from routinely acquired in-hospital patient data. Meta learners Generalized Linear Model (GLM), Multi-Layer Perceptron (MLP), and Partial Least Squares (PLS) had the highest AUROC for both outcomes, while K-Nearest Neighbors (KNN) had the lowest. Performance trended lower in the training set as the number of features increased, and exhibited less variance in both training and validation across all feature subsets as the number of base learners increased.
Conclusion
This study offers a methodology to robustly evaluate ensemble ML performance when analyzing clinical data.}
}
@article{MA2023110490,
title = {Digital twin-assisted enhanced meta-transfer learning for rolling bearing fault diagnosis},
journal = {Mechanical Systems and Signal Processing},
volume = {200},
pages = {110490},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2023.110490},
url = {https://www.sciencedirect.com/science/article/pii/S0888327023003989},
author = {Leiming Ma and Bin Jiang and Lingfei Xiao and Ningyun Lu},
keywords = {Digital twin, Meta-transfer learning, Few-shot learning, Finite element model updating, Bearing fault diagnosis},
abstract = {Fault diagnosis of bearing under variable working conditions is widely required in practice, and the combination of working conditions and fault fluctuations increases the complexity of addressing its related problems. By developing a virtual simulation model, a digital twin (DT) can obtain the same or even more information than the physical object at a lower cost. Furthermore, it has great potential in the application of bearing fault diagnosis. In this paper, the DT model of the bearing test rig is robustly established, and the fault diagnosis bearing between the simulation and physical object is realized using the proposed enhanced meta-transfer learning (EMTL). First, the DT model is established through parameter identification and modal testing, and the modeling accuracy of DT model reaching 95.685%. The bearing simulation and experimental data are then collected under the same conditions using the DT model and bearing test rig, and the simulation data with little deviation from the experimental data is obtained. Finally, an attention mechanism and domain adaptation are introduced into the EMTL, with the average accuracy of fault diagnosis of bearing reaching 95.18% with few-label target domain data. The proposed strategy is both theoretically significant and practically useful. The experiment results demonstrate that our method outperforms a series of state-of-the-art methods on the bearing fault diagnosis across various limited data conditions. The proposed strategy effectively solves the few-shot problem, which is both theoretically significant and practically useful.}
}
@article{LI2023119202,
title = {Dynamic data-free knowledge distillation by easy-to-hard learning strategy},
journal = {Information Sciences},
volume = {642},
pages = {119202},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119202},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523007879},
author = {Jingru Li and Sheng Zhou and Liangcheng Li and Haishuai Wang and Jiajun Bu and Zhi Yu},
keywords = {Data-free knowledge distillation, Curriculum learning, Knowledge distillation, Self-paced learning},
abstract = {Data-free knowledge distillation (DFKD) is a widely-used strategy for Knowledge Distillation (KD) whose training data is not available. It trains a lightweight student model with the aid of a large pretrained teacher model without any access to training data. However, existing DFKD methods suffer from inadequate and unstable training process, as they do not adjust the generation target dynamically based on the status of the student model during learning. To address this limitation, we propose a novel DFKD method called CuDFKD. It teaches students by a dynamic strategy that gradually generates easy-to-hard pseudo samples, mirroring how humans learn. Besides, CuDFKD adapts the generation target dynamically according to the status of student model. Moreover, we provide a theoretical analysis of the majorization minimization (MM) algorithm and explain the convergence of CuDFKD. To measure the robustness and fidelity of DFKD methods, we propose two more metrics, and experiments shows CuDFKD has comparable performance to state-of-the-art (SOTA) DFKD methods on all datasets. Experiments also present that our CuDFKD has the fastest convergence and best robustness over other SOTA DFKD methods.}
}
@article{LI2023108283,
title = {Review on intelligent pipeline technologies: A life cycle perspective},
journal = {Computers & Chemical Engineering},
volume = {175},
pages = {108283},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108283},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423001539},
author = {Zhuochao Li and Yongtu Liang and Youyi Liang and Qi Liao and Bohong Wang and Liqiao Huang and Jianqin Zheng and Haoran Zhang},
keywords = {Oil and gas pipeline, Intelligent pipeline, Key technology, Life cycle},
abstract = {The pipeline is one of the important carriers in the petroleum industry, but facing with the development bottlenecks of low efficiency, high cost and high decision risk. With machine learning and advanced sensor, new technological breakthroughs are being opening up for intelligent pipeline systems to benefit. Nowadays, the intelligent transformation of pipeline is still in the initial stage. To accelerate this process, this paper elaborates the research on intelligent pipeline systems from the perspective of the full life cycle of pipeline. The life cycle is divided into six stages, including exploration, feasibility study, design, construction, operation and scrap. In each stage, the related theoretical research and key technologies have been systematically reviewed. It is observed that full digital construction and operation is an inevitable trend. The Internet of Things, big data, and multi-objective optimization are critical technologies. Finally, some future directions are put forward to prompt a pipeline into intelligence.}
}
@article{ZHANG2023102091,
title = {Efficient visual fault detection for freight train braking system via heterogeneous self distillation in the wild},
journal = {Advanced Engineering Informatics},
volume = {57},
pages = {102091},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102091},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623002197},
author = {Yang Zhang and Huilin Pan and Yang Zhou and Mingying Li and Guodong Sun},
keywords = {Fault detection, Freight train images, Knowledge distillation, Real-time, Light-weight},
abstract = {Efficient visual fault detection of freight trains is a critical part of ensuring the safe operation of railways under the restricted hardware environment. Although deep learning-based approaches have excelled in object detection, the efficiency of freight train fault detection is still insufficient to apply in real-world engineering. This paper proposes a heterogeneous self-distillation framework to ensure detection accuracy and speed while satisfying low resource requirements. The privileged information in the output feature knowledge can be transferred from the teacher to the student model through distillation to boost performance. We first adopt a lightweight backbone to extract features and generate a new heterogeneous knowledge neck. Such neck models positional information and long-range dependencies among channels through parallel encoding to optimize feature extraction capabilities. Then, we utilize the general distribution to obtain more credible and accurate bounding box estimates. Finally, we employ a novel loss function that makes the network easily concentrate on values near the label to improve learning efficiency. Experiments on four fault datasets reveal that our framework can achieve over 37 frames per second and maintain the highest accuracy of 98.88% in comparison with traditional distillation approaches. Moreover, compared to state-of-the-art methods, our framework demonstrates more competitive performance with lower memory usage and the smallest model size.}
}