@article{SOLOMON2022109446,
title = {SDNSandbox — Enabling learning-based innovation in provider networks},
journal = {Computer Networks},
volume = {219},
pages = {109446},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2022.109446},
url = {https://www.sciencedirect.com/science/article/pii/S1389128622004807},
author = {Yossi Solomon and Osnat Mokryn and Tsvi Kuflik},
keywords = {SDN in-a-box, Load prediction, Deep learning, Provider networks, SDN-DCRNN},
abstract = {Provider networks are looking to follow the footsteps of cloud-based networks/data centers and incorporate Software-Defined Networking (SDN) technology. This move is problematic for various reasons, such as the networks’ size and the providers’ inability to control users’ activity. Additionally, research into these networks is handicapped by the lack of information stemming from the confidentiality of these complex networks. To that end, we have created SDNSandbox — an SDN-based provider network simulator prototype. SDNSandbox is an open-source, easy-to-use, provider-network in-a-laptop simulator. It aims to facilitate the creation of reproducible experiments and large-scale synthetic datasets. In its current prototype form, it uses a basic traffic generator module alongside real-world provider topologies. SDNSandbox allows users to simulate provider networks, enabling them to conduct research in the field and examine practical applications. To demonstrate SDNSandbox, we use the prototype to simulate basic traffic conditions over several topologies. We then feed the generated datasets to DCRNN, a Convolutional Neural Network (CNN) traffic patterns prediction module. We adapt DCRNN to accept SDNSandbox output and show that it can predict traffic conditions at various points within the network tens of seconds into the future. We further compare its performance with other baseline algorithms. Our results demonstrate that SDNSandbox can also be used as a testbed for a digital twin, creating datasets that are hard to replicate in production networks. It also serves as a demonstration of the framework’s power and versatility as a modular research tool.}
}
@article{MORANDE2022100124,
title = {Enhancing psychosomatic health using artificial intelligence-based treatment protocol: A data science-driven approach},
journal = {International Journal of Information Management Data Insights},
volume = {2},
number = {2},
pages = {100124},
year = {2022},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2022.100124},
url = {https://www.sciencedirect.com/science/article/pii/S2667096822000672},
author = {Swapnil Morande},
keywords = {Healthcare services, Data science, Machine learning, Psychosomatic health, Well-being},
abstract = {The present study opens an avenue for an improved holistic state of health. Several parameters related to an individual's cognitive interactions to manage stress have been explored. It induces multiple therapeutic interventions in an experimental setting to fulfill the same. This is a quantitative study in which relevant data are captured using a questionnaire and Brain-Computer Interaction (BCI) simultaneously. The research findings establish the role of significant factors that help to determine psychosomatic health. Data-driven models built using unique cognitive instances can augment psychosomatic health in terms of time, cost, and access. Since this study is based on a technological foundation defined by an electroencephalograph (EEG), it can further be scaled for other healthcare applications and incorporated into ‘Digital Twin.’ Using Artificial Intelligence (AI) based treatment protocol, the findings could be extended to the healthcare ecosystem.}
}
@article{JI202329,
title = {Challenges and Opportunities in Product Life Cycle Management in the Context of Industry 4.0},
journal = {Procedia CIRP},
volume = {119},
pages = {29-34},
year = {2023},
note = {The 33rd CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123004225},
author = {Xinxiang Ji and Shiva Abdoli},
keywords = {Product-system, Lifecycle Management, Industry 4.0, Digital Twin},
abstract = {Global competition forces assembly, production, and logistic systems to be highly efficient and agile in delivering their product-systems to customers. To achieve this, Product Lifecycle Management (PLM) and Product Data Management approaches have been developed for managing product-related information across its lifecycle. However, the full potential of PLM has yet to be realized. Industry 4.0 refers to the fourth industrial revolution which promotes the usage of information and digital production with key enabling technologies including digital twins, internet of things, cloud technologies and machine learning. This paper aims to investigate opportunities that industry 4.0 technologies can offer to realize PLM by reviewing existing scholarly papers in this context. The characteristics of industry 4.0 technologies and their usage on PLM is also discussed. As a result of such critical analysis and cross-investigation, this paper discusses the challenges with PLM and proposes future research directions and a roadmap for realization of an integrated PLM by application of key industry 4.0 technologies.}
}
@article{SANTILLANCOOPER2022103104,
title = {Predicting future sedentary behaviour using wearable and mobile devices},
journal = {Information Processing & Management},
volume = {59},
number = {6},
pages = {103104},
year = {2022},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.103104},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322002059},
author = {Martín {Santillán Cooper} and Marcelo G. Armentano},
keywords = {Sedentary behaviour prediction, Machine learning, User modelling, Wearable and mobile devices},
abstract = {Sedentarism is a common problem that can affect human health and wellbeing. Predicting sedentary behaviour is an emerging area that can benefit from data collected from sensors available in ubiquitous devices, such as wearables and smartphones. In this paper, we present an approach aiming at predicting the sedentary behaviour of a user from data collected from sensors installed in wearable/mobile devices. We compare personal and impersonal models using a real-life dataset consisting of sensing data of 48 users during 10 weeks. We found that impersonal models using Deep Neural Networks were able to accurately predict the subject’s future sedentary behaviour.}
}
@article{SOTIRIADIS20232038,
title = {A Digital Twin Assisted and Embedded Strain Gauge Monitoring System},
journal = {Transportation Research Procedia},
volume = {72},
pages = {2038-2045},
year = {2023},
note = {TRA Lisbon 2022 Conference Proceedings Transport Research Arena (TRA Lisbon 2022),14th-17th November 2022, Lisboa, Portugal},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2023.11.686},
url = {https://www.sciencedirect.com/science/article/pii/S2352146523009845},
author = {George Sotiriadis and Thanasis Kotzakolios and Vassilis Kostopoulos and Maria Gemou},
keywords = {Strain monitoring, Digital Twin, Machine Learning, Finite Element},
abstract = {In this work, a strain monitoring system (strip) for assessing the road pavement distress under vehicle loads was developed. The system consists of the sensing element, the data processing and storage unit, and a graphical user interface with post- processing features. The sensing elements were designed to be adhesively bonded on the pavement and are protected by an encapsulating plastic strip. Strain data are sent to a digital reconstruction (the Digital Twin) of a real-life asset (the pavement model) that is frequently and automatically updated through data sampling. This tool provides functionalities to monitor and optimize assets and make informed and data-based decisions, in the context of day-to-day operative conditions and after extreme events. These data not only include sensor data, but also regularly revalidated structural reliability indices formulated on the grounds of the frequently updated Digital Twin model.}
}
@article{CAO2022112347,
title = {Digital twin real time monitoring method of turbine blade performance based on numerical simulation},
journal = {Ocean Engineering},
volume = {263},
pages = {112347},
year = {2022},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2022.112347},
url = {https://www.sciencedirect.com/science/article/pii/S0029801822016419},
author = {Yu Cao and Xiaobo Tang and Oleg Gaidai and Fang Wang},
keywords = {Real time, Digital twin, HATT, Kriging interpolation, Machine learning},
abstract = {Due to the limited number of sensor arrangements, the hydrodynamic performance test and detection of marine equipment cannot achieve real time monitoring and complete coverage of the flow field. The digital twin (DT) technology can solve this problem and help achieve real time monitoring and performance evaluation at sea. This paper takes the horizontal axis tidal turbine (HATT) as the research object, studies the applicability of the simulation-based DT real time monitoring method. Firstly, the feasibility of computational fluid dynamics (CFD) simulation of HATT is verified by experiments. Secondly, the simulation database is established under various working conditions. Then the DT method is used to reduce the three-dimensional numerical model to a first-order digital model and the simulation result data can be quickly loaded into the digital model for real time data monitoring. If the monitoring data is not calculated in the database, the Kriging interpolation method is used to reconstruct the database for flow field display quickly. For the data with large deviation of comparison result curves, the optimization algorithm is used along with machine learning. A real time monitoring engineering reference is provided for flow fields distribution and hydrodynamic performance assessment of blades.}
}
@article{FERRIOLGALMES2022109329,
title = {Building a Digital Twin for network optimization using Graph Neural Networks},
journal = {Computer Networks},
volume = {217},
pages = {109329},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2022.109329},
url = {https://www.sciencedirect.com/science/article/pii/S1389128622003681},
author = {Miquel Ferriol-Galmés and José Suárez-Varela and Jordi Paillissé and Xiang Shi and Shihan Xiao and Xiangle Cheng and Pere Barlet-Ros and Albert Cabellos-Aparicio},
keywords = {Digital Twin, Graph Neural Networks, Network optimization, Deep Learning, Network modeling},
abstract = {Network modeling is a critical component of Quality of Service (QoS) optimization. Current networks implement Service Level Agreements (SLA) by careful configuration of both routing and queue scheduling policies. However, existing modeling techniques are not able to produce accurate estimates of relevant SLA metrics, such as delay or jitter, in networks with complex QoS-aware queueing policies (e.g., strict priority, Weighted Fair Queueing, Deficit Round Robin). Recently, Graph Neural Networks (GNNs) have become a powerful tool to model networks since they are specifically designed to work with graph-structured data. In this paper, we propose a GNN-based network model able to understand the complex relationship between (i) the queueing policy (scheduling algorithm and queue sizes), (ii) the network topology, (iii) the routing configuration, and (iv) the input traffic matrix. We call our model TwinNet, a Digital Twin that can accurately estimate relevant SLA metrics for network optimization. TwinNet can generalize to its input parameters, operating successfully in topologies, routing, and queueing configurations never seen during training. We evaluate TwinNet over a wide variety of scenarios with synthetic traffic and validate it with real traffic traces. Our results show that TwinNet can provide accurate estimates of end-to-end path delays in 106 unseen real-world topologies, under different queuing configurations with a Mean Absolute Percentage Error (MAPE) of 3.8%, as well as a MAPE of 6.3% error when evaluated with a real testbed. We also showcase the potential of the proposed model for SLA-driven network optimization and what-if analysis.}
}
@article{LIU2023106466,
title = {An explainable knowledge distillation method with XGBoost for ICU mortality prediction},
journal = {Computers in Biology and Medicine},
volume = {152},
pages = {106466},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106466},
url = {https://www.sciencedirect.com/science/article/pii/S001048252201174X},
author = {Mucan Liu and Chonghui Guo and Sijia Guo},
keywords = {Intensive care units, Mortality prediction, Knowledge distillation, Explainable machine learning},
abstract = {Background and Objective:
Mortality prediction is an important task in intensive care unit (ICU) for quantifying the severity of patients’ physiological condition. Currently, scoring systems are widely applied for mortality prediction, while the performance is unsatisfactory in many clinical conditions due to the non-specificity and linearity characteristics of the used model. As the availability of the large volume of data recorded in electronic health records (EHRs), deep learning models have achieved state-of-art predictive performance. However, deep learning models are hard to meet the requirement of explainability in clinical conditions. Hence, an explainable Knowledge Distillation method with XGBoost (XGB-KD) is proposed to improve the predictive performance of XGBoost while supporting better explainability.
Methods:
In this method, we first use outperformed deep learning teacher models to learn the complex patterns hidden in high-dimensional multivariate time series data. Then, we distill knowledge from soft labels generated by the ensemble of teacher models to guide the training of XGBoost student model, whose inputs are meaningful features obtained from feature engineering. Finally, we conduct model calibration to obtain predicted probabilities reflecting the true posterior probabilities and use SHapley Additive exPlanations (SHAP) to obtain insights about the trained model.
Results:
We conduct comprehensive experiments on MIMIC-III dataset to evaluate our method. The results demonstrate that our method achieves better predictive performance than vanilla XGBoost, deep learning models and several state-of-art baselines from related works. Our method can also provide intuitive explanations.
Conclusions:
Our method is useful for improving the predictive performance of XGBoost by distilling knowledge from deep learning models and can provide meaningful explanations for predictions.}
}
@article{GHENAI2022102837,
title = {Recent trends of digital twin technologies in the energy sector: A comprehensive review},
journal = {Sustainable Energy Technologies and Assessments},
volume = {54},
pages = {102837},
year = {2022},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2022.102837},
url = {https://www.sciencedirect.com/science/article/pii/S2213138822008852},
author = {Chaouki Ghenai and Lama Alhaj Husein and Marwa {Al Nahlawi} and Abdul Kadir Hamid and Maamar Bettayeb},
keywords = {Digital twin, Energy, Renewable energy, Energy supply, Energy demand, Energy storage, Digitalization, Energy forecasting, Energy optimization, Energy management, IoT},
abstract = {The purpose of a digital twin (DT) is to gain insight into and predict the performance of a physical product, process, or piece of infrastructure. Numerous advantages accrue from the energy industry's adoption of DT technology, such as improved asset performance, higher profits and efficiencies, and less harmful effects on the environment. This paper's goal is to present a literature evaluation that classifies DT principles, usage patterns, and benefits in the energy sector. A thorough literature review covering the past decade of studies on DT in the energy sector was conducted. The originality of this study is in-depth examination of DT's use across the whole energy value chain from power generation and storage to energy usage in buildings, transportation, and industrial applications. From this analysis, it was clear that there is a growing interest in using DT in the energy industry and minimizing energy use is the primary focus of the literature on digital twins. Growth of DT technologies will be aided by recent developments in machine learning and artificial intelligence, as well as the development of more sophisticated control systems, allowing for the enhancement of energy system efficiency and effectiveness, thereby fostering the clean energy transition, and reshaping the future of energy.}
}
@article{SEPAHVAND2023105560,
title = {An adaptive teacher–student learning algorithm with decomposed knowledge distillation for on-edge intelligence},
journal = {Engineering Applications of Artificial Intelligence},
volume = {117},
pages = {105560},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105560},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622005504},
author = {Majid Sepahvand and Fardin Abdali-Mohammadi and Amir Taherkordi},
keywords = {Deep learning, Knowledge distillation, On-edge intelligence, Feature representation, Tensor decomposition},
abstract = {In case the spatial shape of the feature maps of the teacher in feature-based knowledge distillation (KD) is significantly greater than the student model, first, they cannot be compared directly. Second, the knowledge of these complex feature maps cannot be quite apprehensible for the student. This paper proposed a new KD, in which Tucker decomposition was used to decompose the large-dimension feature maps of a teacher to obtain core tensors from the feature maps of the teacher. The knowledge of these tensors can be easily understood by students due to their low complexity. Furthermore, in the proposed KD, an adaptor function is suggested, which balances the spatial shape of the core tensors of the teacher and student and helps compare them using a convolution regressor. Finally, a hybrid loss based on adaptor function is suggested to distill the knowledge of the core tensors of the teacher to the student. Both teacher and student models were implemented on smartphones used as edge devices, and the experiments were evaluated in terms of recognition rate and complexity. According to the results, the student model designed by ResNet-18 architecture has ∼65.44 million fewer parameters, ∼6.45 GFLOPs less computational complexity, ∼1.12 G less GPU memory use, and ∼265.67 times greater compression rate than its teacher model designed by ResNet-50 architecture. While the recognition rate of the student model merely dropped down to 1.5% in the benchmark dataset.}
}
@article{SUN2023100120,
title = {Effects of integrating an open learner model with AI-enabled visualization on students' self-regulation strategies usage and behavioral patterns in an online research ethics course},
journal = {Computers and Education: Artificial Intelligence},
volume = {4},
pages = {100120},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100120},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000753},
author = {Jerry Chih-Yuan Sun and Hsueh-Er Tsai and Wai Ki Rebecca Cheng},
keywords = {Personalized learning, Self-regulation, Data visualization, Sequential analysis, Open learner model},
abstract = {This study seeks to understand the effects of a personalized learning platform, which applied an open learner model with self-regulation and AI-enabled data visualization features, on students' self-regulated learning strategies used and behavioral patterns during their self-directed online learning process. Results were based on a self-regulated learning scale and a prior knowledge test from 182 university students and supplemented with students' system logs to understand their behavioral patterns while interacting with the personalized learning platform. It showed that the combined self-regulation and data visualization features (dual features) improve student performance via self-regulated activities of goal setting and help-seeking. In addition, the dual features improve students' self-regulation behavior of self-assessment and motivate their self-directed learning, reflected by more frequent review of learning content after checking their performance progress charts. Therefore, this study showed that combining self-regulation strategies with data visualization can effectively enhance self-regulated learning behaviors, in which students were able to govern their learning from the feedback provided through data visualization. The results also inferred that the graphical representation using a radar chart provides an intuitive interface with low cognitive affordance to interpret learning analytics data.}
}
@article{VIVIANO2023691,
title = {Synthetic Learner: Model-free inference on treatments over time},
journal = {Journal of Econometrics},
volume = {234},
number = {2},
pages = {691-713},
year = {2023},
issn = {0304-4076},
doi = {https://doi.org/10.1016/j.jeconom.2022.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S030440762200152X},
author = {Davide Viviano and Jelena Bradic},
keywords = {Synthetic control, Difference in differences, Causal inference, Random Forests},
abstract = {Understanding the effect of a particular treatment or a policy pertains to many areas of interest, ranging from political economics, marketing to healthcare. In this paper, we develop a non-parametric algorithm for detecting the effects of treatment over time in the context of Synthetic Controls. The method builds on counterfactual predictions from many algorithms without necessarily assuming that the algorithms correctly capture the model. We introduce an inferential procedure to detect treatment effects and show that the testing procedure controls size asymptotically for stationary, beta mixing processes without imposing any restriction on the set of base algorithms under consideration. We discuss consistency guarantees for average treatment effect estimates and derive regret bounds for the proposed methodology. The class of algorithms may include Random Forest, Lasso, or any other machine-learning estimator. Numerical studies and an application illustrate the advantages of the method.}
}
@incollection{ZOU202361,
title = {Chapter 4 - Optimization-based meta-learning approaches},
editor = {Lan Zou},
booktitle = {Meta-Learning},
publisher = {Academic Press},
pages = {61-87},
year = {2023},
isbn = {978-0-323-89931-4},
doi = {https://doi.org/10.1016/B978-0-323-89931-4.00001-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323899314000018},
author = {Lan Zou},
keywords = {Optimization-based meta-learning, LSTM meta-learner, Meta-LSTM, Reptile, Model-agnostic meta-learning, MAML, First-order model-agnostic meta-learning, FOMAML, Transfer learning, Fine-tuning},
abstract = {This chapter examines the benefits of the state-of-the-art approaches to optimization-based meta-learning: classical long short-term memory (LSTM) meta-learner; model-agnostic meta-learning (MAML) and its variations in few-shot learning, reinforcement learning, and intimation learning; first-order model-agnostic meta-learning; and Reptile. It recaps the motivation behind LSTM meta-learner: covariate shift, batch normalization, LSTM cell, and classical gradient-based optimization. Then, it discusses the intuition of transfer learning and fine-tuning for MAML and MAML's key concepts: adaptation and MAML. Finally, this chapter focuses on several scenarios of Reptile: serial version, parallel, or batch version. It also explains several creative techniques in Reptile: the optimization assumption, minimization of the expected loss function, maximization of generalization within a task, and three modifications of Reptile algorithm. This chapter ends with a precise comparison of these three main methods of optimization-based meta-learning.}
}
@article{HE2023108874,
title = {Structural performance prediction based on the digital twin model: A battery bracket example},
journal = {Reliability Engineering & System Safety},
volume = {229},
pages = {108874},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2022.108874},
url = {https://www.sciencedirect.com/science/article/pii/S0951832022004914},
author = {Wenbin He and Jianxu Mao and Kai Song and Zhe Li and Yulong Su and Yaonan Wang and Xiangcheng Pan},
keywords = {Predictive monitoring, Structural reliability of battery bracket, Digital twin, Machine learning, Response surface, Finite element simulation},
abstract = {Battery bracket for new energy commercial vehicles is subjected to variable loads and battery temperature changes both during the design road test phase and in-service operation. Therefore, their structural performance must be evaluated in real-time for reliability design and health monitoring. With the rapid development of industrial digitization, the digital twin has become an indispensable technology. This paper proposes a digital twin approach for predictive monitoring of the performance of mechanical structures. Taking the structural performance for the battery bracket of new energy commercial vehicles as an example, this paper builds a unit-level digital twin model—DTMAR. It comprises the numerical model, NN-RSR model, and hybrid machine learning model. The results reveal that the DTMAR model can efficiently and accurately calculate and predict the structural performance. This can not only provide constructive guidance for optimal design of the next generation product structure, but also aid in evaluating the structural reliability of the battery bracket of new energy commercial vehicles and improve their driving safety.}
}
@article{SEIDEL2023103831,
title = {Development and validation of a digital twin framework for SMT manufacturing},
journal = {Computers in Industry},
volume = {145},
pages = {103831},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103831},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522002275},
author = {Reinhardt Seidel and Ben Rachinger and Nils Thielen and Konstantin Schmidt and Sven Meier and Jörg Franke},
keywords = {Electronics production, Surface mount technology, Machine learning, Digital twin, Data analysis, Design for manufacturing},
abstract = {Electronics manufacturing is a global industry and key to innovation in the virtual world because it is the physical backbone. The cost-effective development and manufacture of such electronic modules are critical to maintaining the competitiveness of high-wage manufacturing countries. Therefore, two approaches suggest themselves: Design for Manufacturing (DfM) and manufacturing optimization. To apply both approaches in industry, it is necessary to introduce models that describe the relationship between process input and process output. Applied to electronics manufacturing processes, this means that design, process parameters, and material properties must be mapped to process quality criteria in end-of-line testing. Recently, machine learning (ML) algorithms have been emerging and dominating other modeling methods such as numerical simulation. To develop such complex ML models, a unified data structure for each input and output must be defined. This paper proposes an extensible ML-enabled framework that provides direct and structured access to the printed circuit board (PCB) design and process parameters. This framework is used to perform structured data acquisition using a custom data mining board. During the manufacturing of these PCBs on a full surface mount technology (SMT) process line, all available process machine-level data is collected, archived, and parsed into a uniform, standardized, and flat data structure. This enables fast analysis of the correlation between inputs and quality criteria, direct access by ML algorithms, and training of models. Through these measures, the quality of the framework is validated and correlations are revealed and compared to previous literature. This shows the great importance of a data framework for the integration of data analysis technologies into industrial processes.}
}
@article{BARAN202259,
title = {Semantics-driven attentive few-shot learning over clean and noisy samples},
journal = {Neurocomputing},
volume = {513},
pages = {59-69},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.09.121},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222012140},
author = {Orhun Bugra Baran and Ramazan Gokberk Cinbis},
keywords = {Few-shot learning, Vision and language integration},
abstract = {Over the last couple of years, few-shot learning (FSL) has attracted significant attention towards minimizing the dependency on labeled training examples. An inherent difficulty in FSL is handling ambiguities resulting from having too few training samples per class. To tackle this fundamental challenge in FSL, we aim to train meta-learner models that can leverage prior semantic knowledge about novel classes to guide the classifier synthesis process. In particular, we propose semantically-conditioned feature attention and sample attention mechanisms that estimate the importance of representation dimensions and training instances. We also study the problem of sample noise in FSL, towards utilizing meta-learners in more realistic and imperfect settings. Our experimental results demonstrate the effectiveness of the proposed semantic FSL model with and without sample noise.}
}
@article{GAO2023135782,
title = {A digital twin-based approach for optimizing operation energy consumption at automated container terminals},
journal = {Journal of Cleaner Production},
volume = {385},
pages = {135782},
year = {2023},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.135782},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622053562},
author = {Yinping Gao and Daofang Chang and Chun-Hsien Chen},
keywords = {Sustainable development, Energy consumption, Digital twin, Automatic stacking crane scheduling, Container yard},
abstract = {The sustainable development of port operation management is strongly related to the energy consumption of production at automated container terminals (ACTs). This paper focuses on the production activities at a container yard, which is the primary facility of ACTs. A digital twin-based approach is proposed to optimize the operation of an automatic stacking crane (ASC) handling containers in terms of energy consumption. A virtual container yard that syncs with a physical container yard in the ACT digital twin system for observation and validation is developed. A mathematical model is established to minimize the total energy consumption of completing all tasks. Then, the Q-learning algorithm is adapted to optimize a solution based on the operating data from the ACT digital twin system. Numerical experiments are conducted to demonstrate the effectiveness of the proposed approach by comparing it with two other solution algorithms, viz., genetic algorithm (GA) and particle swarm optimization (PSO). The total energy consumption of two operation strategies (i.e., centralized and decentralized) are also compared using the proposed digital twin-based approach. With digital twin, the operational environment and energy consumption are visualized to support optimization and management of ASCs. Managers and operators can choose an appropriate strategy according to the designated sustainable goal.}
}
@article{MAES2022110282,
title = {Features and defects characterisation for virtual verification and certification of composites: A review},
journal = {Composites Part B: Engineering},
volume = {246},
pages = {110282},
year = {2022},
issn = {1359-8368},
doi = {https://doi.org/10.1016/j.compositesb.2022.110282},
url = {https://www.sciencedirect.com/science/article/pii/S1359836822006552},
author = {Vincent K. Maes and Kevin Potter and James Kratz},
keywords = {Defects, Characterisation, Virtual testing, Certification},
abstract = {Composite manufacturing is driven by a balance between costs (i.e. material and time) and quality. Due to the brittle nature of composite materials, even small deviations in the parts (i.e. defects) can result in significant reductions in load carrying ability of a part. The occurrence of defects is a complex problem, with many sources and factors which affect them. To assist in better understanding and predicting part quality, statistical tools and advanced machine learning can be used to help fill the gaps. A solid understanding of part quality can then in turn be used in combination with a digital twin to achieve virtual testing and certifcation of a part while requiring less physical tests. However, as this review shows, the available data in the literature does not sufficiently characterise key defects, nor their dependence on part design and process parameters to achieve this goal. As such it is argued here that enhanced characterisation and manufacturing trials of more complex parts are needed to generate the required database.}
}
@article{ZHOU2023345,
title = {A Machine-Learning-based Surrogate Modeling Methodology for Submodel Integration in the Holistic Railway Digital Twin Platform},
journal = {Procedia CIRP},
volume = {119},
pages = {345-350},
year = {2023},
note = {The 33rd CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.02.141},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123004997},
author = {Shiyang Zhou and Alexander Meierhofer and Ozan Kugu and Yuxi Xia and Manfred Grafinger},
keywords = {Surrogate Model, Multibody Dynamics Simulation, Machine Learning, Railway Vehicle-Track System},
abstract = {A holistic railway infrastructure digital twin (DT) platform is sophisticated and consists of a series of submodels (e.g., turnouts, tracks, vehicles, etc.) that are built through various methodologies and software. However, integrating these submodels into the DT platform is tremendously challenging due to considerable computational complexity, software and interface restrictions. To this end, we designed a machine learning (ML) based surrogate modeling methodology for the submodel integration in the holistic railway infrastructure DT platform and illustrated the methodology through a case study. In this case study, an ML-based surrogate model for multibody simulation of railway vehicle-track dynamics is created, which can replace the railway vehicle-track simulation executed with the Multibody Dynamics (MBD) Simulation commercial software SimPACK. The well-built ML model can accurately and quickly predict the vehicle-track system's dynamic responses to different track irregularities. Besides, the integration process of the ML-based surrogate model into the DT platform through a standardized open-source Functional Mock-up Interface (FMI) is also proposed. The developed surrogate modeling methodology shows great promise owing to its high fidelity, which is verified by the measurement data collected from the Austrian national railway track system. The main contribution of our work lies in the well-built ML-based surrogate modeling methodology for reducing the computation complexity and time of different submodels, which facilitates the unification and integration of different submodels. Furthermore, this approach can also be applied to other submodels and help to build the holistic railway DT platform collaboratively.}
}
@article{LI2023100441,
title = {Graph-powered learning methods in the Internet of Things: A survey},
journal = {Machine Learning with Applications},
volume = {11},
pages = {100441},
year = {2023},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2022.100441},
url = {https://www.sciencedirect.com/science/article/pii/S2666827022001165},
author = {Yuxi Li and Shuxuan Xie and Zhibo Wan and Haibin Lv and Houbing Song and Zhihan Lv},
keywords = {Internet of Things, Graph-powered learning methods, Graph embedding, Graph neural network, Graph convolution network, IoT security},
abstract = {The trend of the era of the Internet of Everything has promoted the integration of various industries and the Internet of Things (IoT) technology, and the scope of influence of the IoT is developing in a wider and deeper level. With the extension of the fields involved, the in-depth progress of the IoT is facing a bottleneck. For example, the security of IoT network and software have problems that are difficult to reconcile. Graph-powered learning methods such as graph embedding and graph neural network (GNN) are expected. How to use the graph learning method in IoT is a question that has to be discussed in relation to the future of the Internet of Things. This paper comprehensively discusses related research and summarizes the progress of using graph-powered learning to promote the network anomaly detection, malware detection, IoT device management, service recommendation and other aspects of IoT. And discuss the results of using graph theory and graph-powered learning methods according to the IoT fields such as smart transportation, Industrial Internet of Things (IIoT), Social Internet of Things (SIoT), smart medical care, smart home, smart grid, and smart city. Finally, in view of the existing issues and trends, this paper proposes future research directions including city various predictions, dynamics and heterogeneity, semantic analysis, resource consumption, point cloud, digital twins, and remote sensing.}
}
@article{SONG2022119995,
title = {Online autonomous calibration of digital twins using machine learning with application to nuclear power plants},
journal = {Applied Energy},
volume = {326},
pages = {119995},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2022.119995},
url = {https://www.sciencedirect.com/science/article/pii/S0306261922012521},
author = {Houde Song and Meiqi Song and Xiaojing Liu},
keywords = {Nuclear power plant, Digital twin, Online calibration, K-means cluster, Artificial neural networks},
abstract = {As a near-zero carbon emission energy source, nuclear energy plays an important role in the current world energy decarbonization scenario. Digital twin is a key technology for the continued development of nuclear energy applications. The digital twin requires real-time, high-precision simulations that are beyond the capabilities of current nuclear energy system simulation programs. Therefore, this study proposes an autonomous calibration method for the digital twin of nuclear power plants to compensate for the error in the results of the low accuracy digital twin that can run quickly to obtain higher accuracy results to meet both high accuracy and real-time requirements. The proposed method consists of offline and online stages. In the offline stage, digital twin simulations are first performed. The simulated data and corresponding measurements data (or real data) are used to build an error database, which will be used for the next step of data-driven model training. To reduce the complexity of calibration model, the error database samples are then grouped by clustering. Data-driven calibration models are built on each group based on the simulated data and errors. In the online stage, the digital twin runs in parallel with the nuclear power plant and receives real-time data. The calibration model is continuously updated using dynamic error database. The feasibility of the new proposed method has been demonstrated on measured data from the PKLIII B3.1 steam generator pipe rupture (SGTR) experiment. The results showed that the physical quantities such as pressure, temperature and mass flow rate were well calibrated during the 1000 s of parallel running. The R2 of all physical quantities including temperature, flow rate, and pressure are above 0.99.}
}
@article{CURRIE2023457,
title = {Radiation Dosimetry, Artificial Intelligence and Digital Twins: Old Dog, New Tricks},
journal = {Seminars in Nuclear Medicine},
volume = {53},
number = {3},
pages = {457-466},
year = {2023},
note = {Hematology},
issn = {0001-2998},
doi = {https://doi.org/10.1053/j.semnuclmed.2022.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0001299822000940},
author = {Geoffrey M. Currie and Eric M. Rohren},
abstract = {Developments in artificial intelligence, particularly convolutional neural networks and deep learning, have the potential for problem solving that has previously confounded human intelligence. Accurate prediction of radiation dosimetry pre-treatment with scope to adjust dosing for optimal target and non-target tissue doses is consistent with striving for improved the outcomes of precision medicine. The combination of artificial intelligence and production of digital twins could provide an avenue for an individualised therapy doses and enhanced outcomes in theranostics. While there are barriers to overcome, the maturity of individual technologies (i.e. radiation dosimetry, artificial intelligence, theranostics and digital twins) places these approaches within reach.}
}
@article{TAKAKURA20236174,
title = {A Log-Likelihood-Based Evaluation Metric for the Reproducibility and Simplicity of Logistics Graphs},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {6174-6180},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.731},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323011084},
author = {Yuriko Takakura and Junichi Mori and Hirokazu Kobayashi},
keywords = {Machine learning and data analytics in process control, Digital twins for power and process systems, Data visualization, Logistics in manufacturing, Production & logistics over manufacturing networking},
abstract = {Logistics are sometimes complex and usually entail the interrelation of different processes. It is beneficial to visualize actual process-flow logs to better understand the underlying processes. However, it is difficult to analyze logistics using graph visualization as the graphs are typically quite large and complex. In the field of process mining, several metrics have been proposed in previous studies to examine the quality of process models created using process mining algorithms. However, these metrics evaluate the efficacy of the graph in terms of reproducing the actual process-flow logs. Thus, there is often process-flow information loss in the resulting graph structure when nodes or edges are aggregated to simplify the graph. To address these limitations, in this paper, we propose a maximum log-likelihood-based metric for measuring the reproducibility of graphs and define the concept in terms of how much of the actual process-flow information the graph retains. To obtain the metrics, we developed a graph model that can generate process-flow logs according to its probability parameters. In addition, we also developed an evaluation metric, which is a weighted sum of both the log-likelihood and model dimensions. An empirical evaluation was conducted using the actual process-flow patterns of steel-making process data. The results revealed that the maximum log-likelihood-based metric effectively evaluated the process by which the graphs with node and edge aggregations reproduced the actual process-flow patterns.}
}
@article{PEDROSOUZADEOLIVEIRA2022104930,
title = {Coupling a neural network technique with CFD simulations for predicting 2-D atmospheric dispersion analyzing wind and composition effects},
journal = {Journal of Loss Prevention in the Process Industries},
volume = {80},
pages = {104930},
year = {2022},
issn = {0950-4230},
doi = {https://doi.org/10.1016/j.jlp.2022.104930},
url = {https://www.sciencedirect.com/science/article/pii/S0950423022002066},
author = {João {Pedro Souza de Oliveira} and Joao {Victor Barbosa Alves} and João {Neuenschwander Escosteguy Carneiro} and Ricardo {de Andrade Medronho} and Luiz {Fernando Lopes Rodrigues Silva}},
abstract = {The Computational Fluid Dynamics (CFD) tool has a remarkable applicability for the prediction of gas dispersion flows by numerically solving the proper governing equations in realistic scenarios. Depending on the problem complexity, undesirably high computational costs can be incurred, which has encouraged the combined use of Machine Learning (ML) seeking to attenuate the CFD simulations requirement for multiple scenario studies. The present work aims at demonstrating the employment the coupling between CFD and the Artificial Neural Network (ANN) algorithm for representative problems in atmospheric dispersion in a preliminary assessment. A limited set of CFD simulation results was used for training neural networks, whose output is given by flow field interpolators, the potential uses of which include digital twin designing and optimization procedures. One possible strategy is the local approach, which treats the network as a transition rule in the scope of Cellular Automata (CA) modeling, allowing it to learn the dynamic behavior of the addressed physics locally. This method gives rise to simpler neural network architectures with closer computing relatively to the CFD calculation. Assessments have been done by predicting, initially, a scalar field time evolution governed by a 1-D advection-diffusion transport equation to verify the method implementation. Subsequently, species concentration distributions were sought in atmospheric dispersion cases from CFD simulations datasets, comprising four case studies followed in the performed analysis, all considering a bidimensional flow domain and a scenario involving methane leaks. The first one indicated an accurate reproduction of subsequent time steps concentration field referring to the displacement of a methane cloud. The second and third cases concerned a plume formation, in transient and steady-state regimes, respectively; their main outcome was the evidence of the CA-ANN methodology's flexibility to address time-dependent and permanent flow simulations interpolation. The last CFD-based case study comprised an additional complexity feature of gas dispersion problems: the wind influence. By redesigning the investigated data-driven approach in terms of ANN's features and labels choice, promising results followed from the analysis with respect to the simultaneous capturing of two global simulation parameters (wind and leakage speeds boundary conditions) in the species concentration field interpolation.}
}
@article{PATIL2023162,
title = {Fairness-driven link scheduling approach for heterogeneous gateways for digital twin enabled industry 4.0},
journal = {International Journal of Intelligent Networks},
volume = {4},
pages = {162-170},
year = {2023},
issn = {2666-6030},
doi = {https://doi.org/10.1016/j.ijin.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666603023000155},
author = {Suvarna Patil and Mandeep Kaur and Katarina Rogulj},
abstract = {The advent of Industry 4.0 has brought with it the integration of digital twin technology, which has enabled businesses to develop a virtual replica of their physical assets. This technology allows businesses to optimize their operations and improve their overall efficiency. However, the successful implementation of digital twin technology in Industry 4.0 heavily relies on the effective utilization of gateways. A significant challenge in gateway utilization is the fair allocation of resources, particularly in heterogeneous environments where gateways have different capabilities. Digital Twin is helping Industry 4.0 vision by connecting the authorized people to the exact data and processes to protect the data/assets from unauthorized access. It is accomplished by connecting sensing devices using a unique addressing system and transmitting their combined data to the Internet of Things (IoT) cloud. Massive volumes of heterogeneous data have resulted from the rapid growth of IoT applications and services. As a result, evaluation of data which affects the Digital Twin enabled industry is studied in this article which focuses on data traffic generated from different Industry 4.0 applications and protection of data along with the industry assets is looked by Digital Twin technology. IoT gateways are currently used to connect the devices from various technologies to the Digital Twins. In such networks, sudden increase in demand of IoT gateways will increase with the increase in IoT devices and the operational cost will also be increased. In the proposed system, low-cost specific gateways are proposed to minimize cost and maximize network performance for protecting assets of smart city through Digital Twin technology. In order to accomplish effective resource allocation in a Digital Twin based infrastructure, data transmission fairness at every gateway is accomplished in an IIoT network by considering link scheduling issues. To address these issues and provide fairness in heterogeneous networks with enhanced data transfer, two steps solution is implemented. The Long Short-Term Memory (LSTM) technique is used in the initial step of traffic prediction to assess the minimal time of prior traffic conditions before being applied to estimate dynamic traffic. In the second step, effective link scheduling and selection are made for each wireless technology, taking into account predicted load, gateway distance, link capacity, and estimated time. More data is transmitted at maximum capacity as a result of improved data transfer fairness for all gateways and then the data is protected by Digital Twin technology. Simulated results show that our suggested strategy performs better than other approaches by obtaining maximum network throughput in Industry 4.0 to provide protective solutions using Digital Twin technology. Index Terms – Internet of Things (IoT), Link Scheduling, Traffic Prediction, Machine Learning (ML), Industry 4.0.}
}
@article{DING2023119060,
title = {Distilling and transferring knowledge via cGAN-generated samples for image classification and regression},
journal = {Expert Systems with Applications},
volume = {213},
pages = {119060},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.119060},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422020784},
author = {Xin Ding and Yongwei Wang and Zuheng Xu and Z. Jane Wang and William J. Welch},
keywords = {Knowledge distillation, Unified framework, Conditional generative adversarial networks},
abstract = {Knowledge distillation (KD) has been actively studied for image classification tasks in deep learning, aiming to improve the performance of a student model based on the knowledge from a teacher model. However, applying KD in image regression with a scalar response variable is also important (e.g., age estimation) yet has been rarely studied. Besides, existing KD methods often require a practitioner to carefully select or adjust the teacher and student architectures, making these methods less flexible in practice. To address the above problems in a unified way, we propose a comprehensive KD framework based on conditional generative adversarial networks (cGANs), termed cGAN-KD. Fundamentally different from existing KD methods, cGAN-KD distills and transfers knowledge from a teacher model to a student model via specifically processed cGAN-generated samples. This novel mechanism makes cGAN-KD suitable for both classification and regression tasks, compatible with other KD methods, and insensitive to the teacher and student architectures. An error bound for a student model trained in the cGAN-KD framework is derived in this work, providing a theory for why cGAN-KD is effective as well as guiding the practical implementation of cGAN-KD. Extensive experiments on CIFAR-100 and ImageNet-100 (a subset of ImageNet with only 100 classes) datasets show that the cGAN-KD framework can leverage state-of-the-art KD methods to yield a new state of the art. Moreover, experiments on Steering Angle and UTKFace datasets demonstrate the effectiveness of cGAN-KD in image regression tasks. Notably, in classification, incorporating cGAN-KD into training improves the state-of-the-art SSKD by an average of 1.32% in test accuracy on ImageNet-100 across five different teacher–student pairs. In regression, cGAN-KD decreases the test mean absolute error of a WRN16 × 1 student model from 5.74 to 1.79 degrees (i.e., 68.82% drop) on Steering Angle.}
}
@article{WANG2023109568,
title = {Data coverage assessment on neural network based digital twins for autonomous control system},
journal = {Annals of Nuclear Energy},
volume = {182},
pages = {109568},
year = {2023},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2022.109568},
url = {https://www.sciencedirect.com/science/article/pii/S0306454922005989},
author = {Longcong Wang and Linyu Lin and Nam Dinh},
keywords = {Machine learning, Neural network, Digital twin, Data coverage assessment},
abstract = {In a recently developed Nearly Autonomous Management and Control (NAMAC) system, neural networks (NNs) are used to develop digital twins for diagnosis (DT-Ds). However, NNs are not usually considered extrapolation models and may result in large errors if they are applied to unseen data outside the training data (uncovered). In this study, we propose a data coverage assessment (DCA) to determine if the NN-based DT-Ds are extrapolated based on their epistemic uncertainty. The uncertainty quantification algorithms and uncertainty thresholds are selected based on the confusion matrix of classifying evaluation data into covered or uncovered data. To demonstrate the adaptability of the proposed framework, we applied it to a basic feedforward neural network and a more advanced recurrent neural network based on a more nonlinear database. Case studies show that the proposed framework can distinguish unseen data for both basic and advanced applications with proper uncertainty quantification algorithms and thresholds.}
}
@article{ROSSI202264,
title = {Neural networks and NARXs to replicate extrusion simulation in digital twins for fused filament fabrication},
journal = {Journal of Manufacturing Processes},
volume = {84},
pages = {64-76},
year = {2022},
issn = {1526-6125},
doi = {https://doi.org/10.1016/j.jmapro.2022.09.048},
url = {https://www.sciencedirect.com/science/article/pii/S1526612522006685},
author = {A. Rossi and M. Moretti and N. Senin},
keywords = {Additive manufacturing, Fused filament fabrication, Machine learning, Digital twin, Simulation of the extrusion process, In-process monitoring},
abstract = {In this work we propose the use of nonlinear autoregressive models with exogenous variables (NARXs), powered by dynamic recurrent neural networks, to replicate the results of a previously developed, complex simulation of the extrusion process in fused filament fabrication. The NARXs predict extrusion rate of the extrudate and compression force acting on the filament with an average discrepancy of 0.12 % with respect to the original simulation, but at a fraction of the computational time (0.1 s of the NARX vs. 600 s needed by the original simulation to process the same one-minute time interval). In addition to illustrating how NARXs can be created to mimic an existing simulation, in this work we show how the NARXs can be physically connected to the sensors of a real FFF machine, thus creating an effective digital twin of the extrusion process, useful to support real-time decision making by an AI machine controller. Finally, we show how the implemented digital twin can be used for in-process monitoring, bringing as example the automated detection of an extrusion clogging event.}
}
@article{ZHANG2022105363,
title = {Building Artificial-Intelligence Digital Fire (AID-Fire) system: A real-scale demonstration},
journal = {Journal of Building Engineering},
volume = {62},
pages = {105363},
year = {2022},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2022.105363},
url = {https://www.sciencedirect.com/science/article/pii/S2352710222013699},
author = {Tianhang Zhang and Zilong Wang and Yanfu Zeng and Xiqiang Wu and Xinyan Huang and Fu Xiao},
keywords = {Digital twin, Cyber-physics, IoT, Building fire, Deep learning, Smart firefighting},
abstract = {The identification of building fire evolution in real-time is of great significance for firefighting, evacuation, and rescue. This work proposed a novel framework of Artificial-Intelligence Digital Fire (AID-Fire) that can identify complex building fire information in real-time. The smart system consists of four main parts, Internet of Things sensor network (data collection and transfer), cloud server (data storage and management), AI Engine (data processing), and User Interface (fire information display). A large numerical database, containing 533 fire scenarios with varying fire sizes, positions, and number of fire sources, is established to train a Convolutional Long-Short Term Memory (Conv-LSTM) neural network. The proposed fire digital twin is demonstrated and validated in a full-scale fire test room (26 m2). Results show that the AI engine successfully identify the fire information by learning the spatial-temporal features of the temperature data with a relative error of less than 15% and a delay time of less than 1 s. Moreover, detailed fire development and spread can be accurately displayed in the digital-twin interface. This proposed AID-Fire system can provide valuable support for smart firefighting practices, thus paving the way for a fire-resilient smart city.}
}
@article{RENZI20231228,
title = {Knowledge and Digitalization: a way to improve safety of Road and Highway Infrastructures},
journal = {Procedia Structural Integrity},
volume = {44},
pages = {1228-1235},
year = {2023},
note = {XIX ANIDIS Conference, Seismic Engineering in Italy},
issn = {2452-3216},
doi = {https://doi.org/10.1016/j.prostr.2023.01.158},
url = {https://www.sciencedirect.com/science/article/pii/S2452321623001658},
author = {Emanuele Renzi and Carla Assunta Trifarò},
keywords = {Safety Assessment, Risk Management, Sesmic Risk, Digitalization, Multi-BIM, Collaboration Platforms, Decision making},
abstract = {This paper, with reference to the activity of the National Agency for the Safety of Rails and Road and Highway Infrastructures (ANSFISA), describes the application of digital methods and tools (BIM modeling; collaboration platforms, Machine Learning / Artificial Intelligence, Digital Twin, etc.) for the management of existing road infrastructure networks, on the basis of the principles contained in the current Italian Guidelines for risk classification and management, safety assessment and monitoring of existing bridges.The safety of infrastructures passes through the digitization of processes and tools aimed primarily at the knowledge of the assets, the evaluation of the risks (structural-foundational, seismic, hydrogeological) and the conscious optimal decisions. The optimal decision making have to be based on structured, quantitative and reliable information. The Agency's objective is to improve the digital information management of road infrastructure assets, in order to enhance the information, making it more accessible and with interoperable languages and consequently also provide a monitoring platform, as well as structuring the bases for subsequent modeling also, possibly, to support the training activities of inspectors using both information models and VR simulations in order to create an educational environment in which to train inspectors. The first step to be taken concerns the identification and insertion of data, by the managers, in the IT Archive of Public Works (AINOP). In this work, the Guidelines of the existing bridges have been imagined in an overall framework of digital information management of infrastructures, where BIM, understood as "multi-BIM" according to a multi-level approach, is one of the main tools, with a view to conscious risk mitigation.}
}
@article{MOKHTARI2023109909,
title = {A digital twin-based framework for multi-element seismic hybrid simulation of structures},
journal = {Mechanical Systems and Signal Processing},
volume = {186},
pages = {109909},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2022.109909},
url = {https://www.sciencedirect.com/science/article/pii/S0888327022009773},
author = {Fardad Mokhtari and Ali Imanpour},
keywords = {Seismic hybrid simulation, Digital twin, Model updating, Machine learning, Structural response evaluation},
abstract = {This paper proposes a digital twin-based multi-element hybrid simulation (DMHS) framework to predict the nonlinear cyclic response of structural components (digital twin), e.g., seismic fuses, that are not physically tested due to laboratory limitations by leveraging the experimental test data collected from the physical test specimen (physical twin) during hybrid simulation. This data-based simulation approach can address biased results of hybrid simulation of structures that contain multiple critical components while improving the efficiency of the seismic hybrid simulation. The digital twin is trained in two phases: (1) passive (initial) training phase using past experimental test data before the hybrid simulation starts, and (2) recursive model updating phase using the active (real-time) data produced by the physical specimen during hybrid simulation. The passive training is achieved using the Prandtl–Ishlinskii (PI) hysteresis model combined with the sparse identification technique, while the recursive least-squares algorithm is used in the second phase as the model updating scheme. In particular, the sparse identification technique facilitates the selection of the optimal number of hysteretic model parameters in the passive training phase, which are then tuned in the model updating phase. The architecture of the proposed DMHS framework is first presented, followed by digital twin training steps. The application of the proposed DMHS is then demonstrated, and its simulation accuracy is assessed through virtual hybrid simulation of a two-storey steel buckling-restrained braced frame, which consists of a digital twin (second-storey brace) and a virtual experimental specimen (first-storey brace) integrated into the numerical model of the structure that is subjected to a set of earthquake ground motion accelerations. The results obtained from the verification study serve to validate the proposed architecture of the DMHS framework and evaluate the accuracy and efficiency of this technique in simulating the nonlinear seismic response of structural systems.}
}
@article{HE2022123424,
title = {A deep-learning reduced-order model for thermal hydraulic characteristics rapid estimation of steam generators},
journal = {International Journal of Heat and Mass Transfer},
volume = {198},
pages = {123424},
year = {2022},
issn = {0017-9310},
doi = {https://doi.org/10.1016/j.ijheatmasstransfer.2022.123424},
url = {https://www.sciencedirect.com/science/article/pii/S0017931022008936},
author = {Shaopeng He and Mingjun Wang and Jing Zhang and Wenxi Tian and Suizheng Qiu and G.H. Su},
keywords = {Reduced-order models, Deep-learning, POD, CFD, Steam generators},
abstract = {Model reduction is a method that maps full-order conservation equations into lower-order subspaces or establish a data-driven surrogate model to reduce the complexity of the entire physical system, which has been widely applied in various fields in recent years. Compared with computational fluid dynamics (CFD) simulations, reduced-order model (ROM) can quickly and instantly obtain simulation results at low cost, which provides an economical alternative approach for the research and design process which need large number of repetitive simulations. In this paper, a deep-learning ROM was developed based on the proper orthogonal decomposition (POD) and machine learning (ML) method. The rapid estimation of two significant thermal hydraulic parameters in steam generator (SG), including the void fraction and temperature, was carried out by ROM. By POD mode analysis, the order for void fraction and temperature field was reduced by 88.3% and 96.7%, respectively. An artificial neural network was trained to reflect the implicit nonlinear mapping relationship between the CFD inputs and feature coefficients. The ROM was validated by comparing the predicted results with refined CFD results. The maximum absolute errors of void fraction and temperature are 0.1 and 0.03 K with speedup on the order of 104, indicating that the developed ROM can quickly and accurately estimate the thermal hydraulic characteristics of SG under different operating conditions. This work may provide a novel approach for the parameter sensitivity analysis and optimization design of SG and give valuable reference for the digital twin and the real-time online monitoring of the SG.}
}
@article{WANG2023115172,
title = {Combined digital twin and hierarchical deep learning approach for intelligent damage identification in cable dome structure},
journal = {Engineering Structures},
volume = {274},
pages = {115172},
year = {2023},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2022.115172},
url = {https://www.sciencedirect.com/science/article/pii/S0141029622012482},
author = {Longxuan Wang and Hongbo Liu and Zhihua Chen and Fan Zhang and Liulu Guo},
keywords = {Cable dome, Deep learning, Digital twin, Damage identification},
abstract = {Accurate identification of structural damage is the most critical step in structural health monitoring. Traditional damage identification strategies are easily interfered by environmental and human factors, resulting in low-accuracy of identification. In this light, a combined digital twin (DT) and hierarchical deep learning (DL) approach for intelligent damage identification in cable dome structures is proposed in this paper. Based on actual engineering cases, a DT model that accurately maps the physical structure of the cable dome is constructed using APDL based on data. A cable dome structure damage sample database is then automatically established through the large-scale finite element analysis of DT. Finally, the damage features of the data samples are extracted using the hierarchical DL framework proposed in this study. Accuracy verification based on cable force confirms that the established DT model can accurately reflect the mechanical state of the physical structure. The identification results of the trained network on a test set demonstrate that the proposed framework can intelligently identify the damage type, damage location, and damage degree in the cable dome structure with a high accuracy and strong robustness. The proposed intelligent damage identification approach is feasible and reliable and can provide a new basis for structural damage identification with broad application prospects.}
}
@article{LI2023128,
title = {Renewable-based microgrids’ energy management using smart deep learning techniques: Realistic digital twin case},
journal = {Solar Energy},
volume = {250},
pages = {128-138},
year = {2023},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2022.12.030},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X2200901X},
author = {Qinghui Li and Zhigao Cui and Yanping Cai and Yanzhao Su and Bo Wang},
keywords = {Renewable microgrid, Demand response management, Energy management, Deep learning modelling, Optimization and prediction algorithms},
abstract = {In this research study, a novel demand response program (DRP) has been proposed for renewable-based microgrids (MGs) which takes into account the high penetration of tidal units and solar energy as important, prevalent renewable resources in the power systems. To this end, multi-objective problem (MOP) structure is a promising solution to reduce the whole operating costs of the scheduling problem as well as decrease the high risk of failure in electrical power transmission because of component increasing failure rates and extended repair time. The complexities and nonlinearity of the problem necessitate an innovative heuristic solution which is derived from the Grey Wolf optimization algorithm to help for resolving the problem without making any assumptions or compromising precision. This paper also proposes the dynamic 3-phase correction (DPC) formulation to boost the layout convergence ability by increasing the global search features. Through such a modification, the diversity of the members in the algorithm population increases which would result in low computational burden and low possibility of trapping in local optima. Moreover, it is necessary to have a clear and accurate estimation of the output power of renewable sources in the system. Considering that solar irradiance is hard to anticipate, this paper develops a deep learning layout that uses generative adversarial networks (GAN) to forecast the hourly power generation of the tidal and solar agents. GAN model consists of two competing networks which help to enhance the training process by increasing the accuracy of distinguishing real data from fake data. At the end, IEEE standard test system is used to evaluate the efficiency and effectiveness of the suggested multi-layer problem. The simulation results display that the suggested deep model outperforms other well-known algorithms in smart microgrids.}
}
@article{LONG202312,
title = {Diversified branch fusion for self-knowledge distillation},
journal = {Information Fusion},
volume = {90},
pages = {12-22},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2022.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S1566253522001397},
author = {Zuxiang Long and Fuyan Ma and Bin Sun and Mingkui Tan and Shutao Li},
keywords = {Deep learning, Self-knowledge distillation, Diversity loss, Knowledge fusion, Multiple branches},
abstract = {Knowledge distillation improves the performance of a compact student network by adding supervision from a pre-trained cumbersome teacher network during training. To avoid the resource consumption of acquiring an extra teacher network, the self-knowledge distillation designs a multi-branch network architecture with shared layers for teacher and student models, which are trained collaboratively in a one-stage manner. However, this method ignores the knowledge of shallow branches and rarely provides diverse knowledge for effective collaboration of different branches. To solve these two shortcomings, this paper proposes a novel Diversified Branch Fusion approach for Self-Knowledge Distillation (DBFSKD). Firstly, we design lightweight networks for adding to the middle layers of the backbone. They capture discriminative information by global–local attention. Then we introduce a diversity loss between different branches to explore diverse knowledge. Moreover, the diverse knowledge is further integrated to form two knowledge sources by a Selective Feature Fusion (SFF) and a Dynamic Logits Fusion (DLF). Thus, the significant knowledge of shallow branches is efficiently utilized and all branches learn from each other through the fused knowledge sources. Extensive experiments with various backbone structures on four public datasets (CIFAR100, Tiny-ImageNet200, ImageNet, and RAF-DB) show superior performance of the proposed method over other methods. More importantly, the DBFSKD achieves even better performance with fewer resource consumption than the baseline.}
}
@article{SAMAK2023277,
title = {Towards Sim2Real Transfer of Autonomy Algorithms using AutoDRIVE Ecosystem},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {3},
pages = {277-282},
year = {2023},
note = {3rd Modeling, Estimation and Control Conference MECC 2023},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.12.037},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323023704},
author = {Chinmay Samak and Tanmay Samak and Venkat Krovi},
keywords = {Autonomous Vehicles, Mobile Robots, Digital Twins, Sim2Real, Real2Sim},
abstract = {The engineering community currently encounters significant challenges in the development of intelligent transportation algorithms that can be transferred from simulation to reality with minimal effort. This can be achieved by robustifying the algorithms using domain adaptation methods and/or by adopting cutting-edge tools that help support this objective seamlessly. This work presents AutoDRIVE, an openly accessible digital twin ecosystem designed to facilitate synergistic development, simulation and deployment of cyber-physical solutions pertaining to autonomous driving technology; and focuses on bridging the autonomy-oriented simulation-to-reality (sim2real) gap using the proposed ecosystem. In this paper, we extensively explore the modeling and simulation aspects of the ecosystem and substantiate its efficacy by demonstrating the successful transition of two candidate autonomy algorithms from simulation to reality to help support our claims: (i) autonomous parking using probabilistic robotics approach; (ii) behavioral cloning using deep imitation learning. The outcomes of these case studies further strengthen the credibility of AutoDRIVE as an invaluable tool for advancing the state-of-the-art in autonomous driving technology.}
}
@article{PATRA2023108069,
title = {Recent advances in machine learning applications in metabolic engineering},
journal = {Biotechnology Advances},
volume = {62},
pages = {108069},
year = {2023},
issn = {0734-9750},
doi = {https://doi.org/10.1016/j.biotechadv.2022.108069},
url = {https://www.sciencedirect.com/science/article/pii/S0734975022001653},
author = {Pradipta Patra and Disha B.R. and Pritam Kundu and Manali Das and Amit Ghosh},
keywords = {Neural networks, Knowledge engineering, Supervised learning, Omics datasets, Gene circuits, CRISPR/Cas, Protein engineering, Digital Twin},
abstract = {Metabolic engineering encompasses several widely-used strategies, which currently hold a high seat in the field of biotechnology when its potential is manifesting through a plethora of research and commercial products with a strong societal impact. The genomic revolution that occurred almost three decades ago has initiated the generation of large omics-datasets which has helped in gaining a better understanding of cellular behavior. The itinerary of metabolic engineering that has occurred based on these large datasets has allowed researchers to gain detailed insights and a reasonable understanding of the intricacies of biosystems. However, the existing trail-and-error approaches for metabolic engineering are laborious and time-intensive when it comes to the production of target compounds with high yields through genetic manipulations in host organisms. Machine learning (ML) coupled with the available metabolic engineering test instances and omics data brings a comprehensive and multidisciplinary approach that enables scientists to evaluate various parameters for effective strain design. This vast amount of biological data should be standardized through knowledge engineering to train different ML models for providing accurate predictions in gene circuits designing, modification of proteins, optimization of bioprocess parameters for scaling up, and screening of hyper-producing robust cell factories. This review briefs on the premise of ML, followed by mentioning various ML methods and algorithms alongside the numerous omics datasets available to train ML models for predicting metabolic outcomes with high-accuracy. The combinative interplay between the ML algorithms and biological datasets through knowledge engineering have guided the recent advancements in applications such as CRISPR/Cas systems, gene circuits, protein engineering, metabolic pathway reconstruction, and bioprocess engineering. Finally, this review addresses the probable challenges of applying ML in metabolic engineering which will guide the researchers toward novel techniques to overcome the limitations.}
}
@article{SUN2022e12375,
title = {Instance segmentation using semi-supervised learning for fire recognition},
journal = {Heliyon},
volume = {8},
number = {12},
pages = {e12375},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e12375},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022036635},
author = {Guangmin Sun and Yuxuan Wen and Yu Li},
keywords = {Fire image recognition, Instance segmentation, Deep learning, Semi-supervised learning, Self-training},
abstract = {Fire disaster brings enormous danger to the safety of human life and property, and it is important to identify the fire situation in time through image processing technology. The current instance segmentation algorithms suffer from problems such as inadequate fire images and annotations, low recognition accuracy, and slow inference speed for fire recognition tasks. In this paper, we propose a semi-supervised learning-based fire instance segmentation method based on deep learning image processing technology. We used a lightweight version of the SOLOv2 network and optimized the network structure to improve accuracy. We propose a semi-supervised learning method based on fire features. To reduce the negative impact of error pseudo-labels on the model training, the pseudo-labels are matched by the color and morphological features of flames and smoke at the pseudo-label generation stage, and some images are screened for strong image enhancement before entering the next round of training for the student model. We further exploit the potential of the model with a limited dataset and improve the model accuracy without affecting the inference efficiency of the model. Experiments show that our proposed algorithm can successfully improve the accuracy of fire instance segmentation with good inference speed.}
}
@article{RUB2023102705,
title = {Hydrocephalus classification in brain computed tomography medical images using deep learning},
journal = {Simulation Modelling Practice and Theory},
volume = {123},
pages = {102705},
year = {2023},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2022.102705},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X22001745},
author = {Salsabeel Abu Al Rub and Ahmad Alaiad and Ismail Hmeidi and Muhannad Quwaider and Omar Alzoubi},
keywords = {Healthcare, Hydrocephalus, Big data analytics, Deep learning, Classification, Segmentation},
abstract = {Recent technological advancements, like big data analytics, is driving the growing adoption of cyber-physical systems and digital twins in the area of healthcare. Congenital hydrocephalus is one important example of recent healthcare data analytics. Congenital hydrocephalus is a buildup of excess cerebrospinal fluid (CSF) in the brain at birth. Congenital hydrocephalus can be lethal without treatment and represents an urgent issue in present-day clinical practice. Congenital hydrocephalus has a significant effect on a human entire life since it causes damage to the brain. It is important to accurately diagnose hydrocephalus early, which will help in the early treatment of the infant by a surgical procedure called ventriculoperitoneal (VP) shunt which will reduce the damage caused by hydrocephalus on the brain. Deep Learning is an evolving technology that is currently actively researched in the field of radiology. Compared to the traditional hydrocephalus diagnosing techniques, automatic diagnosing algorithms in deep learning can save diagnosis time, improve diagnosing accuracy, reduce cost, and reduce the radiologist's workload. In this paper, we have used a novel dataset collected from king Hussein medical center hospital in Jordan that consists of CT scans for hydrocephalus and non-hydrocephalus infants, the dataset has gone through multiple stages in preprocessing which are; cropping and filtering, normalization, segmentation (three segmentation techniques have been applied), and augmentation. These data have been used to build deep learning and machine learning models that will help physicians in the early and accurate diagnosing of congenital hydrocephalus which will lead to a decrease in the death rate and brain damage. The results of our models were impressive with a 98.5% accuracy for congenital hydrocephalus classification in infants' brain CT images.}
}
@article{ZHOU2022106790,
title = {Aero-engine gas path system health assessment based on depth digital twin},
journal = {Engineering Failure Analysis},
volume = {142},
pages = {106790},
year = {2022},
issn = {1350-6307},
doi = {https://doi.org/10.1016/j.engfailanal.2022.106790},
url = {https://www.sciencedirect.com/science/article/pii/S1350630722007579},
author = {Liang Zhou and Huawei Wang and Shanshan Xu},
keywords = {Aero-engine, Depth digital twin, Multi-scale simulation, Data-driven, Health assessment},
abstract = {Aero-engine health assessment is of great significance for accurately understanding the health status of aircraft, supporting maintenance decision-making and ensuring flight safety. However, aero-engine has the characteristics of complex structure, fault coupling and state nonlinearity, coupled with the constraints of many factors such as acquisition means, analysis methods and the limitation of abnormal data. It is difficult to obtain a mapping relationship that fully characterizes its operating status through monitoring information. Therefore, this paper proposes a health assessment method based on depth digital twin, which can be used for real-time monitoring of aero-engine operation state. Firstly, the mechanism model is constructed for the multi-scale simulation of aero-engine gas path system. Combined with the advantages of dynamic learning and self-optimization of deep learning method, the data-driven model for data prediction is constructed, and the two are fused to realize the depth digital twin of aero-engine. Then, the digital twin model is used to simulate the high-dimensional monitoring data generated during the operation of aero-engine. Finally, a multi-scale one-dimensional convolution neural network model (MultiScale1DCNN) is proposed to analyze the simulated data, so as to assess the real-time health status of aero-engine. Through the simulation test of aero-engine sensor data, it is verified that the digital twin model has high reliability. Compared with the traditional simulation model, it has higher accuracy. In the aero-engine health assessment tests, the MultiScale1DCNN model can accurately identify the failure mode and assess the failure level, and has high assessment accuracy. In several assessment tests, the assessment accuracy rate is above 96%. The test results show that the health assessment method can accurately reflect the health status of aero-engine, and has certain real-time performance, which shows that it has high engineering application value.}
}
@article{LOVERDOS2023115256,
title = {Geometrical digital twins of masonry structures for documentation and structural assessment using machine learning},
journal = {Engineering Structures},
volume = {275},
pages = {115256},
year = {2023},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2022.115256},
url = {https://www.sciencedirect.com/science/article/pii/S0141029622013323},
author = {Dimitrios Loverdos and Vasilis Sarhosis},
keywords = {Masonry, Image processing, Watershed transform segmentation, Feature extraction, Structural analysis, Documentation},
abstract = {The generation of numerical models for masonry structures is a timely and costly procedure since it requires the discretization of a large quantity of smaller particles. Similarly, traditional visual inspection involves the cautious consideration of each element on a masonry construction. In both cases, each brick element needs to be considered individually. The work presented in this document aims to alleviate the issues arising from documenting individual masonry units and cracks on a structure using computer vision and convolutional neural networks (CNN). In particular, for the first time a dynamic workflow has been developed in which masonry units and cracks in masonry structures are automatically detected and used for the development of a complete geometric digital twin. The outcome is a collection of space coordinates and geometrical objects that represent the masonry fabric entity and allow the comprehension of the object for documentation and structural assessment. This interoperability between architectural, structural, and structural analysis models paves the way to use engineering to create a smarter, safer, and more sustainable future for our existing infrastructures.}
}
@article{TRIPURA2023115783,
title = {Wavelet Neural Operator for solving parametric partial differential equations in computational mechanics problems},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {404},
pages = {115783},
year = {2023},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2022.115783},
url = {https://www.sciencedirect.com/science/article/pii/S0045782522007393},
author = {Tapas Tripura and Souvik Chakraborty},
keywords = {Nonlinear mappings, Operator learning, Wavelet, Wavelet neural operator, Scientific machine learning},
abstract = {With massive advancements in sensor technologies and Internet-of-things (IoT), we now have access to terabytes of historical data; however, there is a lack of clarity on how to best exploit the data to predict future events. One possible alternative in this context is to utilize an operator learning algorithm that directly learns the nonlinear mapping between two functional spaces; this facilitates real-time prediction of naturally arising complex evolutionary dynamics. In this work, we introduce a novel operator learning algorithm referred to as the Wavelet Neural Operator (WNO) that blends integral kernel with wavelet transformation. WNO harnesses the superiority of the wavelets in time–frequency localization of the functions and enables accurate tracking of patterns in the spatial domain and effective learning of the functional mappings. Since the wavelets are localized in both time/space and frequency, WNO can provide high spatial and frequency resolution. This offers learning of the finer details of the parametric dependencies in the solution for complex problems. The efficacy and robustness of the proposed WNO are illustrated on a wide array of problems involving Burger’s equation, Darcy flow, Navier–Stokes equation, Allen–Cahn equation, and Wave advection equation. A comparative study with respect to existing operator learning frameworks is presented. Finally, the proposed approach is used to build a digital twin capable of predicting Earth’s air temperature based on available historical data.}
}
@article{CHAKRABARTY20235500,
title = {Moving Horizon Estimation for Digital Twins using Deep Autoencoders},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {5500-5505},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.207},
url = {https://www.sciencedirect.com/science/article/pii/S240589632300558X},
author = {Ankush Chakrabarty and Abraham P. Vinod and Hassan Mansour and Scott A. Bortoff and Christopher R. Laughman},
keywords = {Learning, state observers, nonlinear systems, Koopman operator, system identification, black-box models},
abstract = {Digital twins have emerged in recent years as black-box, software-based simulation tools that can mirror the behavior of complex dynamical systems. Digital twin simulations generate the same outputs as the target system using internal states; however, these states are not readily available online from the real system. In this paper, we develop a data-driven moving horizon estimation framework capable of using online noisy measurements of the real system in order to estimate digital twin states. Our framework combines the high expressiveness of deep autoencoders with a moving horizon state estimator that accurately predicts the internal state of the black-box digital twin without access to an analytical model of the system dynamics. We demonstrate that our approach outperforms extended and Koopman Kalman filter solutions on a benchmark reverse van der Pol oscillator example.}
}
@article{WANG2023103804,
title = {Simplexity testbed: A model-based digital twin testbed},
journal = {Computers in Industry},
volume = {145},
pages = {103804},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103804},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522002007},
author = {Tiexin Wang and Chao Tan and Lei Huang and Yize Shi and Tao Yue and Zhiqiu Huang},
keywords = {Digital twin, Model-based systems engineering, Testbed, Uncertainty},
abstract = {In the last few years, due to the advances of computation, network, and wide-spread applications of artificial intelligence and machine learning techniques, developing and benefiting from the digital twin technology to connect the virtual to the physical becomes promising and practically feasible; therefore, a lot of attention has been attracted across industries of various domains. However, there lacks of platforms in the academic to facilitate research activities in digital twin technologies. This shortage has non-eligible and negative impact not only on advancing digital twin technologies, but also leading to scarcely publicly-available datasets for conducting research. To this end, in this paper, we present Simplexity Testbed. Simplexity Testbed is equipped with a physical model — an indoor ”driving ground” featuring various driving scenarios and surface conditions, and four land rovers (named SiLaRs) of two different types. Most importantly, the digital twin model of Simplexity Testbed currently is an integration of multiple models developed with different modeling paradigms (i.e., SysML enhanced with uncertainty information, Modelica, 3D simulators for autonomous driving), which enables model executions, simulations, and cross-model interactions. The architecture of Simplexity Testbed enables future integration of other modeling paradigms. In the paper, we also share our process of developing Simplexity Testbed and lessons learnt. In addition, we put lights on how various research activities can be enabled with Simplexity Testbed. We consider that with Simplexity Testbed, context-aware, autonomous, and adaptive capabilities of digital twins can be studied, which lead to full-fledged applications of digital twins in industry.}
}
@article{BALU202271,
title = {Physics-aware machine learning surrogates for real-time manufacturing digital twin},
journal = {Manufacturing Letters},
volume = {34},
pages = {71-74},
year = {2022},
issn = {2213-8463},
doi = {https://doi.org/10.1016/j.mfglet.2022.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2213846322001845},
author = {Aditya Balu and Soumik Sarkar and Baskar Ganapathysubramanian and Adarsh Krishnamurthy},
keywords = {Real-time digital twin, Physics-aware machine learning, Additive manufacturing, Real-time control},
abstract = {In this Manufacturing Blue Sky idea, we envision a Cyber Adaptive Manufacturing Intelligent System (CyAMIS, pronounced Siamese) that integrates concepts from the emerging area of physics-aware machine learning (ML) to formulate, develop, and deploy a near-real-time Siamese (digital) twin to reliably and efficiently achieve exceptional part quality and desired material properties in additive manufacturing processes. We believe such a real-time digital twin framework to be the future of modern additive manufacturing systems, ultimately leading to Manufacturing 5.0 systems.}
}
@article{BERNARD2022109779,
title = {Improving online education through automatic learning style identification using a multi-step architecture with ant colony system and artificial neural networks},
journal = {Applied Soft Computing},
volume = {131},
pages = {109779},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109779},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622008286},
author = {Jason Bernard and Elvira Popescu and Sabine Graf},
keywords = {Hybrid intelligent systems, Learning styles, Learner model, Learning management systems, Ant colony systems, Artificial neural networks},
abstract = {Learning style is one of the individual differences which play an important role in learning. Being aware of it helps the student to understand their strengths and weaknesses, and the teacher to provide more valuable personalized interventions. Furthermore, learning style-based adaptive educational systems can be designed, which have been shown to increase student satisfaction or learning gain, while reducing the time needed to learn. It is therefore important to have an accurate method for identifying students’ learning styles. Since the traditional approach of filling in dedicated psychological questionnaires has several disadvantages, automatic methods have been proposed, based on investigating student observable behavior in a learning environment. Research done so far generally takes a mono-algorithmic approach to identify learning styles, and the precision rates leave room for improvement. Hence, in this paper we propose a novel hybrid multi-step architecture based on ant colony system and artificial neural networks to increase the precision of learning styles identification. Two different variants are proposed and evaluated with data from 75 students; results show high precision values, outperforming existing automatic approaches for learning style identification. The proposed architecture can be integrated into widely used educational systems (e.g., learning management systems) to provide learners and/or teachers with information about students’ learning styles. In addition, it can be integrated into adaptive educational systems and plugins of learning management systems to automatically identify learning styles and personalize instruction respectively.}
}
@article{GOPAL2023100661,
title = {Digital twin and IOT technology for secure manufacturing systems},
journal = {Measurement: Sensors},
volume = {25},
pages = {100661},
year = {2023},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2022.100661},
url = {https://www.sciencedirect.com/science/article/pii/S2665917422002951},
author = {Lisa Gopal and Harbaksh Singh and Panguluri Mounica and N. Mohankumar and Nagendra Panini Challa and P. Jayaraman},
keywords = {Industry 4.0, IoT, Digital twin, Fault diagnosis},
abstract = {The Digital Twin (DT) method offers new concepts for choosing the context of information technologies and smart production systems. This research focuses on low-price, extremely effective defect diagnosis methods, low-efficiency, high-cost devices to obtain timely feedback and accurate fault detection results, and secure manufacturing systems. The data structure, control plane, and output units are the three components of the manufacturing system that creates a data link between the virtual model using Micro-Electro-Mechanical (MEM) devices and the Zigbee wireless transmission system in the database layer. This study acquired DT information from the control plane using the Internet of Things (IoT) through sensors for secure manufacturing information. It separates and calls the pertinent data by the attribute processor and transfers it to the outcome units. To produce the classification and outcomes of work build features information, the evaluation method analysis the output nodes that split the test set and learning group using a dynamic database. The hybrid IoT with DT technology to examine the consequences of defects detected efficiently predicted and secures the manufacturing system.}
}
@article{WANG2023103171,
title = {Data information processing of traffic digital twins in smart cities using edge intelligent federation learning},
journal = {Information Processing & Management},
volume = {60},
number = {2},
pages = {103171},
year = {2023},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.103171},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322002722},
author = {Weixi Wang and Fan He and Yulei Li and Shengjun Tang and Xiaoming Li and Jizhe Xia and Zhihan Lv},
keywords = {Digital twins cities, Deep learning, Traffic safety, Sign recognization, Edge computing},
abstract = {The present work analyzes the application of deep learning in the context of digital twins (DTs) to promote the development of smart cities. According to the theoretical basis of DTs and the smart city construction, the five-dimensional DTs model is discussed to propose the conceptual framework of the DTs city. Then, edge computing technology is introduced to build an intelligent traffic perception system based on edge computing combined with DTs. Moreover, to improve the traffic scene recognition accuracy, the Single Shot MultiBox Detector (SSD) algorithm is optimized by the residual network, form the SSD-ResNet50 algorithm, and the DarkNet-53 is also improved. Finally, experiments are conducted to verify the effects of the improved algorithms and the data enhancement method. The experimental results indicate that the SSD-ResNet50 and the improved DarkNet-53 algorithm show fast training speed, high recognition accuracy, and favorable training effect. Compared with the original algorithms, the recognition time of the SSD-ResNet50 algorithm and the improved DarkNet-53 algorithm is reduced by 6.37ms and 4.25ms, respectively. The data enhancement method used in the present work is not only suitable for the algorithms reported here, but also has a good influence on other deep learning algorithms. Moreover, SSD-ResNet50 and improved DarkNet-53 algorithms have significant applicable advantages in the research of traffic sign target recognition. The rigorous research with appropriate methods and comprehensive results can offer effective reference for subsequent research on DTs cities.}
}
@article{LU2022953,
title = {A novel stochastic configuration network with iterative learning using privileged information and its application},
journal = {Information Sciences},
volume = {613},
pages = {953-965},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.08.088},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522009987},
author = {Jun Lu and Jinliang Ding},
keywords = {Stochastic configuration network, Iterative learning using privileged information, Sparsity, Alternating optimization},
abstract = {In the real-world applications, some auxiliary information is commonly available in addition to the standard data, which is often ignored by the traditional learning algorithms. To effectively utilize the auxiliary information for assisting in building learner models with improved performance, this paper presents a novel stochastic configuration network (SCN) incorporating the iterative learning using privileged information (LUPI) paradigm, termed ISCN+. Meanwhile, to make the comments generated by the privileged information more closely match the ISCN+, these comments should be iteratively updated as the number of hidden nodes of the SCN increases. To this end, the training of SCN and the learning of comments generated by the privileged information is integrated into a new objective function, and the alternating optimization strategy is adopted to optimize the parameters of ISCN + and update the comments generated by the privileged information. Moreover, the L1/2-norm-regularization-based sparse ISCN+ (S-ISCN+) is proposed to further improve the generalization capacity and reduce the complexity of ISCN+. Furthermore, the convergence analysis of the optimization process is provided. The experimental results on two benchmark data sets and a real-world data set demonstrate the effectiveness of the proposed method.}
}
@article{JIANG2022469,
title = {A multi-dimensional cognitive framework for cognitive manufacturing based on OAR model},
journal = {Journal of Manufacturing Systems},
volume = {65},
pages = {469-485},
year = {2022},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2022.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S0278612522001686},
author = {Tengyuan Jiang and Jingtao Zhou and Jianhua Zhao and Mingwei Wang and Shusheng Zhang},
keywords = {Intelligent manufacturing, Cognitive manufacturing, Cognitive framework, Computable digital twin, Multi-dimensional, OAR model},
abstract = {With the production system shifting to a multi-variety and small-batch production mode, the production process faces more user requirements, changes, and uncertainties. To solve the above problems, it is necessary to obtain the status and trend changes information and provide information support for the optimization of decision-making and dynamic adjustment of the production system. However, the production system cognition faces the problems of state coupling, state dynamic transfer and transition, and multi-system interweaving, which makes the production system cognition face huge challenges. Combining technologies such as the Internet of Things, industrial big data, and artificial intelligence, cognitive manufacturing can realize dynamic cognition of the production process, support dynamic adjustment, and become a promising way to solve the dynamic changes and uncertainties of production systems. In addition, as a formal expression of information processing and knowledge learning process in cognitive informatics, the Object-Attribute-Relation (OAR) model can effectively guide the construction of the production process cognitive mechanism. Therefore, this paper proposes a multi-dimensional cognitive framework based on OAR model of the human cognitive world for the dynamic cognitive needs of production system. The framework carries out dynamic cognition from the three dimensions of the manufacturing unit, production situation, and production system, and builds the continuous cognitive abilities from the three dimensions of analysis, decision-making, and learning. By integrating intelligent algorithms in the fields of artificial intelligence, a computable digital twin model is constructed as a carrier to provide the cognitive enabling technologies and capabilities for the production system. Finally, the feasibility of the proposed framework is illustrated by the developed computational digital twin platform. The computable digital twin platform provides the production system with important cognitive capabilities such as states perception, trend prediction, optimization decision-making, and knowledge learning, to support the dynamic cognition and optimization decision-making of the production system, and lay a technical foundation for adaptive production and cognitive manufacturing.}
}
@article{QI2023119309,
title = {ICD: A new interpretable cognitive diagnosis model for intelligent tutor systems},
journal = {Expert Systems with Applications},
volume = {215},
pages = {119309},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.119309},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422023272},
author = {Tianlong Qi and Meirui Ren and Longjiang Guo and Xiaokun Li and Jin Li and Lichen Zhang},
keywords = {Cognitive diagnosis, Learner modeling, Interpretability, Knowledge concept interaction, The quantitative relationship, Potential unknown ability},
abstract = {Numerous models have been proposed for cognitive diagnosis in intelligent tutoring systems. However, the existing models still have room for improvement: (1) they ignore the interaction among knowledge concepts and (2) they ignore the quantitative relation between exercises and concepts. Here, we propose a cognitive diagnostic model comprising three layers of novel neural networks called ICD to solve the above two problems. Specifically, the first layer fits the influence of exercises on concepts, the second layer fits the interaction between concepts, and the third layer fits the influence of concepts on exercises. The three layers allow ICD to effectively distinguish learners with different cognitive levels, that is, ICD has good interpretability. The experimental results show that both the performance and interpretability of ICD are better than those of the latest state-of-the-art CDMs such as RCD, NCDM, and CDGK, and classical CDMs such as DINA and MIRT.}
}
@article{MCLAUGHLIN2023100103,
title = {Utilizing machine learning models to estimate energy savings from an industrial energy system},
journal = {Resources, Environment and Sustainability},
volume = {12},
pages = {100103},
year = {2023},
issn = {2666-9161},
doi = {https://doi.org/10.1016/j.resenv.2022.100103},
url = {https://www.sciencedirect.com/science/article/pii/S2666916122000470},
author = {Eva McLaughlin and Jun-Ki Choi},
keywords = {Compressed air system, Energy efficiency, Supervised machine learning, Compressed air leaks, Industrial energy audits},
abstract = {Energy audits are an important part of reducing energy usage, costs, and carbon emissions, but there have been discrepancies in the quality of audits depending upon the auditor, which can negatively affect the impacts and credibility of the energy assessment. In this paper, historical energy auditing data from a U.S. Department of Energy sponsored research program was gathered and analyzed with a machine-learning algorithm to predict demand savings from a compressed air system assessment recommendation in industrial manufacturing facilities. Different energy auditors calculate savings for repairing leaks in compressed air systems in various ways, so the energy demand savings have been calculated differently throughout the historical assessment recommendations. Machine learning models are utilized in order to enhance the accuracy of the existing practice and reduce variations resulting from the abovementioned discrepancies. A large set of historical assessment recommendation data was used to train five unique machine learning models. Four base learner models and one metalearner model were devised and compared. Results showed that the distributed random forest model best predicted compressed air energy demand savings against the new scenarios within an error of 17%. This indicates that the distributed random forest model can more accurately quantify savings from repairing leaks in compressed air systems. In addition, the results from this study provide insight into the important factors contributing to leaks in the compressed air systems and why it is crucial to repair those leaks regularly to save money and energy while decreasing emissions.}
}
@article{SEPAHVAND2023106476,
title = {Joint learning method with teacher–student knowledge distillation for on-device breast cancer image classification},
journal = {Computers in Biology and Medicine},
volume = {155},
pages = {106476},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106476},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522011842},
author = {Majid Sepahvand and Fardin Abdali-Mohammadi},
keywords = {Breast cancer images, On-device classification, Knowledge distillation, Teacher-student learning, Lightweight classification},
abstract = {The deep learning models such as AlexNet, VGG, and ResNet achieved a good performance in classifying the breast cancer histopathological images in BreakHis dataset. However, these models are not practically appropriate due to their computational complexity and too many parameters; as a result, they are rarely utilized on devices with limited computational resources. This paper develops a lightweight learning model based on knowledge distillation to classify the histopathological images of breast cancer in BreakHis. This method employs two teacher models based on VGG and ResNext to train two student models, which are similar to the teacher models in development but have fewer deep layers. In the proposed method, the adaptive joint learning approach is adopted to transfer the knowledge in the final-layer output of a teacher model along with the feature maps of its middle layers as the dark knowledge to a student model. According to the experimental results, the student model designed by ResNeXt architecture obtained the recognition rate 97.09% for all histopathological images. In addition, this model has ∼69.40 million fewer parameters, ∼0.93 G less GPU memory use, and 268.17 times greater compression rate than its teacher model. While in the student model the recognition rate merely dropped down to 1.75%. The comparisons indicated that the student model had a rather acceptable outputs compared with state-of-the-art methods in classifying the images of breast cancer in BreakHis.}
}
@article{SU2022100346,
title = {Adaptation of a robotic dialog system for medication reminder in elderly care},
journal = {Smart Health},
volume = {26},
pages = {100346},
year = {2022},
issn = {2352-6483},
doi = {https://doi.org/10.1016/j.smhl.2022.100346},
url = {https://www.sciencedirect.com/science/article/pii/S2352648322000800},
author = {Zhidong Su and Weihua Sheng and Guanci Yang and Alex Bishop and Barbara Carlson},
keywords = {Human–robot interaction, Reinforcement learning, Social robot, Elderly care, Dialog adaptation},
abstract = {Social robots can assist older adults in their daily life. Verbal conversation is a natural and convenient way for older adults to interact with social robots. However, most of the existing conversation-based robot services, such as medication reminders, are rule-based systems. These systems require many hand-crafted rules and a significant amount of expert knowledge, therefore they cannot adapt to older adults’ characteristics and dialog history. There are many reinforcement learning (RL) based methods for task-oriented dialogues, but they mainly focus on completing the tasks through text-based conversations. Those methods cannot be directly used for elderly care applications involving human–robot interactions (HRI). Considering the above shortcomings, we proposed a dialog system adaptation method (DSAM) for social robots. The DSAM is based on reinforcement learning which considers the characteristics of older adults, the dialog history and user preference to adapt the dialog policy and improve the dialog module. We implemented DSAM in our custom-made ASCCBot social robot. To evaluate DSAM, we firstly tested the dialog agent which was trained by a user simulator with different settings. The results show that the obtained agent achieves a good result with the desired dialog flow compared to the baseline agent. Based on the obtained dialog policy, the adaptation process is evaluated. The results show that with a good success rate, the number of dialog turns is decreased and the NLU module performance is improved by the adaptation process, which proves the effectiveness of DSAM. We also tested DSAM with human subjects. The results show that the average adaptation success rate is 94.7% and the preference distance reaches 0 after 6 rounds of adaptation while creating reminders successfully with a limited amount of user feedback.}
}
@article{BUCCHIARONE2022471,
title = {Gamification and virtual reality for digital twin learning and training: architecture and challenges},
journal = {Virtual Reality & Intelligent Hardware},
volume = {4},
number = {6},
pages = {471-486},
year = {2022},
note = {Virtual-reality and intelligent hardware in digital twins B)},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2022.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2096579622000675},
author = {Antonio Bucchiarone},
keywords = {Digital twins, Virtual reality, Gamification, Learning, Training},
abstract = {Background
Digital Twins are becoming increasingly popular in a variety of industries to manage complex systems. As digital twins become more sophisticated, there is an increased need for effective training and learning systems. Teachers, project leaders, and tool vendors encounter challenges while teaching and training their students, co-workers, and users.
Methods
In this study, we propose a new method for training users in using digital twins by proposing a gamified and virtual environment. We present an overall architecture and discuss its practical realization.
Results
We propose a set of future challenges that we consider critical to enabling a more effective learning/training approach.}
}
@article{YEUNG2022103957,
title = {Keyhole pores reduction in laser powder bed fusion additive manufacturing of nickel alloy 625},
journal = {International Journal of Machine Tools and Manufacture},
volume = {183},
pages = {103957},
year = {2022},
issn = {0890-6955},
doi = {https://doi.org/10.1016/j.ijmachtools.2022.103957},
url = {https://www.sciencedirect.com/science/article/pii/S0890695522001080},
author = {H. Yeung and F.H. Kim and M.A. Donmez and J. Neira},
keywords = {Keyhole pores, Scan strategies, X-ray computed tomography, Digital twins},
abstract = {Keyhole pores are common in additively manufactured parts and can badly deteriorate the part's performance. In this study, we demonstrated that the keyhole pores formation in the laser powder bed fusion additive manufacturing process can be significantly reduced by the constant laser power density scan strategy. The constant laser power density is implemented on a custom-built testbed by continuously varying the laser power with the laser scan speed through the time-stepped digital commands developed. Two cubic nickel alloy 625 parts of identical geometry were built, one with the constant laser power density scan strategy, and another with the conventional constant laser power scan strategy. The X-ray computed tomography (XCT) measurement shows a 67% porosity reduction in the part built with constant laser power density. However, the mechanisms for defect formation are not easily distinguishable in XCT, which gives a ‘total’ count of pores. To further investigate the effect of scan strategies on pore formation, two digital twins of process monitoring (DTPM), meltpool intensity volume (MPIV) and melt pool area volume (MAV), were created. The DTPM not only helps to distinguish the keyhole pores from the lack of fusion defects but also provides a foundation for the future development of machine learning models.}
}
@article{HU202289,
title = {Underwater gas leak detection using an autonomous underwater vehicle (robotic fish)},
journal = {Process Safety and Environmental Protection},
volume = {167},
pages = {89-96},
year = {2022},
issn = {0957-5820},
doi = {https://doi.org/10.1016/j.psep.2022.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0957582022007662},
author = {Shuyu Hu and Ao Feng and Jihao Shi and Junjie Li and Faisal Khan and Hongwei Zhu and Jian Chen and Guoming Chen},
keywords = {Autonomous underwater leak detection, Deep learning, Robotic fish, Jetson Nano, Artificial Intelligence, Physical dataset},
abstract = {Gas leaks from subsea oil and gas facilities could cause significant ocean environment damage. Such leaks can cause fire and explosion, for example, a fire on the ocean surface west of Mexico's Yucatan peninsula. Detecting a gas leak is critical in managing fire and explosion risks. This study proposes using autonomous underwater vehicles -robotic fish- for gas leak plume detection. The robotic fish is equipped with advance two well-known deep learning models, Faster RCNN and YOLOV4. A physical experiment system of various sizes of underwater gas leaks is used to generate the benchmark dataset. The results demonstrated the YOLOV4 model has a stronger online real-time capability. It is 43 times faster than the Faster RCNN model with the same level of accuracy. This study verifies the feasibility of integrating deep learning models with the mobile vehicle for real-time autonomous gas leak detection. This contribution will enable the development of a safe and reliable digital twin of subsea emergency management.}
}
@article{JAUHARI2023471,
title = {Modeling of Deep Learning Applications for Chatter Detection in the Milling Process},
journal = {Procedia CIRP},
volume = {118},
pages = {471-476},
year = {2023},
note = {16th CIRP Conference on Intelligent Computation in Manufacturing Engineering},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.06.081},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123003050},
author = {Khairul Jauhari and Achmad Zaki Rahman and Mahfudz Al Huda and Muizuddin Azka and Achmad Widodo and Toni Prahasto and Keiji Yamada},
keywords = {Chatter, Digital Twin, Data-driven, Deep Learning, Milling},
abstract = {This study introduced a preliminary investigation of the development of a Digital Twin (DT) model for the milling machining process for the chatter detection phenomenon. Subsequently, chatter has a dynamic interaction in which there is an unstable condition in the material removal process between the cutting tool and work-piece, leading to a decline in surface roughness and tool life, ultimately reducing the quality of machining output. Therefore, this study aimed to develop a chatter detection model using a deep learning application that can identify stable or unstable chatter. The model was built based on the data-driven method where vibration signal data from the milling process is used to train and test various supervised deep learning methods. The result showed that a model with a good level of accuracy was built, and with the help of a chatter detection application, regular operator staff can monitor the machining conditions when no specialist is available.}
}
@article{SIFAT2023100213,
title = {Towards electric digital twin grid: Technology and framework review},
journal = {Energy and AI},
volume = {11},
pages = {100213},
year = {2023},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2022.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2666546822000593},
author = {Md. Mhamud Hussen Sifat and Safwat Mukarrama Choudhury and Sajal K. Das and Md. Hafiz Ahamed and S.M. Muyeen and Md. Mehedi Hasan and Md. Firoj Ali and Zinat Tasneem and Md. Manirul Islam and Md. Robiul Islam and Md. Faisal R. Badal and Sarafat H. Abhi and Subrata K. Sarker and Prangon Das},
keywords = {Electric digital twin grid, Online analysis of grid, Cloud platform of grid, Real-time grid analysis, Self-healing, Cybersecurity},
abstract = {The major hindrances in the energy system are ecological consciousness, lack of clean and sustainable energy management, insufficient energy distribution–transmission–optimization, expensive power transfer costs, and increased customer knowledge of energy charges. Thus why, universal access to the grid with high cybersecurity, and reliability is needed to solve all these challenges. The digital twin concept turns a new dimension of technology into the world. Electric Digital Twin grid can perform online analysis of the grid in real-time and integrates all the past and present data and express the current grid status to the producers and consumers and also predicts the future grid status. Thus, the power grid transmission loss and location of the overheated line and power connection missing can be detected in addition decision-making and self-healing can possible. The future prediction saves the power grid from small to long accidents such as power outages and even blackout problems. The whole consumers and nation feel relief from these types of accidents and saves from large economic and business loss. The blockchain-enabled digital twin grid provides high security for the grid from cyberattacks. The paper conveys the framework of the electric digital twin grid and the concept of the DT grid processing and the way of serving the producer, prosumers, consumers even the whole nation in infrastructure, education, research, economic, business, and political development.}
}
@article{DELCARO202311154,
title = {Dealing with the curse of dimensionality in Twin-in-the-Loop observer design},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {11154-11159},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.834},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323012120},
author = {Giacomo Delcaro and Federico Dettù and Simone Formentin and Sergio M. Savaresi},
keywords = {vehicle dynamics, observer design, bayesian optimization, twin-in-the-loop},
abstract = {Many vehicle dynamics controllers require the knowledge of unmeasured signals, for instance, the sideslip angle in electronic stability control. For this reason, vehicles are usually equipped with several observers running in parallel in different electronic control units. The Twin-in-the-loop approach represents an effective alternative paradigm, in which a single complex Digital Twin is run on-board and a data-driven correction matrix is employed to adjust the estimate of the whole vehicle state in real-time. However, such a complex observer might require the tuning of (too) many parameters if no prior knowledge is available. In this work, we propose an unsupervised learning approach to reduce the dimensionality of the problem, so as to deal also with numerically intractable problems. The strategy is experimentally tested on speed/yaw rate estimation for a real-world vehicle setup.}
}
@article{QIAN2023102456,
title = {Digital twin driven production progress prediction for discrete manufacturing workshop},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {80},
pages = {102456},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2022.102456},
url = {https://www.sciencedirect.com/science/article/pii/S0736584522001387},
author = {Weiwei Qian and Yu Guo and Hao Zhang and Shaohua Huang and Litong Zhang and Hailang Zhou and Weiguang Fang and Shanshan Zha},
keywords = {Digital twin model (DTM), Synchronous evolution, Discrete manufacturing workshop (DMW), Production progress (PP), Adaboost, Deep neural networks (DNN), Long-short term memory (LSTM), Competition mechanism},
abstract = {In make-to-order manufacturing enterprises, accurate production progress (PP) prediction is an important basis for dynamic production process optimization and on-time delivery of orders. Digital twin technology offers an enabling tool for PP analysis. Although the production process can be observed, analyzed, and controlled in real-time by digital twin model (DTM), there exist some uncertain events, degradation of manufacturing elements, and abnormal disturbance in physical workshop (PW), which would cause the deviation between DTM and PW performance and affect the prediction accuracy of PP. Synchronous evolution of DTM for precision holding to ensure the consistency between DTM and the performance of PW, and guarantee the accuracy of DTM is still a challenging issue, especially when dealing with new dynamic samples for complex production environment of discrete manufacturing workshop (DMW). This article focuses on how to effectively construct DTM synchronous update methods based on dynamic sample data for DMW. This study proposes a representation model of performance degradation and an Adaboost-DNN-LSTM based synchronous update model with competitive election mechanism to enhance the accuracy of PP prediction with time in industrial environment. The experiment is conducted in the realistic production dataset, which demonstrates that the proposed synchronous evolution model has good performance for realizing the synchronization of the performance of physical workshop in industrial environment, and can greatly improve the prediction ability for PP.}
}
@article{ZHOU202356,
title = {AdaDS: Adaptive data selection for accelerating pre-trained language model knowledge distillation},
journal = {AI Open},
volume = {4},
pages = {56-63},
year = {2023},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2023.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666651023000074},
author = {Qinhong Zhou and Peng Li and Yang Liu and Yuyang Guan and Qizhou Xing and Ming Chen and Maosong Sun and Yang Liu},
keywords = {Knowledge distillation, Pre-trained language model, Active learning},
abstract = {Knowledge distillation (KD) is a widely used method for transferring knowledge from large teacher models to computationally efficient student models. Unfortunately, the computational cost of KD becomes unaffordable as pre-trained language models (PLMs) grow larger. Computing KD loss on only part of the training set is a promising way to accelerate KD. However, existing works heuristically leverage only one static data selection strategy during the KD process, demonstrating inconsistent improvements across different distillation scenarios. In this work, we conduct a thorough study on various typical data selection strategies for KD, and show that this problem is due to the fact that the best data selection strategy is specific to various factors, including task, selected data size, and training stage. To automatically adapt to these factors, we propose a framework named AdaDS to learn to choose the data selection strategy adaptively during the KD process. Experimental results show that our proposed method is effective for various tasks and selected data sizes under both fine-tuning and pre-training stages, achieving comparable performance to DistilBERT with only 10% amount of queries to the teacher model.}
}
@article{SZPYTKO20236612,
title = {Maintenance Management Practices Using Digital Twins Framework: Oil Extraction Pumping System Case Study},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {6612-6617},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.360},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323007279},
author = {Janusz Szpytko and Yorlandys Salgado-Duarte},
keywords = {Simulation of stochastic systems, Model predictive control for distributed parameter systems, Decision making and cognitive processes},
abstract = {Conceptually, the digital twins’ framework is a virtual representation of an object, system, or process. However, one of its significant contributions has been to merge certain features into a single framework: updating the system modeled from real-time data, using simulation, machine learning, and reasoning to aid decision-making. Specifically, in the maintenance management field and its associated decision-making, the contributions have been prominent, and in this paper, we intend to contribute in the same direction. Here, we describe an adaptive digital twin model designed to coordinate maintenance activities in an oil extraction pumping system. The model is a digital representation of the maintenance decision-making process and cognitive management. The adaptability comes from a self-calibration of the distributed operating parameters of the modeled system under study using a machine learning approach with smart layers in the data management filtering and synthesis. Given the nature of a maintenance modeling process, where randomness and planning are merged, the Monte Carlo method emerges as an easy way to convolute the stochastic degradation due to the system operation and the planning of maintenance activities to keep it working with the required standards. This paper discusses the conceptual model implementation for an oil extraction pumping system using the digital twins’ framework and proposes the first exposure of the modeling results in practice as a study case. The modeling results justify the improvements introduced by implementing the digital twins’ framework.}
}
@article{TANG2023118151,
title = {Particle classification of iron ore sinter green bed mixtures by 3D X-ray microcomputed tomography and machine learning},
journal = {Powder Technology},
volume = {415},
pages = {118151},
year = {2023},
issn = {0032-5910},
doi = {https://doi.org/10.1016/j.powtec.2022.118151},
url = {https://www.sciencedirect.com/science/article/pii/S0032591022010324},
author = {Kunning Tang and Ying Da Wang and Yufu Niu and Tom A. Honeyands and Damien O’ Dea and Peyman Mostaghimi and Ryan T. Armstrong and Mark Knackstedt},
keywords = {Iron ore, Sinter green bed, Micro-CT image, Machine learning, Particle classification, Domain inconsistency},
abstract = {The iron ore sintering process needs to be optimised to decrease its energy intensity and emissions of carbon and atmospheric pollutants, while continuing to produce sinter of sufficient quality for current and future low carbon blast furnace operations. Ideally, the sinter structure and mineralogy should be related back to the particle-level structure of the iron ore types mixed from different mine sources. This particle-level detail can be visually obtained by 3D X-ray micro-Computed Tomography (micro-CT), but requires subsequent algorithms to individually identify and classify particles and identify the relationship between ore sources and sinter quality. In this study, individual particles in sinter green — beds comprising a mixture of coking coal, fluxes, return fines and 5 iron ore samples from different mine sources are identified and classified in high resolution micro-CT images using a machine learning algorithm and associated data processing workflow. Coking coal, fluxes, and return fines are first segmented from iron ores based on their X-ray attenuation and texture. By imaging individual samples from each iron ore source, reliable training data is readily obtained from particle isolation with Convolutional Neural Networks (CNNs) guided by Trainable Weka Segmentation (TWS). Supervised machine learning is then applied to the datasets of isolated particles to produce a per-particle segmented digital sinter green bed image. A collection of geometric, texture, and greyscale features are computed for the particles and used to train a gradient boosting classifier. Tests are then performed on unseen subsets of the single ore source data, on a stratified mixture, and on a random mixture. An accuracy over 90% is achieved for iron ores that are morphologically domain-distinct in their feature space, while lower accuracy in the order of 40%–80% is achieved between iron ore particles that derive from different mine sources, but are domain-similar, suggesting similar mineralogy. The effect of limited training domain, the visual/morphological/feature space similarities and the resulting domain shift in data between training and testing are carefully analysed to identify major sources of similarity. This per-particle multilabel classification of sinter green bed mixtures distinguishes both similar and distinct ores from different mines, and provides a high resolution, accurately characterised digital twin analogue of mixed iron ore sinter green beds. This allows for future detailed analysis of sinter quality, energy intensity, and carbon emissions during the metallurgical process, all of which could be optimised to produce cleaner, higher quality iron.}
}
@article{FICSOR2023109769,
title = {Machine learning model ensemble based on multi-scale predictors confirms ecological segregation and accurately predicts the occurrence of net-spinning caddisfly larvae species groups (Trichoptera: Hydropsychidae) at catchment-scale},
journal = {Ecological Indicators},
volume = {146},
pages = {109769},
year = {2023},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2022.109769},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X22012420},
author = {Márk Ficsór and Zoltán Csabai},
keywords = {Hydropsychidae, Longitudinal distribution, Environmental factors, Machine learning ensemble model, Caddisfly, Distribution modelling},
abstract = {In riverine ecosystems the species distribution, determined primarily by their environment often shows zonation patterns that are also typical in the case of net-spinning caddisfly larvae (Trichoptera: Hydropsychidae). In the present research, we aimed to build an ensemble of base learner machine learning (ML) models based on the most important environmental parameters shaping the sequential distribution of ten Central European species of the genus Hydropsyche in the North Hungarian catchment area of Tisza, one of the major rivers of Central and Eastern Europe. The model could explain and effectively predict the occurrence of species and/or groups of them with similar niche preferences. Variable selection revealed the importance of predictors, measured at various spatial scales and with gradient-like characteristics, such as elevation, annual means of discharge, water temperature or the composition of habitat substrates as well as those related to the ecological quality of water or anthropogenic impacts, like annual means of dissolved oxygen and orthophosphate-phosphorous content. Trained on the predictions of different base learner models a final ensemble model predicted the presence and absence of three individual species and three species-groups with significantly improved overall accuracy. High group-wise balanced accuracies of the final model shows that longitudinal, catchment-scale distribution models in stream ecosystems are best built on predictors with variable spatial scales, several of which are routinely measured or recorded in environmental monitoring programmes. Accurate species distribution models (SDMs), capable of adequately predicting presence and absence of bio-indicator taxa, such as Hydropsyche species, can be applied to support environmental management or conservation measures regarding streams and rivers, that are among the most vulnerable of anthropogenic pollution, hydrologic alteration, climate change and biodiversity loss.}
}
@article{TARIQ2023106538,
title = {Deep learning artificial intelligence framework for sustainable desiccant air conditioning system: Optimization towards reduction in water footprints},
journal = {International Communications in Heat and Mass Transfer},
volume = {140},
pages = {106538},
year = {2023},
issn = {0735-1933},
doi = {https://doi.org/10.1016/j.icheatmasstransfer.2022.106538},
url = {https://www.sciencedirect.com/science/article/pii/S0735193322006601},
author = {Rasikh Tariq and Muzaffar Ali and Nadeem Ahmed Sheikh and Muhammad Wakil Shahzad and Ben Bin Xu},
keywords = {Artificial neural network, Desiccant evaporative cooling, Water footprint, White-box modeling, Multicriteria decision-analysis, Sustainable buildings},
abstract = {Desiccant evaporative cooling systems pave the path towards energy and environmental sustainability in buildings especially; however, the direct evaporative coolers in such configurations result in high water consumption. The application of modern computational intelligence tools, including artificial intelligence and meta-heuristic optimization algorithms, can improve the operational comprehension of desiccant cooling systems while addressing the minimization of total water footprints with the maximization of the cooling capacity. The contribution/objective of this research is to address the gaps in understanding through the application of deep learning, genetic algorithm, and multicriteria decision analysis applied to a desiccant cooling system working under real transient experimental conditions of a building located in Austria. Within the methodology, calibrated, experimental, and validated data monitoring system displaying the real desiccant-enhanced cooling system is adapted to generate a set of input-output data sets. The set of data includes ambient temperature, ambient humidity, regeneration temperature, supply airflow rate, and return airflow rate yielding the cooling capacity and total water footprints of the system. The results of deep learning algorithm using an artificial neural network have suggested that the architectures 5-[6]-[6]-1 and 5-[12]-[12]-1 are the best to accurately predict the cooling capacity and total water footprints with a coefficient of determination of 0.98856 and 0.99246, respectively. Secondly, the “white-box model” of the deep learning algorithm is used to develop a digital twin model which helps in the replication of the earlier experimental conditions. The optimization results have suggested that the optimized total water footprints are 45.17 kg/h with a system of 3.32 tons of refrigeration. These optimal values are found in the best combination of design variables in which the ambient temperature is 28 °C, ambient relative humidity is 52.0%, supply airflow rate is 2.13 kg/s, and regeneration flow rate is 2.35 kg/s, and the regeneration temperature is 70.0 °C. It is concluded that the application of data-driven models can extend the interpretation of desiccant cooling systems and can participate in its performance enhancement.}
}
@article{FENG2023109896,
title = {Digital twin-driven intelligent assessment of gear surface degradation},
journal = {Mechanical Systems and Signal Processing},
volume = {186},
pages = {109896},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2022.109896},
url = {https://www.sciencedirect.com/science/article/pii/S0888327022009645},
author = {Ke Feng and J.C. Ji and Yongchao Zhang and Qing Ni and Zheng Liu and Michael Beer},
keywords = {Gearbox, Digital twin, Surface degradation, Health management, Wear assessment},
abstract = {Gearbox has a compact structure, a stable transmission capability, and a high transmission efficiency. Thus, it is widely applied as a power transmission system in various applications, such as wind turbines, industrial machinery, aircraft, space vehicles, and land vehicles. The gearbox usually operates in harsh and non-stationary working environments, expediting the degradation process of the gear surface. The degradation process may lead to severe gear failures, such as tooth breakage and root crack, which could damage the gear transmission system. Therefore, it is essential to assess the progression of gear surface degradation in order to ensure a reliable operation. The digital twin is an emerging technology for machine health management. A high-fidelity digital twin model can help reflect the operation status of the gearbox and reveal the corresponding degradation mechanism, which could benefit the remaining useful life (RUL) prediction and the predictive maintenance-based decision-making framework. This paper develops a digital twin-driven intelligent health management method to monitor and assess the gear surface degradation progression. The developed method can effectively reveal the gear wear propagation characteristics and predict the RUL accurately. Furthermore, the knowledge learned from digital twin models can be well transferred to the surface wear assessment of the physical gearbox in wide industrial applications, which is of great practical significance. Two endurance tests with different dominant degradation mechanisms were conducted to validate the effectiveness of the proposed methodology for gear wear assessment.}
}
@article{ARABLOUEI2023100159,
title = {In-situ animal behavior classification using knowledge distillation and fixed-point quantization},
journal = {Smart Agricultural Technology},
volume = {4},
pages = {100159},
year = {2023},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2022.100159},
url = {https://www.sciencedirect.com/science/article/pii/S277237552200123X},
author = {Reza Arablouei and Liang Wang and Caitlin Phillips and Lachlan Currie and Jordan Yates and Greg Bishop-Hurley},
keywords = {Animal behavior classification, Deep learning, Dynamic quantization, Embedded systems, Fix-point arithmetic, Knowledge distillation},
abstract = {We explore the use of knowledge distillation (KD) for learning compact and accurate models that enable classification of animal behavior from accelerometry data on wearable devices. To this end, we take a deep and complex convolutional neural network, known as residual neural network (ResNet), as the teacher model. ResNet is specifically designed for multivariate time-series classification. We use ResNet to distill the knowledge of animal behavior classification datasets into soft labels, which consist of the predicted pseudo-probabilities of every class for each datapoint. We then use the soft labels to train our significantly less complex student models, which are based on the gated recurrent unit (GRU) and multilayer perceptron (MLP). The evaluation results using two real-world animal behavior classification datasets show that the classification accuracy of the student GRU-MLP models improves appreciably through KD, approaching that of the teacher ResNet model. To further reduce the computational and memory requirements of performing inference using the student models trained via KD, we utilize dynamic fixed-point quantization (DQ) through an appropriate modification of the computational graph of the considered models. We implement both unquantized and quantized versions of the developed KD-based models on the embedded systems of our purpose-built collar and ear tag devices to classify animal behavior in situ and in real time. Our evaluations corroborate the effectiveness of KD and DQ in improving the accuracy and efficiency of in-situ animal behavior classification.}
}
@article{LV2023102489,
title = {A bio-inspired LIDA cognitive-based Digital Twin architecture for unmanned maintenance of machine tools},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {80},
pages = {102489},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2022.102489},
url = {https://www.sciencedirect.com/science/article/pii/S0736584522001715},
author = {Jianhao Lv and Xinyu Li and Yicheng Sun and Yu Zheng and Jinsong Bao},
keywords = {Unmanned maintenance, Digital Twin, Machine tools, Learning intelligent distribution agent (LIDA), Cognitive manufacturing},
abstract = {Affected by COVID-19, the maintenance process of machine tools is significantly hindered, while unmanned maintenance becomes an emerging trend in such background. So far, three challenges, namely, the dependence on maintenance experts, the dynamic maintenance environments, and unsynchronized interactions between physical and information sides, exist as the main obstacles in its widespread applications. In order to fill this gap, a bio-inspired LIDA cognitive-based Digital Twin architecture is proposed, so as to achieve unmanned maintenance of machine tools through a self-constructed, self-evaluated, and self-optimized manner. A three phases process in the architecture, including the physical phase, virtual phase, and service phase, is further introduced to support the cognitive cycle for unmanned maintenance of machine tools. An illustrative example is depicted in the unmanned fault diagnosis on the rolling bearing of a drilling platform, which validates the feasibility and advantages of the proposed architecture. As an explorative study, it is wished that this work provides useful insights for unmanned maintenance of machine tools in a dynamic production environment.}
}
@article{SEHRAWAT202390,
title = {Solar irradiance forecasting models using machine learning techniques and digital twin: A case study with comparison},
journal = {International Journal of Intelligent Networks},
volume = {4},
pages = {90-102},
year = {2023},
issn = {2666-6030},
doi = {https://doi.org/10.1016/j.ijin.2023.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666603023000064},
author = {Neha Sehrawat and Sahil Vashisht and Amritpal Singh},
abstract = {The ever-increasing demand for energy and power consumption due to population growth, economic expansion, and evolving consumer choices has led to the need for renewable energy sources. Traditional energy sources such as coal, oil, and gas have contributed to global pollution and have adverse effects on human health. As a result, the use of renewable energy for power generation has increased tremendously. One such area of research is solar irradiation prediction, which utilizes Artificial Intelligence and Machine Learning techniques. With the use of real-time predicted data, the digital twins are intended to add value to the organization by identifying and preventing problems, predicting performance, and improving operations. This paper provides an overview of various learning methods used for predicting irradiance and presents a new ensemble solar irradiance forecasting model that combines eight machine learning models to ensure model diversity. The model's most critical factors for predicting irradiance include temperature, cloudiness index, relative humidity, and day of the week. To conduct a comprehensive analysis, the proposed 8-Stacking Regression Cross Validation (8 STR-CV) model was tested using data from three different climatic zones in India. The model's high accuracy scores of 98.8% for Visakhapatnam, 98% for Nagpur, and 97.8% for the mountainous region make it a valuable tool for future prediction in various sectors, including power generation and utilization planning.}
}
@article{ZHAO2022109832,
title = {Multi-instance semantic similarity transferring for knowledge distillation},
journal = {Knowledge-Based Systems},
volume = {256},
pages = {109832},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109832},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122009327},
author = {Haoran Zhao and Xin Sun and Junyu Dong and Hui Yu and Gaige Wang},
keywords = {Deep neural networks, Image classification, Model compression, Knowledge distillation},
abstract = {Knowledge distillation is a popular paradigm for learning portable neural networks by transferring the knowledge from a large model into a smaller one. Most existing approaches enhance the student model by utilizing the similarity information between the categories of instance level provided by the teacher model. However, these works ignore the similarity correlation between different instances that plays an important role in confidence prediction. To tackle this issue, we propose a novel method in this paper, called multi-instance semantic similarity transferring for knowledge distillation (STKD), which aims to fully utilize the similarities between categories of multiple samples. Furthermore, we propose to better capture the similarity correlation between different instances by the mixup technique, which creates virtual samples by a weighted linear interpolation. Note that, our distillation loss can fully utilize the incorrect classes similarities by the mixed labels. The proposed approach promotes the performance of student model as the virtual sample created by multiple images produces a similar probability distribution in the teacher and student networks. Experiments and ablation studies on several public classification datasets including CIFAR-10, CIFAR-100, CINIC-10 and Tiny-ImageNet verify that this light-weight method can effectively boost the performance of the compact student model. It shows that STKD has substantially outperformed the vanilla knowledge distillation and achieved superior accuracy over the state-of-the-art knowledge distillation methods.}
}
@article{CHAUDHARI20231128,
title = {A Generic Digital Twin Application Framework for Emerging Trends in Industrial Process Heaters},
journal = {Procedia CIRP},
volume = {119},
pages = {1128-1133},
year = {2023},
note = {The 33rd CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123006297},
author = {Sanket Sharad Chaudhari and Kiran Suresh Bhole and Santosh Rane and Suhas Deshmukh},
keywords = {Digital twin, Design Thinking, Process Heater, IoT Framework},
abstract = {Industrial process heaters have challenging future considering recent emission norms and efficient performance for cost optimization. It is therefore necessary to have real-time technical data and vigilant system to improve operations and elimination of abrupt failures. Though digital twin is highly suitable to address this requirement however its application knowledge for Process Heater is obsolete. Therefore, this paper objects to illustrate a generic digital twin methodology for industrial process heaters including key operational aspects which contain potential of optimization of performance and cost. The framework proposed in this study will integrate it to show its practical implications. This study is performed for typical vertical cylindrical process heaters; however, it is also applicable to other types of heaters. The ready to implement framework of digital twin will impact on saving of infrastructure development and limited dependability on commercial agencies while installation of digital twin. It will also address industrial challenges including reduction in emissions, fuel consumption, equipment downtime and unexpected failures. The framework will be path forward for future necessities like Artificial Intelligence, Machine Learning etc.}
}
@article{ALEXOPOULOS20232963,
title = {Machine Learning Agents Augmented by Digital Twinning for Smart Production Scheduling},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {2963-2968},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.1420},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323018281},
author = {Kosmas Alexopoulos and Nikolaos Nikolakis and Emmanouil Bakopoulos and Vasilis Siatras and Panagiotis Mavrothalassitis},
keywords = {Machine Learning, Digital Twin, Production Scheduling, Deep Learning, Asset Administration Shell, Smart Agents, Industry 4.0},
abstract = {Digital manufacturing tools aim to provide intelligent solutions that can support manufacturing industry to adapt to the volatile operational environment. The successful implementation of such tools highly depends on the capabilities of the digital frameworks or platforms they are deployed upon as well as the quality of their intelligence. The objective of this work is to develop and discuss a framework for training and deploying Machine Learning (ML) agents for production scheduling with the augmentation of Digital Twin (DT) technologies. Two types of ML production scheduling agents have been developed and integrated with the DT framework: a Deep Learning agent and a Deep Reinforcement Learning agent. In order to increase interoperability, Asset Administration Shell Industry4.0 standard has been utilized for the integration and deployment of the proposed DT framework into industrial practice. The proposed framework is tested and validated upon an industrial case study from the bicycles’ production industry.}
}
@article{LU2023104203,
title = {Uncertainty-aware pseudo-label and consistency for semi-supervised medical image segmentation},
journal = {Biomedical Signal Processing and Control},
volume = {79},
pages = {104203},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2022.104203},
url = {https://www.sciencedirect.com/science/article/pii/S1746809422006577},
author = {Liyun Lu and Mengxiao Yin and Liyao Fu and Feng Yang},
keywords = {Semi-supervised learning, Medical image segmentation, Pseudo-labeling, Consistency regularization, Uncertainty estimation},
abstract = {In medical image segmentation tasks, fully-supervised learning has been a huge success by using abundant labeled data. However, it is time-consuming and expensive for technicians to label medical images. In this paper, we propose a novel framework for semi-supervised medical image segmentation, named Uncertainty-aware Pseudo-label and Consistency. Our framework is made up of the student–teacher models. The supervised loss on labeled data and the consistency loss on both labeled and unlabeled data are weighted and combined to optimize the models. Our method combines the recent state-of-the-art semi-supervised methods, which are consistency regularization and pseudo-labeling. More importantly, we calculate the Kullback–Leibler variance between the student model’s prediction and the teacher model’s prediction as uncertainty estimation, and directly use the uncertainty to rectify the learning of noisy pseudo-labels, instead of setting a fixed threshold to filter the pseudo-labels. Experiments on the Left Atrium dataset show that our method can efficiently utilize unlabeled data to achieve high performance and outperform other state-of-the-art semi-supervised methods. In addition, we have also analyzed its difference from conventional methods of consistency regularization and pseudo-labeling in semi-supervised medical image segmentation. Code is available in https://github.com/GXU-GMU-MICCAI/UPC-Pytorch.}
}
@article{HUYNHTHE2023105581,
title = {Artificial intelligence for the metaverse: A survey},
journal = {Engineering Applications of Artificial Intelligence},
volume = {117},
pages = {105581},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105581},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622005711},
author = {Thien Huynh-The and Quoc-Viet Pham and Xuan-Qui Pham and Thanh Thi Nguyen and Zhu Han and Dong-Seong Kim},
keywords = {Artificial intelligence, Blockchain, Deep learning, Immersive experience, Machine learning, Machine vision, Metaverse, Metaverse applications, Networking, Virtual worlds},
abstract = {Along with the massive growth of the Internet from the 1990s until now, various innovative technologies have been created to bring users breathtaking experiences with more virtual interactions in cyberspace. Many virtual environments have been developed with immersive experience and digital transformation, but most are incoherent instead of being integrated into a platform. In this context, metaverse has been introduced as a shared virtual world that is fueled by many emerging technologies. Among such technologies, artificial intelligence (AI) has shown the great importance of enhancing immersive experience and enabling human-like intelligence of virtual agents. In this survey, we make a beneficial effort to explore the role of AI, including machine learning algorithms and deep learning architectures, in the foundation and development of the metaverse. As the main contributions, we convey a comprehensive investigation of AI-based methods concerning several technical aspects (e.g., natural language processing, machine vision, blockchain, networking, digital twin, and neural interface) that have potentials to build virtual worlds in the metaverse. Furthermore, several primary AI-aided applications, including healthcare, manufacturing, smart cities, and gaming, are studied to be promisingly deployed in the virtual worlds. Finally, we conclude the key contribution and open some future research directions of AI for the metaverse. Serving as a foundational survey, this work will help researchers, including experts and non-experts in related fields, in applying, developing, and optimizing AI techniques to polish the appearance of virtual worlds and improve the quality of applications built in the metaverse.}
}
@article{LIN2022109439,
title = {Development and assessment of prognosis digital twin in a NAMAC system},
journal = {Annals of Nuclear Energy},
volume = {179},
pages = {109439},
year = {2022},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2022.109439},
url = {https://www.sciencedirect.com/science/article/pii/S0306454922004698},
author = {Linyu Lin and Anil Gurgen and Nam Dinh},
keywords = {Digital twin, Prognosis, Machine learning, Autonomous control},
abstract = {The nearly autonomous management and control (NAMAC) system is a comprehensive control system to assist plant operations by furnishing control recommendations to operators. Prognosis digital twin (DT-P) is a critical component in NAMAC for predicting action effects and supporting NAMAC decision-making during normal and accident scenarios. To quantifying and reducing uncertainty of machine-learning-based DT-Ps in multi-step predictions, this work investigates and derives insights from the application of three techniques for optimizing the performance of DT-P by long short-term memory recurrent neural networks, including manual search, sequential model-based optimization, and physics-guided machine learning. Sequential model-based optimization and physics-guide machine learning result in smallest errors when the predicting transients are similar to the training data.}
}
@article{JIMENEZ20239588,
title = {A simple framework for working with MATLAB and Home I/O},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {9588-9593},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.262},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323006134},
author = {Javier Jiménez and Elena M. Mosquera and José M. Maestre},
keywords = {Control education, virtual and remote labs, centralized internet repository, predictive control, system Identification},
abstract = {A software framework that communicates MATLAB and Home I/O software, which provides a pedagogic digital twin of a smart home, is presented. This software is packaged as a MATLAB class code and allows reading and writing to Home I/O from MATLAB. It also includes useful tools to simplify the implementation of learning and research algorithms using its built-in methods. A basic thermal Identification and a simple MPC (Model Predictive Controller) with all rooms’ heaters are built using this framework to prove its functionality.}
}
@article{GONG2022109431,
title = {An efficient digital twin based on machine learning SVD autoencoder and generalised latent assimilation for nuclear reactor physics},
journal = {Annals of Nuclear Energy},
volume = {179},
pages = {109431},
year = {2022},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2022.109431},
url = {https://www.sciencedirect.com/science/article/pii/S0306454922004613},
author = {Helin Gong and Sibo Cheng and Zhang Chen and Qing Li and César Quilodrán-Casas and Dunhui Xiao and Rossella Arcucci},
keywords = {Operational digital twins, Machine learning, Latent assimilation, SVD-autoencoder, Nuclear reactor physics},
abstract = {This paper proposes an approach that combines reduced-order models with machine learning in order to create an digital twin to predict the power distribution over the core during the operation stage. The operational digital twin is designed to solve forward problems given input operation parameters, as well as to solve inverse problems given some observations of the power field. The forward model is non-intrusive and realised using SVD autoencoder reduced order model with the combination of machine learning methods, namely, k-nearest-neighbours and decision trees to build the input–output map. For model parameter estimation, the inverse model is based on a generalised latent assimilation method. The proposed approach is able to make use of the non intrusive reduced order model and the online measurements of the power field. The effectiveness in the sense of accuracy and real-time solver of the digital twin is illustrated through a real engineering problem in nuclear reactor physics — reactor core simulation in the life cycle of HPR1000 affected by input parameters, i.e., control rod inserting step, burnup, power level and inlet temperature of the coolant, which shows potential applications for on-line monitoring purpose.}
}
@article{ZHOU2022,
title = {Multimodal fusion recognition for digital twin},
journal = {Digital Communications and Networks},
year = {2022},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2022.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S2352864822002176},
author = {Tianzhe Zhou and Xuguang Zhang and Bing Kang and Mingkai Chen},
keywords = {Digital twin, Multimodal fusion, Object recognition, Deep learning, Transfer learning},
abstract = {The digital twin is the concept of transcending reality, which is the reverse feedback from the real physical space to the virtual digital space. People hold great prospects for this emerging technology. In order to realize the upgrading of the digital twin industrial chain, it is urgent to introduce more modalities, such as vision, haptics, hearing and smell, into the virtual digital space, which assists physical entities and virtual objects in creating a closer connection. Therefore, perceptual understanding and object recognition have become an urgent hot topic in the digital twin. Existing surface material classification schemes often achieve recognition through machine learning or deep learning in a single modality, ignoring the complementarity between multiple modalities. In order to overcome this dilemma, we propose a multimodal fusion network in our article that combines two modalities, visual and haptic, for surface material recognition. On the one hand, the network makes full use of the potential correlations between multiple modalities to deeply mine the modal semantics and complete the data mapping. On the other hand, the network is extensible and can be used as a universal architecture to include more modalities. Experiments show that the constructed multimodal fusion network can achieve 99.42% classification accuracy while reducing complexity.}
}
@article{BANAFAA2023245,
title = {6G Mobile Communication Technology: Requirements, Targets, Applications, Challenges, Advantages, and Opportunities},
journal = {Alexandria Engineering Journal},
volume = {64},
pages = {245-274},
year = {2023},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2022.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S111001682200549X},
author = {Mohammed Banafaa and Ibraheem Shayea and Jafri Din and Marwan {Hadri Azmi} and Abdulaziz Alashbi and Yousef {Ibrahim Daradkeh} and Abdulraqeb Alhammadi},
keywords = {6G, Autonomous vehicle, Visible light communication, Intelligence systems, Machine learning, Massive multi-input multi-output (MIMO)},
abstract = {The sixth-generation (6G) technology of mobile networks will establish new standards to fulfill unreachable performance requirements by fifth-generation (5G) mobile networks. This is due to the high requirements for more intelligent network, ultra-lower latency, extreme network communication speed, and supporting massive number of various connected applications. In the long term, the convergence of various business developments with communication platforms, as initiated by 5G, will exaggerate and highlight areas where 5G's capabilities will fall short of performance requirements. Motivated by the development of applications in massive connections, future networks, developments, and technological advancements for mobile communications that go beyond fifth-generation (B5G) networks are being developed. In this context, highly immersive applications are demanded, such as three-dimensional (3D) communications, digital twins, or massive extended reality (XR)/virtual reality (VR) applications, which will need 6G capabilities to be realized at scale to be commercially feasible. Mainly, we anticipate that only the upcoming 6G networks will be capable of running extremely high-performance connectivity with massive numbers of connected devices, even under laborious scenarios such as extreme density, diverse mobility, and energetic environments. In this article, we look at the most recent trends and future emerging trends that are possible to operate 6G network. Paper aims to provide more inclusive and brief review about 6G mobile communication technology in one survey paper. Initially, a comprehensive overview of the 6G system is introduced in terms of visions, drivers, requirements, architecture, and usage scenarios required to enable 6G applications. After that, the opportunities and advantages of 6G mobile technology has been discussed. Further, the promising new techniques that enable 6G technology has been highlighted. This is followed by a potential discussion of challenges and research directions. This article is envisioned to serve as an informative guideline to stimulate interest and further studies for subsequent research and development of 6G networks. Paper will enable the readers to briefly figure out the key requirements, targets, that will be need and the applications, advantages, and opportunities that can be offered as well as the challenges that need to be addressed before the implementation of this new technology.}
}
@article{JEON2023466,
title = {Leveraging angular distributions for improved knowledge distillation},
journal = {Neurocomputing},
volume = {518},
pages = {466-481},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.11.029},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222014096},
author = {Eun Som Jeon and Hongjun Choi and Ankita Shukla and Pavan Turaga},
keywords = {Knowledge distillation, Angular distribution, Angular margin, Image classification},
abstract = {Knowledge distillation as a broad class of methods has led to the development of lightweight and memory efficient models, using a pre-trained model with a large capacity (teacher network) to train a smaller model (student network). Recently, additional variations for knowledge distillation, utilizing activation maps of intermediate layers as the source of knowledge, have been studied. Generally, in computer vision applications, it is seen that the feature activation learned by a higher-capacity model contains richer knowledge, highlighting complete objects while focusing less on the background. Based on this observation, we leverage the teacher’s dual ability to accurately distinguish between positive (relevant to the target object) and negative (irrelevant) areas. We propose a new loss function for distillation, called angular margin-based distillation (AMD) loss. AMD loss uses the angular distance between positive and negative features by projecting them onto a hypersphere, motivated by the near angular distributions seen in many feature extractors. Then, we create a more attentive feature that is angularly distributed on the hypersphere by introducing an angular margin to the positive feature. Transferring such knowledge from the teacher network enables the student model to harness the teacher’s higher discrimination of positive and negative features, thus distilling superior student models. The proposed method is evaluated for various student–teacher network pairs on four public datasets. Furthermore, we show that the proposed method has advantages in compatibility with other learning techniques, such as using fine-grained features, augmentation, and other distillation methods.}
}
@article{ZHAO2023104645,
title = {A blockchain 3.0 paradigm for digital twins in construction project management},
journal = {Automation in Construction},
volume = {145},
pages = {104645},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104645},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522005155},
author = {Rui Zhao and Zhe Chen and Fan Xue},
keywords = {Blockchain 3.0, Construction project management, Digital twin, Smart contract, Modular construction},
abstract = {Construction project management (CPM) is inherently complex and distributed, while digital twin and blockchain are recognized as promising solutions for information-reliant CPM. By learning from the lessons of Blockchain 1.0 and 2.0 paradigms in the literature, such as slow synchronization and failed offline functions, this paper proposes ChainPM as a Blockchain 3.0 paradigm. ChainPM extends Blockchain 2.0 with innovative indexing, query, and analysis function sets for key CPM data. Experimental results from a pilot study of a modular construction project showed that the information synchronization latency was reduced by 99.2% to 99.8%, and query and analytical functions worked equally well without network connections. ChainPM contributes to a novel trend of Blockchain 3.0 paradigms for CPM digital twins, emphasizing indexing key CPM data, combinatorial query, digital authorship, and fast response without downgrading the ‘single source of truth.’ For practitioners, ChainPM addresses key barriers of Internet reliance and information delay to CPM digital twins.}
}
@article{TANG2023693,
title = {Towards better utilization of pseudo labels for weakly supervised temporal action localization},
journal = {Information Sciences},
volume = {623},
pages = {693-708},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.12.044},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522015390},
author = {Yiping Tang and Junyao Ge and Kaitai Guo and Yang Zheng and Haihong Hu and Jimin Liang},
keywords = {Untrimmed video analysis, Temporal action detection, Weakly supervised learning, Pseudo label},
abstract = {Weakly supervised temporal action localization (WS-TAL) aims to simultaneously recognize and localize action instances of interest in untrimmed videos with the use of the video-level label only. Some works have demonstrated that pseudo labels play an important role for performance improvement in WS-TAL. Since pseudo labels are inevitably inaccurate, direct adoption of noisy labels can lead to inappropriate knowledge transfer. Although some previous studies have shown the benefits of using only “reliable” pseudo labels, performance improvement is still limited. In this work, we experimentally analyze how the noise in pseudo labels affects model performance within the self-distillation framework. Motivated by the finding that incorrect pseudo labels with large confidence scores have a significant impact on performance, we propose the overconfidence suppression (OCS) strategy to mitigate the effect of the overconfident pseudo labels, and thus prevent over-fitting of the student model. In addition, a simplified contrast learning method is utilized to fine-tune the feature representation by increasing the separation of the foreground and background snippets. Equipped with the proposed methods, the benefits of pseudo labels can be better exploited and allow the model to achieve state-of-the-art performance on THUMOS’14 and ActivityNet-1.2 benchmarks.}
}
@article{ZHANG202356,
title = {A multi-access edge computing enabled framework for the construction of a knowledge-sharing intelligent machine tool swarm in Industry 4.0},
journal = {Journal of Manufacturing Systems},
volume = {66},
pages = {56-70},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2022.11.015},
url = {https://www.sciencedirect.com/science/article/pii/S0278612522002060},
author = {Chao Zhang and Guanghui Zhou and Jingjing Li and Fengtian Chang and Kai Ding and Dongxu Ma},
keywords = {Multi-access edge computing, Digital twin, Intelligent machine tool, Industry 4.0, Knowledge sharing},
abstract = {Developing intelligent machine tools has been front and center for manufacturing enterprises to take a step towards intelligent manufacturing in Industry 4.0, which has attracted increasing attention from both academics and industry. Nevertheless, most current approaches focus on the construction of a single digital twin machine tool with limited intelligence due to the lack of data and knowledge accumulated by that machine tool for decision-making support. Consequently, this paper integrates digital twin with multi-access edge computing (MEC) and proposes a novel framework for the construction of a knowledge-sharing intelligent machine tool swarm that supports the secure knowledge sharing across the authorized machine tools in the swarm with ultra-low latency performance. Then, three key enabling methodologies of the framework are introduced from the perspective of digital twin machine tool swarm construction, knowledge-based cloud brain learning, and MEC-enhanced system deployment. Finally, a prototype system is implemented, where its application examples and evaluation experiments demonstrate the feasibility and effectiveness of the proposed approach.}
}
@article{LI2023148,
title = {An improved stochastic configuration network for concentration prediction in wastewater treatment process},
journal = {Information Sciences},
volume = {622},
pages = {148-160},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.11.134},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522014451},
author = {Kang Li and Cuili Yang and Wei Wang and Junfei Qiao},
keywords = {Stochastic configuration networks, Incremental learning, Randomized neural networks, Wastewater treatment process},
abstract = {A learner model with fast learning and compact architecture is expected for industrial data modeling. To achieve these goals during stochastic configuration networks (SCNs) construction, we propose an improved version of SCNs in this paper. Unlike the original SCNs, the improved one employs a new inequality constraint in the construction process. In addition, to speed up the construction efficiency of SCNs, a node selection method is proposed to adaptively select nodes from a candidate pool. Moreover, to reduce the redundant nodes of the built SCNs model, we further compress the model based on the singular value decomposition algorithm. The improved SCNs are compared with other methods over four datasets and then applied to the ammonia–nitrogen concentration prediction task in the wastewater treatment process. Experimental results indicate that the proposed method has good potential for industrial data analytics.}
}
@article{WANG20236921,
title = {Neural network and Sparse identification of Nonlinear Dynamics Integrated Algorithm for Digital Twin identification},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {6921-6926},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.503},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323008704},
author = {Jingyi Wang and Jesús Moreira and Yankai Cao and R. Bhushan Gopaluni},
keywords = {Digital twin, Feature engineering, Hybrid modelling, Industry 4.0, Nonlinear model reduction, Sparse process modelling and identification},
abstract = {Digital twins play a critical role in simulating industrial manufacturing systems to increase productivity and reduce time spent on troubleshooting. Owing to the complexity of real-world industrial systems, automatic sparse identification has emerged as an attractive approach to perform digital twin modelling. The sparse identification of nonlinear dynamics (SINDy) is a machine learning algorithm that performs feature engineering by generating a model term library and then solves a sparse regression problem between the objective outputs and the generated features. By solving a linear-in-parameter sparse regression problem, SINDy provides automatic discovery of system governing equations. However, the performance of SINDy-based algorithms may decline dramatically when applied to identify complex nonlinear relationships, such as implicit relationships. The substantial number of input variables for a real industrial process may further complicate the modelling procedure. We therefore propose the neural network and SINDy integrated algorithm to automatically select the critical features from a model term library and utilize the neural network to capture the process nonlinearity that cannot be captured by a linear-in-parameter model. SINDy performs feature generation considering both numerical methods and first-principles knowledge, making the proposed algorithm a hybrid system identification approach. A diesel hydrotreating unit case study with 37 input variables is analyzed in this paper to demonstrate the advantages of the proposed algorithm for nonlinear digital twin identification. By combining the advantages from both SINDy and neural networks, the proposed algorithm is able to improve the output prediction accuracy for all the three objectives.}
}
@article{WANG2023102693,
title = {SSD-KD: A self-supervised diverse knowledge distillation method for lightweight skin lesion classification using dermoscopic images},
journal = {Medical Image Analysis},
volume = {84},
pages = {102693},
year = {2023},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102693},
url = {https://www.sciencedirect.com/science/article/pii/S1361841522003218},
author = {Yongwei Wang and Yuheng Wang and Jiayue Cai and Tim K. Lee and Chunyan Miao and Z. Jane Wang},
keywords = {Skin cancer detection, Knowledge distillation, Deep learning, Dermoscopy},
abstract = {Skin cancer is one of the most common types of malignancy, affecting a large population and causing a heavy economic burden worldwide. Over the last few years, computer-aided diagnosis has been rapidly developed and make great progress in healthcare and medical practices due to the advances in artificial intelligence, particularly with the adoption of convolutional neural networks. However, most studies in skin cancer detection keep pursuing high prediction accuracies without considering the limitation of computing resources on portable devices. In this case, the knowledge distillation (KD) method has been proven as an efficient tool to help improve the adaptability of lightweight models under limited resources, meanwhile keeping a high-level representation capability. To bridge the gap, this study specifically proposes a novel method, termed SSD-KD, that unifies diverse knowledge into a generic KD framework for skin disease classification. Our method models an intra-instance relational feature representation and integrates it with existing KD research. A dual relational knowledge distillation architecture is self-supervised trained while the weighted softened outputs are also exploited to enable the student model to capture richer knowledge from the teacher model. To demonstrate the effectiveness of our method, we conduct experiments on ISIC 2019, a large-scale open-accessed benchmark of skin diseases dermoscopic images. Experiments show that our distilled MobileNetV2 can achieve an accuracy as high as 85% for the classification tasks of 8 different skin diseases with minimal parameters and computing requirements. Ablation studies confirm the effectiveness of our intra- and inter-instance relational knowledge integration strategy. Compared with state-of-the-art knowledge distillation techniques, the proposed method demonstrates improved performance. To the best of our knowledge, this is the first deep knowledge distillation application for multi-disease classification on the large-scale dermoscopy database. Our codes and models are available at https://github.com/enkiwang/Portable-Skin-Lesion-Diagnosis.}
}
@article{VOOGD20231510,
title = {Reinforcement Learning from Simulation to Real World Autonomous Driving using Digital Twin},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {1510-1515},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.1846},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323022553},
author = {Kevin L. Voogd and Jean Pierre Allamaa and Javier Alonso-Mora and Tong Duy Son},
keywords = {Learning and adaptation, autonomous vehicles, Sim2Real, reinforcement learning},
abstract = {Reinforcement learning (RL) is a promising solution for autonomous vehicles to deal with complex and uncertain traffic environments. The RL training process is however expensive, unsafe, and time-consuming. Algorithms are often developed first in simulation and then transferred to the real-world, leading to a common sim2real challenge where performance decreases when the domain changes. In this paper, we propose a transfer learning process to minimize the gap by exploiting digital twin technology, relying on a systematic and simultaneous combination of virtual and real world data coming from vehicle dynamics and traffic scenarios. The model and testing environment is evolved from model, hardware to vehicle in the loop and proving ground testing stages, similar to standard development cycle in the automotive industry. In particular, we also integrate other transfer learning techniques such as domain randomization and adaptation in each stage. The simulation and real data are gradually incorporated to accelerate and make the transfer learning process more robust. The proposed RL methodology is applied to develop a path-following steering controller for an autonomous electric vehicle. After learning and deploying the real-time RL control policy on the vehicle, we obtained satisfactory and safe control performance already from the first deployment, demonstrating the advantages of the proposed digital twin based learning process.}
}
@article{YI2022,
title = {Digital twin driven and intelligence enabled content delivery in end-edge-cloud collaborative 5G networks},
journal = {Digital Communications and Networks},
year = {2022},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2022.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S2352864822001894},
author = {Bo Yi and Jianhui Lv and Xingwei Wang and Lianbo Ma and Min Huang},
keywords = {Digital twin, IoE, Content delivery, Caching, Routing},
abstract = {The rapid development of 5G/6G and AI enables an environment of Internet of Everything (IoE) which can support millions of connected mobile devices and applications to operate smoothly at high speed and low delay. However, these massive devices will lead to explosive traffic growth, which in turn cause great burden for the data transmission and content delivery. This challenge can be eased by sinking some critical content from cloud to edge. In this case, how to determine the critical content, where to sink and how to access the content correctly and efficiently become new challenges. This work focuses on establishing a highly efficient content delivery framework in the IoE environment. In particular, the IoE environment is re-constructed as an end-edge-cloud collaborative system, in which the concept of digital twin is applied to promote the collaboration. Based on the digital asset obtained by digital twin from end users, a content popularity prediction scheme is firstly proposed to decide the critical content by using the Temporal Pattern Attention (TPA) enabled Long Short-Term Memory (LSTM) model. Then, the prediction results are input for the proposed caching scheme to decide where to sink the critical content by using the Reinforce Learning (RL) technology. Finally, a collaborative routing scheme is proposed to determine the way to access the content with the objective of minimizing overhead. The experimental results indicate that the proposed schemes outperform the state-of-the-art benchmarks in terms of the caching hit rate, the average throughput, the successful content delivery rate and the average routing overhead.}
}
@article{GONG2023109497,
title = {Parameter identification and state estimation for nuclear reactor operation digital twin},
journal = {Annals of Nuclear Energy},
volume = {180},
pages = {109497},
year = {2023},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2022.109497},
url = {https://www.sciencedirect.com/science/article/pii/S0306454922005278},
author = {Helin Gong and Tao Zhu and Zhang Chen and Yaping Wan and Qing Li},
keywords = {Digital twin, Machine learning, Differential evolution, Nuclear reactor physics},
abstract = {Reactor Operation Digital Twin (RODT) is now receiving increasing attention and investment in nuclear engineering domain. A prototype of a RODT was first brought out by Gong et al. at Nuclear Power Institute of China. The RODT contains a forward solver for online real-time simulation and an inverse problem solver for parameter identification and state estimation. To further improve the efficiency and accuracy of RODT and promote the practical deployment of RODT (i) we first propose an advanced differential evolution algorithm to upgrade the inverse solver; (ii) then we bring out a systematical uncertainty quantification of RODT considering assimilation noisy observations. The accuracy and validity of the proposed RODT are tested along one cycle operating stage of HPR1000, at various operating temperatures, control rod steps, general power level and the inlet temperature of a practical nuclear reactor core. Numerous numerical results confirm its potential for practical engineering applications for on-line parameter identification and state estimation.}
}
@article{ABHIRAMAN2023274,
title = {Fault detection for vaccine refrigeration via convolutional neural networks trained on simulated datasets},
journal = {International Journal of Refrigeration},
volume = {149},
pages = {274-285},
year = {2023},
issn = {0140-7007},
doi = {https://doi.org/10.1016/j.ijrefrig.2022.12.019},
url = {https://www.sciencedirect.com/science/article/pii/S0140700722004790},
author = {Bhaskar Abhiraman and Riley Fotis and Leo Eskin and Harvey Rubin},
keywords = {Digital twin, Modeling, Machine learning, Fault detection, Cold chain, Synthetic data, Jumeau numérique, Modélisation, Apprentissage automatique, Détection des défaillances, Chaîne du froid, Données synthétiques},
abstract = {In low-and middle-income countries, the cold chain that supports vaccine storage and distribution is vulnerable due to insufficient infrastructure and interoperable data. To bolster these networks, we developed a convolutional neural network-based fault detection method for vaccine refrigerators using datasets synthetically generated by thermodynamic modeling. We demonstrate that these thermodynamic models can be calibrated to real cooling systems in order to identify system-specific faults under a diverse range of operating conditions. If implemented on a large scale, this portable, flexible approach has the potential to increase the fidelity and lower the cost of vaccine distribution in remote communities.}
}
@article{MANOCHA2023110138,
title = {Digital Twin-assisted Blockchain-inspired irregular event analysis for eldercare},
journal = {Knowledge-Based Systems},
volume = {260},
pages = {110138},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.110138},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122012345},
author = {Ankush Manocha and Yasir Afaq and Munish Bhatia},
keywords = {Digital Twin, Irregular event determination, Smart healthcare, Internet of Things, Eldercare},
abstract = {Since the development of smart healthcare services, different solutions have been developed in the field of healthcare to increase the life expectancy of the patient by reducing the cost of healthcare. Digital Twin (DT) is considered one of the most promising technologies and a game changer in the field of healthcare. DT is generating a virtual imitation of a physical object that mimics the status of an event by changing the information in real time. In this article, a smart context-aware physical activity monitoring framework is developed by combining different advanced techniques such as IoT, DT, FoT, CoT, and Blockchain to maintain the sensitiveness of the healthcare domain. In the proposed study, the physical movements of an elder are analyzed by utilizing the sequential data processing capability of deep learning to detect irregular physical events. In addition, the proposed framework can keep the data of an individual secured by applying progressed security highlights of blockchain. The proposed solution effectively analyzed an irregular event of an individual with considerable accuracy in real time. The calculated outcomes have shown the effectiveness of DT with smart healthcare solutions that would help to develop effective medical services by bringing patients and medical care experts together. Furthermore, the performance of the proposed solution is measured with respect to irregular event recognition, model training and testing, rate of latency, and data processing cost. In this manner, a case study defines the effectiveness of the proposed methodology in the smart healthcare industry.}
}
@article{JASSIM2023109908,
title = {Forecasting domestic waste generation during successive COVID-19 lockdowns by Bidirectional LSTM super learner neural network},
journal = {Applied Soft Computing},
volume = {133},
pages = {109908},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109908},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622009577},
author = {Majeed S. Jassim and Gulnur Coskuner and Nahid Sultana and S.M. Zakir Hossain},
keywords = {Solid waste, ARIMA, BiLSTM, Machine learning, Predictive modeling},
abstract = {Accurate prediction of domestic waste generation is a challenging task for municipalities to implement sustainable waste management strategies. In the present study, domestic waste generation in the Kingdom of Bahrain, representing a Small Island Developing State (SIDS) case study, has been investigated during successive COVID-19 lockdowns due to the pandemic in 2020. Temporal trends of daily domestic waste generation between 2019 and 2020 and their statistical analyses exhibited remarkable variations highlighting the impact of consecutive COVID-19 lockdowns on domestic waste generation. Machine learning has great potential for predicting solid waste generation rates, but only a few studies utilized deep learning approaches. The state-of-the-art Bidirectional Long Short-Term Memory (BiLSTM) network model as a deep learning method is applied to forecast daily domestic waste data in 2020. Bayesian optimization algorithm (BOA) was hybridized with BiLSTM to generate a super learner approach. The performance of the BOA-BiLSTM super learner model was further compared with the statistical ARIMA model. Performance indicators of the developed models using ARIMA and BiLSTM showed that the latter yielded superior performance for short-term forecasts of domestic waste generation. The MAE, RMSE, MAPE, and R2 were 47.38, 60.73, 256.43, and 0.46, respectively, for the ARIMA model, compared to 3.67, 12.57, 0.24, and 0.96, respectively, for the BiLSTM model. Additionally, the relative errors for the BiLSTM model were lower than those of the ARIMA model. This study highlights that the BiLSTM can be a reliable forecasting tool for solid waste management policymakers during public health emergencies.}
}
@article{SHEN2023142,
title = {UniSKGRep: A unified representation learning framework of social network and knowledge graph},
journal = {Neural Networks},
volume = {158},
pages = {142-153},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004518},
author = {Yinghan Shen and Xuhui Jiang and Zijian Li and Yuanzhuo Wang and Chengjin Xu and Huawei Shen and Xueqi Cheng},
keywords = {Social knowledge graph, Graph representation learning, Knowledge graph, Social network},
abstract = {The human-oriented applications aim to exploit behaviors of people, which impose challenges on user modeling of integrating social network (SN) with knowledge graph (KG), and jointly analyzing two types of graph data. However, existing graph representation learning methods merely represent one of two graphs alone, and hence are unable to comprehensively consider features of both SN and KG with profiling the correlation between them, resulting in unsatisfied performance in downstream tasks. Considering the diverse gap of features and the difficulty of associating of the two graph data, we introduce a Unified Social Knowledge Graph Representation learning framework (UniSKGRep), with the goal to leverage the multi-view information inherent in the SN and KG for improving the downstream tasks of user modeling. To the best of our knowledge, we are the first to present a unified representation learning framework for SN and KG. Concretely, the SN and KG are organized as the Social Knowledge Graph (SKG), a unified representation of SN and KG. For the representation learning of SKG, first, two separate encoders in the Intra-graph model capture both the social-view and knowledge-view in two embedding spaces, respectively. Then the Inter-graph model is learned to associate the two separate spaces via bridging the semantics of overlapping node pairs. In addition, the overlapping node enhancement module is designed to effectively align two spaces with the consideration of a relatively small number of overlapping nodes. The two spaces are gradually unified by continuously iterating the joint training procedure. Extensive experiments on two real-world SKG datasets have proved the effectiveness of UniSKGRep in yielding general and substantial performance improvement compared with the strong baselines in various downstream tasks.}
}
@article{QIAO202345,
title = {A blockchain-based decentralized collaborative learning model for reliable energy digital twins},
journal = {Internet of Things and Cyber-Physical Systems},
volume = {3},
pages = {45-51},
year = {2023},
issn = {2667-3452},
doi = {https://doi.org/10.1016/j.iotcps.2023.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S2667345223000147},
author = {Liang Qiao and Zhihan Lv},
keywords = {Blockchain, Federated learning, Collaborative learning, Digital twins},
abstract = {This paper proposes a blockchain-based decentralized collaborative learning method for the Industrial Internet environment to solve the trust and security issues in Federated Learning. Deploy a decentralized network for collaborative learning based on the alliance chain, design a block data structure suitable for asynchronous learning, and model three stages of computing event triggering, computing task distribution, and computing result integration for cross-domain device collaborative learning. List the critical steps for network deployment, including inspection, tearing down old networks, creating organizational encryption material, creating channels, and deploying chaincode. It also introduces the development of crucial chaincode such as initialization, creation, query, and modification. Finally, the correlation between the number of data pieces of the network, the number of communications, and the time of communications are analyzed through experiments. This paper also proposes a decentralized asynchronous collaborative learning algorithm, develops chaincode middleware between the blockchain network and Artificial Intelligence training, and conducts experimental analysis on the industrial steam volume prediction data set in thermal power generation. The performance on the data set, and the experimental results prove that the asynchronous collaborative learning algorithm proposed in this paper can achieve a good convergence effect. It is also compared with the single-machine single-card regression prediction algorithm, proving that the proposed model has better generalization.}
}
@article{CHABANET202310384,
title = {An object-oriented architecture to couple simulators and their machine learning surrogates models in the context of digital shadows},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {10384-10389},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.1051},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323014532},
author = {Sylvain Chabanet and Emmanuel Zimmermann and Philippe Thomas and Hind Bril El-Haouzi},
keywords = {active learning, surrogate models, digital twins, artificial intelligence, sawmill simulation},
abstract = {This article studies a method to couple two digital models in the context of digital twins. The first model is a simulation model which is supposed to be very accurate but computationally intensive. The second is a fast but approximate machine-learning model of the simulation. Both models serve, therefore, the same prediction task in an online environment but have different advantages and drawbacks. An object-oriented architecture is introduced to implement the proposed coupling strategy. Numerical experiment results on four datasets are also provided to evaluate the performances of the proposed strategy and compare it with a baseline. Three of these datasets originate from the University of California, Irvine machine learning repository. The last one originates from the Canadian forest product industry and contains the outputs of sawing simulation for real wood logs. These experiments demonstrate that the proposed method allows to consistently reduce the average error of the couple predictions.}
}
@article{LI2023102471,
title = {An AR-assisted Deep Reinforcement Learning-based approach towards mutual-cognitive safe human-robot interaction},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {80},
pages = {102471},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2022.102471},
url = {https://www.sciencedirect.com/science/article/pii/S0736584522001533},
author = {Chengxi Li and Pai Zheng and Yue Yin and Yat Ming Pang and Shengzeng Huo},
keywords = {Smart manufacturing, Human robot interaction, Augmented reality, Deep reinforcement learning, Manufacturing safety},
abstract = {With the emergence of Industry 5.0, the human-centric manufacturing paradigm requires manufacturing equipment (robots, etc.) interactively assist human workers to deal with dynamic and complex production tasks. To achieve symbiotic human–robot interaction (HRI), the safety issue serves as a prerequisite foundation. Regarding the growing individualized demand of manufacturing tasks, the conventional rule-based safe HRI measures could not well address the safety requirements due to inflexibility and lacking synergy. To fill the gap, this work proposes a mutual-cognitive safe HRI approach including worker visual augmentation, robot velocity control, Digital Twin-enabled motion preview and collision detection, and Deep Reinforcement Learning-based robot collision avoidance motion planning in the Augmented Reality-assisted manner. Finally, the feasibility of the system design and the performance of the proposed approach are validated by establishing and executing the prototype HRI system in a practical scene.}
}
@article{YE2022112886,
title = {Research on acoustic reconstruction methods of the hull vibration based on the limited vibration monitor data},
journal = {Ocean Engineering},
volume = {266},
pages = {112886},
year = {2022},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2022.112886},
url = {https://www.sciencedirect.com/science/article/pii/S0029801822021692},
author = {Linchang Ye and Jianping Shen and Zongpeng Tong and Yun Liu},
keywords = {Hull vibration reconstruction, Limited monitor points, P-GRU Neutral network, Acoustic experiment, Multi-parameter comprehensive method},
abstract = {The prediction of hull vibration response is the basis for the quantitative control of cabin noise and underwater radiated noise, which has an important engineering value to obtain vibration characteristics accurately. In this paper, a new method is proposed to reconstruct hull vibration by some monitoring data in low frequencies. The hull vibration response is reconstructed by the monitoring data and the transfer function, and the ill-posed problem of inversion for the transfer function matrix is solved by the total least-squares regularization. A P-GRU (Peak-based Gated Recurrent Unit) neural network correction model is proposed to improve the prediction accuracy of vibration response. Taking a certain cabin structure as an example, some research such as the hull vibration data monitoring, the vibration transfer function calculation, vibration response reconstruction, and correction based on experimental data were carried out, and the simulation calculations and verification of experiment models were obtained. The multi-parameter comprehensive method is adopted to quantitatively evaluate the results between the simulation and the experiment. The results show that the acoustic reconstruction results are in good agreement with the experimental data. The overall level error is within 3 dB, the main peak value correlation coefficient is above 0.9, and the main peak difference is within 4 dB. The mechanism of the rapid and accurate prediction of the low-frequency vibration for the hull based on limited monitoring data is discussed by using a semi-physical simulation method combining the simulation calculation, vibration monitoring, and machine learning. The problem of phase asynchrony was solved, and strong support was provided for the construction of the ship's acoustic digital twin.}
}
@article{MILLO2023100156,
title = {Development of a neural network-based energy management system for a plug-in hybrid electric vehicle},
journal = {Transportation Engineering},
volume = {11},
pages = {100156},
year = {2023},
issn = {2666-691X},
doi = {https://doi.org/10.1016/j.treng.2022.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2666691X22000549},
author = {Federico Millo and Luciano Rolando and Luigi Tresca and Luca Pulvirenti},
keywords = {Hybrid electric vehicle, Energy management system, Artificial intelligence, LSTM deep learning},
abstract = {The high potential of Artificial Intelligence (AI) techniques for effectively solving complex parameterization tasks also makes them extremely attractive for the design of the Energy Management Systems (EMS) of Hybrid Electric Vehicles (HEVs). In this framework, this paper aims to design an EMS through the exploitation of deep learning techniques, which allow high non-linear relationships among the data characterizing the problem to be described. In particular, the deep learning model was designed employing two different Recurrent Neural Networks (RNNs). First, a previously developed digital twin of a state-of-the-art plug-in HEV was used to generate a wide portfolio of Real Driving Emissions (RDE) compliant vehicle missions and traffic scenarios. Then, the AI models were trained off-line to achieve CO2 emissions minimization providing the optimal solutions given by a global optimization control algorithm, namely Dynamic Programming (DP). The proposed methodology has been tested on a virtual test rig and it has been proven capable of achieving significant improvements in terms of fuel economy for both charge-sustaining and charge-depleting strategies, with reductions of about 4% and 5% respectively if compared to the baseline Rule-Based (RB) strategy.}
}
@article{POLLOCK2023102761,
title = {Quality assurance of uncured polymer matrix prepregs through the application of non-destructive methods},
journal = {NDT & E International},
volume = {133},
pages = {102761},
year = {2023},
issn = {0963-8695},
doi = {https://doi.org/10.1016/j.ndteint.2022.102761},
url = {https://www.sciencedirect.com/science/article/pii/S0963869522001608},
author = {Luke Pollock and Sean O'Byrne and Graham Wild},
keywords = {Composites, Non-destructive testing, Non-destructive evaluation, Prepreg, Uncured},
abstract = {The Airbus A350 is 53% composite, primarily Hexcel prepreg, making uncured polymer matrix prepregs a key material in aerospace applications. Non-Destructive Testing and Evaluation (NDT&E) of prepregs is essential for Quality Assurance (QA) purposes during manufacturing. Following an introduction to fibre reinforced polymers, this study reports current and evolving technologies such as automated tape laying, automated fibre placement, and out-of-autoclave prepregs. Sources of variations in quality of prepregs are identified to highlight the need to ensure their quality as structural materials. The technologies that may be employed to ensure the quality of prepreg materials is broken into the three main life cycle stages prior to curing: manufacturing, storage, and lay-up. These stages are further sub-classified dependent upon the methodologies and technologies applied for QA. A final discussion is given regarding the future trends of NDT&E QA for prepreg materials including the potential use of digital twin and machine learning technologies for future aerospace systems.}
}