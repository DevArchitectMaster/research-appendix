@article{ZHANG2021107659,
title = {Adversarial co-distillation learning for image recognition},
journal = {Pattern Recognition},
volume = {111},
pages = {107659},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107659},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320304623},
author = {Haoran Zhang and Zhenzhen Hu and Wei Qin and Mingliang Xu and Meng Wang},
keywords = {Knowledge distillation, Data augmentation, Generative adversarial nets, Divergent examples, Image classification},
abstract = {Knowledge distillation is an effective way to transfer the knowledge from a pre-trained teacher model to a student model. Co-distillation, as an online variant of distillation, further accelerates the training process and paves a new way to explore the “dark knowledge” by training n models in parallel. In this paper, we explore the “divergent examples”, which can make the classifiers have different predictions and thus induce the “dark knowledge”, and we propose a novel approach named Adversarial Co-distillation Networks (ACNs) to enhance the “dark knowledge” by generating extra divergent examples. Note that we do not involve any extra dataset, and we only utilize the standard training set to train the entire framework. ACNs are end-to-end frameworks composed of two parts: an adversarial phase consisting of Generative Adversarial Networks (GANs) to generate the divergent examples and a co-distillation phase consisting of multiple classifiers to learn the divergent examples. These two phases are learned in an iterative and adversarial way. To guarantee the quality of the divergent examples and the stability of ACNs, we further design “Weakly Residual Connection” module and “Restricted Adversarial Search” module to assist in the training process. Extensive experiments with various deep architectures on different datasets well demonstrate the effectiveness of our approach.}
}
@article{EDER2020107075,
title = {FASTIGUE: A computationally efficient approach for simulating discrete fatigue crack growth in large-scale structures},
journal = {Engineering Fracture Mechanics},
volume = {233},
pages = {107075},
year = {2020},
issn = {0013-7944},
doi = {https://doi.org/10.1016/j.engfracmech.2020.107075},
url = {https://www.sciencedirect.com/science/article/pii/S0013794419315565},
author = {Martin Alexander Eder and Xiao Chen},
keywords = {Digital twin, Fatigue crack growth, Large-scale structures, Computational efficiency, Stress intensity factor},
abstract = {The renaissance of digital twin technology heralded by recent advancements in machine learning raises the demand for structural analysis tools for real time predictions of the structural performance and ultimately the remaining lifetime. This paper proposes a novel approach – FASTIGUE - for computationally super-efficient discrete fatigue crack growth analysis of large structures particularly for bondlines with high aspect ratios. The computational speed is considerably increased by outsourcing the finite element analysis into a pre-processing step in which the numerical model is solved for a comparatively small number of crack stages; providing the Stress Intensity Factors (SIFs) for a set of auxiliary crack tip location permutations. 3D surface fitting of the auxiliary data provides the SIF ranges as continuous functions of the crack lengths. The fatigue crack growth simulation is performed independently from finite element analysis by utilising the SIF-functions within an explicit growth prediction scheme. The method is applied to a trailing edge crack in a 14.3 m wind turbine blade model and further validated against an analytical solution. It is demonstrated that the computation speed outperforms conventional fatigue analysis approaches relying on update-and-rerun schemes.}
}
@article{VALCKENAERS2020103226,
title = {Perspective on holonic manufacturing systems: PROSA becomes ARTI},
journal = {Computers in Industry},
volume = {120},
pages = {103226},
year = {2020},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2020.103226},
url = {https://www.sciencedirect.com/science/article/pii/S0166361520302530},
author = {Paul Valckenaers},
keywords = {Holonic manufacturing systems, Manufacturing execution systems, Design for the unexpected, Obedient digital twins, PROSA, ARTI, Sciences of the artificial, Bounded rationality, Complex-adaptive systems, Autocatalytic sets},
abstract = {Looking back at 30 years of research into holonic manufacturing systems, these explorations made a lasting scientific contribution to the overall architecture of intelligent manufacturing systems. Most notably, holonic architectures are defined in terms of their world-of-interest (Van Brussel et al., 1998). They do not have an information layer, a communication layer, etc. Instead, they have components that relate to real-world assets (e.g. machine tools) and activities (e.g. assembly). And, they mirror and track the structure of their world-of-interest, which allows them to scale and adapt accordingly. This research has wandered around, at times learning from its mistakes, and progressively carved out an invariant structure while it translated and applied scientific insights from complex-adaptive systems theory (e.g. autocatalytic sets) and from bounded rationality (e.g. holons). This paper presents and discusses the outcome of these research efforts. At the top level, the holonic structure distinguishes intelligent beings (or digital twins) from intelligent agents. These digital twins inherit the consistency from reality, which they mirror. They are intelligent beings when they reflect what exists in the world without imposing artificial limitations in this reality. Consequently, a conflict with a digital twin is a conflict with reality. In contrast, intelligent agents typically transform NP-hard challenges into computations with low-polynomial complexity. Unavoidably, this involves arbitrariness (e.g. don’t care choices). Likewise, relying on case-specific properties, to ensure an outcome in polynomial time, usually renders the validity of an agent’s choices both short-lived and situation-dependent. Here, intelligent agents create conflicts by imposing limitations of their own making in their world-of-interest. Real-world smart systems are aggregates comprising both intelligent beings and intelligent agents. They are performers. Inside these performers, digital twins may constitute the foundations, supporting walls, support beams and pillars because these intelligent beings are protected by their real-world counterpart. Further refining the top-level of this architecture, a holonic structure enables these digital twins to shadow their real-world counterpart whenever it changes, adapts and evolves. In contrast, the artificial limitations, imposed by the intelligent agents, cannot be allowed to build up inertia, which would hamper the undoing of arbitrary or case-specific limitations. To this end, performers explicitly manage the rights over their assets. Revoking such rights from a limitation-imposing agent will free the assets. This will be at the cost of reduced services from the agent. When other service providers rely on this agent, their services may be affected as well; that’s how the inertia builds up and how harmful legacy is created. Thus, the services of digital twins are to be preferred over the services of an intelligent agent by developers of holonic manufacturing systems. Finally, digital twins corresponding to the decision making in the world-of-interest (a non-physical asset) allow to mirror the world-of-interest in a predictive mode (in addition to track and trace). It allows to generate short-term forecasts while preserving the benefits of intelligent beings. These twins are the intentions of the decision-making intelligent agents. Evidently, when intentions change, the forecasts needs to be regenerated (i.e. tracking the corresponding reality by the twin). This advanced feature can be deployed in a number of configurations (cf. annex).}
}
@article{WEI2021100703,
title = {Mechanistic models for additive manufacturing of metallic components},
journal = {Progress in Materials Science},
volume = {116},
pages = {100703},
year = {2021},
issn = {0079-6425},
doi = {https://doi.org/10.1016/j.pmatsci.2020.100703},
url = {https://www.sciencedirect.com/science/article/pii/S0079642520300670},
author = {H.L. Wei and T. Mukherjee and W. Zhang and J.S. Zuback and G.L. Knapp and A. De and T. DebRoy},
keywords = {Additive manufacturing, 3D printing, Modeling, Heat transfer and fluid flow, Microstructure, Defects},
abstract = {Additive manufacturing (AM), also known as 3D printing, is gaining wide acceptance in diverse industries for the manufacturing of metallic components. The microstructure and properties of the components vary widely depending on printing process and process parameters, and prediction of causative variables that affect structure, properties and defects is helpful for their control. Since models are most useful when they can correctly predict experimental observations, we focus on the available mechanistic models of AM that have been adequately validated. Specifically, the applications of transport phenomena models in the studies of solidification, residual stresses, distortion, formation of defects and the evolution of microstructure and properties are critically reviewed. The functionality of AM models in understanding of the printability of commonly used AM alloys and the fabrication of functionally graded alloys are also assessed. Opportunities for future research are identified considering the gaps in knowledge in modeling. The uniqueness of this review includes substantive discussions of the rapid certification of the AM components aided by scale models, bidirectional models, cloud based big data, machine learning and digital twins of AM hardware.}
}
@article{KEAVENEY20211674,
title = {Development and Implementation of a Digital Manufacturing Demonstrator for Engineering Education},
journal = {Procedia CIRP},
volume = {104},
pages = {1674-1679},
year = {2021},
note = {54th CIRP CMS 2021 - Towards Digitalized Manufacturing 4.0},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.11.282},
url = {https://www.sciencedirect.com/science/article/pii/S221282712101180X},
author = {Shane Keaveney and Lydia Athanasopoulou and Vasilis Siatras and Panagiotis Stavropoulos and Dimitris Mourtzis and Denis P. Dowling},
keywords = {IoT, Augment Reliaty, 3D printing, Engineering education},
abstract = {The fourth industrial revolution (Industry 4.0) offers enhanced processing efficiencies and reduced downtime, however there is a lack of manufacturing training equipment for those seeking practical training in the key underpinning digital technologies. This paper reports on the development of a digital manufacturing training demonstrator, called the PERFORM turbine demonstrator, which incorporates four aspects of Industry 4.0, that of the Internet of Things (IoT), Augmented Reality (AR), the digital twin and additive manufacturing (3D printing). The program involves the printing of a polymer turbine and its testing using a turbine demonstrator system. This incorporates the use of an Arduino microcontroller, and sensors to monitor the systems variable pump speed, turbine speed, temperature, and humidity. A cloud-based platform allows for data logging and passing to the AR application, visualization, and system control. The design and development of the system is presented, alongside the results of pilot training programme, which involved undergraduate engineering students and industry trainees, on the practical application of Industry 4.0. This paper demonstrated the effectiveness of the PERFORM demonstrator in successfully integrating different digital technologies in the same system.}
}
@article{WANG202116,
title = {A digital twin-based big data virtual and real fusion learning reference framework supported by industrial internet towards smart manufacturing},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {16-32},
year = {2021},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301990},
author = {Pei Wang and Ming Luo},
keywords = {Virtual and real fusion learning, Big data learning and analysis models, Digital twin, Industrial internet, Smart manufacturing},
abstract = {Digital twin takes Industrial Internet as a carrier deeply coordinating and integrating virtual spaces with physical spaces, which effectively promotes smart factory development. Digital twin-based big data learning and analysis (BDLA) deepens virtual and real fusion, interaction and closed-loop iterative optimization in smart factories. This paper proposes a digital twin-based big data virtual and real fusion (DT-BDVRL) reference framework supported by Industrial Internet towards smart manufacturing. The reference framework is synthetically designed from three perspectives. The first one is an overall framework of DT-BDVRL supported by Industrial Internet. The second one is the establishment method and flow of BDLA models based on digital twin. The final one is digital thread of DT-BDVRL in virtual and real fusion analysis, iteration and closed-loop feedback in product full life cycle processes. For different virtual scenes, iterative optimization and verification methods and processes of BDLA models in virtual spaces are established. Moreover, the BDLA results can drive digital twin running in virtual spaces. By this, the BDLA results can be validated iteratively multiple times in virtual spaces. At same time, the BDLA results that run in virtual spaces are synchronized and executed in physical spaces through Industrial Internet platforms, effectively improving the physical execution effect of BDLA models. Finally, the above contents were applied and verified in the actual production case study of power switchgear equipment.}
}
@article{HU20201,
title = {Petri-net-based dynamic scheduling of flexible manufacturing system via deep reinforcement learning with graph convolutional network},
journal = {Journal of Manufacturing Systems},
volume = {55},
pages = {1-14},
year = {2020},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520300145},
author = {Liang Hu and Zhenyu Liu and Weifei Hu and Yueyang Wang and Jianrong Tan and Fei Wu},
keywords = {Dynamic scheduling, Petri nets, Deep reinforcement learning, Graph convolutional networks, Digital twin},
abstract = {To benefit from the accurate simulation and high-throughput data contributed by advanced digital twin technologies in modern smart plants, the deep reinforcement learning (DRL) method is an appropriate choice to generate a self-optimizing scheduling policy. This study employs the deep Q-network (DQN), which is a successful DRL method, to solve the dynamic scheduling problem of flexible manufacturing systems (FMSs) involving shared resources, route flexibility, and stochastic arrivals of raw products. To model the system in consideration of both manufacturing efficiency and deadlock avoidance, we use a class of Petri nets combining timed-place Petri nets and a system of simple sequential processes with resources (S3PR), which is named as the timed S3PR. The dynamic scheduling problem of the timed S3PR is defined as a Markov decision process (MDP) that can be solved by the DQN. For constructing deep neural networks to approximate the DQN action-value function that maps the timed S3PR states to scheduling rewards, we innovatively employ a graph convolutional network (GCN) as the timed S3PR state approximator by proposing a novel graph convolution layer called a Petri-net convolution (PNC) layer. The PNC layer uses the input and output matrices of the timed S3PR to compute the propagation of features from places to transitions and from transitions to places, thereby reducing the number of parameters to be trained and ensuring robust convergence of the learning process. Experimental results verify that the proposed DQN with a PNC network can provide better solutions for dynamic scheduling problems in terms of manufacturing performance, computational efficiency, and adaptability compared with heuristic methods and a DQN with basic multilayer perceptrons.}
}
@article{BOOYSE2020106612,
title = {Deep digital twins for detection, diagnostics and prognostics},
journal = {Mechanical Systems and Signal Processing},
volume = {140},
pages = {106612},
year = {2020},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2019.106612},
url = {https://www.sciencedirect.com/science/article/pii/S0888327019308337},
author = {Wihan Booyse and Daniel N. Wilke and Stephan Heyns},
keywords = {Artificial intelligence, Deep learning, System health management, Predictive maintenance, Deep generative models, Digital twins},
abstract = {A generic framework for prognostics and health monitoring (PHM) which is rapidly deployable to heterogeneous fleets of assets would allow for the automation of predictive maintenance scheduling directly from operational data. Deep learning based PHM implementations provide part of the solution, but their main benefits are lost when predictions still rely on historical failure data and case-by-case feature engineering. We propose a solution to these challenges in the form of a Deep Digital Twin (DDT). The DDT is constructed from deep generative models which learn the distribution of healthy data directly from operational data at the beginning of an asset’s life-cycle. As the DDT learns the distribution of healthy data it does not rely on historical failure data in order to produce an estimation of asset health. This article presents an overview of the DDT framework and investigates its performance on a number of datasets. Based on these investigations, it is demonstrated that the DDT is able to detect incipient faults, track asset degradation and differentiate between failure modes in both stationary and non-stationary operating conditions when trained on only healthy operating data.}
}
@article{GAO2021154,
title = {Residual error based knowledge distillation},
journal = {Neurocomputing},
volume = {433},
pages = {154-161},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.10.113},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220318117},
author = {Mengya Gao and Yujun Wang and Liang Wan},
keywords = {Model compression, Knowledge distillation, Residual learning},
abstract = {Knowledge distillation (KD) is one of the most popular ways for model compression. The key idea is to transfer the knowledge from a deep teacher model (T) to a shallower student (S). However, existing methods suffer from performance degradation due to the substantial gap between the learning capacities of S and T. To remedy this problem, this paper proposes Residual error based Knowledge Distillation (RKD), which further distills the knowledge by introducing an assistant model(A). Specifically, S is trained to mimic the feature maps of T, and A aids this process by learning the residual error between them. In this way, S and A complement with each other to get better knowledge from T. Furthermore, we devise an effective method to derive S and A from a given model without increasing the total computational cost. Extensive experiments show that our approach achieves appealing results on popular classification datasets, CIFAR-100 and ImageNet, surpassing state-of-the-art methods and keep strong robustness to adversarial samples.}
}
@article{RITTO2021107614,
title = {Digital twin, physics-based model, and machine learning applied to damage detection in structures},
journal = {Mechanical Systems and Signal Processing},
volume = {155},
pages = {107614},
year = {2021},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2021.107614},
url = {https://www.sciencedirect.com/science/article/pii/S0888327021000091},
author = {T.G. Ritto and F.A. Rochinha},
keywords = {Digital twin, Physical based model, Machine learning classifier, Damage identification, Structural dynamics},
abstract = {This work is interested in digital twins, and the development of a simplified framework for them, in the context of dynamical systems. Digital twin is an ingenious concept that helps on organizing different areas of expertise aiming at supporting engineering decisions related to a specific asset; it articulates computational models, sensors, learning, real time analysis, diagnosis, prognosis, and so on. In this framework, and to leverage its capacity, we explore the integration of physics-based models with machine learning. A digital twin is constructed for a damaged structure, where a discrete physics-based computational model is employed to investigate several damage scenarios. A machine learning classifier, that serves as the digital twin, is trained with data taken from a stochastic computational model. This strategy allows the use of an interpretable model (physics-based) to build a fast digital twin (machine learning) that will be connected to the physical twin to support real time engineering decisions. Different classifiers (quadratic discriminant, support vector machines, etc) are tested, and different model parameters (number of sensors, level of noise, damage intensity, uncertainty, operational parameters, etc) are considered to construct datasets for the training. The accuracy of the digital twin depends on the scenario analyzed. Through the chosen application, we are able to emphasize each step of a digital twin construction, including the possibility of integrating physics-based models with machine learning. The different scenarios explored yield conclusions that might be helpful for a large range of applications.}
}
@article{PAPACHARALAMPOPOULOS2021490,
title = {Incorporating process physics phenomena in formation of digital twins: laser welding case},
journal = {Procedia CIRP},
volume = {99},
pages = {490-495},
year = {2021},
note = {14th CIRP Conference on Intelligent Computation in Manufacturing Engineering, 15-17 July 2020},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.03.069},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121003528},
author = {Alexios Papacharalampopoulos and Kyriakos Sabatakakis and Panos Stavropoulos},
keywords = {Laser cutting, digital twin, physics, modelling, machine learning},
abstract = {Manufacturing process design and implementation can benefit from the adaptation of Digital Twins. However, the explanatory power coming by physics models presents a strong contradiction with the demand of rapid decision making required for their control and optimization. In the context of laser welding applications, this work investigates three physics-based modelling methods (namely direct Stefan method, apparent heat capacity method and Enthalpy method) along with sensorial data towards the formation of a knowledge database in order to aid the development of a Digital Twin. Also, the methodology for creating such a Digital Twin is discussed incorporating the best result(s) and method(s). This Digital Twin is proved useful in optimizing the process itself but also monitoring, through selection of sensors.}
}
@article{ZABALA2020109920,
title = {Virtual testbed for model predictive control development in district cooling systems},
journal = {Renewable and Sustainable Energy Reviews},
volume = {129},
pages = {109920},
year = {2020},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2020.109920},
url = {https://www.sciencedirect.com/science/article/pii/S1364032120302112},
author = {Laura Zabala and Jesus Febres and Raymond Sterling and Susana López and Marcus Keane},
keywords = {District cooling, MPC, Modelling, Modelica, Machine learning, Testbed},
abstract = {Recently, with increasing cooling demands, district cooling has assumed an important role as it is more efficient than stand-alone cooling systems. District cooling reduces the environmental impact and promotes the use of renewable sources. Earlier studies to optimise the production plants of district cooling systems were focused primarily on plants with compressor chillers and thermal energy storage devices. Although absorption chillers are crucial for integrating renewable sources into these systems, very few studies have considered them from the cooling perspective. In this regard, this paper presents the progress and results of the implementation of a virtual testbed based on a digital twin of a district cooling production plant with both compressor and absorption chillers. The aim of this study, carried out within the framework of INDIGO, a European Union-funded project, was (i) to develop a reliable model that can be used in a model predictive controller and (ii) to simulate the plant using this controller. The production plant components, which included absorption and compressor chillers, as well as cooling towers, were built using the equation-based Modelica programming language, and were calibrated using information from the manufacturer, together with real operation data. The remainder of the plant was modelled in Python. To integrate the Modelica models into the Python environment, a combination of machine learning techniques and state-space representation models was used. With these techniques, models with a high computational speed were obtained, which were suitable for real-time applications. These models were then used to build a model predictive control for the production plant to minimise the primary energy usage. The improvements in the control and the resultant energy savings achieved were compared with a baseline case working on a standard cascade control. Energy savings up to 50% were obtained in the simulation-based experiments.}
}
@article{ZOHDI2021113446,
title = {A digital twin framework for machine learning optimization of aerial fire fighting and pilot safety},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {373},
pages = {113446},
year = {2021},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2020.113446},
url = {https://www.sciencedirect.com/science/article/pii/S0045782520306319},
author = {T.I. Zohdi},
keywords = {Aerial fire-fighting, Fire retardants, Optimization, Machine-learning},
abstract = {The objective of this work is to model and simulate aerial drops of fire retardants in dangerous fire environments. Specifically, the work develops a computational framework for a model problem combining: •[1.] A meshless discrete element component that tracks the trajectory of released airborne materials from a controlled aircraft, ranging from retardant powders to encapsulated packets, subjected to prevailing wind velocities and fire-driven updrafts.•[2.] A Machine Learning Algorithm (MLA) to rapidly ascertain the optimal aircraft (unmanned or manned) dynamics to maximize the fire-retardant release effectiveness (released material usage and target impact). The framework is designed to enable Digital Twin type technologies, i.e. digital replicas that run in real time with the physical system. However, it is also designed to run at much faster rates, in order to enable MLA’s to optimize the planning, by running quickly on laptops and mobile systems. The overall guiding motivation is to provide a useful tool to enable rapid flight-path planning for aerial first-responders in real-time and to train pilots. Numerical examples are provided to illustrate the process.}
}
@article{VRABIC2021349,
title = {An intelligent agent-based architecture for resilient digital twins in manufacturing},
journal = {CIRP Annals},
volume = {70},
number = {1},
pages = {349-352},
year = {2021},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2021.04.049},
url = {https://www.sciencedirect.com/science/article/pii/S0007850621000731},
author = {Rok Vrabič and John Ahmet Erkoyuncu and Maryam Farsi and Dedy Ariansyah},
keywords = {Manufacturing system, Digital twin, Machine learning},
abstract = {Digital twins (DTs) offer the potential for improved understanding of current and future manufacturing processes. This can only be achieved by DTs consistently and accurately representing the real processes. However, the robustness and resilience of the DT itself remain an issue. Accordingly, this paper offers an approach to deal with uncertainty and disruptions, as the DT detects these effectively and self-adapts as needed to maintain representativeness. The paper proposes an intelligent agent-based architecture to improve the robustness (including accuracy of representativeness) and resilience (including timely update) of the DT. The approach is demonstrated on a case of cryogenic secondary manufacturing.}
}
@article{SCHROEDER2021737,
title = {Digital Twin connectivity topologies},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {737-742},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.086},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321008302},
author = {Greyce N. Schroeder and Charles Steinmetz and Ricardo N. Rodrigues and Achim Rettberg and Carlos E. Pereira},
keywords = {Digital Twin, Digitalization, Topology, Model},
abstract = {Digital Twin (DT) is one of the key concepts in the industry 4.0. Through the Internet of Things (IoT), it brings the ability of having a virtual representation of a real-world element which enables many possibilities such as saving and tracking its life-cycle, perform simulations, learning based on all this data and so on. However, it is still an ongoing concept that is continuously being evolved. Therefore, a well defined topology of how a DT can be build is still needed. In this context, this paper specifies six ways of how a DT can be build in different kind of applications. Examples of models for each proposed topology are given in AutomationML for better understanding of the proposal.}
}
@article{MOHANTY2021102032,
title = {A multi-modal approach towards mining social media data during natural disasters - A case study of Hurricane Irma},
journal = {International Journal of Disaster Risk Reduction},
volume = {54},
pages = {102032},
year = {2021},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2020.102032},
url = {https://www.sciencedirect.com/science/article/pii/S221242092031534X},
author = {Somya D. Mohanty and Brown Biggers and Saed Sayedahmed and Nastaran Pourebrahim and Evan B. Goldstein and Rick Bunch and Guangqing Chi and Fereidoon Sadri and Tom P. McCoy and Arthur Cosby},
keywords = {Data mining, Social media, Natural disaster, Machine learning},
abstract = {Streaming social media provides a real-time glimpse of extreme weather impacts. However, the volume of streaming data makes mining information a challenge for emergency managers, policy makers, and disciplinary scientists. Here we explore the effectiveness of data learned approaches to mine and filter information from streaming social media data from Hurricane Irma's landfall in Florida, USA. We use 54,383 Twitter messages (out of 784 K geolocated messages) from 16,598 users from Sept. 10–12, 2017 to develop 4 independent models to filter data for relevance: 1) a geospatial model based on forcing conditions at the place and time of each tweet, 2) an image classification model for tweets that include images, 3) a user model to predict the reliability of the tweeter, and 4) a text model to determine if the text is related to Hurricane Irma. All four models are independently tested, and can be combined to quickly filter and visualize tweets based on user-defined thresholds for each submodel. We envision that this type of filtering and visualization routine can be useful as a base model for data capture from noisy sources such as Twitter. The data can then be subsequently used by policy makers, environmental managers, emergency managers, and domain scientists interested in finding tweets with specific attributes to use during different stages of the disaster (e.g., preparedness, response, and recovery), or for detailed research.}
}
@article{WURSTER2021158,
title = {Towards planning and control in cognitive factories - A generic model including learning effects and knowledge transfer across system entities},
journal = {Procedia CIRP},
volume = {103},
pages = {158-163},
year = {2021},
note = {9th CIRP Global Web Conference – Sustainable, resilient, and agile manufacturing and service operations : Lessons from COVID-19},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.10.025},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121008660},
author = {Marco Wurster and Yannick Exner and Jan-Philipp Kaiser and Nicole Stricker and Gisela Lanza},
keywords = {Learning Effects, Cognitive Robots, Digital Twin, Hybrid Production Systems, Disassembly},
abstract = {Cognitive abilities allow robots to learn and reason from their environment. The gained knowledge can then be incorporated into the robot’s actions which in turn affect the environment. Therefore, a cognitive robot is no longer a static system that performs actions based on a pre-defined set of rules but a complex entity that dynamically adjusts over time. With this, challenges arise for production systems that need to observe and ideally anticipate the cognitive robot’s behavior. Often, digital twins are employed to test and optimize production control systems. This paper presents a generic approach to characterize, model and simulate learning processes and formalized knowledge in hybrid production systems assuming different station types with learning effects. Thereby, quantitative and qualitative learning processes are mapped including knowledge sharing and transfer across entities. A modular and parameterizable design enables the adjustment to different use cases. Eventually, the model is instantiated as a digital twin of a real production system for product disassembly employing cognitive-autonomous robots among human operators and rigidly automated machines. The model shows great potential to be integrated into test beds for planning and control systems of cognitive factories.}
}
@article{DAI2021107051,
title = {A tucker decomposition based knowledge distillation for intelligent edge applications},
journal = {Applied Soft Computing},
volume = {101},
pages = {107051},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.107051},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620309893},
author = {Cheng Dai and Xingang Liu and Zhuolin Li and Mu-Yen Chen},
keywords = {Knowledge distillation, Intelligent edge computing, Deep learning, Tensor decomposition},
abstract = {Knowledge distillation(KD) has been proven an effective method in intelligent edge computing and have achieved extensive study in recent deep learning research. However, when the teacher network is too stronger compared to the student network, the effect of knowledge distillation is not ideal. Aiming at resolving this problem, an improved method of knowledge distillation (TDKD) is proposed, which enables to transfer the complex mapping functions learned by cumbersome models to relatively simpler models. Firstly, the tucker-2 decomposition was performed on the convolutional layers of the original teacher model to reduce the capacity variance between the teacher network and student network. Then, the decomposed model will be used as a new teacher to participate in knowledge distillation for the student model. The experimental results show that the TDKD method can effectively solve the problem of poor distillation performance, which not only get better results if the KD method is effective, but also can reactivate the invalid KD method to some extents.}
}
@article{MERAGHNI20212555,
title = {A data-driven digital-twin prognostics method for proton exchange membrane fuel cell remaining useful life prediction},
journal = {International Journal of Hydrogen Energy},
volume = {46},
number = {2},
pages = {2555-2564},
year = {2021},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2020.10.108},
url = {https://www.sciencedirect.com/science/article/pii/S0360319920339252},
author = {Safa Meraghni and Labib Sadek Terrissa and Meiling Yue and Jian Ma and Samir Jemei and Noureddine Zerhouni},
keywords = {Deep learning, Digital twin, Prognostics, Proton exchange membrane fuel cell, Remaining useful life},
abstract = {Prognostics and health management of proton exchange membrane fuel cell (PEMFC) systems have driven increasing research attention in recent years as the durability of PEMFC stack remains as a technical barrier for its large-scale commercialization. To monitor the health state during PEMFC operation, digital twin (DT), as a smart manufacturing technique, is applied in this paper to establish an ensemble remaining useful life prediction system. A data-driven DT is constructed to integrate the physical knowledge of the system and a deep transfer learning model based on stacked denoising autoencoder is used to update the DT with online measurement. A case study with experimental PEMFC degradation data is presented where the proposed data-driven DT prognostics method has applied and reached a high prediction accuracy. Furthermore, the predicted results are proved to be less affected even with limited measurement data.}
}
@article{ROWE2020S52,
title = {Artificial Intelligence for Personalized Preventive Adolescent Healthcare},
journal = {Journal of Adolescent Health},
volume = {67},
number = {2, Supplement },
pages = {S52-S58},
year = {2020},
note = {Innovative Digital Technologies to Improve Adolescent and Young Adult Health},
issn = {1054-139X},
doi = {https://doi.org/10.1016/j.jadohealth.2020.02.021},
url = {https://www.sciencedirect.com/science/article/pii/S1054139X20300951},
author = {Jonathan P. Rowe and James C. Lester},
keywords = {Artificial intelligence, Prevention, Health information technology, Adaptive learning technologies, User modeling, Interactive narrative generation, Adolescents},
abstract = {Recent advances in artificial intelligence (AI) are creating new opportunities for personalizing technology-based health interventions to adolescents. This article provides a computer science perspective on how emerging AI technologies—intelligent learning environments, interactive narrative generation, user modeling, and adaptive coaching—can be utilized to model adolescent learning and engagement and deliver personalized support in adaptive health technologies. Many of these technologies have emerged from human-centered applications of AI in education, training, and entertainment. However, their application to improving healthcare, to date, has been comparatively limited. We illustrate the opportunities provided by AI-driven adaptive technologies for adolescent preventive healthcare by describing a vision of how future adolescent preventive health interventions might be delivered both inside and outside of the clinic. Key challenges posed by AI-driven health technologies are also presented, including issues of privacy, ethics, encoded bias, and integration into clinical workflows and adolescent lives. Examples of empirical findings about the effectiveness of AI technologies for user modeling and adaptive coaching are presented, which underscore their promise for application toward adolescent health. The article concludes with a brief discussion of future research directions for the field, which is well positioned to leverage AI to improve adolescent health and well-being.}
}
@article{ECHLIN2020100817,
title = {Serial sectioning in the SEM for three dimensional materials science},
journal = {Current Opinion in Solid State and Materials Science},
volume = {24},
number = {2},
pages = {100817},
year = {2020},
issn = {1359-0286},
doi = {https://doi.org/10.1016/j.cossms.2020.100817},
url = {https://www.sciencedirect.com/science/article/pii/S1359028620300152},
author = {McLean P. Echlin and Timothy L. Burnett and Andrew T. Polonsky and Tresa M. Pollock and Philip J. Withers},
keywords = {Serial sectioning, Materials science, Life sciences, Biology, Scanning electron microscopy},
abstract = {Here we explore the range of serial sectioning techniques that have evolved over the past decade, providing a comprehensive toolkit for capturing rich 3D microstructures, chemistries and crystallographic information, with sub-micron resolution at volumes that extend out to mm3 or even cm3. In each case we consider the challenges associated with their application, the volumes they can analyze, the damage to the surface they impart, and their suitability for different materials. In certain cases these warrant hybrid methods, motivating workflows that leverage multiple sectioning modes within the same instrument. Finally, we provide a perspective on their future development, including advances in data collection, segmentation, registration, data fusion, and correlative microscopy. Furthermore, the exploitation of 3D techniques for a better understanding of existing materials, and the design of new ones, is discussed through their use in multiscale modelling, digital twinning, material informatics and machine learning frameworks.}
}
@article{EHWERHEMUEPHA2021100030,
title = {A super learner ensemble of 14 statistical learning models for predicting COVID-19 severity among patients with cardiovascular conditions},
journal = {Intelligence-Based Medicine},
volume = {5},
pages = {100030},
year = {2021},
issn = {2666-5212},
doi = {https://doi.org/10.1016/j.ibmed.2021.100030},
url = {https://www.sciencedirect.com/science/article/pii/S2666521221000065},
author = {Louis Ehwerhemuepha and Sidy Danioko and Shiva Verma and Rachel Marano and William Feaster and Sharief Taraman and Tatiana Moreno and Jianwei Zheng and Ehsan Yaghmaei and Anthony Chang},
keywords = {Super learning, Ensemble learning, Cardiovascular conditions, COVID-19, COVID-19 severity, Predicting COVID-19 severity},
abstract = {Background
Cardiovascular and other circulatory system diseases have been implicated in the severity of COVID-19 in adults. This study provides a super learner ensemble of models for predicting COVID-19 severity among these patients.
Method
The COVID-19 Dataset of the Cerner Real-World Data was used for this study. Data on adult patients (18 years or older) with cardiovascular diseases between 2017 and 2019 were retrieved and a total of 13 of these conditions were identified. Among these patients, 33,042 admitted with positive diagnoses for COVID-19 between March 2020 and June 2020 (from 59 hospitals) were identified and selected for this study. A total of 14 statistical and machine learning models were developed and combined into a more powerful super learning model for predicting COVID-19 severity on admission to the hospital.
Result
LASSO regression, a full extreme gradient boosting model with tree depth of 2, and a full logistic regression model were the most predictive with cross-validated AUROCs of 0.7964, 0.7961, and 0.7958 respectively. The resulting super learner ensemble model had a cross validated AUROC of 0.8006 (range: 0.7814, 0.8163). The unbiased AUROC of the super learner model on an independent test set was 0.8057 (95% CI: 0.7954, 0.8159).
Conclusion
Highly predictive models can be built to predict COVID-19 severity of patients with cardiovascular and other circulatory conditions. Super learning ensembles will improve individual and classical ensemble models significantly.}
}
@article{LIANG2020103370,
title = {Teaching robots to perform quasi-repetitive construction tasks through human demonstration},
journal = {Automation in Construction},
volume = {120},
pages = {103370},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103370},
url = {https://www.sciencedirect.com/science/article/pii/S092658052030950X},
author = {Ci-Jyun Liang and Vineet R. Kamat and Carol C. Menassa},
keywords = {Robot learning from demonstration, Visual demonstration, Autoencoder, Reinforcement learning, Digital twin, Ceiling tile installation, Robot apprentice},
abstract = {Robots can assist workers in performing physically-demanding construction tasks, which are typically quasi-repetitive, wherein the geometry of the workspace is dissimilar despite similar tasks. As a result, robots must determine motion trajectories based on the encountered workspace geometry. Learning from Demonstration (LfD) methods have the potential to be used in teaching robots specific tasks through human demonstration, such that robots can then perform learned tasks under different conditions. In this paper, the LfD method is investigated to teach robots how to perform quasi-repetitive construction tasks. Considering ceiling tile installation as the experimental process, the tasks of maneuvering and positioning tiles in a ceiling grid are defined as the target knowledge to be learned. Using a set of human demonstration videos, the designed approach first translates the physical work context, e.g., the pose of the tile, to the target digital twin, i.e., the workspace as-perceived by the robot. The Reinforcement Learning method is then applied to generate the control policy for the robot to perform the subsequent tasks. The proposed method is evaluated in the Robot Operating System (ROS) Gazebo simulator using a KUKA mobile industrial robotic arm emulator and 60 different scenes as test cases. The results show a 78% success rate in installing ceiling tiles based on 3000 virtual and 85 real demonstration videos. The success rate tends to continually rise with an increase in the number of real demonstration videos, confirming the promise and applicability of the LfD method in teaching robot apprentices to perform quasi-repetitive tasks on construction sites.}
}
@article{ALGURI2021106338,
title = {Sim-to-Real: Employing ultrasonic guided wave digital surrogates and transfer learning for damage visualization},
journal = {Ultrasonics},
volume = {111},
pages = {106338},
year = {2021},
issn = {0041-624X},
doi = {https://doi.org/10.1016/j.ultras.2020.106338},
url = {https://www.sciencedirect.com/science/article/pii/S0041624X20302675},
author = {K. Supreet Alguri and Chen Ciang Chia and Joel B. Harley},
keywords = {Ultrasonic guided waves, Dictionary learning, Transfer learning, Digital twin, Baseline subtraction},
abstract = {Wavefield imaging is a powerful visualization tool in nondestructive evaluation for studying ultrasonic wave propagation and its interactions with damage. To isolate and study damage scattering, damage-free baseline data is often subtracted from a wavefield. This is often necessary because the damage wavefield can be orders of magnitude weaker than the incident waves. Yet, baselines are not always accessible. When the baselines are accessible, the experimental conditions for the baseline and test data must be extremely similar. Researchers have created several baseline-free approaches for isolating damage wavefields, but these often rely on specific experimental setups. In this paper, we discuss a flexible approach based on ultrasonic guided wave digital surrogates (i.e., numerical simulations of incident waves) and transfer learning. We demonstrate this approach with two setups. We first isolate reflections from a circular, 2 mm diameter half-thickness hole on a 10 × 10 cm steel plate. We then isolate 8 circular, half-thickness holes of various diameters from 1 mm to 40 mm on a 60 × 60 cm steel plate. The second plate has a non-square geometry and the data has multi-path reflections. With both data sets, we isolate damage reflections without explicit experimental baselines. We also briefly illustrate the comparison of our dictionary learning method with wavenumber filtering technique which is often used to enhance the defect wavefields.}
}
@article{JONES2021283,
title = {Towards integrated version control of virtual and physical artefacts in new product development: inspirations from software engineering and the digital twin paradigm},
journal = {Procedia CIRP},
volume = {100},
pages = {283-288},
year = {2021},
note = {31st CIRP Design Conference 2021 (CIRP Design 2021)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.05.121},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121005953},
author = {David Jones and Aydin Nassehi and Chris Snider and James Gopsill and Peter Rosso and Ric Real and Mark Goudswaard and Ben Hicks},
keywords = {Digital Twin, New Product Development, Engineering Design, Version Control},
abstract = {Modern version control strategies are highly capable at supporting the management of virtual artefacts. The process of developing a new product, however, is not limited to virtual artefacts. Today’s fast-paced industrial processes require a diverse range of both virtual and physical artefacts to explore, refine, and evaluate designs. These virtual and physical artefacts are interrelated, and the information they embody, the knowledge they generate, and the transfer of learning between are fundamental to the design history. Consequently, there is a requirement to capture and curate both virtual and physical artefacts, iterations thereof, and the interrelationships between. The Digital Twin paradigm couples physical and virtual artefacts throughout the product life-cycle, providing a means to capture an evolving design irrespective of the medium in which the designer is working. Recent literature has, however, raised questions about the concept of a Digital Twin early in the product life-cycle when the design in question is conceptual (a cognitive model) rather than physical or virtual. This paper reflects on the challenges of implementing Digital Twin-based version control in the early-stage of new product development, moving towards integrated version control of virtual, physical and cognitive models/artefacts. Firstly, by presenting an argument that current design practices capture cognitive models through stakeholder creation and evaluation of physical and virtual boundary objects, the ambiguity surrounding conceptual design and the Digital Twin is addressed. Secondly, the principles of the Digital Twin and current version control strategies are reviewed to determine how one can maintain digital/physical synchronicity as a design evolves. Finally, this paper reflects on the implementation of such an approach and the proposed future work.}
}
@article{AGAPAKI2020101121,
title = {CLOI-NET: Class segmentation of industrial facilities’ point cloud datasets},
journal = {Advanced Engineering Informatics},
volume = {45},
pages = {101121},
year = {2020},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101121},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620300902},
author = {Eva Agapaki and Ioannis Brilakis},
keywords = {Class segmentation, Industrial facilities, Point cloud processing, CLOI},
abstract = {Shape segmentation from point cloud data is a core step of the digital twinning process for industrial facilities. However, it is also a very labor intensive step, which counteracts the perceived value of the resulting model. The state-of-the-art method for automating cylinder detection can detect cylinders with 62% precision and 70% recall, while other shapes must then be segmented manually and shape segmentation is not achieved. This performance is promising, but it is far from drastically eliminating the manual labor cost. We argue that the use of class segmentation deep learning algorithms has the theoretical potential to perform better in terms of per point accuracy and less manual segmentation time needed. However, such algorithms could not be used so far due to the lack of a pre-trained dataset of laser scanned industrial shapes as well as the lack of appropriate geometric features in order to learn these shapes. In this paper, we tackle both problems in three steps. First, we parse the industrial point cloud through a novel class segmentation solution (CLOI-NET) that consists of an optimized PointNET++ based deep learning network and post-processing algorithms that enforce stronger contextual relationships per point. We then allow the user to choose the optimal manual annotation of a test facility by means of active learning to further improve the results. We achieve the first step by clustering points in meaningful spatial 3D windows based on their location. Then, we apply a class segmentation deep network, and output a probability distribution of all label categories per point and improve the predicted labels by enforcing post-processing rules. We finally optimize the results by finding the optimal amount of data to be used for training experiments. We validate our method on the largest richly annotated dataset of the most important to model industrial shapes (CLOI) and yield 82% average accuracy per point, 95.6% average AUC among all classes and estimated 70% labor hour savings in class segmentation. This proves that it is the first to automatically segment industrial point cloud shapes with no prior knowledge at commercially viable performance and is the foundation for efficient industrial shape modeling in cluttered point clouds.}
}
@article{HURKAMP20211,
title = {Simulation-based digital twin for the manufacturing of thermoplastic composites},
journal = {Procedia CIRP},
volume = {100},
pages = {1-6},
year = {2021},
note = {31st CIRP Design Conference 2021 (CIRP Design 2021)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121004583},
author = {André Hürkamp and Ralf Lorenz and Tim Ossowski and Bernd-Arno Behrens and Klaus Dröder},
keywords = {Thermoplastic Composites, Thermoforming, Finite Element Method, Reduced Order Modelling, Digital Twin},
abstract = {The bond strength between a thermoformed fibre reinforced thermoplastic sheet and an injected polymer is the limiting factor for the structural integrity of overmoulded thermoplastic composites. In this contribution, a simulation based digital twin of the thermoforming process is presented. From numerical parametric studies a reduced order model based on Proper Orthogonal Decomposition (POD) is developed. The combination with machine learning methods enables the real-time computation of arbitrary physical reliable temperature fields with sufficient accuracy to be used for design purposes and as inline quality gates.}
}
@article{GROEN2020102876,
title = {FlexMM: A standard method for material descriptions in FEM},
journal = {Advances in Engineering Software},
volume = {148},
pages = {102876},
year = {2020},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2020.102876},
url = {https://www.sciencedirect.com/science/article/pii/S0965997820300855},
author = {Manso Groen and Soheil Solhjoo and Ruud Voncken and Jan Post and Antonis. I. Vakis},
keywords = {FEM analysis, Digital twin, Material modeling, Multi stage modeling, User subroutines, Zero-defect manufacturing, Industry 4.0},
abstract = {This article discusses a number of key issues concerning simulation-based digital twins in the domain of multistage processes. Almost all production processes are multistage in nature, and so most digital twins involve multiple physical phenomena, process steps and different solvers for the simulations. Good interoperability between model solvers and processes are key to achieving a functional digital twin. Passing information between steps can be challenging, complex and time consuming, especially for material data, because the constitutive model interacts with the full modeling environment: material behavior is interdependent with the history of the process, the solver subroutines and the boundary conditions. This work proposes a flexible yet robust standardization approach, called FlexMM, for dealing with material data, constitutive models, measurement data or mathematical models to overcome part of the abovementioned complexity. The implementation of FlexMM consists of a general rule structure in which constitutive behavior is described, as well as its interaction with the subroutines used by the finite element solver. The definition of the constitutive model is stored in a separate file, in which the material behavior can be described in a user selected format, such as look-up tables, standard statistical models, machine learning or analytical expressions. After a calculation step, the new local material properties are mapped to a file to facilitate the next history-dependent step. In this way, the interaction between the different fabrication steps and processes can be incorporated. A material/process case study is presented to demonstrate the flexibility and robustness of FlexMM.}
}
@article{PITKAAHO2021540,
title = {Indoor positioning, artificial intelligence and digital twins for enhanced robotics safety},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {540-545},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.062},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321007849},
author = {Tomi Pitkäaho and Tero Kaarlela and Sakari Pieskä and Sami Sarlin},
keywords = {Robotics technology, Perception, sensing, Positioning systems, Machine learning, Intelligent interfaces},
abstract = {Flexible robotics safety solutions allowing the implementation of fenceless robot cells are becoming a reality nowadays. Safety approved sensors such as light curtains, safety scanners, and safety cameras have been deployed already successfully in various industrial robotic solutions. Still, as these safety systems are installed in fixed locations, monitoring predefined regions, the systems can be rigid and inflexible. This paper introduces a novel hybrid safety solution. The solution comprises safety-approved sensors, additional sensors, and artificial intelligence analysis. The system increases flexibility, especially in cases where collaborating humans and robots need monitoring in larger areas. Typically, in such environments, work objects are large and heavy, introducing additional challenges. In addition, the proposed system includes a digital twin implementation that allows a connection between the real and virtual worlds. Already virtual models and robot simulation have been used for designing safe robot applications. However, the efficient use of digital twins in safety planning and safety monitoring is still uncommon.}
}
@article{GOVINDSAMY2021192,
title = {Leak Detection at Anglo Platinum Converting Process Using Digital Twins},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {21},
pages = {192-197},
year = {2021},
note = {Control Conference Africa CCA 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.12.033},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321023727},
author = {D. Govindsamy and G.A. Georgalli and A. Hoosen},
keywords = {ACP, Fault Detection, Digital Twins, Machine Learning, Data Processing},
abstract = {Leaks on the high-pressure cooling system supporting the Convertor at the Anglo Converting Process (ACP) poses safety risks and requires plant downtime to repair. The leaks are difficult to detect, as the accuracy of available sensors are insufficient at the operating conditions of the system. Fault detection using digital twins have been employed successfully in the process industry. This paper discusses the construction of digital twins for the leak detection problem at ACP and focuses on the practical considerations of data preparation and modelling. This analytic has been implemented in the control room Human Machine Interface and a web enabled dashboard.}
}
@article{RAMAPURAM2020381,
title = {Lifelong generative modeling},
journal = {Neurocomputing},
volume = {404},
pages = {381-400},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.02.115},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220303623},
author = {Jason Ramapuram and Magda Gregorova and Alexandros Kalousis},
keywords = {Lifelong learning, Continual learning, Variational inference, Generative modeling},
abstract = {Lifelong learning is the problem of learning multiple consecutive tasks in a sequential manner, where knowledge gained from previous tasks is retained and used to aid future learning over the lifetime of the learner. It is essential towards the development of intelligent machines that can adapt to their surroundings. In this work we focus on a lifelong learning approach to unsupervised generative modeling, where we continuously incorporate newly observed distributions into a learned model. We do so through a student-teacher Variational Autoencoder architecture which allows us to learn and preserve all the distributions seen so far, without the need to retain the past data nor the past models. Through the introduction of a novel cross-model regularizer, inspired by a Bayesian update rule, the student model leverages the information learned by the teacher, which acts as a probabilistic knowledge store. The regularizer reduces the effect of catastrophic interference that appears when we learn over sequences of distributions. We validate our model’s performance on sequential variants of MNIST, FashionMNIST, PermutedMNIST, SVHN and Celeb-A and demonstrate that our model mitigates the effects of catastrophic interference faced by neural networks in sequential learning scenarios.}
}
@article{HUANG2021106,
title = {Stochastic configuration network ensembles with selective base models},
journal = {Neural Networks},
volume = {137},
pages = {106-118},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000198},
author = {Changqin Huang and Ming Li and Dianhui Wang},
keywords = {Stochastic configuration networks, Randomized learner models, Neural network ensemble, Educational data analytics},
abstract = {Studies have demonstrated that stochastic configuration networks (SCNs) have good potential for rapid data modeling because of their sufficient adequate learning power, which is theoretically guaranteed. Empirical studies have verified that the learner models produced by SCNs can usually achieve favorable test performance in practice but more in-depth theoretical analysis of their generalization power would be useful for constructing SCN-based ensemble models with enhanced generalization capacities. In particular, given a collection of independently developed SCN-based learner models, it is useful to select certain base learners that can potentially obtain preferable test results rather than considering all of the base models together, before simply taking their average in order to build an effective ensemble model. In this study, we propose a novel framework for building SCN ensembles by exploring key factors that might potentially affect the generalization performance of the base model. Under a mild assumption, we provide a comprehensive theoretical framework for examining a learner model’s generalization error, as well as formulating a novel indicator that contains measurement information for the training errors, output weights, and a hidden layer output matrix, which can be used by our proposed algorithm to find a subset of appropriate base models from a pool of randomized learner models. A toy example of one-dimensional function approximation, a case study for developing a predictive model for forecasting student learning performance, and two large-scale data sets were used in our experiments. The experimental results indicate that our proposed method has some remarkable advantages for building ensemble models.}
}
@article{CHAKRABORTY2021106410,
title = {Machine learning based digital twin for dynamical systems with multiple time-scales},
journal = {Computers & Structures},
volume = {243},
pages = {106410},
year = {2021},
issn = {0045-7949},
doi = {https://doi.org/10.1016/j.compstruc.2020.106410},
url = {https://www.sciencedirect.com/science/article/pii/S0045794920302133},
author = {S. Chakraborty and S. Adhikari},
keywords = {Digital twin, Multi-timescale dynamics, Mixture of experts, Gaussian process, Frequency},
abstract = {Digital twin technology has a huge potential for widespread applications in different industrial sectors such as infrastructure, aerospace, and automotive. However, practical adoptions of this technology have been slower, mainly due to a lack of application-specific details. Here we focus on a digital twin framework for linear single-degree-of-freedom structural dynamic systems evolving in two different operational time scales in addition to its intrinsic dynamic time-scale. Our approach strategically separates into two components – (a) a physics-based nominal model for data processing and response predictions, and (b) a data-driven machine learning model for the time-evolution of the system parameters. The physics-based nominal model is system-specific and selected based on the problem under consideration. On the other hand, the data-driven machine learning model is generic. For tracking the multi-timescale evolution of the system parameters, we propose to exploit a mixture of experts as the data-driven model. Within the mixture of experts model, Gaussian Process (GP) is used as the expert model. The primary idea is to let each expert track the evolution of the system parameters at a single time-scale. For learning the hyperparameters of the ‘mixture of experts using GP’, an efficient framework that exploits expectation-maximization and sequential Monte Carlo sampler is used. Performance of the digital twin is illustrated on a multi-timescale dynamical system with stiffness and/or mass variations. The digital twin is found to be robust and yields reasonably accurate results. One exciting feature of the proposed digital twin is its capability to provide reasonable predictions at future time-steps. Aspects related to the data quality and data quantity are also investigated.}
}
@article{LADJ2021168,
title = {A knowledge-based Digital Shadow for machining industry in a Digital Twin perspective},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {168-179},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S027861252030128X},
author = {Asma Ladj and Zhiqiang Wang and Oussama Meski and Farouk Belkadi and Mathieu Ritou and Catherine {Da Cunha}},
keywords = {Digital shadow, Digital twin, Data and knowledge management, Machining},
abstract = {This paper addresses the problems of data management and analytics for decision-aid by proposing a new vision of Digital Shadow (DS) which would be considered as the core component of a future Digital Twin. Knowledge generated by experts and artificial intelligence, is transformed into formal business rules and integrated into the DS to enable the characterization of the real behavior of the physical system throughout its operation stage. This behavior model is continuously enriched by direct or derived learning, in order to improve the digital twin. The proposed DS relies on data analytics (based on unsupervised learning) and on a knowledge inference engine. It enables the incidents to be detected and it is also able to decipher its operational context. An example of this application in the aeronautic machining industry is provided to stress both the feasibility of the proposition and its potential impact on shop floor performance.}
}
@article{XIA2021210,
title = {A digital twin to train deep reinforcement learning agent for smart manufacturing plants: Environment, interfaces and intelligence},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {210-230},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301059},
author = {Kaishu Xia and Christopher Sacco and Max Kirkpatrick and Clint Saidy and Lam Nguyen and Anil Kircaliali and Ramy Harik},
keywords = {Smart manufacturing systems, Robotics, Artificial intelligence, Digital transformation, Virtual commissioning},
abstract = {Filling the gaps between virtual and physical systems will open new doors in Smart Manufacturing. This work proposes a data-driven approach to utilize digital transformation methods to automate smart manufacturing systems. This is fundamentally enabled by using a digital twin to represent manufacturing cells, simulate system behaviors, predict process faults, and adaptively control manipulated variables. First, the manufacturing cell is accommodated to environments such as computer-aided applications, industrial Product Lifecycle Management solutions, and control platforms for automation systems. Second, a network of interfaces between the environments is designed and implemented to enable communication between the digital world and physical manufacturing plant, so that near-synchronous controls can be achieved. Third, capabilities of some members in the family of Deep Reinforcement Learning (DRL) are discussed with manufacturing features within the context of Smart Manufacturing. Trained results for Deep Q Learning algorithms are finally presented in this work as a case study to incorporate DRL-based artificial intelligence to the industrial control process. As a result, developed control methodology, named Digital Engine, is expected to acquire process knowledges, schedule manufacturing tasks, identify optimal actions, and demonstrate control robustness. The authors show that integrating a smart agent into the industrial platforms further expands the usage of the system-level digital twin, where intelligent control algorithms are trained and verified upfront before deployed to the physical world for implementation. Moreover, DRL approach to automated manufacturing control problems under facile optimization environments will be a novel combination between data science and manufacturing industries.}
}
@article{VO202127,
title = {An integrated framework of learning and evidential reasoning for user profiling using short texts},
journal = {Information Fusion},
volume = {70},
pages = {27-42},
year = {2021},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520304292},
author = {Duc-Vinh Vo and Jessada Karnjana and Van-Nam Huynh},
keywords = {User profiling, Short texts, Mass functions, Information fusion, Dempster–Shafer theory},
abstract = {Inferring user profiles based on texts created by users on social networks has a variety of applications in recommender systems such as job offering, item recommendation, and targeted advertisement. The problem becomes more challenging when working with short texts like tweets on Twitter, or posts on Facebook. This work aims at proposing an integrated framework based on Dempster–Shafer theory of evidence, word embedding, and k-means clustering for user profiling problem, which is capable of not only working well with short texts but also dealing with uncertainty inherently in user texts. The proposed framework is essentially composed of three phases: (1) Learning abstract concepts at multiple levels of abstraction from user corpora; (2) Evidential inference and combination for user modeling; and (3) User profile extraction. Particularly, in the first phase, a word embedding technique is used to convert preprocessed texts into vectors which capture semantics of words in user corpus, and then k-means clustering is utilized for learning abstract concepts at multiple levels of abstraction, each of which reflects appropriate semantics of user profiles. In the second phase, by considering each document in user corpus as an evidential source that carries some partial information for inferring user profiles, we first infer a mass function associated with each user document by maximum a posterior estimation, and then apply Dempster’s rule of combination for fusing all documents’ mass functions into an overall one for the user corpus. Finally, in the third phase, we apply the so-called pignistic probability principle to extract top-n keywords from user’s overall mass function to define the user profile. Thanks to the ability of combining pieces of information from many documents, the proposed framework is flexible enough to be scaled when input data coming from not only multiple modes but different sources on web environments. Besides, the resulting profiles are interpretable, visualizable, and compatible in practical applications. The effectiveness of the proposed framework is validated by experimental studies conducted on datasets crawled from Twitter and Facebook.}
}
@article{WANG2021261,
title = {Digital twin improved via visual question answering for vision-language interactive mode in human–machine collaboration},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {261-269},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301217},
author = {Tian Wang and Jiakun Li and Zhaoning Kong and Xin Liu and Hichem Snoussi and Hongqiang Lv},
keywords = {Digital twin, Human–machine collaboration, Visual question answer, Deep learning},
abstract = {The human–machine collaboration system is a key means of manufacturing. Its surveillance, prognostic, and health management are related to safety and manufacturing persistence. This paper begins with the mission requirements of intelligent manufacturing. The study is based on the visual question answering (VQA) technology with a digital twin to increase efficiency. The research contents are as follows: (1) A method of modeling human–machine collaboration based on digital twins is proposed. (2) A VQA is adopted in the digital twin. The video and neural language are considered. (3) VQA technology is introduced into the modeling of the human–machine collaboration system for consistent integration. With VQA technology, humans and machines can collaborate. Human–machine interaction and product counting are implemented in a case study to provide a comprehensive perception.}
}
@article{SANTAMARIABONFIL2020103871,
title = {Learning analytics for student modeling in virtual reality training systems: Lineworkers case},
journal = {Computers & Education},
volume = {151},
pages = {103871},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103871},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520300701},
author = {Guillermo Santamaría-Bonfil and María Blanca Ibáñez and Miguel Pérez-Ramírez and Gustavo Arroyo-Figueroa and Francisco Martínez-Álvarez},
keywords = {Learning analytics, Performance prediction, Feature importance analysis, Exploratory data analysis, Virtual reality},
abstract = {Live-line maintenance is a high risk activity. Hence, lineworkers require effective and safe training. Virtual Reality Training Systems (VRTS) provide an affordable and safe alternative for training in such high risk environments. However, their effectiveness relies mainly on having meaningful activities for supporting learning and on their ability to detect untrained students. This study builds a student model based on Learning Analytics (LA), using data collected from 1399 students that used a VRTS for the maintenance training of lineworkers in 329 courses carried out from 2008 to 2016. By employing several classifiers, the model allows discriminating between trained and untrained students in different maneuvers using three minimum evaluation proficiency scores. Using the best classifier, a Feature Importance Analysis is carried out to understand the impact of the variables regarding the trainees’ final performances. The model also involves the exploration of the trainees’ trace data through a visualization tool to pose non-observable behavioral variables related to displayed errors. The results show that the model can discriminate between trained and untrained students, the Random Forest algorithm standing out. The feature importance analysis revealed that the most relevant features regarding the trainees’ final performance were profile and course variables along with specific maneuver steps. Finally, using the visual tool, and with human expert aid, several error patterns in trace data associated with misconceptions and confusion were identified. In the light of these, LA enables disassembling the data jigsaw quandary from VRTS to enhance the human-in-the-loop evaluation.}
}
@article{UHLMANN20211430,
title = {Holistic Concept Towards a Reference Architecture Model for Predictive Maintenance},
journal = {Procedia CIRP},
volume = {104},
pages = {1430-1433},
year = {2021},
note = {54th CIRP CMS 2021 - Towards Digitalized Manufacturing 4.0},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.11.241},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121011392},
author = {Eckart Uhlmann and Julian Polte and Nikolaos-Stefanos Koutrakis},
keywords = {Analytics, Reference Architecture, Digital Twin, Predictive Maintenance, IIoT, Machine Learning},
abstract = {In the era of digital transformation of factories, one of the most challenging applications of the Industrial Internet of Things (IIoT) is predictive maintenance. This paper presents a holistic concept for predictive maintenance together with a reference architecture that includes data acquisition on the sensor level, edge computing and digital twin applications. For that purpose, condition-based maintenance, lifecycle monitoring and digital assistance systems are integrated to develop application-specific digital twins based on the proposed architecture, integrating heterogenous data sources in order to enhance the accuracy of the machine learning models. The concept is illustrated through an experimental use case.}
}
@article{MOLINARO2021104759,
title = {Embedding data analytics and CFD into the digital twin concept},
journal = {Computers & Fluids},
volume = {214},
pages = {104759},
year = {2021},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2020.104759},
url = {https://www.sciencedirect.com/science/article/pii/S0045793020303297},
author = {Roberto Molinaro and Joel-Steven Singh and Sotiris Catsoulis and Chidambaram Narayanan and Djamel Lakehal},
keywords = {Fluid flow simulations, Data analytics, Machine learning, Data-driven models},
abstract = {Computer-Aided Engineering (CAE) has supported the industry in its transition from trial-and-error towards physics-based modelling, but our ways of treating and exploiting the simulation results have changed little during this period. Indeed, the business model of CAE centers almost exclusively around delivering base-case simulation results with a few additional operational conditions. In this contribution, we introduce a new paradigm for the exploitation of computational physics data, consisting in using machine learning to enlarge the simulation databases in order to cover a wider spectrum of operational conditions and provide quick response directly on field. The resulting product from this hybrid physics-informed and data-driven modelling is referred to as Simulation Digital Twin (SDT). While the paradigm can be equally used in different CAE applications, in this paper we address its implementation in the context of Computational Fluid Dynamics (CFD). We show that the generation of Simulation Digital Twins can be efficiently accomplished with the combination of the CFD tool TransAT and the data analytics platform eDAP.}
}
@article{ODWYER2020102412,
title = {Integration of an energy management tool and digital twin for coordination and control of multi-vector smart energy systems},
journal = {Sustainable Cities and Society},
volume = {62},
pages = {102412},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102412},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720306338},
author = {Edward O’Dwyer and Indranil Pan and Richard Charlesworth and Sarah Butler and Nilay Shah},
keywords = {Urban energy systems, Smart cities, Building energy, Transport energy, Machine learning},
abstract = {As Internet of Things (IoT) technologies enable greater communication between energy assets in smart cities, the operational coordination of various energy networks in a city or district becomes more viable. Suitable tools are needed that can harness advanced control and machine learning techniques to achieve environmental, economic and resilience objectives. In this paper, an energy management tool is presented that can offer optimal control, scheduling, forecasting and coordination services to energy assets across a district, enabling optimal decisions under user-defined objectives. The tool presented here can coordinate different sub-systems in a district to avoid the violation of high-level system constraints and is designed in a generic fashion to enable transferable use across different energy sectors. The work demonstrates the potential for a single open-source optimisation framework to be applied across multiple energy vectors, providing local government the opportunity to manage different assets in a coordinated fashion. This is shown through case studies that integrate low-carbon communal heating for social housing with electric vehicle charge-point management to achieve high-level system constraints and local government objectives in the borough of Greenwich, London. The paper illustrates the theoretical methodology, the software architecture and the digital twin-based testing environment underpinning the proposed approach.}
}
@article{GREGORIO2021108,
title = {A digital twin-based approach for the management of geometrical deviations during assembly processes},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {108-117},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520300649},
author = {Jean-Loup Grégorio and Claire Lartigue and François Thiébaut and Régis Lebrun},
keywords = {Digital twin, Assembly, Geometry assurance, 3D acquisition},
abstract = {The recent transformation in the aeronautical industry gives new prospects in the field of product geometry assurance. These include, in particular the creation of sophisticated virtual models, or digital twins, which can reflect the as-built geometry of physical products and optimize the assembly operations consequently. One of the current obstacles to the implementation of such digital twins is linked to the difficult transition from a conceptual model to a usable virtual representation. In this article, we present the hybrid representation of a product which is capable of integrating the different states of the components at each step of the assembly process. We propose a method to update the virtual representation of already assembled components, in order to include the position and orientation deviations of their surfaces. The B-Rep model of each component is updated from data acquired during the assembly of the product. The various steps of this update, and its associated tools are discussed in the article. Based on the knowledge of the as-built component geometry, the geometry of the yet-to-be-assembled components is adapted so that the final product complies with the functional requirements. To this end, we also discuss a formalism to model the product's functional information and to translate it at a geometrical level thanks to an assembly skeleton.}
}
@article{MAY202127,
title = {Foresighted digital twin for situational agent selection in production control},
journal = {Procedia CIRP},
volume = {99},
pages = {27-32},
year = {2021},
note = {14th CIRP Conference on Intelligent Computation in Manufacturing Engineering, 15-17 July 2020},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121002614},
author = {Marvin Carl May and Leonard Overbeck and Marco Wurster and Andreas Kuhnle and Gisela Lanza},
keywords = {Fluid Automation, Production Control, Digital Twin, Machine Learning, Human Behavior},
abstract = {As intelligent Data Acquisition and Analysis in Manufacturing nears its apex, a new era of Digital Twins is dawning. Foresighted Digital Twins enable short- to medium-term system behavior predictions to infer optimal production operation strategies. Creating up-to-the-minute Digital Twins requires both the availability of real-time data and its incorporation and serve as a stepping-stone into developing unprecedented forms of production control. Consequently, we regard a new concept of Digital Twins that includes foresight, thereby enabling situational selection of production control agents. One critical element for adequate system predictions is human behavior as it is neither rule-based nor deterministic, which we therefore model applying Reinforcement Learning. Owing to these ever-changing circumstances, rigid operation strategies crucially restrain reactions, as opposed to circumstantial control strategies that hence can outperform traditional approaches. Building on enhanced foresights we show the superiority of this approach and present strategies for improved situational agent selection.}
}
@article{CUNHA2021874,
title = {Designing the Digital Twins of Reconfigurable Manufacturing Systems: application on a smart factory},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {874-879},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.103},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321008521},
author = {Catherine da Cunha and Olivier Cardin and Guillaume Gallot and Julien Viaud},
keywords = {Reconfigurable Manufacturing Systems, Modularity, Digital Twin, Manufacturing systems},
abstract = {The emergence of Digital Twins in manufacturing enables in-depth integration of the physical and informational worlds. Meanwhile, the concept of Reconfigurable Manufacturing Systems exhibits new opportunities and new constraints in the way the manufacturing systems are designed and managed. Among others, the notion of modularity is a prerequisite for both physical components and their informational counterparts. To provide the benefits of Digital Twin to Reconfigurable Manufacturing Systems, this paper introduces a modular design of the Digital Twin counterpart of the components. A prototype system is developed to demonstrate the modular design’s benefits, with an application on a reconfigurable learning factory.}
}
@article{LIN2021101209,
title = {Evolutionary digital twin: A new approach for intelligent industrial product development},
journal = {Advanced Engineering Informatics},
volume = {47},
pages = {101209},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101209},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620301786},
author = {Ting Yu Lin and Zhengxuan Jia and Chen Yang and Yingying Xiao and Shulin Lan and Guoqiang Shi and Bi Zeng and Heyu Li},
keywords = {Evolutionary digital twin, Intelligent industrial product, Collaborative evolution, Approximate world, Multiple cyber spaces, Simple evolution paradigm, Model evolution paradigm},
abstract = {To fulfill increasingly difficult and demanding tasks in the ever-changing complex world, intelligent industrial products are to be developed with higher flexibility and adaptability. Digital twin (DT) brings about a possible means, due to its ability to provide candidate behavior adjustments based on received “feedbacks” from its physical part. However, such candidate adjustments are deterministic, and thus lack of flexibility and adaptability. To address such problem, in this paper an extended concept – evolutionary digital twin (EDT) and an EDT-based new mode for intelligent industrial product development has been proposed. With our proposed EDT, a more precise approximated model of the physical world could be established through supervised learning, based on which the collaborative exploration for optimal policies via parallel simulation in multiple cyberspaces could be performed through reinforcement learning. Hence, more flexibility and adaptability could be brought to industrial products through machine learning (such as supervised learning and reinforcement learning) based self-evolution. As a primary verification of the effectiveness of our proposed approach, a case study has been carried out. The experimental results have well confirmed the effectiveness of our EDT based development mode.}
}
@article{CHRYSAFIADI2020113614,
title = {Combination of fuzzy and cognitive theories for adaptive e-assessment},
journal = {Expert Systems with Applications},
volume = {161},
pages = {113614},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113614},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420304383},
author = {Konstantina Chrysafiadi and Christos Troussas and Maria Virvou},
keywords = {Adaptivity, E-assessment, E-learning, Cognitive theories, Fuzzy rules},
abstract = {A crucial factor for successful educational results in computer-based educational systems and e-learning systems is the learner’s assessment. Assessment is more effective when it is tailored to each individual student’s learning needs and abilities. Therefore, a significant research challenge is to create tests that include exercises/questions/activities etc., which conform to each learner’s knowledge level and learning needs and abilities. This goal constitutes the need for creating adaptive tests. However, the area of adaptive e-assessment has not yet been explored sufficiently and thus there is scope for a lot of improvement. To this end, in this paper we present a novel solution for adaptive e-assessment. The novelty and significance lie in the blending of fuzzy logic and cognitive theories for further enhancing the personalization and adaptivity in e-assessment. Particularly, fuzzy sets are used to describe the knowledge level of students in a more realistic way. Furthermore, the cognitive theory of Revised Bloom Taxonomy is used to express the learning objectives that are required to be assessed through the created test. In addition, a fuzzy rule-based reasoner, which decides about the number and the difficulty level of the test items that have to be included into the created personalized test for each level of the Revised Bloom Taxonomy, is used. The fuzzy rules are applied to the fuzzy sets that describe the learners’ knowledge level. For the formation of the fuzzy sets and rules, the opinion of several tutors, holding experience in the educational process and instruction, was taken into consideration. The created adaptive test comprises distinct test items based on the individual learning needs of each student. The presented method has been used in two tutoring systems and has been fully evaluated. The evaluation results show great accuracy in the selection of test items for each individual student.}
}
@article{BIDEAULT20211540,
title = {Verification and Validation of Computational Models Used in Biopharmaceutical Manufacturing: Potential Application of the ASME Verification and Validation 40 Standard and FDA Proposed AI/ML Model Life Cycle Management Framework},
journal = {Journal of Pharmaceutical Sciences},
volume = {110},
number = {4},
pages = {1540-1544},
year = {2021},
issn = {0022-3549},
doi = {https://doi.org/10.1016/j.xphs.2021.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0022354921000319},
author = {Gautier Bideault and Anthony Scaccia and Thomas Zahel and Robert W. Landertinger and Chathuri Daluwatte},
keywords = {Verification and validation, Computational models, Machine learning, Digital twins, Biopharmaceutical manufacturing, GMLP},
abstract = {A wide variety of computational models covering statistical, mechanistic, and machine learning (locked and adaptive) methods are explored for use in biopharmaceutical manufacturing. Limited discussion exists on how to establish the credibility of a computational model for application in biopharmaceutical manufacturing. In this work, we tried to use the American Society of Mechanical Engineers (ASME) Verification and Validation 40 (V&V 40) standard and FDA proposed AI/ML model life cycle management framework for Software as a Medical Device (SaMD) in biopharmaceutical manufacturing use cases, by applying to a set of curated hypothetical examples. We discussed the need for standardized frameworks to facilitate consistent decision making to enable efficient adoption of computational models in biopharmaceutical manufacturing and alignment of existing good practices with existing frameworks. In the study of our examples, we anticipate existing frameworks like V&V 40 can be adopted.}
}
@article{SHI2021119572,
title = {Probabilistic real-time deep-water natural gas hydrate dispersion modeling by using a novel hybrid deep learning approach},
journal = {Energy},
volume = {219},
pages = {119572},
year = {2021},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2020.119572},
url = {https://www.sciencedirect.com/science/article/pii/S0360544220326797},
author = {Jihao Shi and Junjie Li and Asif Sohail Usmani and Yuan Zhu and Guoming Chen and Dongdong Yang},
keywords = {Marine natural hydrate gas, Probabilistic dispersion modeling, Convolution variational autoencoder, Variational Bayesian neural network, Uncertainty estimation of spatial features, Digital twin of emergency management},
abstract = {Computational Fluid Dynamic (CFD) has been widely used for the gas release and dispersion modeling, which however could not support real-time emergency response planning due to its high computation overhead. Surrogate models offer a potential alternative to rigorous computational approaches, however, as the point-estimation alternatives, the existing neural network-based surrogate models are not able to quantify the uncertainty of the released gas spatial concentration. This study aims to fill a gap by proposing an advanced hybrid probabilistic Convolutional-Variational Autoencoder-Variational Bayesian neural network (Conv-VAE-VBnn). Experimental study based on a benchmark simulation dataset was conducted. The results demonstrated the additional uncertainty information estimated by the proposed model contributes to reducing the harmful effect of too ‘confidence’ of the point-estimation models. In addition, the proposed model exhibits competitive accuracy with R2 = 0.94 compared and real-time capacity with inference time less than 1s. Latent size Nz = 2, noise σz=0.1 and Monte Carlo sampling number m = 500 to ensure the model’s real-time capacity, were also given. Overall, our proposed model could provide a reliable alternative for constructing a digital twin for emergency management during the exploration and exploitation of marine natural gas hydrate (NHG) in the near future.}
}
@article{WANG2020373,
title = {Intelligent welding system technologies: State-of-the-art review and perspectives},
journal = {Journal of Manufacturing Systems},
volume = {56},
pages = {373-391},
year = {2020},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301102},
author = {Baicun Wang and S. Jack Hu and Lei Sun and Theodor Freiheit},
keywords = {Intelligent welding, Artificial intelligence (AI), Intelligent manufacturing, Robotic welding, Monitoring and control, Machine learning},
abstract = {Welding systems are being transformed by the advent of modern information technologies such as the internet of things, big data, artificial intelligence, cloud computing, and intelligent manufacturing. Intelligent welding systems (IWS), making use of these technologies, are drawing attention from academic and industrial communities. Intelligent welding is the use of computers to mimic, strengthen, and/or replace human operators in sensing, learning, decision-making, monitoring and control, etc. This is accomplished by integrating the advantages of humans and physical systems into intelligent cyber systems. While intelligent welding has found pilot applications in industry, a systematic analysis of its components, applications, and future directions will help provide a unified definition of intelligent welding systems. This paper examines fundamental components and techniques necessary to make welding systems intelligent, including sensing and signal processing, feature extraction and selection, modeling, decision-making, and learning. Emerging technologies and their application potential to IWS will also be surveyed, including Industry 4.0, cyber-physical system (CPS), digital twins, etc. Typical applications in IWS will be surveyed, including weld design, task sequencing, robot path planning, robot programming, process monitoring and diagnosis, prediction, process control, quality inspection and assessment, human-robot collaboration, and virtual welding. Finally, conclusions and suggestions for future development will be proposed. This review is intended to provide a reference of the state-of-the-art for those seeking to introduce intelligent welding capabilities as they modernize their traditional welding stations, systems, and factories.}
}
@article{KUMAR2021104111,
title = {Collaborative knowledge distillation for incomplete multi-view action prediction},
journal = {Image and Vision Computing},
volume = {107},
pages = {104111},
year = {2021},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2021.104111},
url = {https://www.sciencedirect.com/science/article/pii/S0262885621000160},
author = {Deepak Kumar and Chetan Kumar and Ming Shao},
keywords = {Multi-view, Action prediction, Knowledge distillation, Graph attention},
abstract = {Predicting future actions is a key in visual understanding, surveillance, and human behavior analysis. Current methods for video-based prediction are primarily using single-view data, while in the real world multiple cameras and produced videos are readily available, which may potentially benefit the action prediction tasks. However, it may bring up a new challenge: subjects in the videos are more likely to be occluded by objects when captured from different angles, or suffer from signal jittering in transmission. To that end, in this paper we propose a novel student network called Collaborative Knowledge Distillation (CKD) to predict human actions with missing information under a multi-view setting, i.e., incomplete multi-view action prediction. First, we create a graph attention based teacher model capable of fusing multi-view video features for prediction task. Second, we construct a corruption pattern bank (CPB) to simulate various missing segments in multi-view video, and each student model will manage one pattern through privileged information and knowledge distillation. Third, to account for arbitrary missing video segments in real-world, the ensemble of student models will be developed to make a joint prediction. The proposed framework has been extensively evaluated on popular multi-view visual action datasets, including PKU-MMD and NTU-RGB to validate the effectiveness of our approach and to the best of our knowledge action prediction has not yet been explored in the multi-view setting.}
}
@article{RAOPABOLU20211367,
title = {A dynamic job rotation scheduling conceptual framework by a human representing digital twin},
journal = {Procedia CIRP},
volume = {104},
pages = {1367-1372},
year = {2021},
note = {54th CIRP CMS 2021 - Towards Digitalized Manufacturing 4.0},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.11.230},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121011288},
author = {Venkata Krishna {Rao Pabolu} and Divya Shrivastava},
keywords = {Worker Job rotation, Work fatigue, ALWABP, Fatigue classifier, IIoT},
abstract = {This work is an extension part of the Assembly Line Worker Assignment Balancing Problem(ALWABP), aims to provide a dynamic solution for an assembly line fatigue worker job rotation by using machine learning based digital twin. This framework explains, fatigue worker identification and work rotation possibilities for a reconfigurable assembly line. The fatigue causing parameters are sensed from the workers and classified with a fatigue classifier then send the fatigue worker details to a worker job rotation search algorithm. The job rotation search algorithm provides a suggestion to the production supervisor for a best possible worker job rotation/reallocation solution dynamically.}
}
@article{MANETTAS2021237,
title = {Synthetic datasets for Deep Learning in computer-vision assisted tasks in manufacturing},
journal = {Procedia CIRP},
volume = {103},
pages = {237-242},
year = {2021},
note = {9th CIRP Global Web Conference – Sustainable, resilient, and agile manufacturing and service operations : Lessons from COVID-19},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.10.038},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121008799},
author = {Christos Manettas and Nikolaos Nikolakis and Kosmas Alexopoulos},
keywords = {digital-twin, artificial intelligence, robotics, artificial datasets, machine learning},
abstract = {Artificial Intelligence applications based on Machine Learning methods are widely accepted as promising technologies in manufacturing. Deep Learning (DL) techniques, such as Convolutional Neural Networks (CNN), are successfully used in many computer-vision tasks in manufacturing. These state-of-the-art techniques are requiring large volumes of annotated datasets for training. However, such an approach is expensive, prone to errors and labor as well as time intensive, especially in highly complex and dynamic production environments. Synthetic datasets can be utilized for accelerating the training phase of DL by creating suitable training datasets. This work presents a framework for generating datasets through a chain of simulation tools. The framework is used for generating synthetic images of manufactured parts. States of the parts such as the rotation in different rotation axis need to be recognized by a computer-vision system that assists a manufacturing operation. A number of prior trained CNNs are retrained with the synthetically generated images. The CNNs are tested upon actual images of manufactured parts. The performance of different CNN models is presented, compared and discussed. The results indicate that CNNs trained on synthetically generated datasets may have acceptable performance when used in for assisting tasks in manufacturing.}
}
@article{HOOSHYAR2020103878,
title = {Open learner models in supporting self-regulated learning in higher education: A systematic literature review},
journal = {Computers & Education},
volume = {154},
pages = {103878},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103878},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520300774},
author = {Danial Hooshyar and Margus Pedaste and Katrin Saks and Äli Leijen and Emanuele Bardone and Minhong Wang},
keywords = {Open learner model, Systematic review, Self-regulated learning, Higher education},
abstract = {The open learner model (OLM) represents the knowledge or skill levels of learners in various ways, encouraging learners to actively participate in thinking about and crafting their own learning. Despite the important roles that OLMs play in higher education to support the learning process and self-regulated learning (SRL) in particular, there are few studies systematically reviewing OLM technology in higher education, and investigating their potential to foster self-regulated learning. Therefore, we carried out a systematic review of a 30-year sample of OLM studies in higher education and identified 64 articles that study the use of OLMs in supporting SRL. Our findings show that OLMs have been mainly used to support learners' cognition and a bit less metacognition and motivation; however, emotional support has been rarely provided. The most supported ones are Appraisal and Performance phases; Preparation of learning is enhanced by OLMs not so often. Although learners can edit or negotiate with their learning model in advanced ways, a simple inspectable OLM is more preferred. Reliance on unobservable nodes is less favored in modeling techniques in OLMs because such methods are highly dependent on expert authoring, thereby time-intensive and costly. Comparison and color-coding are two most-used features in OLMs, where the comparison feature is often used for enhancing learners’ engagement and motivation.}
}
@article{REICHARDT2021968,
title = {Procedure model for the development and launch of intelligent assistance systems},
journal = {Procedia Computer Science},
volume = {180},
pages = {968-977},
year = {2021},
note = {Proceedings of the 2nd International Conference on Industry 4.0 and Smart Manufacturing (ISM 2020)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.348},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921004026},
author = {Paul Reichardt and Sebastian Lang and Tobias Reggelin},
keywords = {Production planning, control, Machine learning, Planning assistance system, Practical implementation, Generic procedure model, Digital twin},
abstract = {The paper analyses the current state of knowledge on approaches for the practical implementation of machine learning based assistance systems for production planning and control. A concept of a procedure model for application-oriented projects in the field of industrial series production is proposed. It focusses on order sequencing and machine allocation in a real time production environment. As part of an application-oriented research project, a use case is referenced. In this paper, a first conceptual approach is presented, using the example of an industrial production of printed circuit boards. In the following steps, practical suitability is checked on the basis of the practical reference, conclusions are drawn and the methodology will be developed further. The aim is a generally valid procedure model for industrial series production.}
}
@article{NGUYENMEIDINE2021104096,
title = {Knowledge distillation methods for efficient unsupervised adaptation across multiple domains},
journal = {Image and Vision Computing},
volume = {108},
pages = {104096},
year = {2021},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2021.104096},
url = {https://www.sciencedirect.com/science/article/pii/S0262885621000019},
author = {Le Thanh Nguyen-Meidine and Atif Belal and Madhu Kiran and Jose Dolz and Louis-Antoine Blais-Morin and Eric Granger},
keywords = {Deep learning, Convolutional NNs, Knowledge distillation, Unsupervised domain adaptation, CNN acceleration and compression},
abstract = {Beyond the complexity of CNNs that require training on large annotated datasets, the domain shift between design and operational data has limited the adoption of CNNs in many real-world applications. For instance, in person re-identification, videos are captured over a distributed set of cameras with non-overlapping viewpoints. The shift between the source (e.g. lab setting) and target (e.g. cameras) domains may lead to a significant decline in recognition accuracy. Additionally, state-of-the-art CNNs may not be suitable for such real-time applications given their computational requirements. Although several techniques have recently been proposed to address domain shift problems through unsupervised domain adaptation (UDA), or to accelerate/compress CNNs through knowledge distillation (KD), we seek to simultaneously adapt and compress CNNs to generalize well across multiple target domains. In this paper, we propose a progressive KD approach for unsupervised single-target DA (STDA) and multi-target DA (MTDA) of CNNs. Our method for KD-STDA adapts a CNN to a single target domain by distilling from a larger teacher CNN, trained on both target and source domain data in order to maintain its consistency with a common representation. This method is extended to address MTDA problems, where multiple teachers are used to distill multiple target domain knowledge to a common student CNN. A different target domain is assigned to each teacher model for UDA, and they alternatively distill their knowledge to the student model to preserve specificity of each target, instead of directly combining the knowledge from each teacher using fusion methods. Our proposed approach is compared against state-of-the-art methods for compression and STDA of CNNs on the Office31 and ImageClef-DA image classification datasets. It is also compared against state-of-the-art methods for MTDA on Digits, Office31, and OfficeHome. In both settings – KD-STDA and KD-MTDA – results indicate that our approach can achieve the highest level of accuracy across target domains, while requiring a comparable or lower CNN complexity.}
}
@article{APOSTOLIDIS202155,
title = {An AI-based Digital Twin Case Study in the MRO Sector},
journal = {Transportation Research Procedia},
volume = {56},
pages = {55-62},
year = {2021},
note = {1st International Conference on Aviation Future: Challenge and Solution (AFCS 2020)},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2021.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S2352146521006347},
author = {Asteris Apostolidis and Konstantinos P. Stamoulis},
keywords = {Digital Twin, Machine Learning, Artificial Intelligence, Aviation MRO, Predictive Maintenance},
abstract = {In this work, the concept of an Artificial Intelligence-based (AI) Digital Twin (DT) of an aircraft system is introduced, with the goal to improve the corresponding MRO Operations. More specifically, the current study aims to obtaining knowledge on the optimal placement of sensors in an ideal Power Electronics Cooling System (PECS) of a modern airliner, aiming to improve input data as a basis for an AI-based DT. The three main fluid parameters to be measured directly or indirectly at various physical locations at the PECS are mass flow rate, temperature and static pressure. The physics-based model can then be combined with a Machine Learning (ML) model, such as a Random Forest (RF), with a multitude of decision trees. Following, the AI system determines whether the PECS operations is considered normal, aiming to optimize the performance of the system and to maximize the Useful Remaining Life (URL). The suggested AI-DT approach is based both on data-driven and physics-based models, an approach which results in increased reliability and availability, reducing possible Aircraft on Ground (AOG) events. Subsequently, the enhanced prediction capability results in the optimization of the maintenance processes and in reduced operational costs.}
}
@article{YU2021293,
title = {A Digital Twin approach based on nonparametric Bayesian network for complex system health monitoring},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {293-304},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301151},
author = {Jinsong Yu and Yue Song and Diyin Tang and Jing Dai},
keywords = {Digital Twin, Health monitoring, Nonparametric Bayesian networks, Dirichlet process mixture model},
abstract = {This paper proposes a Digital Twin approach for health monitoring. In this approach, a Digital Twin model based on nonparametric Bayesian network is constructed to denote the dynamic degradation process of health state and the propagation of epistemic uncertainty. Then, a real-time model updating strategy based on improved Gaussian particle filter (GPF) and Dirichlet process mixture model (DPMM) is presented to enhance the model adaptability. On one hand, for those parameters in the nonparametric Bayesian network with prior models, the improved GPF is used to update them in real time. On the other hand, for parameters lacking a prior model, DPMM is proposed to learn hidden variables, which adaptively update the model structure and greatly reduce uncertainty. Experiments on the electro-optical system are conducted to validate the feasibility of the Digital Twin approach and verify the effectiveness of the nonparametric Bayesian network. The results of comparative experiments prove that the Digital Twin approach based on nonparametric Bayesian Network has a good model self-learning ability, which improves the accuracy of health monitoring.}
}
@incollection{RAJ2021355,
title = {Chapter Eighteen - Industrial use cases at the cusp of the IoT and blockchain paradigms},
editor = {Shubhani Aggarwal and Neeraj Kumar and Pethuru Raj},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {121},
pages = {355-385},
year = {2021},
booktitle = {The Blockchain Technology for Secure and Smart Applications across Industry Verticals},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2020.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0065245820300735},
author = {Pethuru Raj},
keywords = {Blockchain, Smart contracts, Decentralized applications, Artificial intelligence, Digital twins, The Internet of Things, Consensus algorithms, Hashing, Machine learning, Cloud computing},
abstract = {There are fair amount of reasons and requirements for both the IoT and blockchain concepts to cooperate closely to solve bigger problems at hand. This deadly combination is to result in scores of fresh and fabulous opportunities and possibilities for the total human society. The Internet of Things (IoT) paradigm has made it possible to have digitized and connected things in plenty in our everyday environments. That is, all kinds of physical, mechanical, electrical, and electronics systems are systematically being digitized and connected through proven and potential edge and connectivity technologies. The leading market analysts and researchers have come out with forecasts that there will be billions of connected devices and trillions of digitized entities in the years ahead. The noteworthy point here is that all these empowered entities, on purposefully collaborating and correlating with one another, can generate massive amounts of multistructured data. The challenge is how to secure IoT devices and data. The arrival of the blockchain technology is being celebrated as the best thing toward convincingly meeting up the IoT security requirements. This chapter is to explore and expound how the cool linkage between IoT and blockchain is to substantially enhance the security and privacy needs of IoT devices and data.}
}
@article{OVERBECK2021170,
title = {Reinforcement Learning Based Production Control of Semi-automated Manufacturing Systems},
journal = {Procedia CIRP},
volume = {103},
pages = {170-175},
year = {2021},
note = {9th CIRP Global Web Conference – Sustainable, resilient, and agile manufacturing and service operations : Lessons from COVID-19},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.10.027},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121008684},
author = {Leonard Overbeck and Adrien Hugues and Marvin Carl May and Andreas Kuhnle and Gisela Lanza},
keywords = {Machine Learning, Reinforcement Learning, Digital Twin, Production Control, Task Allocation, Productivity},
abstract = {In an environment which is marked by an increasing speed of changes, industrial companies have to be able to quickly adapt to new market demands and innovative technologies. This leads to a need for continuous adaption of existing production systems and the optimization of their production control. To tackle this problem digitalization of production systems has become essential for new and existing systems. Digital twins based on simulations of real production systems allow the simplification of analysis processes and, thus, a better understanding of the systems, which leads to broad optimization possibilities. In parallel, machine learning methods can be integrated to process the numerical data and discover new production control strategies. In this work, these two methods are combined to derive a production control logic in a semi-automated production system based on the chaku-chaku principle. A reinforcement learning method is integrated into the digital twin to autonomously learn a superior production control logic for the distribution of tasks between the different workers on a production line. By analyzing the influence of different reward shaping and hyper-parameter optimization on the quality and stability of the results obtained, the use of a well-configured policy-based algorithm enables an efficient management of the workers and the deduction of an optimal production control logic for the production system. The algorithm manages to define a control logic that leads to an increase in productivity while having a stable task assignment so that a transfer to daily business is possible. The approach is validated in the digital twin of a real assembly line of an automotive supplier. The results obtained suggest a new approach to optimizing production control in production lines. Production control shall be centered directly on the workers’ routines and controlled by artificial intelligence infused with a global overview of the entire production system.}
}
@article{LIU2022857,
title = {Digital Twin-enabled Collaborative Data Management for Metal Additive Manufacturing Systems},
journal = {Journal of Manufacturing Systems},
volume = {62},
pages = {857-874},
year = {2022},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520300741},
author = {Chao Liu and Léopold {Le Roux} and Carolin Körner and Olivier Tabaste and Franck Lacan and Samuel Bigot},
keywords = {Metal Additive Manufacturing, Digital Twin, data management, data model, machine learning, product lifecycle management},
abstract = {Metal Additive Manufacturing (AM) has been attracting a continuously increasing attention due to its great advantages compared to traditional subtractive manufacturing in terms of higher design flexibility, shorter development time, lower tooling cost, and fewer production wastes. However, the lack of process robustness, stability and repeatability caused by the unsolved complex relationships between material properties, product design, process parameters, process signatures, post AM processes and product quality has significantly impeded its broad acceptance in the industry. To facilitate efficient implementation of advanced data analytics in metal AM, which would support the development of intelligent process monitoring, control and optimisation, this paper proposes a novel Digital Twin (DT)-enabled collaborative data management framework for metal AM systems, where a Cloud DT communicates with distributed Edge DTs in different product lifecycle stages. A metal AM product data model that contains a comprehensive list of specific product lifecycle data is developed to support the collaborative data management. The feasibility and advantages of the proposed framework are validated through the practical implementation in a distributed metal AM system developed in the project MANUELA. A representative application scenario of cloud-based and deep learning-enabled metal AM layer defect analysis is also presented. The proposed DT-enabled collaborative data management has shown great potential in enhancing fundamental understanding of metal AM processes, developing simulation and prediction models, reducing development times and costs, and improving product quality and production efficiency.}
}
@article{WU2021139,
title = {A Framework of Dynamic Data Driven Digital Twin for Complex Engineering Products: the Example of Aircraft Engine Health Management},
journal = {Procedia Manufacturing},
volume = {55},
pages = {139-146},
year = {2021},
note = {FAIM 2021},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2021.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S2351978921002171},
author = {Zhenhua Wu and Jianzhi Li},
keywords = {Digital Twin, Dynamic Data Driven, Complex Engineering Products, Aircraft Engine, Health Management},
abstract = {Digital twin is a vital enabling technology for smart manufacturing in the era of Industry 4.0. Digital twin effectively replicates its physical asset enabling easy visualization, smart decision-making and cognitive capability in the system. In this paper, a framework of dynamic data driven digital twin for complex engineering products was proposed. To illustrate the proposed framework, an example of health management on aircraft engines was studied. This framework models the digital twin by extracting information from the various sensors and Industry Internet of Things (IIoT) monitoring the remaining useful life (RUL) of an engine in both cyber and physical domains. Then, with sensor measurements selected from linear degradation models, a long short-term memory (LSTM) neural network is proposed to dynamically update the digital twin, which can estimate the most up-to-date RUL of the physical aircraft engine. Through comparison with other machine learning algorithms, including similarity based linear regression and feed forward neural network, on RUL modelling, this LSTM based dynamical data driven digital twin provides a promising tool to accurately replicate the health status of aircraft engines. This digital twin based RUL technique can also be extended for health management and remote operation of manufacturing systems.}
}
@article{WANG2020429,
title = {Deep learning-empowered digital twin for visualized weld joint growth monitoring and penetration control},
journal = {Journal of Manufacturing Systems},
volume = {57},
pages = {429-439},
year = {2020},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301710},
author = {Qiyue Wang and Wenhua Jiao and YuMing Zhang},
keywords = {Convolutional neural networks, (CNNs), Deep learning, Digital twin, Smart manufacturing, Welding quality},
abstract = {This paper presents an innovative digital twin to monitor and control complex manufacturing processes by integrating deep learning which offers strong feature extraction and analysis abilities. Taking welding manufacturing as a case study, a deep learning-empowered digital twin is developed as the visualized digital replica of the physical welding for joint growth monitoring and penetration control. In such a system, the information available directly from sensors including weld pool images, arc images, welding current and arc voltage is collected in pulsed gas tungsten arc welding (GTAW-P). Then, the undirect information charactering the weld joint geometry and determining the welding quality, including the weld joint top-side bead width (TSBW) and back-side bead width (BSBW), is computed/estimated by traditional image processing methods and deep convolutional neural networks (CNNs) respectively. Compared with single image source, weld pool image or arc image, the CNN model performs better when taking the 2-channel composite image combined by both as the input and the state-of-the-art accuracy in BSBW prediction with mean square error (MSE) as 0.047 mm2 is obtained. Then, a decision-making strategy is developed to control the welding penetration to meet the quality requirement and applied successfully in various welding conditions. By modeling the weld joint cross section as an ellipse, the developed digital twin is visualized to offer a graphical user interface (GUI) for users perceiving the weld joint growth intuitively and effectively.}
}
@article{OEDA2021804,
title = {Verification of Usefulness of Student Modeling with Real Educational Data using Convex Factorization Machines},
journal = {Procedia Computer Science},
volume = {192},
pages = {804-811},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.083},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921015714},
author = {Shinichi Oeda and Daiki Shimizu},
keywords = {Educational Data Mining, Student Modeling, Convex Factorization Machines, Factorization Machines, Convex Optimization, Recommendation, Intelligent Tutoring Systems},
abstract = {Extracting useful information generated from educational settings involves the application of data mining, machine learning, and statistics to the large amount of electronic data collected by educational systems. To generate better higher learning outcomes using an intelligent tutoring system, such as an e-learning system, it is necessary to more accurately understand the state of student knowledge. The purpose of student modeling is to estimate the students’ skills from log data, such as examination results, and to predict whether or not a student will be able to solve a problem. In this study, we propose a student performance prediction method using convex factorization machines. Factorization machines offer a combination of the advantages of support vector machines and factorization models such as matrix factorization. The results of conventional methods, which predict student performance using factorization machines, exhibited better results than they have before. However, because factorization machines are not convex optimizations, they acquire local minima, which is a disadvantage. Therefore, we used convex factorization machines in order to improve the performance of student modeling predictions.}
}
@article{CALKA2021105786,
title = {Machine-Learning based model order reduction of a biomechanical model of the human tongue},
journal = {Computer Methods and Programs in Biomedicine},
volume = {198},
pages = {105786},
year = {2021},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2020.105786},
url = {https://www.sciencedirect.com/science/article/pii/S0169260720316199},
author = {Maxime Calka and Pascal Perrier and Jacques Ohayon and Christelle Grivot-Boichon and Michel Rochette and Yohan Payan},
keywords = {Real-time simulation, Model Order Reduction, Digital Twins, Human tongue},
abstract = {Background and Objectives: This paper presents the results of a Machine-Learning based Model Order Reduction (MOR) method applied to a complex 3D Finite Element (FE) biomechanical model of the human tongue, in order to create a Digital Twin Model (DTM) that enables real-time simulations. The DTM is designed for future inclusion in a computer assisted protocol for tongue surgery planning. Methods: The proposed method uses an “a posteriori” MOR that allows, from a limited number of simulations with the FE model, to predict in real time mechanical responses of the human tongue to muscle activations. Results: The MOR method is evaluated for simulations associated with separate single tongue muscle activations. It is shown to be able to account with a sub-millimetric spatial accuracy for the non-linear dynamical behavior of the tongue model observed in these simulations. Conclusion: Further evaluations of the MOR method will include tongue movements induced by multiple muscle activations. At this stage our MOR method offers promising perspectives for the use of the tongue model in a clinical context to predict the impact of tongue surgery on tongue mobility. As a long term application, this DTM of the tongue could be used to predict the functional consequences of the surgery in terms of speech production and swallowing.}
}
@article{ASADI2021767,
title = {Machine-Learning Digital Twin of Overlay Metal Deposition for Distortion Control of Panel Structures},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {767-772},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.089},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321008351},
author = {Mahyar Asadi and Michael Fernandez and Majid Tanbakuei Kashani and Mathew Smith},
keywords = {cyber-manufacturing, digital twin, machine learning, metal deposition, overlay pattern, distortion control, adaptive learning},
abstract = {Cyber-manufacturing relies on smart digital-twins of manufacturing processes that can quickly act for making a wise decision. However, the cognitive computing part of the digital-twin becomes time-intensive beyond the requirement of a smart system when it uses simulation tools that solve governing constitutive equations in the form of partial differential equations (PDE). On the other hand, many artificial intelligence (AI) and machine learning (ML) solutions rely on a large data set that does not exist in many manufacturing systems. We build a hybrid digital-twin that takes advantage of an ML-based digital-twin for quick response while gaining fidelity through adaptive learning with a PDE-based digital-twin. We use our hybrid digital-twin for active exploration of various overlay metal deposition patterns in real-time. This tool enables engineers to explore and compare many patterns they need to assess metal deposition scenarios with no delay for computational time.}
}
@article{SHENGLI2021100014,
title = {Is Human Digital Twin possible?},
journal = {Computer Methods and Programs in Biomedicine Update},
volume = {1},
pages = {100014},
year = {2021},
issn = {2666-9900},
doi = {https://doi.org/10.1016/j.cmpbup.2021.100014},
url = {https://www.sciencedirect.com/science/article/pii/S2666990021000136},
author = {Wei Shengli},
keywords = {Human digital twin, Augmented digital twin, Smart healthcare},
abstract = {While Digital Twin finds its applications in many fields, mainly in advanced manufacturing, PLM (Product Lifecycle Management), and smart healthcare, attempt of using Digital Twin in full lifecycle management of human being is discussed. The concept of Augmented Digital Twin is put forward as the basis of the concept of Human Digital Twin (HDT), which is the core idea of the paper. With the experiences of Digital Twin application in smart manufacturing, PLM and smart healthcare, and the development of other related technologies such as Data Mining, Data Fusion Analysis, Artificial Intelligence, especially Deep Learning and Human Computer Science, a conclusion can be drawn naturally, that HDT is an enabling way of full lifecycle health management and it is possible to construct Human Digital Twin, particularly from the technology view. Comparison between Digital Twin and Human Digital Twin demonstrates the possibility. The concept, conceptual model and characteristics of HDT are presented for preparation of its construction. How to construct Human Digital Twin is discussed by proposing Human Digital Twin System Architecture and Implementation Approach. Also, it is pointed out that there will be a long way to go because of not only its extreme complexity, but also so many aspects being involved, especially the security and social ethics problem.}
}
@incollection{RAJ20211,
title = {Chapter One - Demystifying the blockchain technology},
editor = {Shubhani Aggarwal and Neeraj Kumar and Pethuru Raj},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {121},
pages = {1-42},
year = {2021},
booktitle = {The Blockchain Technology for Secure and Smart Applications across Industry Verticals},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2020.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065245820300565},
author = {Pethuru Raj},
keywords = {Blockchain, Smart contracts, Decentralized applications, Artificial intelligence, Digital twins, The Internet of things, Consensus algorithms, Hashing, Machine learning, Cloud computing},
abstract = {The blockchain paradigm is being widely touted by many as the innovative and disruptive one capable of bringing in a few exemplary and elegant transformations in the IT space. As business operations and offerings are substantially enabled through the various crucial accomplishments and advancements in the IT field, business executives across the globe are equally keen to experiment with and embrace this new and futuristic technology to reap a slew of business benefits. Interestingly, blockchain has the inherent potential and promise to bring forth a bevy of strategically sound implications for various industry verticals. Cryptocurrency is one of the finest and foremost applications of the blockchain technology. The supply chain domain is exploring this new phenomenon for realizing some crucial advantages. The IoT discipline is another one capable of attaining a number of distinct benefits out of all the trendsetting improvisations being realized in the blockchain space. This chapter is specially crafted to tell what, why, how, and where the indispensable blockchain paradigm is being used toward real digital transformations.}
}
@article{KIM2020107423,
title = {Damage detection of bottom-set gillnet using Artificial Neural Network},
journal = {Ocean Engineering},
volume = {208},
pages = {107423},
year = {2020},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2020.107423},
url = {https://www.sciencedirect.com/science/article/pii/S0029801820304509},
author = {HanSung Kim and Chungkuk Jin and MooHyun Kim and Kiseon Kim},
keywords = {Digital twins, Artificial neural network (ANN), Machine learning, Gillnet, Damage detection, Real-time monitoring},
abstract = {This paper presents a method for detecting damage of a bottom-set gillnet based on sensor fusion and the Artificial Neural Network (ANN) model. In this regard, time-domain numerical simulations for a 300-m-long bottom-set gillnet with an equivalent-drag-net model are extensively performed. Various wave conditions as well as numerous damaged scenarios are considered in the numerical simulations, and extensive data are collected for the training and testing of the ANN-based machine-learning scheme. In training, representative sea states, net-assembly accelerations, and location-buoy displacements are selected as the input variables. The back-propagation learning algorithm is employed for training to maximize the damage-detection performance. The output of the ANN model is the identification of the type and location of the damaged net. The damage-detection capability is significantly enhanced by employing the moving standard deviation and median filter. The well-trained ANN models are shown to accurately (96% correct) detect the damage of the net even for the sea states not included in training. This study demonstrates that the real-time automatic monitoring of the underwater net systems can be designed by using the digital-twins technology with the applied ANN model and machine-learning scheme for the detection of damages and malfunctions.}
}
@article{RALPH2021335,
title = {MUL 4.0: Systematic Digitalization of a Value Chain from Raw Material to Recycling},
journal = {Procedia Manufacturing},
volume = {55},
pages = {335-342},
year = {2021},
note = {FAIM 2021},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2021.10.047},
url = {https://www.sciencedirect.com/science/article/pii/S2351978921002444},
author = {Benjamin James Ralph and Manuel Woschank and Philipp Miklautsch and Alexander Kaiblinger and Corina Pacher and Marcel Sorger and Helmut Zsifkovits and Martin Stockinger},
keywords = {Digitalization, Industry 4.0, Industrial Logistics, Engineering Education, Digital Twin, Finite Element Analysis, Metal Forming},
abstract = {The digital revolution, also known as Industry 4.0, offers a variety of new technologies and technological concepts for the continuous optimization of production and logistics processes in manufacturing enterprises. Up to now, a multitude of scholars have investigated potential opportunities, barriers, threads, and necessary enablers of Industry 4.0 initiatives. However, most of the recent Industry 4.0 approaches can still not resist practical tests due to their limited view on a small range of relevant topics. This paper introduces the research project ‘MUL4.0’ which aims to digitalize an entire value chain, from raw material to recycling. Based on an action-research-orientated approach, the authors use a multi-case-study design to investigate the potential of digitalization approaches within production and logistics processes. Furthermore, the authors present future research activities and discuss the therefore necessary prerequisites, from a materials science, mechanical engineering, metallurgical, logistics engineering, and management perspective.}
}
@incollection{RAJ2021267,
title = {Chapter Thirteen - Empowering digital twins with blockchain},
editor = {Shubhani Aggarwal and Neeraj Kumar and Pethuru Raj},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {121},
pages = {267-283},
year = {2021},
booktitle = {The Blockchain Technology for Secure and Smart Applications across Industry Verticals},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2020.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0065245820300681},
author = {Pethuru Raj},
keywords = {Blockchain, Smart contracts, Decentralized applications, Artificial intelligence, Digital twins, The Internet of Things, Consensus algorithms, Hashing, Machine learning, Cloud computing},
abstract = {A digital twin is an exact digital/logical/cyber/virtual representation/replica of any tangible physical system or process. And the digital twin runs on a competent IT infrastructure (say, cloud centers). In essence, a digital twin is typically a software program that takes various real-world data about a ground-level physical system as prospective inputs and produces useful outputs in the form of insights. The outputs generally are the value-adding and decision-enabling predictions or simulations of how that physical system will act on those inputs. These help in quickly and easily realizing highly optimized and organized products with less cost and risk. The manufacturing industry had embraced the digital twin technology long time back to be modern in their operations, outputs, and offerings. The distinct contributions of the digital twin paradigm, since then, have gone up significantly with the seamless synchronization with a number of pioneering technologies such as the Internet of Things (IoT), artificial intelligence (AI), big and streaming data analytics, data lakes, software-defined cloud environments, blockchain, etc. With the concept of cyber physical systems (CPS) is being adopted and adapted widely and wisely, complicated yet sophisticated electronics devices at the ground level are being blessed with their corresponding digital twins. The digital twins enable data scientists and system designers to optimize a number of things including process excellence, knowledge discovery and dissemination in time, better system design, robust verification and validation, etc. In the recent past, with the flourishing of the blockchain technology, the scope for digital twins has gone up remarkably. This unique combination is bound to produce additional competencies and fresh use cases for enterprises. This chapter is to explain how they integrate and initiate newer opportunities to be grabbed and gained for a better tomorrow.}
}
@incollection{CLARK2021211,
title = {Chapter 11 - Adaptive Complex Systems: Digital Twins},
editor = {Gurjit Kaur and Pradeep Tomar and Marcus Tanque},
booktitle = {Artificial Intelligence to Solve Pervasive Internet of Things Issues},
publisher = {Academic Press},
pages = {211-238},
year = {2021},
isbn = {978-0-12-818576-6},
doi = {https://doi.org/10.1016/B978-0-12-818576-6.00011-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128185766000113},
author = {Tony Clark and Vinay Kulkarni},
keywords = {Complex systems, digital twins, machine learning, multiagent systems},
abstract = {The design, control, and maintenance of complex systems are a challenge. Often it is difficult to understand the whole-system behavior because the knowledge of component behavior and interaction is uncertain. Such systems are often deployed into dynamic environments whose behavior is liable to change. This chapter reviews the features of complex systems and proposes an approach based on creating digital twins of systems that are capable of adaptation. We discuss technologies for digital twins and propose that the adaptation should be based on machine learning. We provide a simple tutorial example of agents with machine learning using our proposed technology and describe how we have used the technology to build a digital twin for supply chain networks.}
}
@article{BENBARA2020115587,
title = {Bending waves focusing in arbitrary shaped plate-like structures: Application to spatial audio in cars},
journal = {Journal of Sound and Vibration},
volume = {487},
pages = {115587},
year = {2020},
issn = {0022-460X},
doi = {https://doi.org/10.1016/j.jsv.2020.115587},
url = {https://www.sciencedirect.com/science/article/pii/S0022460X20304193},
author = {Nassim Benbara and Marc Rebillat and Nazih Mechbal},
keywords = {Spatial vibration control, Bending wave focusing, Multifunctional materials, Advanced signal processing, Inverse problems, Digital twin},
abstract = {Advanced automotive audio applications are more and more demanding with respect to the visual impact of loudspeakers while still requiring more and more channels for high quality spatial sound rendering. The use of arbitrary plate-like structures driven by electromagnetic actuators or by piezoelectric elements appears as a promising solution to tackle both issues. However, to meet spatial rendering audio constraints (i.e. to be as close as possible to omnidirectional piston-like sources), the generated bending waves must be focused at a given position and to a certain extent within the host plate which can be of arbitrary shape, material, and thickness. Theoretically, this means being able to invert the spatio-temporal wave propagation operator for the generated bending waves to fit a given target shape. There are several methods (modal control, time-reversal, and propagating waves operator inversion) that allow to focus bending waves in a media. However, there is scarce work on their adaption and performances assessment in the context of audio applications. These methods depend differently on the available knowledge of wave propagation in the plate (theoretical, partial spatial or full spatial knowledge) and are here investigated to perform this task. Their performances are assessed with respect to several aspects: geometrical complexity, thickness, and material damping of the host structure, number and type of actuators, position and extent of the focusing area. The various methods are presented in a unified theoretical framework and they are compared by means of two key performance indexes (focus localization error and spatial contrast). An experimental validation on a relevant industrial case is also carried out and learning through a digital twin instead of time consuming experimental data investigated. This work falls within the framework of research which tries to bridge the gap between laboratory research and industrial deployment of this kind of technologies.}
}
@article{VRABIC2021336,
title = {An architecture for sim-to-real and real-to-sim experimentation in robotic systems},
journal = {Procedia CIRP},
volume = {104},
pages = {336-341},
year = {2021},
note = {54th CIRP CMS 2021 - Towards Digitalized Manufacturing 4.0},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.11.057},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121009550},
author = {Rok Vrabič and Gašper Škulj and Andreja Malus and Dominik Kozjek and Luka Selak and Drago Bračun and Primož Podržaj},
keywords = {robotics, simulation, machine learning, reinforcement learning, digital twin},
abstract = {Research in the area of robotic systems has greatly benefited from the use of simulation models. Recent approaches allow the transfer of developed algorithms from simulation to reality (sim-to-real) and increasingly accurate representations of real systems as simulation models (real-to-sim). The paper presents an architecture based on open software that supports simultaneous experiments on real robots and their simulation models. Two illustrative examples are shown: a digital twin of an industrial robot and a sim-to-real transfer in an autonomous mobile robot system. The possibilities of future research on the interaction between robotic systems and their simulation models are discussed.}
}
@article{WANG2020100717,
title = {Comparison of the effectiveness of Taiwanese college and high school students participating in creative contests},
journal = {Thinking Skills and Creativity},
volume = {38},
pages = {100717},
year = {2020},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2020.100717},
url = {https://www.sciencedirect.com/science/article/pii/S1871187120301917},
author = {Yu-Hung Wang and Mei-Chen Chang and Jia-Ru Liou},
keywords = {Creative contest, Motivation, Team composition, Knowledge},
abstract = {This study investigated the college students (N = 725) and high school students (N = 585) that participated in the National Energy Technology Creative Contest (NETCC) of Taiwan. AMOS analysis was performed to establish a model of students’ performances in creative contests and t-test was conducted to analyze and compare the differences in variables between the two groups of students in the model. The findings of this study are as follows: (1) the research model fits the model of college and high school students’ performances in creative contests; (2) for college students (Model 1), their performances in creative contests are directly affected by team composition and knowledge variables, and team composition variables can also directly affect knowledge variables, (3) for high school students (Model 2), their performances in creative contest are directly affected by team composition and knowledge variables, but there is no direct correlation between team composition variables and knowledge variables, (4) comparison and analysis of the mean of the variables that affect the students’ performances in creative contests show that, for most variables, the mean of high school students is significantly higher than that of college students.}
}
@incollection{VALEEV2021159,
title = {Chapter 5 - Simulation technologies for process safety},
editor = {Sagit Valeev and Natalya Kondratyeva},
booktitle = {Process Safety and Big Data},
publisher = {Elsevier},
pages = {159-208},
year = {2021},
isbn = {978-0-12-822066-5},
doi = {https://doi.org/10.1016/B978-0-12-822066-5.00006-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128220665000066},
author = {Sagit Valeev and Natalya Kondratyeva},
keywords = {Simulation, Accuracy, Algorithms, Digital twin, Aggregated model, Hierarchical system of models, Real time modeling},
abstract = {The chapter discusses the features of the application of technologies of simulation based on big data to provide process safety. One of the important problems during the simulation is ensuring the accuracy of simulation models and finding potential sources of errors. Algorithms for modeling input random effects are based on the Monte Carlo method. Markov processes are considered as the most common method for modeling stochastic systems, in particular, in risk management. The following discusses the possibilities of using digital twins in process safety management. Constructing a hierarchical system of models within the framework of digital twins is a complex task, as well as solving the problem of reducing accuracy when complicating models. The relevance of real-time modeling of chemical processes while ensuring safety is substantiated. Edge computing is an effective tool for building digital twins in real time mode. Extreme learning machines are considered as modern data analysis tools based on statistical models. In conclusion, the role of big data in constructing and analyzing the results of simulation models is considered.}
}
@article{LUO2020107451,
title = {Every node counts: Self-ensembling graph convolutional networks for semi-supervised learning},
journal = {Pattern Recognition},
volume = {106},
pages = {107451},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107451},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320302545},
author = {Yawei Luo and Rongrong Ji and Tao Guan and Junqing Yu and Ping Liu and Yi Yang},
keywords = {Teacher-student models, Self-ensemble learning, Graph convolutional networks, Semi-supervised learning},
abstract = {Graph convolutional network (GCN) provides a powerful means for graph-based semi-supervised tasks. However, as a localized first-order approximation of spectral graph convolution, the classic GCN can not take full advantage of unlabeled data, especially when the unlabeled node is far from labeled ones. To capitalize on the information from unlabeled nodes to boost the training for GCN, we propose a novel framework named Self-Ensembling GCN (SEGCN), which marries GCN with Mean Teacher – a powerful self-ensemble learning mechanism for semi-supervised task. SEGCN contains a student model and a teacher model. As a student, it not only learns to correctly classify the labeled nodes, but also tries to be consistent with the teacher on unlabeled nodes in more challenging situations, such as a high dropout rate and graph corrosion. As a teacher, it averages the student model weights and generates more accurate predictions to lead the student. In such a mutual-promoting process, both labeled and unlabeled samples can be fully utilized for backpropagating effective gradients to train GCN. In a variety of semi-supervised classification benchmarks, i.e. Citeseer, Cora, Pubmed and NELL, we validate that the proposed method matches the state of the arts in the classification accuracy. The code is publicly available at https://github.com/RoyalVane/SEGCN.}
}
@article{OLUWASEGUN20202262,
title = {The application of machine learning for the prognostics and health management of control element drive system},
journal = {Nuclear Engineering and Technology},
volume = {52},
number = {10},
pages = {2262-2273},
year = {2020},
issn = {1738-5733},
doi = {https://doi.org/10.1016/j.net.2020.03.028},
url = {https://www.sciencedirect.com/science/article/pii/S1738573319308654},
author = {Adebena Oluwasegun and Jae-Cheon Jung},
keywords = {Digital twin, PHM, Machine learning, Nuclear power plant},
abstract = {Digital twin technology can provide significant value for the prognostics and health management (PHM) of critical plant components by improving insight into system design and operating conditions. Digital twinning of systems can be utilized for anomaly detection, diagnosis and the estimation of the system's remaining useful life in order to optimize operations and maintenance processes in a nuclear plant. In this regard, a conceptual framework for the application of digital twin technology for the prognosis of Control Element Drive Mechanism (CEDM), and a data-driven approach to anomaly detection using coil current profile are presented in this study. Health management of plant components can capitalize on the data and signals that are already recorded as part of the monitored parameters of the plant's instrumentation and control systems. This work is focused on the development of machine learning algorithm and workflow for the analysis of the CEDM using the recorded coil current data. The workflow involves features extraction from the coil-current profile and consequently performing both clustering and classification algorithms. This approach provides an opportunity for health monitoring in support of condition-based predictive maintenance optimization and in the development of the CEDM digital twin model for improved plant safety and availability.}
}
@article{ZHOU202122,
title = {Digital-twin-driven geometric optimization of centrifugal impeller with free-form blades for five-axis flank milling},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {22-35},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301096},
author = {Yu Zhou and Tong Xing and Yue Song and Yajing Li and Xuefeng Zhu and Guo Li and Shuiting Ding},
keywords = {Smart manufacturing, Digital twin (DT), Centrifugal impeller (CI), Ruled-surface blade, Aerodynamic optimization, Flank milling, Machining experiment, Performance test},
abstract = {Centrifugal impeller (CI) manufacturing is moving toward a new paradigm, with the objective to improve efficiency and competitiveness through Industry 4.0 and smart manufacturing. Making a CI developable and ruled has become a crucial technology to obviously improve machining efficiency and save costs although it may bring negative effects on aerodynamic performance accordingly. Hence, it is extremely challenging to consider and balance both machinability and aerodynamic performance in the process of CI geometric optimization. Digital Twin (DT) provides an attractive option for the integrated design and manufacturing due to multi-dimension and real-time. This paper breaks traditional procedures and presents a DT-based optimization strategy on the consideration of both machining efficiency and aerodynamic performance, as well as builds a reified 5-dimensional DT model. The virtual model consists of three sub-functional modules, including geometric modeling, machining optimization and aerodynamic performance evaluation. A tool-path generation method for CI five-axis flank milling is proposed to improve machining efficiency. The negative influences on aerodynamic performance and internal flow field are simulated and analyzed. Reinforce Learning is introduced to determine the optimization decision-making. Machining experiment and performance test with respect to various CI workpieces are conducted to provide immediate feedback to DT model. Real world and virtual world are combined to make CI geometry dynamically updated and iteratively optimized, which is desirable and significative to effectively shorten cycles and save costs in CI development.}
}
@article{QIE2021135,
title = {A function-oriented surface reconstruction framework for reverse engineering},
journal = {CIRP Annals},
volume = {70},
number = {1},
pages = {135-138},
year = {2021},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2021.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0007850621000408},
author = {Yifan Qie and Sebastian Bickel and Sandro Wartzack and Benjamin Schleich and Nabil Anwer},
keywords = {Reverse engineering, Machine learning, Data-driven design},
abstract = {Reverse engineering can be considered as the methodological process of analyzing and reconstructing a digital model of a physical asset. It has gained considerable interest with the advent of sophisticated sensors and data processing technologies hence becoming an important enabler for the product digital twin. However, while existing approaches to reverse engineering focus on the mere geometric reconstruction, this paper presents a novel paradigm called function-oriented surface reconstruction, that is capable of reconstructing the underlying part and surface function and thus outperforms existing methods. The applicability of the presented method is demonstrated through a case study of a gearbox.}
}
@article{BEKELE2021420,
title = {Physics-informed deep learning for one-dimensional consolidation},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
volume = {13},
number = {2},
pages = {420-430},
year = {2021},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2020.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1674775520301384},
author = {Yared W. Bekele},
keywords = {Physics-informed deep learning, Consolidation, Forward problems, Inverse problems},
abstract = {Neural networks with physical governing equations as constraints have recently created a new trend in machine learning research. In this context, a review of related research is first presented and discussed. The potential offered by such physics-informed deep learning models for computations in geomechanics is demonstrated by application to one-dimensional (1D) consolidation. The governing equation for 1D problems is applied as a constraint in the deep learning model. The deep learning model relies on automatic differentiation for applying the governing equation as a constraint, based on the mathematical approximations established by the neural network. The total loss is measured as a combination of the training loss (based on analytical and model predicted solutions) and the constraint loss (a requirement to satisfy the governing equation). Two classes of problems are considered: forward and inverse problems. The forward problems demonstrate the performance of a physically constrained neural network model in predicting solutions for 1D consolidation problems. Inverse problems show prediction of the coefficient of consolidation. Terzaghi’s problem, with varying boundary conditions, is used as a numerical example and the deep learning model shows a remarkable performance in both the forward and inverse problems. While the application demonstrated here is a simple 1D consolidation problem, such a deep learning model integrated with a physical law has significant implications for use in, such as, faster real-time numerical prediction for digital twins, numerical model reproducibility and constitutive model parameter optimization.}
}
@article{WU2020100016,
title = {Battery digital twins: Perspectives on the fusion of models, data and artificial intelligence for smart battery management systems},
journal = {Energy and AI},
volume = {1},
pages = {100016},
year = {2020},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2020.100016},
url = {https://www.sciencedirect.com/science/article/pii/S2666546820300161},
author = {Billy Wu and W. Dhammika Widanage and Shichun Yang and Xinhua Liu},
abstract = {Effective management of lithium-ion batteries is a key enabler for a low carbon future, with applications including electric vehicles and grid scale energy storage. The lifetime of these devices depends greatly on the materials used, the system design and the operating conditions. This complexity has therefore made real-world control of battery systems challenging. However, with the recent advances in understanding battery degradation, modelling tools and diagnostics, there is an opportunity to fuse this knowledge with emerging machine learning techniques towards creating a battery digital twin. In this cyber-physical system, there is a close interaction between a physical and digital embodiment of a battery, which enables smarter control and longer lifetime. This perspectives paper thus presents the state-of-the-art in battery modelling, in-vehicle diagnostic tools, data driven modelling approaches, and how these elements can be combined in a framework for creating a battery digital twin. The challenges, emerging techniques and perspective comments provided here, will enable scientists and engineers from industry and academia with a framework towards more intelligent and interconnected battery management in the future.}
}
@article{ZHAO2021105183,
title = {IoT and digital twin enabled smart tracking for safety management},
journal = {Computers & Operations Research},
volume = {128},
pages = {105183},
year = {2021},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2020.105183},
url = {https://www.sciencedirect.com/science/article/pii/S0305054820303002},
author = {Zhiheng Zhao and Leidi Shen and Chen Yang and Wei Wu and Mengdi Zhang and George Q. Huang},
keywords = {Digital twin, Internet of things, Abnormal state detection, Indoor positioning, Safety management},
abstract = {Modern warehousing systems for fresh and cold-keeping storage, have presented characteristics of complex operation procedures, accelerated operating pace, and high labour intensity. Thus, the working environment has become complicated and hazardous. Two recent fatal accidents that occurred in cold warehouses have shifted wide focus to safety management. The invisibility of operators’ status and location causes late responsiveness for rescuing. This paper first proposes an IoT and digital twin-enabled tracking solution framework for safety management. Then an indoor safety tracking mechanism for detecting motionless behaviour and self-learning genetic positioning is developed for recognizing the abnormal condition and obtaining precise location information in a real-time manner. A real-life case study with physical and cyber world implementation is conducted to demonstrate the feasibility and effectiveness of our proposed techniques. The results show that the detection of abnormal motionless behaviour is fulfilled, and the indoor positioning algorithm with self-learning ability not only achieves high accuracy up to 96.5% but also ensures the long-term use through adaptation.}
}
@article{RAGHEB2021108426,
title = {Effects of extensible modelling on composite riser mechanical responses},
journal = {Ocean Engineering},
volume = {220},
pages = {108426},
year = {2021},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2020.108426},
url = {https://www.sciencedirect.com/science/article/pii/S0029801820313330},
author = {Hossam Ragheb and Adam Sobey},
keywords = {Composite risers, Cable dynamics, Time domain, Benchmarking},
abstract = {The change from steel risers to composites comes with uncertainties that led to large safety factors. One area of uncertainty is the predicted response and stresses derived from commercial packages that are based on formulations that assume in-extensible riser. However, composite pipes exhibit a lower axial stiffness and therefore the velocity of the axial waves will change with a corresponding change in dynamic response. To determine the effect of this assumption, this paper assesses the effect of extensibility on the time-domain response. It is found that the in-extensible model predicts 3 times the number of high frequency tension cycles in the 20 kN tension range. To determine the impact of this change on the stress, the accuracy of available composite pipe models is benchmarked using shell, continuum-shell and solid elements. The quadratic and continuum-shell elements provide a maximum percentage difference of 4% compared to solid elements but the continuum-shell is selected as it has a lower computational cost. The response from the extensible and in-extensible models are input into the pipe model, they provide similar Tsai-Wu failure factors, alleviating concerns when modelling the strength. However, the change in dynamics remains a concern for other applications such as machine-learning or digital-twins.}
}
@article{ZIMMERMAN2020102746,
title = {Factors influencing hand hygiene practice of nursing students: A descriptive, mixed-methods study},
journal = {Nurse Education in Practice},
volume = {44},
pages = {102746},
year = {2020},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2020.102746},
url = {https://www.sciencedirect.com/science/article/pii/S1471595318306565},
author = {Peta-Anne P. Zimmerman and Ishtar Sladdin and Ramon Zenel Shaban and Julia Gilbert and Lynne Brown},
keywords = {Undergraduate nursing, Infection prevention and control, Hand hygiene},
abstract = {Developing nursing students' knowledge and practice of infection prevention and control (IPC) is fundamental to safe healthcare. A two-phase descriptive, mixed-method study conducted within a Bachelor of Nursing program at an Australian university aimed to explore: (i) theoretical knowledge of IPC, highlighting hand hygiene, of nursing students and; (ii) nursing students' and clinical facilitators' perceptions of factors influencing these practices during clinical placement. Phase One utilised an anonymous validated questionnaire assessing students' knowledge; identifying variables influencing students' IPC practices, subjected to descriptive and inferential analysis. Phase Two were semi-structured interviews exploring clinical facilitators' experiences/perceptions of students during clinical placement, analysed thematically. Students' demonstrated satisfactory knowledge of IPC in their second and third year, but clinical facilitators perceived that. students lacked awareness of the importance of these practices. Five themes arose from the interviews: (i) understanding workplace culture; (ii) students' modelling local behaviour; (iii) enhancing and consolidating knowledge for practice; (iv) adjusting to practice reality and; (v) accessing additional hand hygiene resources. Factors specific to workplace setting and culture were perceived to influence nursing students' socialisation. Future practice/education strategies could address these factors by ensuring students receive adequate supervision during clinical placement, and having strong advocates/role models present in the workplace.}
}
@article{WANG2021107934,
title = {Advanced fault diagnosis method for nuclear power plant based on convolutional gated recurrent network and enhanced particle swarm optimization},
journal = {Annals of Nuclear Energy},
volume = {151},
pages = {107934},
year = {2021},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2020.107934},
url = {https://www.sciencedirect.com/science/article/pii/S0306454920306307},
author = {Hang Wang and Min-jun Peng and Abiodun Ayodeji and Hong Xia and Xiao-kun Wang and Zi-kang Li},
keywords = {Fault diagnosis, Deep learning, GRU network, Convolutional kernel, Particle swarm optimization},
abstract = {A predictive approach to fault diagnosis in complex systems such as the Nuclear power plant (NPP) is becoming popular because of the efficiency and accuracy it presents. However, there is still a huge gap between the proposed fault diagnosis techniques and engineering applications. To further optimize the fault diagnosis route and encourage real-time application, this paper presents a highly accurate and adaptable fault diagnosis technique based on the convolutional gated recurrent unit (CGRU) and enhanced particle swarm optimization (EPSO). Stacking convolutional kernel and GRU results in a model that speedily extract the local characteristics and learn the time-series information. The EPSO is utilized to adaptively search for optimal hyper-parameters for the CGRU. Finally, the accuracy is evaluated on a dataset obtained from experiments, and comparative analysis of the proposed model with existing architectures and models are presented. Relevant research results that show the usefulness of the proposed model are also presented, which highlights the enhanced intelligence and information level achieved in the NPP fault diagnosis.}
}
@article{LIU2020106,
title = {Adaptive multi-teacher multi-level knowledge distillation},
journal = {Neurocomputing},
volume = {415},
pages = {106-113},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.048},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220311565},
author = {Yuang Liu and Wei Zhang and Jun Wang},
keywords = {Knowledge distillation, Adaptive learning, Multi-teacher},
abstract = {Knowledge distillation (KD) is an effective learning paradigm for improving the performance of lightweight student networks by utilizing additional supervision knowledge distilled from teacher networks. Most pioneering studies either learn from only a single teacher in their distillation learning methods, neglecting the potential that a student can learn from multiple teachers simultaneously, or simply treat each teacher to be equally important, unable to reveal the different importance of teachers for specific examples. To bridge this gap, we propose a novel adaptive multi-teacher multi-level knowledge distillation learning framework (AMTML-KD), which consists two novel insights: (i) associating each teacher with a latent representation to adaptively learn instance-level teacher importance weights which are leveraged for acquiring integrated soft-targets (high-level knowledge) and (ii) enabling the intermediate-level hints (intermediate-level knowledge) to be gathered from multiple teachers by the proposed multi-group hint strategy. As such, a student model can learn multi-level knowledge from multiple teachers through AMTML-KD. Extensive results on publicly available datasets demonstrate the proposed learning framework ensures student to achieve improved performance than strong competitors.}
}
@article{TAN2021100032,
title = {Developing a gamified AI-enabled online learning application to improve students’ perception of university physics},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100032},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100032},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X21000266},
author = {Da Yang Tan and Chin Wei Cheah},
keywords = {Intelligent tutoring systems, Gamification, University physics, Self-directed learning},
abstract = {This article discusses the current progress of the on-going design efforts in creating an AI-enabled gamified web-based online learning application in the university introductory physics courses. The application aims to cater to the learning needs of students with diversity of the background, particularly students with little or weak background. The overall design architecture and principles are discussed, focusing on the rationale and design of the gamified elements that have been incorporated within the application, namely: (i) incremental difficulties, (ii) points and streaks, (iii) leaderboard, and (iv) gamified and animated user interface. Particularly, the gamified elements are considered through the lens of the ‘Head, Hands, and Heart’ of the students, with the objective to first encourage and motivate participation, stimulate practice, and strengthen the students’ domain knowledge of physics. In this article, an architecture to incorporate AI program into the web-based gamification platform by including various AI models (learner model, pedagogy model and domain model) is proposed. With the architecture, we aim to create a personalized tutor that provide effective and unique learning experience to help a learner achieve learning objectives. The AI enabled gamification platform also serves as an efficient feedback tool to teacher for optimization and redesigning of curriculum to best suit the need of individual learner.}
}
@article{MASHALY2021299,
title = {Connecting the Twins: A Review on Digital Twin Technology & its Networking Requirements},
journal = {Procedia Computer Science},
volume = {184},
pages = {299-305},
year = {2021},
note = {The 12th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 4th International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.03.039},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921006694},
author = {Maggie Mashaly},
keywords = {Digital Twin, Digital Transformation, Data Analytics, Artificial Intelligence, Real-time Communications, Network Requirements},
abstract = {Digital twin technology can be considered as an innovation accelerator. By providing a live copy of physical systems, digital twins bring to the table numerous advantages such as accelerated business processes, enhanced productivity, and faster innovation with reduced costs. For these numerous advantages digital twin is an ideal solution for several problems in domains such as Industry 4.0, education, healthcare and smart cities. However, to make sure the digital twin contributes effectively to these domains by representing a synchronized real-time copy of the physical system, the network connecting the physical and digital twins should fulfill a set of requirements such as low latency of real-time communication, data security and quality. This paper provides an overview on the technology of digital twin and its application domains with a detailed discussion on its networking requirements and proposed enabling technologies to fulfill them.}
}
@article{FANG2020100955,
title = {A 2020 perspective on “A generalized stereotype learning approach and its instantiation in trust modeling”},
journal = {Electronic Commerce Research and Applications},
volume = {40},
pages = {100955},
year = {2020},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2020.100955},
url = {https://www.sciencedirect.com/science/article/pii/S1567422320300326},
author = {Hui Fang and Jie Zhang and Murat Sensoy},
keywords = {Data management, Few-shot learning, Learning with limited data, Recommender systems, User modeling, User profiling},
abstract = {Owing to the rapid increase of user data and development of machine learning techniques, user modeling has been explored in depth and exploited by both academia and industry. It has prominent impacts in e-commerce-related applications by facilitating users’ experience in online platforms and supporting business organizations’ decision-making. Among all the techniques and applications, user profiling and recommender systems are two representative and effective ones, which have also obtained growing attention. In view of its wide applications, researchers and practitioners should improve user modeling from two perspectives: (1) more effort should be devoted to obtain more user data via techniques like sensing devices and develop more effective ways to manage complex data; and (2) improving the ability of learning from a limited number of data samples (e.g., few-shot learning) has become an increasingly hot topic for researchers.}
}
@article{QU2020113857,
title = {Lithium-ion battery performance degradation evaluation in dynamic operating conditions based on a digital twin model},
journal = {Microelectronics Reliability},
volume = {114},
pages = {113857},
year = {2020},
note = {31st European Symposium on Reliability of Electron Devices, Failure Physics and Analysis, ESREF 2020},
issn = {0026-2714},
doi = {https://doi.org/10.1016/j.microrel.2020.113857},
url = {https://www.sciencedirect.com/science/article/pii/S0026271420304765},
author = {X. Qu and Y. Song and D. Liu and X. Cui and Y. Peng},
abstract = {The performance of lithium-ion batteries degrades over time. Evaluating the performance degradation for lithium-ion batteries is essential to ensure the operational reliability and reduces the risk of host-system downtime. The battery capacity that is obtained by completely charging and discharging a battery cell, directly reflects the performance of a lithium-ion battery. But in practical applications, the battery is dynamically charged and discharged. This makes it difficult to measure the actual capacity and further evaluate battery performance degradation to ensure the battery operating safety. To address this challenging issue, this paper proposes a performance degradation evaluation model by estimating the battery actual capacity in dynamic operating conditions. A health indicator (HI) is extracted from the measurable parameters to reflect the battery performance degradation. A battery digital twin model that describes the relationship between the cell voltage and the cell state-of-charge (SOC) are modelled by the long short-term memory (LSTM) algorithm, which takes the HI as a temporal measurement. The battery actual capacity can be obtained by virtually completely discharging this digital twin model. The experimental results illustrate the potential of the proposed method applying in dynamic operating conditions.}
}
@article{MUELLERZHANG2021408,
title = {Integrated Planning and Scheduling for Customized Production using Digital Twins and Reinforcement Learning},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {408-413},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.046},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321007631},
author = {Zai Mueller-Zhang and Pablo {Oliveira Antonino} and Thomas Kuhn},
keywords = {Digital Twin, Reinforcement Learning, Deep-Q-Network, Integrated Planning, Scheduling},
abstract = {For customized production in small lot-sizes, traditional production plants have to be reconfigured manually multiple times to be adapted to variable order changes, what significantly increases the production costs. One of the goals of Industry 4.0 is to enable flexible production, allowing for customer-specific production or even production with lot size 1 in order to react dynamically to changes in production orders. All of this with increased quality parameters such as optimized use of machines, conveyor belts and raw materials, which ultimately leads to optimized resource utilization and cost-efficiency. To address this challenge, in this paper, we present a digital twin based self-learning process planning approach using Deep-Q-Network that is capable of identifying optimized process plans and workflows for the simultaneous production of personalized products. We have evaluated our approach on a virtual aluminum cold milling factory from the SMS Group, in the context of the BaSys 4 project. The goal of the evaluation was to provide evidence that the proposed approach is able to handle large problem space effectively. Our approach ensures the efficiency of the personalized production and the adaptivity of the production system.}
}
@article{OGUNSANYA2021427,
title = {In-situ Droplet Monitoring of Inkjet 3D Printing Process using Image Analysis and Machine Learning Models},
journal = {Procedia Manufacturing},
volume = {53},
pages = {427-434},
year = {2021},
note = {49th SME North American Manufacturing Research Conference (NAMRC 49, 2021)},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2021.06.045},
url = {https://www.sciencedirect.com/science/article/pii/S2351978921000524},
author = {Michael Ogunsanya and Joan Isichei and Santosh Kumar Parupelli and Salil Desai and Yi Cai},
keywords = {additive manufacturing, inkjet 3D Printing, image analysis, machine learning, neural network},
abstract = {Additive manufacturing (AM) has yielded major innovations in the electronics, biomedical and energy domains. One of the AM techniques which has witnessed widespread use is the inkjet 3D printing (IJP). The IJP process fabricates parts by depositing colloidal liquid droplets on substrates. Despite its advantages, variations in input process parameters and fluid properties can have a profound impact on the print quality. This paper aims to address this issue by presenting a novel vision-based approach for in-situ monitoring of droplet formation. Further, a machine learning model was used to study the relationship between droplet attributes and droplet modes. A drop watcher camera was used to capture a sequence of videos obtained from different combinations of voltage and frequency. Custom source code was developed using python libraries to capture variations in droplet attributes (droplet size, velocity, aspect ratio, and presence of satellites) and their impact on the droplet modes (normal, satellite, and no-droplet) using computer vision. A backpropagation neural network mode (BPNN) was applied, with the droplet features as inputs, to classify output droplet modes. The BPNN classified droplet modes with 90% (high) accuracy. This research forms the basis for future development of digital twin model of inkjet 3D printing towards predictive analysis and process optimization.}
}
@incollection{ODELL20213,
title = {1 - The evolution of AI and the human-machine interface as a manager in Industry 4.0},
editor = {Hamid Jahankhani and Liam M. O’Dell and Gordon Bowen and Daniel Hagan and Arshad Jamal},
booktitle = {Strategy, Leadership, and AI in the Cyber Ecosystem},
publisher = {Academic Press},
pages = {3-22},
year = {2021},
isbn = {978-0-12-821442-8},
doi = {https://doi.org/10.1016/B978-0-12-821442-8.00015-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012821442800015X},
author = {Liam M. O’Dell and Hamid Jahankhani},
keywords = {Artificial intelligence, Big data, Machine learning, Digital twin, Ethics and governance, Knowledge competency areas and frameworks},
abstract = {The role of project management is changing dramatically in the backdrop of Industry 4.0 and the digital revolution. This exciting transformation is taking place in the next few years whilst embracing artificial intelligence (AI) technology into the body of the knowledge competencies. With this intelligence explosion, the influence of AI technology and the key themes of machine learning, big data, and digital twin are evolving, creating the possibility of a cyber physical project professional. This brings with it further issues around ethics and governance with the development and use of AI technology. The aim of this chapter is to provides a useful initial insight whilst assisting the project management professional to gain further understanding of how AI innovation is entering the workplace and how to potentially engage with AI. In addition, this study will hopefully stimulate future researchers to develop ideas for innovation in the use of AI and the cyberphysical digital twin coworking relationships within the project management profession.}
}
@article{VASANTHAN20217,
title = {Combining Supervised Learning and Digital Twin for Autonomous Path-planning⁎⁎This work was sponsored by the Research Council of Norway through the Centre of Excellence funding scheme, project number 223254, AMOS.},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {16},
pages = {7-15},
year = {2021},
note = {13th IFAC Conference on Control Applications in Marine Systems, Robotics, and Vehicles CAMS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.10.066},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321014683},
author = {Chanjei Vasanthan and Dong T. Nguyen},
keywords = {Autonomy, Path-planning, Supervised learning, Digital twin, Maneuvering, Collision avoidance, COLREGs},
abstract = {Over the last decade, the evolution of autonomous automobiles based on artificial intelligence has increased rapidly with significant success. Naturally, this has caught the interest of the maritime industry and the development of autonomous vessels. However, unlike the highway, the ocean is considered a complex environment carrying unpredictable environmental forces, such as current, waves and wind-condition. For autonomous path-following and path-planning, particularly within the machine learning-field, Deep Reinforcement Learning (DRL) have generally been the favored approach. This follows from the fact that resulting models have demonstrated staggering performance. However, for practical implementations, Deep learning-based models are generally considered black box-solutions, and hence often introduce uncertainties in the operating domain. Therefore, in this paper an autonomous path-planner based on Supervised learning is proposed. Different Supervised learning models were investigated, and Gradient Boosting Regressor was found to be the most adequate model based on hyperparameter-tuning. The model was developed on constraints proposed by the class society DNV GL combined with International Regulations for Preventing Collision at Sea (COLREGs) rule 14 for collision-avoidance. Following this, the model was trained to design a suitable path based on parametrization of a cubic Bézier curve. To follow the parametrized path, a maneuvering-controller derived from the Maneuvering problem presented in Skjetne (2005) was applied. However, a drawback of Supervised learning is the necessity for large-scale training data. Hence, a digital twin of the own vessel was developed and utilized to generate sufficient training data. To demonstrate the performance of the autonomous path-planner, a number of simulation scenarios were introduced.}
}
@article{RAGAZZINI2021743,
title = {A Digital Twin-based Predictive Strategy for Workload Control},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {743-748},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.183},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321009538},
author = {Lorenzo Ragazzini and Elisa Negri and Marco Macchi},
keywords = {Digital Twin, Production Control, Workload Control, Order Release, Card Controlling, Reinforcement Learning},
abstract = {The paper aims at proposing a card controlling model to improve the standard CONWIP procedure, granting a similar system throughput while reducing Work In Progress (WIP) levels. To achieve this objective, the authors developed a Digital Twin-based production control system including a reinforcement learning algorithm (i.e. Q-Learning). The Digital Twin is responsible for short term predictions of the behavior of the system aimed at a what-if analysis with different numbers of cards. As there is lack of evidence of research related to Digital Twin applications for production control and for order release systems in particular, we aim at proposing this as an initial work to start the exploration of problems in this control area. The proposed model has been tested both in a Job Shop and in a Flow Shop systems with promising results.}
}
@article{MASCHLER2021127,
title = {Transfer learning as an enabler of the intelligent digital twin},
journal = {Procedia CIRP},
volume = {100},
pages = {127-132},
year = {2021},
note = {31st CIRP Design Conference 2021 (CIRP Design 2021)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121004790},
author = {Benjamin Maschler and Dominik Braun and Nasser Jazdi and Michael Weyrich},
keywords = {Case Study, Deep Learning, Industrial Transfer Learning, Intelligent Digital Twin, Lifecycle, Production Engineering, Qualitative Analysis, Sim2Real Transfer, Simulation, Use Cases},
abstract = {Digital Twins have been described as beneficial in many areas, such as virtual commissioning, fault prediction or reconfiguration planning. Equipping Digital Twins with artificial intelligence functionalities can greatly expand those beneficial applications or open up altogether new areas of application, among them cross-phase industrial transfer learning. In the context of machine learning, transfer learning represents a set of approaches that enhance learning new tasks based upon previously acquired knowledge. Here, knowledge is transferred from one lifecycle phase to another in order to reduce the amount of data or time needed to train a machine learning algorithm. Looking at common challenges in developing and deploying industrial machinery with deep learning functionalities, embracing this concept would offer several advantages: Using an intelligent Digital Twin, learning algorithms can be designed, configured and tested in the design phase before the physical system exists and real data can be collected. Once real data becomes available, the algorithms must merely be fine-tuned, significantly speeding up commissioning and reducing the probability of costly modifications. Furthermore, using the Digital Twin’s simulation capabilities virtually injecting rare faults in order to train an algorithm’s response or using reinforcement learning, e.g. to teach a robot, become practically feasible. This article presents several cross-phase industrial transfer learning use cases utilizing intelligent Digital Twins. A real cyber physical production system consisting of an automated welding machine and an automated guided vehicle equipped with a robot arm is used to illustrate the respective benefits.}
}
@article{HWANGBO2020106910,
title = {Design of control framework based on deep reinforcement learning and Monte-Carlo sampling in downstream separation},
journal = {Computers & Chemical Engineering},
volume = {140},
pages = {106910},
year = {2020},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2020.106910},
url = {https://www.sciencedirect.com/science/article/pii/S0098135419310750},
author = {Soonho Hwangbo and Gürkan Sin},
keywords = {Liquid-liquid extraction column, Deep reinforcement learning, Monte-Carlo sampling, Control system, API production, Biopharmaceuticals},
abstract = {This paper proposes a systematic framework to develop deep reinforcement learning (RL)-based algorithms for control system of downstream separation in biopharmaceutical process as follows. First, a simulation model as a digital twin is built and Monte-Carlo sampling generates substantial amounts of samples considering disturbances. Second, the deep RL-based control system is designed and the optimization subject to sample datasets is conducted. The methodology is implemented in a prototype software and relevant codes are shared by Mendeley Data. The proposed model is successfully applied to control the liquid-liquid extraction column for the recovery of fusidic acid as part of downstream processing. The resulting deep RL algorithm provides an operation performance with a better API recovery yield (32 % higher than open loop operation) and lower deviations (23 % lower than open loop operation) against disturbances.}
}
@article{ZOHDI2020112907,
title = {A machine-learning framework for rapid adaptive digital-twin based fire-propagation simulation in complex environments},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {363},
pages = {112907},
year = {2020},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2020.112907},
url = {https://www.sciencedirect.com/science/article/pii/S0045782520300906},
author = {T.I. Zohdi},
keywords = {Fire-propagation, Ember flow, Digital-twin, Machine-learning algorithms},
abstract = {The objective of this work is to illustrate how to algorithmically integrate Machine-Learning Algorithms (MLA’s) with multistage/multicomponent fire spread models. In order to tangibly illustrate this process, this work develops a framework for a specific model problem combining: (I) a meshless discrete element “submodel” that tracks the trajectory of airborne hot particles/embers, subject to prevailing wind velocities and updrafts, (II) a topographical “submodel” of the ambient combustible material whereby airborne embers that make contact are allowed to start secondary fires (if conditions are appropriate), combined with ground-based surface spread and burn rates for generating new embers, new updrafts (due to hot air), etc., and (III) a Machine-Learning Algorithm to rapidly ascertain the multi-submodel system parameters that force the overall model to match observations. The submodels compute both ground and airborne hot-ember driven fire propagation, as well as subsequent distribution of debris/soot, which is important for air-quality assessment. The overall framework is designed for use in digital twin technology, which refers to an adaptive digital replica of a physical system, whereby model updates are continuously in near real-time. This necessitates a rapid simulation paradigm that can easily interface with telecommunications, cameras and sensors. The presented framework is designed to run quickly on laptops and hand held devices, with the guiding principle being to make it potentially useful for first-responders in real-time.}
}
@article{AI20201,
title = {Distributed stochastic configuration networks with cooperative learning paradigm},
journal = {Information Sciences},
volume = {540},
pages = {1-16},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.05.112},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520305375},
author = {Wu Ai and Dianhui Wang},
keywords = {Stochastic configuration networks, Randomized neural networks, Alternating direction method of multipliers, Distributed learning},
abstract = {As a new category of randomized neural networks (RNNs), stochastic configuration networks (SCNs) have demonstrated great potential for data analytics. Unlike conventional randomized learning techniques, e.g., random vector functional-link (RVFL) networks, SCNs provide a stochastic configuration mechanism on the assignment of input parameters which guarantees the universal approximation capability of a resulting learner model. In this paper, a distributed version of SCN is developed for decentralized datasets in cooperative learning paradigm. This paper proposes an approach to deal with datasets stored across a network of multiple learning agents without any fusion center. Specifically, we formulate the centralized learning problem as an equivalent form with the decomposition of subproblems coupled in a network and a consensus restriction. Then, a cooperative configuration scheme is proposed for randomly assigning the input weights and bias. Finally, based on the well-known parallel alternating direction method of multipliers (ADMM), the output weights are evaluated iteratively. Simulation studies with comparisons on three benchmark datasets are carried out. The experimental results indicate that our proposed learning scheme performs well and outperforms distributed RVFL networks.}
}
@article{BELDICEANU2021641,
title = {ASSISTANT: Learning and Robust Decision Support System for Agile Manufacturing Environments},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {641-646},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.074},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321008041},
author = {Nicolas Beldiceanu and Alexandre Dolgui and Clemens Gonnermann and Gabriel Gonzalez-Castañé and Niki Kousi and Bart Meyers and Julien Prud’homme and Simon Thevenin and Eduardo Vyhmeister and Per-Olov Östberg},
keywords = {Artificial intelligence, Data analytics, Digital twins, Decision aid, Reconfigurable manufacturing systems, Process, production planning, Scheduling, real-time control},
abstract = {The European project ASSISTANT will provide a set of AI-based digital twins that helps process engineers and production planners to operate collaborative mixed-model assembly lines based on the data collected from IoT devices and external data sources. Such a tool will help planners to design the assembly line, plan the production, operate the line, and improve process tuning. In addition, the system monitors the line in real-time, ensures that all required resources are available, and allows fast re-planning when necessary. ASSISTANT aims to make cost-effective decisions while ensuring product quality, safety and wellbeing of the workers, and managing the various sources of uncertainties. The resulting digital twin systems will be data-driven, agile, autonomous, collaborative and explainable, safe but reactive.}
}